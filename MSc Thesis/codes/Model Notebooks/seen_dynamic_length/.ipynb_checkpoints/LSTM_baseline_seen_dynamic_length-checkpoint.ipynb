{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JYsWwiwnPzi",
    "outputId": "a86d2bc8-9d8b-4e22-ec04-38f8153ba9ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 14 08:26:02 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   32C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdNIB899nhlq",
    "outputId": "ded1f6e3-6256-4b87-e743-ae6f051be370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#mounting google drive on colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfSazzTdnmaM"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXN_d9Evntel"
   },
   "outputs": [],
   "source": [
    "X_train=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_X_trainv7_exp1_exp5_strat.npy\")\n",
    "y_train=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_y_trainv7_exp1_exp5_strat.npy\").astype(int)\n",
    "\n",
    "X_test=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_X_testv7_exp1_exp5_strat.npy\")\n",
    "y_test=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_y_testv7_exp1_exp5_strat.npy\").astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SoFH--QG3kWr"
   },
   "outputs": [],
   "source": [
    "def custom_scaler(X, range=(0, 1),min=None,max=None):\n",
    "    mi, ma = range\n",
    "    if(min==None):\n",
    "      min=X.min()\n",
    "      max=X.max()\n",
    "      print(\"\\nTrain_Scaling:- min=\",min,\" max=\",max)\n",
    "    X_std = (X - min) / (max - min)\n",
    "    X_scaled = X_std * (ma - mi) + mi\n",
    "    return min,max,X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JceKGdin-e6",
    "outputId": "96e7635d-bdc3-47cf-cfbe-c0a960b66e97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train_Scaling:- min= -28.708703327621013  max= 37.07106781186548\n",
      "\n",
      "Train_Scaling:- min= -33.71032582929608  max= 32.1558468622422\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "#X_train contains 8 signals x1,x2,y1,y2,x1d,2d,y1d,y2d\n",
    "X_train_scaled=copy.copy(X_train)\n",
    "X_test_scaled=copy.copy(X_test)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,0:2]=custom_scaler(X_train_scaled[:,:,0:2],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,0:2]=custom_scaler(X_test_scaled[:,:,0:2],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,2:4]=custom_scaler(X_train_scaled[:,:,2:4],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,2:4]=custom_scaler(X_test_scaled[:,:,2:4],range=(0,1),min=min_temp,max=max_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPw-_16T3sH3",
    "outputId": "70791131-0a46-4b0f-afd7-57523aac1c55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21346, 50, 4)\n",
      "(2851, 50, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8CMIO_ToBr9"
   },
   "outputs": [],
   "source": [
    "# Part 2 - Building the RNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Initialising the RNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "classifier.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train_scaled.shape[1], X_train_scaled.shape[2])))\n",
    "#regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "classifier.add(LSTM(units = 50))\n",
    "#regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1,activation='sigmoid'))\n",
    "\n",
    "# Compiling the RNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uf-jNI2KZJUu"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\",\n",
    "                             monitor=\"val_accuracy\",\n",
    "                             mode=\"max\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', # value being monitored for improvement\n",
    "                          min_delta = 0, #Abs value and is the min change required before we stop\n",
    "                          patience = 20, #Number of epochs we wait before stopping \n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True) #keeps the best weigths once stopped\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop,checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcUvZBOYoFNC",
    "outputId": "61376294-5747-4d25-d58e-f70615699d44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.5367 - accuracy: 0.7242\n",
      "Epoch 1: val_accuracy improved from -inf to 0.77727, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 11s 11ms/step - loss: 0.5352 - accuracy: 0.7252 - val_loss: 0.4419 - val_accuracy: 0.7773\n",
      "Epoch 2/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.3962 - accuracy: 0.7989\n",
      "Epoch 2: val_accuracy improved from 0.77727 to 0.79797, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3962 - accuracy: 0.7989 - val_loss: 0.3906 - val_accuracy: 0.7980\n",
      "Epoch 3/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.3791 - accuracy: 0.8150\n",
      "Epoch 3: val_accuracy improved from 0.79797 to 0.82357, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3793 - accuracy: 0.8148 - val_loss: 0.3662 - val_accuracy: 0.8236\n",
      "Epoch 4/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.8105\n",
      "Epoch 4: val_accuracy did not improve from 0.82357\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3820 - accuracy: 0.8104 - val_loss: 0.3745 - val_accuracy: 0.8120\n",
      "Epoch 5/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.3737 - accuracy: 0.8166\n",
      "Epoch 5: val_accuracy improved from 0.82357 to 0.82918, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3739 - accuracy: 0.8167 - val_loss: 0.3586 - val_accuracy: 0.8292\n",
      "Epoch 6/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.3626 - accuracy: 0.8249\n",
      "Epoch 6: val_accuracy did not improve from 0.82918\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3629 - accuracy: 0.8247 - val_loss: 0.3657 - val_accuracy: 0.8130\n",
      "Epoch 7/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.3627 - accuracy: 0.8268\n",
      "Epoch 7: val_accuracy did not improve from 0.82918\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3629 - accuracy: 0.8267 - val_loss: 0.3601 - val_accuracy: 0.8253\n",
      "Epoch 8/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.3519 - accuracy: 0.8328\n",
      "Epoch 8: val_accuracy improved from 0.82918 to 0.83935, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.3518 - accuracy: 0.8328 - val_loss: 0.3411 - val_accuracy: 0.8394\n",
      "Epoch 9/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.3463 - accuracy: 0.8372\n",
      "Epoch 9: val_accuracy did not improve from 0.83935\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3465 - accuracy: 0.8373 - val_loss: 0.3500 - val_accuracy: 0.8229\n",
      "Epoch 10/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.3337 - accuracy: 0.8427\n",
      "Epoch 10: val_accuracy did not improve from 0.83935\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3336 - accuracy: 0.8430 - val_loss: 0.4101 - val_accuracy: 0.7724\n",
      "Epoch 11/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.3330 - accuracy: 0.8426\n",
      "Epoch 11: val_accuracy improved from 0.83935 to 0.84146, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.3328 - accuracy: 0.8427 - val_loss: 0.3359 - val_accuracy: 0.8415\n",
      "Epoch 12/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.3190 - accuracy: 0.8513\n",
      "Epoch 12: val_accuracy improved from 0.84146 to 0.84321, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3192 - accuracy: 0.8511 - val_loss: 0.3185 - val_accuracy: 0.8432\n",
      "Epoch 13/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.3177 - accuracy: 0.8540\n",
      "Epoch 13: val_accuracy did not improve from 0.84321\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3177 - accuracy: 0.8540 - val_loss: 0.3378 - val_accuracy: 0.8341\n",
      "Epoch 14/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.3126 - accuracy: 0.8541\n",
      "Epoch 14: val_accuracy did not improve from 0.84321\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3126 - accuracy: 0.8541 - val_loss: 0.3504 - val_accuracy: 0.8380\n",
      "Epoch 15/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.3113 - accuracy: 0.8540\n",
      "Epoch 15: val_accuracy did not improve from 0.84321\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3113 - accuracy: 0.8540 - val_loss: 0.3868 - val_accuracy: 0.8008\n",
      "Epoch 16/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.3182 - accuracy: 0.8510\n",
      "Epoch 16: val_accuracy did not improve from 0.84321\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3182 - accuracy: 0.8509 - val_loss: 0.3164 - val_accuracy: 0.8432\n",
      "Epoch 17/200\n",
      "327/334 [============================>.] - ETA: 0s - loss: 0.3096 - accuracy: 0.8571\n",
      "Epoch 17: val_accuracy did not improve from 0.84321\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3100 - accuracy: 0.8572 - val_loss: 0.3176 - val_accuracy: 0.8411\n",
      "Epoch 18/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.3046 - accuracy: 0.8591\n",
      "Epoch 18: val_accuracy improved from 0.84321 to 0.86531, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.3038 - accuracy: 0.8595 - val_loss: 0.2973 - val_accuracy: 0.8653\n",
      "Epoch 19/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.2898 - accuracy: 0.8677\n",
      "Epoch 19: val_accuracy improved from 0.86531 to 0.87443, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2898 - accuracy: 0.8677 - val_loss: 0.2806 - val_accuracy: 0.8744\n",
      "Epoch 20/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.2861 - accuracy: 0.8686\n",
      "Epoch 20: val_accuracy improved from 0.87443 to 0.87513, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2863 - accuracy: 0.8686 - val_loss: 0.2746 - val_accuracy: 0.8751\n",
      "Epoch 21/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.2798 - accuracy: 0.8730\n",
      "Epoch 21: val_accuracy did not improve from 0.87513\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2802 - accuracy: 0.8728 - val_loss: 0.3342 - val_accuracy: 0.8429\n",
      "Epoch 22/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.2704 - accuracy: 0.8757\n",
      "Epoch 22: val_accuracy did not improve from 0.87513\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2701 - accuracy: 0.8758 - val_loss: 0.2824 - val_accuracy: 0.8674\n",
      "Epoch 23/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2651 - accuracy: 0.8795\n",
      "Epoch 23: val_accuracy did not improve from 0.87513\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2651 - accuracy: 0.8795 - val_loss: 0.3084 - val_accuracy: 0.8527\n",
      "Epoch 24/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2593 - accuracy: 0.8817\n",
      "Epoch 24: val_accuracy improved from 0.87513 to 0.88811, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2593 - accuracy: 0.8817 - val_loss: 0.2560 - val_accuracy: 0.8881\n",
      "Epoch 25/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.2575 - accuracy: 0.8851\n",
      "Epoch 25: val_accuracy did not improve from 0.88811\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2574 - accuracy: 0.8853 - val_loss: 0.2533 - val_accuracy: 0.8850\n",
      "Epoch 26/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.2568 - accuracy: 0.8847\n",
      "Epoch 26: val_accuracy did not improve from 0.88811\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2577 - accuracy: 0.8841 - val_loss: 0.4204 - val_accuracy: 0.8106\n",
      "Epoch 27/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2859 - accuracy: 0.8678\n",
      "Epoch 27: val_accuracy did not improve from 0.88811\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2859 - accuracy: 0.8678 - val_loss: 0.3265 - val_accuracy: 0.8432\n",
      "Epoch 28/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.2574 - accuracy: 0.8846\n",
      "Epoch 28: val_accuracy did not improve from 0.88811\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2573 - accuracy: 0.8845 - val_loss: 0.2639 - val_accuracy: 0.8811\n",
      "Epoch 29/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.2499 - accuracy: 0.8885\n",
      "Epoch 29: val_accuracy did not improve from 0.88811\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2500 - accuracy: 0.8885 - val_loss: 0.2733 - val_accuracy: 0.8755\n",
      "Epoch 30/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.2429 - accuracy: 0.8923\n",
      "Epoch 30: val_accuracy did not improve from 0.88811\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2430 - accuracy: 0.8923 - val_loss: 0.2938 - val_accuracy: 0.8622\n",
      "Epoch 31/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.2336 - accuracy: 0.8988\n",
      "Epoch 31: val_accuracy improved from 0.88811 to 0.89021, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2335 - accuracy: 0.8988 - val_loss: 0.2444 - val_accuracy: 0.8902\n",
      "Epoch 32/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.2363 - accuracy: 0.8957\n",
      "Epoch 32: val_accuracy did not improve from 0.89021\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2363 - accuracy: 0.8957 - val_loss: 0.2571 - val_accuracy: 0.8881\n",
      "Epoch 33/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2436 - accuracy: 0.8913\n",
      "Epoch 33: val_accuracy did not improve from 0.89021\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2436 - accuracy: 0.8913 - val_loss: 0.2417 - val_accuracy: 0.8857\n",
      "Epoch 34/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.2208 - accuracy: 0.9030\n",
      "Epoch 34: val_accuracy did not improve from 0.89021\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2214 - accuracy: 0.9027 - val_loss: 0.2352 - val_accuracy: 0.8885\n",
      "Epoch 35/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.2345 - accuracy: 0.8979\n",
      "Epoch 35: val_accuracy did not improve from 0.89021\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2342 - accuracy: 0.8980 - val_loss: 0.2494 - val_accuracy: 0.8874\n",
      "Epoch 36/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.2158 - accuracy: 0.9067\n",
      "Epoch 36: val_accuracy improved from 0.89021 to 0.89092, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2158 - accuracy: 0.9067 - val_loss: 0.2486 - val_accuracy: 0.8909\n",
      "Epoch 37/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.2148 - accuracy: 0.9061\n",
      "Epoch 37: val_accuracy improved from 0.89092 to 0.90810, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2144 - accuracy: 0.9061 - val_loss: 0.2056 - val_accuracy: 0.9081\n",
      "Epoch 38/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.2157 - accuracy: 0.9066\n",
      "Epoch 38: val_accuracy did not improve from 0.90810\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2154 - accuracy: 0.9067 - val_loss: 0.2541 - val_accuracy: 0.8839\n",
      "Epoch 39/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.2029 - accuracy: 0.9117\n",
      "Epoch 39: val_accuracy improved from 0.90810 to 0.91477, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2025 - accuracy: 0.9122 - val_loss: 0.1998 - val_accuracy: 0.9148\n",
      "Epoch 40/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1971 - accuracy: 0.9156\n",
      "Epoch 40: val_accuracy improved from 0.91477 to 0.92073, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1973 - accuracy: 0.9156 - val_loss: 0.1902 - val_accuracy: 0.9207\n",
      "Epoch 41/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1994 - accuracy: 0.9130\n",
      "Epoch 41: val_accuracy did not improve from 0.92073\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1999 - accuracy: 0.9127 - val_loss: 0.2142 - val_accuracy: 0.9109\n",
      "Epoch 42/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.2010 - accuracy: 0.9132\n",
      "Epoch 42: val_accuracy did not improve from 0.92073\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2005 - accuracy: 0.9133 - val_loss: 0.1922 - val_accuracy: 0.9155\n",
      "Epoch 43/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.1891 - accuracy: 0.9173\n",
      "Epoch 43: val_accuracy did not improve from 0.92073\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1883 - accuracy: 0.9175 - val_loss: 0.1927 - val_accuracy: 0.9169\n",
      "Epoch 44/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1824 - accuracy: 0.9211\n",
      "Epoch 44: val_accuracy improved from 0.92073 to 0.92178, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1822 - accuracy: 0.9212 - val_loss: 0.1777 - val_accuracy: 0.9218\n",
      "Epoch 45/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1730 - accuracy: 0.9252\n",
      "Epoch 45: val_accuracy did not improve from 0.92178\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1729 - accuracy: 0.9252 - val_loss: 0.1962 - val_accuracy: 0.9141\n",
      "Epoch 46/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1723 - accuracy: 0.9257\n",
      "Epoch 46: val_accuracy did not improve from 0.92178\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1721 - accuracy: 0.9259 - val_loss: 0.2522 - val_accuracy: 0.8874\n",
      "Epoch 47/200\n",
      "327/334 [============================>.] - ETA: 0s - loss: 0.1639 - accuracy: 0.9302\n",
      "Epoch 47: val_accuracy did not improve from 0.92178\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1657 - accuracy: 0.9296 - val_loss: 0.2149 - val_accuracy: 0.9014\n",
      "Epoch 48/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.1767 - accuracy: 0.9255\n",
      "Epoch 48: val_accuracy did not improve from 0.92178\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1760 - accuracy: 0.9258 - val_loss: 0.1863 - val_accuracy: 0.9186\n",
      "Epoch 49/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1754 - accuracy: 0.9255\n",
      "Epoch 49: val_accuracy did not improve from 0.92178\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1750 - accuracy: 0.9256 - val_loss: 0.1937 - val_accuracy: 0.9085\n",
      "Epoch 50/200\n",
      "327/334 [============================>.] - ETA: 0s - loss: 0.1603 - accuracy: 0.9336\n",
      "Epoch 50: val_accuracy did not improve from 0.92178\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1601 - accuracy: 0.9335 - val_loss: 0.1816 - val_accuracy: 0.9186\n",
      "Epoch 51/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1531 - accuracy: 0.9342\n",
      "Epoch 51: val_accuracy improved from 0.92178 to 0.93616, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1528 - accuracy: 0.9343 - val_loss: 0.1557 - val_accuracy: 0.9362\n",
      "Epoch 52/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1482 - accuracy: 0.9384\n",
      "Epoch 52: val_accuracy did not improve from 0.93616\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1482 - accuracy: 0.9384 - val_loss: 0.2496 - val_accuracy: 0.8979\n",
      "Epoch 53/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1974 - accuracy: 0.9146\n",
      "Epoch 53: val_accuracy did not improve from 0.93616\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1974 - accuracy: 0.9146 - val_loss: 0.1934 - val_accuracy: 0.9158\n",
      "Epoch 54/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.1455 - accuracy: 0.9405\n",
      "Epoch 54: val_accuracy did not improve from 0.93616\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1454 - accuracy: 0.9405 - val_loss: 0.1622 - val_accuracy: 0.9306\n",
      "Epoch 55/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.1517 - accuracy: 0.9383\n",
      "Epoch 55: val_accuracy did not improve from 0.93616\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1520 - accuracy: 0.9382 - val_loss: 0.1615 - val_accuracy: 0.9320\n",
      "Epoch 56/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1396 - accuracy: 0.9422\n",
      "Epoch 56: val_accuracy did not improve from 0.93616\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1394 - accuracy: 0.9423 - val_loss: 0.1751 - val_accuracy: 0.9260\n",
      "Epoch 57/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1420 - accuracy: 0.9410\n",
      "Epoch 57: val_accuracy did not improve from 0.93616\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1419 - accuracy: 0.9410 - val_loss: 0.1910 - val_accuracy: 0.9267\n",
      "Epoch 58/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1518 - accuracy: 0.9371\n",
      "Epoch 58: val_accuracy did not improve from 0.93616\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1518 - accuracy: 0.9370 - val_loss: 0.2115 - val_accuracy: 0.9060\n",
      "Epoch 59/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.1554 - accuracy: 0.9358\n",
      "Epoch 59: val_accuracy improved from 0.93616 to 0.94248, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1549 - accuracy: 0.9361 - val_loss: 0.1401 - val_accuracy: 0.9425\n",
      "Epoch 60/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.1298 - accuracy: 0.9469\n",
      "Epoch 60: val_accuracy improved from 0.94248 to 0.94984, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1303 - accuracy: 0.9468 - val_loss: 0.1292 - val_accuracy: 0.9498\n",
      "Epoch 61/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1255 - accuracy: 0.9487\n",
      "Epoch 61: val_accuracy did not improve from 0.94984\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1255 - accuracy: 0.9487 - val_loss: 0.1354 - val_accuracy: 0.9435\n",
      "Epoch 62/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.1346 - accuracy: 0.9450\n",
      "Epoch 62: val_accuracy did not improve from 0.94984\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1350 - accuracy: 0.9447 - val_loss: 0.1968 - val_accuracy: 0.9127\n",
      "Epoch 63/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.1294 - accuracy: 0.9483\n",
      "Epoch 63: val_accuracy did not improve from 0.94984\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1286 - accuracy: 0.9487 - val_loss: 0.1527 - val_accuracy: 0.9407\n",
      "Epoch 64/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.1276 - accuracy: 0.9488\n",
      "Epoch 64: val_accuracy did not improve from 0.94984\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1280 - accuracy: 0.9486 - val_loss: 0.1340 - val_accuracy: 0.9435\n",
      "Epoch 65/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.1169 - accuracy: 0.9517\n",
      "Epoch 65: val_accuracy did not improve from 0.94984\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1166 - accuracy: 0.9519 - val_loss: 0.1480 - val_accuracy: 0.9393\n",
      "Epoch 66/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1394 - accuracy: 0.9422\n",
      "Epoch 66: val_accuracy did not improve from 0.94984\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1393 - accuracy: 0.9422 - val_loss: 0.1386 - val_accuracy: 0.9393\n",
      "Epoch 67/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1066 - accuracy: 0.9570\n",
      "Epoch 67: val_accuracy improved from 0.94984 to 0.95931, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1063 - accuracy: 0.9571 - val_loss: 0.1034 - val_accuracy: 0.9593\n",
      "Epoch 68/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1413 - accuracy: 0.9420\n",
      "Epoch 68: val_accuracy did not improve from 0.95931\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1412 - accuracy: 0.9421 - val_loss: 0.1230 - val_accuracy: 0.9558\n",
      "Epoch 69/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1055 - accuracy: 0.9575\n",
      "Epoch 69: val_accuracy did not improve from 0.95931\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1054 - accuracy: 0.9575 - val_loss: 0.1049 - val_accuracy: 0.9593\n",
      "Epoch 70/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1174 - accuracy: 0.9542\n",
      "Epoch 70: val_accuracy did not improve from 0.95931\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1181 - accuracy: 0.9539 - val_loss: 0.1890 - val_accuracy: 0.9204\n",
      "Epoch 71/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1131 - accuracy: 0.9551\n",
      "Epoch 71: val_accuracy did not improve from 0.95931\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1130 - accuracy: 0.9550 - val_loss: 0.1164 - val_accuracy: 0.9548\n",
      "Epoch 72/200\n",
      "327/334 [============================>.] - ETA: 0s - loss: 0.1199 - accuracy: 0.9518\n",
      "Epoch 72: val_accuracy did not improve from 0.95931\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1192 - accuracy: 0.9522 - val_loss: 0.1066 - val_accuracy: 0.9590\n",
      "Epoch 73/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 0.9584\n",
      "Epoch 73: val_accuracy did not improve from 0.95931\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1101 - accuracy: 0.9584 - val_loss: 0.1841 - val_accuracy: 0.9186\n",
      "Epoch 74/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.9543\n",
      "Epoch 74: val_accuracy improved from 0.95931 to 0.96001, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1146 - accuracy: 0.9548 - val_loss: 0.1058 - val_accuracy: 0.9600\n",
      "Epoch 75/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0981 - accuracy: 0.9629\n",
      "Epoch 75: val_accuracy did not improve from 0.96001\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0983 - accuracy: 0.9629 - val_loss: 0.4162 - val_accuracy: 0.8646\n",
      "Epoch 76/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1192 - accuracy: 0.9545\n",
      "Epoch 76: val_accuracy did not improve from 0.96001\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1191 - accuracy: 0.9543 - val_loss: 0.1467 - val_accuracy: 0.9379\n",
      "Epoch 77/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0934 - accuracy: 0.9636\n",
      "Epoch 77: val_accuracy did not improve from 0.96001\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0936 - accuracy: 0.9633 - val_loss: 0.1073 - val_accuracy: 0.9569\n",
      "Epoch 78/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1062 - accuracy: 0.9594\n",
      "Epoch 78: val_accuracy did not improve from 0.96001\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1069 - accuracy: 0.9590 - val_loss: 0.1125 - val_accuracy: 0.9569\n",
      "Epoch 79/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1007 - accuracy: 0.9618\n",
      "Epoch 79: val_accuracy improved from 0.96001 to 0.96352, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1007 - accuracy: 0.9617 - val_loss: 0.0976 - val_accuracy: 0.9635\n",
      "Epoch 80/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1396 - accuracy: 0.9447\n",
      "Epoch 80: val_accuracy did not improve from 0.96352\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1393 - accuracy: 0.9448 - val_loss: 0.1304 - val_accuracy: 0.9530\n",
      "Epoch 81/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.0979 - accuracy: 0.9620\n",
      "Epoch 81: val_accuracy did not improve from 0.96352\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0979 - accuracy: 0.9620 - val_loss: 0.1399 - val_accuracy: 0.9488\n",
      "Epoch 82/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0963 - accuracy: 0.9625\n",
      "Epoch 82: val_accuracy did not improve from 0.96352\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0967 - accuracy: 0.9625 - val_loss: 0.1050 - val_accuracy: 0.9597\n",
      "Epoch 83/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.0874 - accuracy: 0.9668\n",
      "Epoch 83: val_accuracy did not improve from 0.96352\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0874 - accuracy: 0.9667 - val_loss: 0.1186 - val_accuracy: 0.9548\n",
      "Epoch 84/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1030 - accuracy: 0.9591\n",
      "Epoch 84: val_accuracy did not improve from 0.96352\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1036 - accuracy: 0.9589 - val_loss: 0.1146 - val_accuracy: 0.9583\n",
      "Epoch 85/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.9650\n",
      "Epoch 85: val_accuracy did not improve from 0.96352\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0910 - accuracy: 0.9650 - val_loss: 0.1019 - val_accuracy: 0.9590\n",
      "Epoch 86/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1000 - accuracy: 0.9615\n",
      "Epoch 86: val_accuracy did not improve from 0.96352\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1000 - accuracy: 0.9615 - val_loss: 0.1137 - val_accuracy: 0.9555\n",
      "Epoch 87/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1269 - accuracy: 0.9483\n",
      "Epoch 87: val_accuracy improved from 0.96352 to 0.96633, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1267 - accuracy: 0.9485 - val_loss: 0.0970 - val_accuracy: 0.9663\n",
      "Epoch 88/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0843 - accuracy: 0.9674\n",
      "Epoch 88: val_accuracy did not improve from 0.96633\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0843 - accuracy: 0.9674 - val_loss: 0.1930 - val_accuracy: 0.9267\n",
      "Epoch 89/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1025 - accuracy: 0.9602\n",
      "Epoch 89: val_accuracy did not improve from 0.96633\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1024 - accuracy: 0.9602 - val_loss: 0.0920 - val_accuracy: 0.9621\n",
      "Epoch 90/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0930 - accuracy: 0.9642\n",
      "Epoch 90: val_accuracy did not improve from 0.96633\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0926 - accuracy: 0.9644 - val_loss: 0.1105 - val_accuracy: 0.9562\n",
      "Epoch 91/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0861 - accuracy: 0.9667\n",
      "Epoch 91: val_accuracy did not improve from 0.96633\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0864 - accuracy: 0.9667 - val_loss: 0.1520 - val_accuracy: 0.9467\n",
      "Epoch 92/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.0781 - accuracy: 0.9701\n",
      "Epoch 92: val_accuracy did not improve from 0.96633\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0780 - accuracy: 0.9701 - val_loss: 0.1230 - val_accuracy: 0.9526\n",
      "Epoch 93/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9485\n",
      "Epoch 93: val_accuracy did not improve from 0.96633\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1303 - accuracy: 0.9485 - val_loss: 0.0958 - val_accuracy: 0.9628\n",
      "Epoch 94/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0847 - accuracy: 0.9682\n",
      "Epoch 94: val_accuracy improved from 0.96633 to 0.97089, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0844 - accuracy: 0.9683 - val_loss: 0.0784 - val_accuracy: 0.9709\n",
      "Epoch 95/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0766 - accuracy: 0.9713\n",
      "Epoch 95: val_accuracy did not improve from 0.97089\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0769 - accuracy: 0.9712 - val_loss: 0.1077 - val_accuracy: 0.9583\n",
      "Epoch 96/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.0939 - accuracy: 0.9651\n",
      "Epoch 96: val_accuracy did not improve from 0.97089\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0932 - accuracy: 0.9654 - val_loss: 0.0790 - val_accuracy: 0.9670\n",
      "Epoch 97/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9709\n",
      "Epoch 97: val_accuracy did not improve from 0.97089\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0751 - accuracy: 0.9709 - val_loss: 0.0987 - val_accuracy: 0.9618\n",
      "Epoch 98/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.0847 - accuracy: 0.9679\n",
      "Epoch 98: val_accuracy did not improve from 0.97089\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0844 - accuracy: 0.9681 - val_loss: 0.0957 - val_accuracy: 0.9597\n",
      "Epoch 99/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0824 - accuracy: 0.9692\n",
      "Epoch 99: val_accuracy did not improve from 0.97089\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0820 - accuracy: 0.9693 - val_loss: 0.0823 - val_accuracy: 0.9691\n",
      "Epoch 100/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.0738 - accuracy: 0.9718\n",
      "Epoch 100: val_accuracy did not improve from 0.97089\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0739 - accuracy: 0.9718 - val_loss: 0.0872 - val_accuracy: 0.9695\n",
      "Epoch 101/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.0937 - accuracy: 0.9623\n",
      "Epoch 101: val_accuracy did not improve from 0.97089\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0940 - accuracy: 0.9621 - val_loss: 0.1358 - val_accuracy: 0.9481\n",
      "Epoch 102/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0854 - accuracy: 0.9672\n",
      "Epoch 102: val_accuracy did not improve from 0.97089\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0848 - accuracy: 0.9675 - val_loss: 0.0890 - val_accuracy: 0.9656\n",
      "Epoch 103/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.0752 - accuracy: 0.9710\n",
      "Epoch 103: val_accuracy did not improve from 0.97089\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0751 - accuracy: 0.9710 - val_loss: 0.1106 - val_accuracy: 0.9642\n",
      "Epoch 104/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0662 - accuracy: 0.9754\n",
      "Epoch 104: val_accuracy improved from 0.97089 to 0.97229, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0663 - accuracy: 0.9754 - val_loss: 0.0798 - val_accuracy: 0.9723\n",
      "Epoch 105/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.0752 - accuracy: 0.9717\n",
      "Epoch 105: val_accuracy improved from 0.97229 to 0.97264, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0751 - accuracy: 0.9717 - val_loss: 0.0744 - val_accuracy: 0.9726\n",
      "Epoch 106/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.1246 - accuracy: 0.9512\n",
      "Epoch 106: val_accuracy did not improve from 0.97264\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1233 - accuracy: 0.9517 - val_loss: 0.0996 - val_accuracy: 0.9653\n",
      "Epoch 107/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.0692 - accuracy: 0.9744\n",
      "Epoch 107: val_accuracy did not improve from 0.97264\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0691 - accuracy: 0.9744 - val_loss: 0.0827 - val_accuracy: 0.9702\n",
      "Epoch 108/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.9741\n",
      "Epoch 108: val_accuracy did not improve from 0.97264\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0684 - accuracy: 0.9741 - val_loss: 0.1081 - val_accuracy: 0.9621\n",
      "Epoch 109/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.9702\n",
      "Epoch 109: val_accuracy did not improve from 0.97264\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0803 - accuracy: 0.9702 - val_loss: 0.3549 - val_accuracy: 0.8727\n",
      "Epoch 110/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.0679 - accuracy: 0.9751\n",
      "Epoch 110: val_accuracy did not improve from 0.97264\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0676 - accuracy: 0.9752 - val_loss: 0.1159 - val_accuracy: 0.9572\n",
      "Epoch 111/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.0710 - accuracy: 0.9741\n",
      "Epoch 111: val_accuracy did not improve from 0.97264\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0710 - accuracy: 0.9741 - val_loss: 0.1462 - val_accuracy: 0.9428\n",
      "Epoch 112/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0657 - accuracy: 0.9749\n",
      "Epoch 112: val_accuracy did not improve from 0.97264\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0654 - accuracy: 0.9751 - val_loss: 0.0822 - val_accuracy: 0.9702\n",
      "Epoch 113/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1723 - accuracy: 0.9279\n",
      "Epoch 113: val_accuracy did not improve from 0.97264\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1716 - accuracy: 0.9282 - val_loss: 0.1901 - val_accuracy: 0.9228\n",
      "Epoch 114/200\n",
      "327/334 [============================>.] - ETA: 0s - loss: 0.1143 - accuracy: 0.9539\n",
      "Epoch 114: val_accuracy did not improve from 0.97264\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1133 - accuracy: 0.9544 - val_loss: 0.1233 - val_accuracy: 0.9523\n",
      "Epoch 115/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.0818 - accuracy: 0.9685\n",
      "Epoch 115: val_accuracy did not improve from 0.97264\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0820 - accuracy: 0.9686 - val_loss: 0.1154 - val_accuracy: 0.9551\n",
      "Epoch 116/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.0906 - accuracy: 0.9651\n",
      "Epoch 116: val_accuracy improved from 0.97264 to 0.97475, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0905 - accuracy: 0.9652 - val_loss: 0.0772 - val_accuracy: 0.9747\n",
      "Epoch 117/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.0728 - accuracy: 0.9719\n",
      "Epoch 117: val_accuracy did not improve from 0.97475\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0744 - accuracy: 0.9710 - val_loss: 0.1648 - val_accuracy: 0.9334\n",
      "Epoch 118/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.0898 - accuracy: 0.9649\n",
      "Epoch 118: val_accuracy did not improve from 0.97475\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0897 - accuracy: 0.9649 - val_loss: 0.0946 - val_accuracy: 0.9681\n",
      "Epoch 119/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0626 - accuracy: 0.9770\n",
      "Epoch 119: val_accuracy did not improve from 0.97475\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0625 - accuracy: 0.9771 - val_loss: 0.0928 - val_accuracy: 0.9667\n",
      "Epoch 120/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.0826 - accuracy: 0.9685\n",
      "Epoch 120: val_accuracy did not improve from 0.97475\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0821 - accuracy: 0.9687 - val_loss: 0.0809 - val_accuracy: 0.9719\n",
      "Epoch 121/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0647 - accuracy: 0.9755\n",
      "Epoch 121: val_accuracy did not improve from 0.97475\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0652 - accuracy: 0.9753 - val_loss: 0.0887 - val_accuracy: 0.9681\n",
      "Epoch 122/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0540 - accuracy: 0.9790\n",
      "Epoch 122: val_accuracy did not improve from 0.97475\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0544 - accuracy: 0.9788 - val_loss: 0.1020 - val_accuracy: 0.9600\n",
      "Epoch 123/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1312 - accuracy: 0.9466\n",
      "Epoch 123: val_accuracy did not improve from 0.97475\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1306 - accuracy: 0.9468 - val_loss: 0.1519 - val_accuracy: 0.9446\n",
      "Epoch 124/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.0762 - accuracy: 0.9712\n",
      "Epoch 124: val_accuracy did not improve from 0.97475\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0766 - accuracy: 0.9710 - val_loss: 0.1241 - val_accuracy: 0.9523\n",
      "Epoch 125/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.0610 - accuracy: 0.9763\n",
      "Epoch 125: val_accuracy did not improve from 0.97475\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0613 - accuracy: 0.9761 - val_loss: 0.0997 - val_accuracy: 0.9642\n",
      "Epoch 126/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.9762\n",
      "Epoch 126: val_accuracy did not improve from 0.97475\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0650 - accuracy: 0.9762 - val_loss: 0.0801 - val_accuracy: 0.9730\n",
      "Epoch 127/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.0779 - accuracy: 0.9711\n",
      "Epoch 127: val_accuracy did not improve from 0.97475\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0775 - accuracy: 0.9713 - val_loss: 0.0894 - val_accuracy: 0.9677\n",
      "Epoch 128/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.0628 - accuracy: 0.9771\n",
      "Epoch 128: val_accuracy did not improve from 0.97475\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0631 - accuracy: 0.9771 - val_loss: 0.3290 - val_accuracy: 0.8832\n",
      "Epoch 129/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.0682 - accuracy: 0.9747\n",
      "Epoch 129: val_accuracy did not improve from 0.97475\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0678 - accuracy: 0.9748 - val_loss: 0.0794 - val_accuracy: 0.9702\n",
      "Epoch 130/200\n",
      "327/334 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.9839\n",
      "Epoch 130: val_accuracy did not improve from 0.97475\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0444 - accuracy: 0.9840 - val_loss: 0.0874 - val_accuracy: 0.9691\n",
      "Epoch 131/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.0805 - accuracy: 0.9711\n",
      "Epoch 131: val_accuracy improved from 0.97475 to 0.97510, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0801 - accuracy: 0.9712 - val_loss: 0.0797 - val_accuracy: 0.9751\n",
      "Epoch 132/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0649 - accuracy: 0.9757\n",
      "Epoch 132: val_accuracy did not improve from 0.97510\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0651 - accuracy: 0.9756 - val_loss: 0.0863 - val_accuracy: 0.9695\n",
      "Epoch 133/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 0.9787\n",
      "Epoch 133: val_accuracy did not improve from 0.97510\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0591 - accuracy: 0.9786 - val_loss: 0.1634 - val_accuracy: 0.9449\n",
      "Epoch 134/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.0698 - accuracy: 0.9737\n",
      "Epoch 134: val_accuracy did not improve from 0.97510\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0692 - accuracy: 0.9739 - val_loss: 0.1037 - val_accuracy: 0.9618\n",
      "Epoch 135/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 0.9825\n",
      "Epoch 135: val_accuracy did not improve from 0.97510\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0472 - accuracy: 0.9826 - val_loss: 0.0817 - val_accuracy: 0.9705\n",
      "Epoch 136/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0630 - accuracy: 0.9785\n",
      "Epoch 136: val_accuracy did not improve from 0.97510\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0625 - accuracy: 0.9787 - val_loss: 0.0935 - val_accuracy: 0.9677\n",
      "Epoch 137/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.0728 - accuracy: 0.9719\n",
      "Epoch 137: val_accuracy did not improve from 0.97510\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0723 - accuracy: 0.9723 - val_loss: 0.0909 - val_accuracy: 0.9681\n",
      "Epoch 138/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.0487 - accuracy: 0.9819\n",
      "Epoch 138: val_accuracy did not improve from 0.97510\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0486 - accuracy: 0.9820 - val_loss: 0.0875 - val_accuracy: 0.9716\n",
      "Epoch 139/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.0549 - accuracy: 0.9810\n",
      "Epoch 139: val_accuracy improved from 0.97510 to 0.97545, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0549 - accuracy: 0.9811 - val_loss: 0.0732 - val_accuracy: 0.9754\n",
      "Epoch 140/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9814\n",
      "Epoch 140: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0494 - accuracy: 0.9814 - val_loss: 0.0754 - val_accuracy: 0.9726\n",
      "Epoch 141/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0512 - accuracy: 0.9813\n",
      "Epoch 141: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0514 - accuracy: 0.9812 - val_loss: 0.1232 - val_accuracy: 0.9586\n",
      "Epoch 142/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0661 - accuracy: 0.9758\n",
      "Epoch 142: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0682 - accuracy: 0.9748 - val_loss: 0.4273 - val_accuracy: 0.8418\n",
      "Epoch 143/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1559 - accuracy: 0.9347\n",
      "Epoch 143: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1551 - accuracy: 0.9352 - val_loss: 0.1219 - val_accuracy: 0.9544\n",
      "Epoch 144/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0778 - accuracy: 0.9706\n",
      "Epoch 144: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0777 - accuracy: 0.9707 - val_loss: 0.0967 - val_accuracy: 0.9642\n",
      "Epoch 145/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9802\n",
      "Epoch 145: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0518 - accuracy: 0.9802 - val_loss: 0.0797 - val_accuracy: 0.9744\n",
      "Epoch 146/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.0434 - accuracy: 0.9850\n",
      "Epoch 146: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0434 - accuracy: 0.9850 - val_loss: 0.0895 - val_accuracy: 0.9730\n",
      "Epoch 147/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1258 - accuracy: 0.9504\n",
      "Epoch 147: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1258 - accuracy: 0.9504 - val_loss: 0.1394 - val_accuracy: 0.9449\n",
      "Epoch 148/200\n",
      "327/334 [============================>.] - ETA: 0s - loss: 0.0676 - accuracy: 0.9740\n",
      "Epoch 148: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0673 - accuracy: 0.9741 - val_loss: 0.0872 - val_accuracy: 0.9684\n",
      "Epoch 149/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.0798 - accuracy: 0.9714\n",
      "Epoch 149: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0797 - accuracy: 0.9713 - val_loss: 0.1131 - val_accuracy: 0.9579\n",
      "Epoch 150/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0403 - accuracy: 0.9862\n",
      "Epoch 150: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0406 - accuracy: 0.9861 - val_loss: 0.0964 - val_accuracy: 0.9688\n",
      "Epoch 151/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.0579 - accuracy: 0.9792\n",
      "Epoch 151: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0578 - accuracy: 0.9792 - val_loss: 0.1435 - val_accuracy: 0.9460\n",
      "Epoch 152/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.9752\n",
      "Epoch 152: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0682 - accuracy: 0.9752 - val_loss: 0.0843 - val_accuracy: 0.9712\n",
      "Epoch 153/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0646 - accuracy: 0.9755\n",
      "Epoch 153: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0644 - accuracy: 0.9757 - val_loss: 0.0915 - val_accuracy: 0.9684\n",
      "Epoch 154/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.0641 - accuracy: 0.9771\n",
      "Epoch 154: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0637 - accuracy: 0.9773 - val_loss: 0.0778 - val_accuracy: 0.9698\n",
      "Epoch 155/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.0522 - accuracy: 0.9819\n",
      "Epoch 155: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0522 - accuracy: 0.9820 - val_loss: 0.1076 - val_accuracy: 0.9614\n",
      "Epoch 156/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0461 - accuracy: 0.9842\n",
      "Epoch 156: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0458 - accuracy: 0.9843 - val_loss: 0.0745 - val_accuracy: 0.9747\n",
      "Epoch 157/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9838\n",
      "Epoch 157: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0458 - accuracy: 0.9838 - val_loss: 0.5302 - val_accuracy: 0.8204\n",
      "Epoch 158/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1262 - accuracy: 0.9512\n",
      "Epoch 158: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1262 - accuracy: 0.9512 - val_loss: 0.1086 - val_accuracy: 0.9586\n",
      "Epoch 159/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0476 - accuracy: 0.9839Restoring model weights from the end of the best epoch: 139.\n",
      "\n",
      "Epoch 159: val_accuracy did not improve from 0.97545\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0503 - accuracy: 0.9828 - val_loss: 0.4672 - val_accuracy: 0.8309\n",
      "Epoch 159: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "history=classifier.fit(X_train_scaled, y_train[:,0], epochs = 200, batch_size = 64,validation_data=(X_test_scaled,y_test[:,0]),callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7puZMrQ6rZ8B",
    "outputId": "c68124ac-a31b-4f17-b479-8557352e1c3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 4ms/step - loss: 0.0732 - accuracy: 0.9754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07324966043233871, 0.9754472374916077]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(X_test_scaled,y_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "pXaIqqGvsq2-",
    "outputId": "241e2f39-b00a-439f-90ff-ae2cffb22e65"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def display_learning_curves(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    ax1.plot(history.history[\"loss\"])\n",
    "    ax1.plot(history.history[\"val_loss\"])\n",
    "    ax1.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "    ax2.plot(history.history[\"accuracy\"])\n",
    "    ax2.plot(history.history[\"val_accuracy\"])\n",
    "    ax2.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "display_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzJ3rz1JZlM7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0VKJswYTc4O"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "temp=tf.keras.models.load_model(\"./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_baseline_exp1_exp5_strat_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9bgdUJETn0g",
    "outputId": "e43f0116-15a9-4147-d938-5e23c4a87b35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2851/2851 [==============================] - 9s 3ms/step - loss: 0.0732 - accuracy: 0.9754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07324938476085663, 0.9754472374916077]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.evaluate(X_test_scaled, y_test[:,0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RD4YF1AuT2tn"
   },
   "outputs": [],
   "source": [
    "y_pred = temp.predict(X_test_scaled)\n",
    "y_pred= (y_pred>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjx-DjHUWp52",
    "outputId": "eb1fa524-d382-4506-a70a-8f8fba427180"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ipevqB9rXDeW"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rSeo2ltUXffg",
    "outputId": "15433a42-eb9e-4bb6-f7eb-022e98c0d03a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1993,   38],\n",
       "       [  32,  788]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eM1TBa2IXtj2",
    "outputId": "95dc8e9f-6f0b-401e-d93e-d5aaa472869a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9754472115047352"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9V2DcARYNq6",
    "outputId": "e6c1b8bd-d498-4b02-c883-f3ed546b21d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9574726609963548"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwAjeUnMYQ1O",
    "outputId": "703e61e4-f1fb-4d59-d009-e10c8cc7f49a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2031\n",
      "           1       0.95      0.96      0.96       820\n",
      "\n",
      "    accuracy                           0.98      2851\n",
      "   macro avg       0.97      0.97      0.97      2851\n",
      "weighted avg       0.98      0.98      0.98      2851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test[:,0],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xA7V29U2Gg8f"
   },
   "outputs": [],
   "source": [
    "f1_score=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "17bd55d11dfc4e1e8cf951035a87b051",
      "fdd65fcdb24b4b4abfa75d106c35a25a",
      "7f31a8d7abb9466d87c300efe71e33cf",
      "a1a8492fe46b434f85ae75c46cf3610e",
      "5518ed50327b43df9322057dfcd408ce",
      "8f9bdcf769454cd3adbac838523fb84b",
      "dd0debb5fd8043c195076e62deeef43b",
      "79741ebc40764fbe94751e07ebe9a0de",
      "809c6f839c3a411c8ce78534a319a78a",
      "bcfda5a8a5194640afb5e089b170d1ea",
      "655b452cfbfe4b62888d6c1f00c0271f"
     ]
    },
    "id": "lHU5psTGqgpd",
    "outputId": "675ab812-c9dc-4f8b-f971-47b954037510"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bd55d11dfc4e1e8cf951035a87b051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 9ms/step - loss: 0.5762 - accuracy: 0.7083 - val_loss: 0.4674 - val_accuracy: 0.7131\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4020 - accuracy: 0.7965 - val_loss: 0.4293 - val_accuracy: 0.7780\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3737 - accuracy: 0.8151 - val_loss: 0.3573 - val_accuracy: 0.8271\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3662 - accuracy: 0.8220 - val_loss: 0.3628 - val_accuracy: 0.8218\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 7ms/step - loss: 0.3569 - accuracy: 0.8260 - val_loss: 0.3954 - val_accuracy: 0.8130\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3509 - accuracy: 0.8293 - val_loss: 0.3735 - val_accuracy: 0.8215\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.3536 - accuracy: 0.8321 - val_loss: 0.3381 - val_accuracy: 0.8365\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.3437 - accuracy: 0.8349 - val_loss: 0.3327 - val_accuracy: 0.8436\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3403 - accuracy: 0.8395 - val_loss: 0.3589 - val_accuracy: 0.8278\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3280 - accuracy: 0.8464 - val_loss: 0.3371 - val_accuracy: 0.8443\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.3300 - accuracy: 0.8440 - val_loss: 0.3755 - val_accuracy: 0.8225\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 7ms/step - loss: 0.3281 - accuracy: 0.8448 - val_loss: 0.3338 - val_accuracy: 0.8446\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3183 - accuracy: 0.8497 - val_loss: 0.3449 - val_accuracy: 0.8411\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3236 - accuracy: 0.8484 - val_loss: 0.3998 - val_accuracy: 0.8029\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3095 - accuracy: 0.8563 - val_loss: 0.2985 - val_accuracy: 0.8632\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3071 - accuracy: 0.8581 - val_loss: 0.3011 - val_accuracy: 0.8572\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2987 - accuracy: 0.8612 - val_loss: 0.2875 - val_accuracy: 0.8664\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2884 - accuracy: 0.8663 - val_loss: 0.2981 - val_accuracy: 0.8653\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 7ms/step - loss: 0.2945 - accuracy: 0.8624 - val_loss: 0.2969 - val_accuracy: 0.8622\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2928 - accuracy: 0.8645 - val_loss: 0.2694 - val_accuracy: 0.8730\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2739 - accuracy: 0.8740 - val_loss: 0.2669 - val_accuracy: 0.8758\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2823 - accuracy: 0.8673 - val_loss: 0.2562 - val_accuracy: 0.8818\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2587 - accuracy: 0.8811 - val_loss: 0.2480 - val_accuracy: 0.8850\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 2s 7ms/step - loss: 0.2658 - accuracy: 0.8790 - val_loss: 0.3091 - val_accuracy: 0.8558\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2559 - accuracy: 0.8809 - val_loss: 0.2572 - val_accuracy: 0.8797\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2425 - accuracy: 0.8875 - val_loss: 0.2284 - val_accuracy: 0.8986\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2513 - accuracy: 0.8840 - val_loss: 0.2980 - val_accuracy: 0.8597\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2332 - accuracy: 0.8932 - val_loss: 0.2657 - val_accuracy: 0.8737\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 7ms/step - loss: 0.2306 - accuracy: 0.8939 - val_loss: 0.3037 - val_accuracy: 0.8604\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2249 - accuracy: 0.8988 - val_loss: 0.3024 - val_accuracy: 0.8608\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2178 - accuracy: 0.9028 - val_loss: 0.2146 - val_accuracy: 0.9067\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2172 - accuracy: 0.9031 - val_loss: 0.2163 - val_accuracy: 0.9074\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2216 - accuracy: 0.9017 - val_loss: 0.2169 - val_accuracy: 0.9021\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2230 - accuracy: 0.9008 - val_loss: 0.2842 - val_accuracy: 0.8734\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2109 - accuracy: 0.9048 - val_loss: 0.2227 - val_accuracy: 0.9028\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2033 - accuracy: 0.9109 - val_loss: 0.2515 - val_accuracy: 0.8885\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1967 - accuracy: 0.9113 - val_loss: 0.2082 - val_accuracy: 0.9074\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2006 - accuracy: 0.9113 - val_loss: 0.2068 - val_accuracy: 0.9148\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1954 - accuracy: 0.9144 - val_loss: 0.1901 - val_accuracy: 0.9225\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1942 - accuracy: 0.9168 - val_loss: 0.2238 - val_accuracy: 0.9014\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1868 - accuracy: 0.9177 - val_loss: 0.2254 - val_accuracy: 0.9074\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1884 - accuracy: 0.9165 - val_loss: 0.1775 - val_accuracy: 0.9309\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1813 - accuracy: 0.9207 - val_loss: 0.2223 - val_accuracy: 0.8976\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1750 - accuracy: 0.9247 - val_loss: 0.1672 - val_accuracy: 0.9358\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1761 - accuracy: 0.9246 - val_loss: 0.1863 - val_accuracy: 0.9176\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 3s 7ms/step - loss: 0.1727 - accuracy: 0.9267 - val_loss: 0.1752 - val_accuracy: 0.9249\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1648 - accuracy: 0.9287 - val_loss: 0.2088 - val_accuracy: 0.9144\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1609 - accuracy: 0.9333 - val_loss: 0.1772 - val_accuracy: 0.9274\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1651 - accuracy: 0.9302 - val_loss: 0.2008 - val_accuracy: 0.9172\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1605 - accuracy: 0.9305 - val_loss: 0.1732 - val_accuracy: 0.9320\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1552 - accuracy: 0.9344 - val_loss: 0.2216 - val_accuracy: 0.9106\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1600 - accuracy: 0.9316 - val_loss: 0.1622 - val_accuracy: 0.9316\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1488 - accuracy: 0.9365 - val_loss: 0.1567 - val_accuracy: 0.9393\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1523 - accuracy: 0.9360 - val_loss: 0.1992 - val_accuracy: 0.9158\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1408 - accuracy: 0.9413 - val_loss: 0.1437 - val_accuracy: 0.9463\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1402 - accuracy: 0.9423 - val_loss: 0.2178 - val_accuracy: 0.9078\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1556 - accuracy: 0.9334 - val_loss: 0.1875 - val_accuracy: 0.9260\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1542 - accuracy: 0.9354 - val_loss: 0.1751 - val_accuracy: 0.9256\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1246 - accuracy: 0.9489 - val_loss: 0.1601 - val_accuracy: 0.9393\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1278 - accuracy: 0.9471 - val_loss: 0.1429 - val_accuracy: 0.9446\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1278 - accuracy: 0.9476 - val_loss: 0.1433 - val_accuracy: 0.9435\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2590 - accuracy: 0.8851 - val_loss: 0.2423 - val_accuracy: 0.8944\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1856 - accuracy: 0.9205 - val_loss: 0.1951 - val_accuracy: 0.9221\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1690 - accuracy: 0.9277 - val_loss: 0.2203 - val_accuracy: 0.9092\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1481 - accuracy: 0.9359 - val_loss: 0.1713 - val_accuracy: 0.9358\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1421 - accuracy: 0.9407 - val_loss: 0.1606 - val_accuracy: 0.9341\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1267 - accuracy: 0.9492 - val_loss: 0.1442 - val_accuracy: 0.9428\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1251 - accuracy: 0.9488 - val_loss: 0.1604 - val_accuracy: 0.9355\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1186 - accuracy: 0.9518 - val_loss: 0.1386 - val_accuracy: 0.9421\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1115 - accuracy: 0.9551 - val_loss: 0.1408 - val_accuracy: 0.9449\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1096 - accuracy: 0.9559 - val_loss: 0.1421 - val_accuracy: 0.9414\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1123 - accuracy: 0.9536 - val_loss: 0.1886 - val_accuracy: 0.9235\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1012 - accuracy: 0.9584 - val_loss: 0.1212 - val_accuracy: 0.9576\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1124 - accuracy: 0.9563 - val_loss: 0.1235 - val_accuracy: 0.9530\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1015 - accuracy: 0.9611 - val_loss: 0.1343 - val_accuracy: 0.9488\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1034 - accuracy: 0.9584 - val_loss: 0.1160 - val_accuracy: 0.9551\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0952 - accuracy: 0.9633 - val_loss: 0.1566 - val_accuracy: 0.9435\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1036 - accuracy: 0.9585 - val_loss: 0.1315 - val_accuracy: 0.9491\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0947 - accuracy: 0.9625 - val_loss: 0.1244 - val_accuracy: 0.9541\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0980 - accuracy: 0.9613 - val_loss: 0.1247 - val_accuracy: 0.9551\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0875 - accuracy: 0.9654 - val_loss: 0.1149 - val_accuracy: 0.9625\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0901 - accuracy: 0.9637 - val_loss: 0.2686 - val_accuracy: 0.9060\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0877 - accuracy: 0.9659 - val_loss: 0.1254 - val_accuracy: 0.9544\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0886 - accuracy: 0.9658 - val_loss: 0.1170 - val_accuracy: 0.9562\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0846 - accuracy: 0.9678 - val_loss: 0.1218 - val_accuracy: 0.9565\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0756 - accuracy: 0.9705 - val_loss: 0.1270 - val_accuracy: 0.9488\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0752 - accuracy: 0.9711 - val_loss: 0.1007 - val_accuracy: 0.9646\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0842 - accuracy: 0.9673 - val_loss: 0.2808 - val_accuracy: 0.9039\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0937 - accuracy: 0.9620 - val_loss: 0.1013 - val_accuracy: 0.9611\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0767 - accuracy: 0.9707 - val_loss: 0.1025 - val_accuracy: 0.9618\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0709 - accuracy: 0.9732 - val_loss: 0.1115 - val_accuracy: 0.9628\n",
      "Epoch 92/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0887 - accuracy: 0.9651 - val_loss: 0.1104 - val_accuracy: 0.9667\n",
      "Epoch 93/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0681 - accuracy: 0.9730 - val_loss: 0.1117 - val_accuracy: 0.9614\n",
      "Epoch 94/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0694 - accuracy: 0.9736 - val_loss: 0.1168 - val_accuracy: 0.9611\n",
      "Epoch 95/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0812 - accuracy: 0.9682 - val_loss: 0.1004 - val_accuracy: 0.9653\n",
      "Epoch 96/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0656 - accuracy: 0.9756 - val_loss: 0.1200 - val_accuracy: 0.9593\n",
      "Epoch 97/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0659 - accuracy: 0.9742 - val_loss: 0.1263 - val_accuracy: 0.9558\n",
      "Epoch 98/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0672 - accuracy: 0.9740 - val_loss: 0.1120 - val_accuracy: 0.9590\n",
      "Epoch 99/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0702 - accuracy: 0.9728 - val_loss: 0.0970 - val_accuracy: 0.9667\n",
      "Epoch 100/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0625 - accuracy: 0.9763 - val_loss: 0.0989 - val_accuracy: 0.9698\n",
      "Epoch 101/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0661 - accuracy: 0.9755 - val_loss: 0.0984 - val_accuracy: 0.9639\n",
      "Epoch 102/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0596 - accuracy: 0.9775 - val_loss: 0.1095 - val_accuracy: 0.9639\n",
      "Epoch 103/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0685 - accuracy: 0.9740 - val_loss: 0.1906 - val_accuracy: 0.9277\n",
      "Epoch 104/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0627 - accuracy: 0.9760 - val_loss: 0.0979 - val_accuracy: 0.9663\n",
      "Epoch 105/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0670 - accuracy: 0.9744 - val_loss: 0.1226 - val_accuracy: 0.9586\n",
      "Epoch 106/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0605 - accuracy: 0.9758 - val_loss: 0.1109 - val_accuracy: 0.9646\n",
      "Epoch 107/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0663 - accuracy: 0.9730 - val_loss: 0.1098 - val_accuracy: 0.9604\n",
      "Epoch 108/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0609 - accuracy: 0.9759 - val_loss: 0.1116 - val_accuracy: 0.9621\n",
      "Epoch 109/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0648 - accuracy: 0.9743 - val_loss: 0.1009 - val_accuracy: 0.9677\n",
      "Epoch 110/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0536 - accuracy: 0.9796 - val_loss: 0.1393 - val_accuracy: 0.9541\n",
      "Epoch 111/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0877 - accuracy: 0.9669 - val_loss: 0.1648 - val_accuracy: 0.9442\n",
      "Epoch 112/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0544 - accuracy: 0.9793 - val_loss: 0.1132 - val_accuracy: 0.9607\n",
      "Epoch 113/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0671 - accuracy: 0.9742 - val_loss: 0.1196 - val_accuracy: 0.9579\n",
      "Epoch 114/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0575 - accuracy: 0.9784 - val_loss: 0.1138 - val_accuracy: 0.9618\n",
      "Epoch 115/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0566 - accuracy: 0.9781 - val_loss: 0.1250 - val_accuracy: 0.9544\n",
      "Epoch 116/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0570 - accuracy: 0.9794 - val_loss: 0.1338 - val_accuracy: 0.9551\n",
      "Epoch 117/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0624 - accuracy: 0.9768 - val_loss: 0.0990 - val_accuracy: 0.9677\n",
      "Epoch 118/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0496 - accuracy: 0.9822 - val_loss: 0.1173 - val_accuracy: 0.9621\n",
      "Epoch 119/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0594 - accuracy: 0.9784 - val_loss: 0.1030 - val_accuracy: 0.9698\n",
      "Epoch 120/500\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9772Restoring model weights from the end of the best epoch: 100.\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0584 - accuracy: 0.9772 - val_loss: 0.1251 - val_accuracy: 0.9572\n",
      "Epoch 120: early stopping\n",
      "Number of iterations 1\n",
      "F1-scores:  [0.9488095238095238]\n",
      "Average F1-Score 0.9488095238095238\n",
      "Std Dev F1-Score 0.0\n",
      "Error bar F1-Score 0.0\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 10ms/step - loss: 0.5017 - accuracy: 0.7423 - val_loss: 0.3746 - val_accuracy: 0.8187\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3857 - accuracy: 0.8099 - val_loss: 0.3717 - val_accuracy: 0.8267\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3780 - accuracy: 0.8150 - val_loss: 0.3612 - val_accuracy: 0.8264\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3763 - accuracy: 0.8159 - val_loss: 0.3774 - val_accuracy: 0.8067\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3740 - accuracy: 0.8168 - val_loss: 0.3677 - val_accuracy: 0.8239\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4574 - accuracy: 0.7671 - val_loss: 0.5142 - val_accuracy: 0.7120\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5386 - accuracy: 0.7157 - val_loss: 0.5708 - val_accuracy: 0.7124\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4764 - accuracy: 0.7475 - val_loss: 0.3812 - val_accuracy: 0.8085\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.4800 - accuracy: 0.7537 - val_loss: 0.6013 - val_accuracy: 0.7124\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5981 - accuracy: 0.7140 - val_loss: 0.5977 - val_accuracy: 0.7124\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5962 - accuracy: 0.7140 - val_loss: 0.5997 - val_accuracy: 0.7124\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5990 - accuracy: 0.7140 - val_loss: 0.6043 - val_accuracy: 0.7124\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5984 - accuracy: 0.7140 - val_loss: 0.6004 - val_accuracy: 0.7124\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5981 - accuracy: 0.7140 - val_loss: 0.5986 - val_accuracy: 0.7124\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5965 - accuracy: 0.7140 - val_loss: 0.6005 - val_accuracy: 0.7124\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5880 - accuracy: 0.7164 - val_loss: 0.5259 - val_accuracy: 0.6647\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4186 - accuracy: 0.7796 - val_loss: 0.3732 - val_accuracy: 0.8253\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3765 - accuracy: 0.8230 - val_loss: 0.3610 - val_accuracy: 0.8313\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3738 - accuracy: 0.8207 - val_loss: 0.3764 - val_accuracy: 0.8285\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3649 - accuracy: 0.8269 - val_loss: 0.3449 - val_accuracy: 0.8397\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3570 - accuracy: 0.8334 - val_loss: 0.3469 - val_accuracy: 0.8355\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3526 - accuracy: 0.8351 - val_loss: 0.3424 - val_accuracy: 0.8408\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3693 - accuracy: 0.8224 - val_loss: 0.4581 - val_accuracy: 0.7369\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3739 - accuracy: 0.8289 - val_loss: 0.3477 - val_accuracy: 0.8376\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3618 - accuracy: 0.8316 - val_loss: 0.3492 - val_accuracy: 0.8369\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3551 - accuracy: 0.8314 - val_loss: 0.3376 - val_accuracy: 0.8450\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3384 - accuracy: 0.8439 - val_loss: 0.3222 - val_accuracy: 0.8488\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3442 - accuracy: 0.8446 - val_loss: 0.3329 - val_accuracy: 0.8471\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3413 - accuracy: 0.8438 - val_loss: 0.3260 - val_accuracy: 0.8471\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3425 - accuracy: 0.8432 - val_loss: 0.3273 - val_accuracy: 0.8513\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3252 - accuracy: 0.8518 - val_loss: 0.3293 - val_accuracy: 0.8485\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3483 - accuracy: 0.8397 - val_loss: 0.3177 - val_accuracy: 0.8565\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3494 - accuracy: 0.8348 - val_loss: 0.3864 - val_accuracy: 0.7962\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3570 - accuracy: 0.8336 - val_loss: 0.3502 - val_accuracy: 0.8527\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3445 - accuracy: 0.8472 - val_loss: 0.3288 - val_accuracy: 0.8523\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3522 - accuracy: 0.8399 - val_loss: 0.3602 - val_accuracy: 0.8281\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3328 - accuracy: 0.8477 - val_loss: 0.3582 - val_accuracy: 0.8376\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3320 - accuracy: 0.8457 - val_loss: 0.3397 - val_accuracy: 0.8429\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3287 - accuracy: 0.8477 - val_loss: 0.3414 - val_accuracy: 0.8365\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3239 - accuracy: 0.8519 - val_loss: 0.3701 - val_accuracy: 0.8208\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3201 - accuracy: 0.8544 - val_loss: 0.3103 - val_accuracy: 0.8650\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3160 - accuracy: 0.8568 - val_loss: 0.2995 - val_accuracy: 0.8625\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3220 - accuracy: 0.8523 - val_loss: 0.3178 - val_accuracy: 0.8513\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3093 - accuracy: 0.8601 - val_loss: 0.3017 - val_accuracy: 0.8643\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3178 - accuracy: 0.8537 - val_loss: 0.3116 - val_accuracy: 0.8618\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3079 - accuracy: 0.8581 - val_loss: 0.4924 - val_accuracy: 0.7639\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3095 - accuracy: 0.8589 - val_loss: 0.3052 - val_accuracy: 0.8597\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3028 - accuracy: 0.8607 - val_loss: 0.2929 - val_accuracy: 0.8660\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3019 - accuracy: 0.8624 - val_loss: 0.2968 - val_accuracy: 0.8678\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3658 - accuracy: 0.8243 - val_loss: 0.3481 - val_accuracy: 0.8453\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3129 - accuracy: 0.8590 - val_loss: 0.2871 - val_accuracy: 0.8674\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3052 - accuracy: 0.8591 - val_loss: 0.2860 - val_accuracy: 0.8681\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3055 - accuracy: 0.8610 - val_loss: 0.2934 - val_accuracy: 0.8723\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3067 - accuracy: 0.8604 - val_loss: 0.2947 - val_accuracy: 0.8720\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3061 - accuracy: 0.8585 - val_loss: 0.2938 - val_accuracy: 0.8664\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2909 - accuracy: 0.8650 - val_loss: 0.2909 - val_accuracy: 0.8671\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2823 - accuracy: 0.8708 - val_loss: 0.2977 - val_accuracy: 0.8660\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2819 - accuracy: 0.8709 - val_loss: 0.2726 - val_accuracy: 0.8818\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2799 - accuracy: 0.8709 - val_loss: 0.2768 - val_accuracy: 0.8793\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2875 - accuracy: 0.8681 - val_loss: 0.2712 - val_accuracy: 0.8800\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2816 - accuracy: 0.8726 - val_loss: 0.2871 - val_accuracy: 0.8716\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2877 - accuracy: 0.8682 - val_loss: 0.2738 - val_accuracy: 0.8751\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2759 - accuracy: 0.8736 - val_loss: 0.2665 - val_accuracy: 0.8776\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2749 - accuracy: 0.8754 - val_loss: 0.3040 - val_accuracy: 0.8615\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5546 - accuracy: 0.7340 - val_loss: 0.5939 - val_accuracy: 0.7124\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5957 - accuracy: 0.7140 - val_loss: 0.5883 - val_accuracy: 0.7124\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5772 - accuracy: 0.7127 - val_loss: 0.5760 - val_accuracy: 0.7124\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5353 - accuracy: 0.7132 - val_loss: 0.4923 - val_accuracy: 0.7124\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4595 - accuracy: 0.7446 - val_loss: 0.4121 - val_accuracy: 0.7885\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3993 - accuracy: 0.7993 - val_loss: 0.3986 - val_accuracy: 0.7874\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3676 - accuracy: 0.8231 - val_loss: 0.3446 - val_accuracy: 0.8439\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3500 - accuracy: 0.8354 - val_loss: 0.3298 - val_accuracy: 0.8488\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3415 - accuracy: 0.8392 - val_loss: 0.3657 - val_accuracy: 0.8123\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3316 - accuracy: 0.8451 - val_loss: 0.3786 - val_accuracy: 0.8201\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3229 - accuracy: 0.8504 - val_loss: 0.3203 - val_accuracy: 0.8499\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3141 - accuracy: 0.8508 - val_loss: 0.3261 - val_accuracy: 0.8485\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3085 - accuracy: 0.8556 - val_loss: 0.2947 - val_accuracy: 0.8671\n",
      "Epoch 78/500\n",
      "327/334 [============================>.] - ETA: 0s - loss: 0.3017 - accuracy: 0.8601Restoring model weights from the end of the best epoch: 58.\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3008 - accuracy: 0.8607 - val_loss: 0.2906 - val_accuracy: 0.8650\n",
      "Epoch 78: early stopping\n",
      "Number of iterations 2\n",
      "F1-scores:  [0.9488095238095238, 0.7921036397285626]\n",
      "Average F1-Score 0.8704565817690432\n",
      "Std Dev F1-Score 0.0783529420404806\n",
      "Error bar F1-Score 0.055403896642740355\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 10ms/step - loss: 0.5063 - accuracy: 0.7308 - val_loss: 0.3834 - val_accuracy: 0.8085\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3967 - accuracy: 0.8006 - val_loss: 0.4420 - val_accuracy: 0.7176\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3842 - accuracy: 0.8101 - val_loss: 0.3911 - val_accuracy: 0.7973\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3849 - accuracy: 0.8092 - val_loss: 0.3735 - val_accuracy: 0.8130\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3720 - accuracy: 0.8150 - val_loss: 0.3980 - val_accuracy: 0.7997\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3719 - accuracy: 0.8183 - val_loss: 0.3577 - val_accuracy: 0.8281\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3623 - accuracy: 0.8229 - val_loss: 0.3493 - val_accuracy: 0.8351\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3779 - accuracy: 0.8154 - val_loss: 0.3706 - val_accuracy: 0.8145\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3570 - accuracy: 0.8268 - val_loss: 0.3618 - val_accuracy: 0.8197\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3569 - accuracy: 0.8291 - val_loss: 0.3571 - val_accuracy: 0.8127\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3576 - accuracy: 0.8281 - val_loss: 0.3420 - val_accuracy: 0.8355\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3524 - accuracy: 0.8287 - val_loss: 0.3558 - val_accuracy: 0.8264\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3407 - accuracy: 0.8388 - val_loss: 0.3259 - val_accuracy: 0.8418\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3359 - accuracy: 0.8425 - val_loss: 0.3461 - val_accuracy: 0.8373\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3326 - accuracy: 0.8426 - val_loss: 0.3239 - val_accuracy: 0.8450\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3332 - accuracy: 0.8438 - val_loss: 0.3287 - val_accuracy: 0.8485\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3251 - accuracy: 0.8472 - val_loss: 0.3138 - val_accuracy: 0.8548\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4802 - accuracy: 0.7465 - val_loss: 0.4393 - val_accuracy: 0.7745\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3960 - accuracy: 0.7988 - val_loss: 0.3987 - val_accuracy: 0.7973\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3615 - accuracy: 0.8253 - val_loss: 0.3404 - val_accuracy: 0.8401\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3457 - accuracy: 0.8376 - val_loss: 0.3412 - val_accuracy: 0.8362\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3387 - accuracy: 0.8414 - val_loss: 0.3548 - val_accuracy: 0.8334\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3285 - accuracy: 0.8437 - val_loss: 0.3688 - val_accuracy: 0.8180\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3204 - accuracy: 0.8491 - val_loss: 0.3065 - val_accuracy: 0.8579\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3143 - accuracy: 0.8543 - val_loss: 0.3192 - val_accuracy: 0.8629\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3067 - accuracy: 0.8585 - val_loss: 0.2902 - val_accuracy: 0.8678\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2959 - accuracy: 0.8604 - val_loss: 0.3126 - val_accuracy: 0.8548\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2913 - accuracy: 0.8640 - val_loss: 0.2777 - val_accuracy: 0.8786\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2786 - accuracy: 0.8712 - val_loss: 0.2695 - val_accuracy: 0.8790\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2665 - accuracy: 0.8794 - val_loss: 0.2744 - val_accuracy: 0.8765\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2605 - accuracy: 0.8813 - val_loss: 0.2488 - val_accuracy: 0.8857\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2566 - accuracy: 0.8834 - val_loss: 0.2638 - val_accuracy: 0.8769\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2518 - accuracy: 0.8886 - val_loss: 0.2588 - val_accuracy: 0.8818\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2461 - accuracy: 0.8869 - val_loss: 0.2376 - val_accuracy: 0.8937\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2448 - accuracy: 0.8891 - val_loss: 0.2702 - val_accuracy: 0.8790\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2424 - accuracy: 0.8911 - val_loss: 0.2392 - val_accuracy: 0.8899\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2353 - accuracy: 0.8923 - val_loss: 0.2534 - val_accuracy: 0.8885\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2331 - accuracy: 0.8970 - val_loss: 0.2419 - val_accuracy: 0.8902\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2255 - accuracy: 0.8988 - val_loss: 0.2162 - val_accuracy: 0.9074\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2225 - accuracy: 0.8995 - val_loss: 0.2202 - val_accuracy: 0.8993\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2365 - accuracy: 0.8989 - val_loss: 0.3003 - val_accuracy: 0.8629\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2389 - accuracy: 0.8930 - val_loss: 0.2152 - val_accuracy: 0.9049\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2129 - accuracy: 0.9056 - val_loss: 0.2186 - val_accuracy: 0.9046\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2240 - accuracy: 0.9017 - val_loss: 0.2153 - val_accuracy: 0.9063\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2047 - accuracy: 0.9089 - val_loss: 0.2101 - val_accuracy: 0.9081\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1945 - accuracy: 0.9149 - val_loss: 0.2108 - val_accuracy: 0.9056\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1984 - accuracy: 0.9127 - val_loss: 0.2001 - val_accuracy: 0.9123\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1879 - accuracy: 0.9201 - val_loss: 0.2101 - val_accuracy: 0.9067\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1970 - accuracy: 0.9170 - val_loss: 0.1903 - val_accuracy: 0.9221\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1815 - accuracy: 0.9221 - val_loss: 0.2078 - val_accuracy: 0.9155\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1730 - accuracy: 0.9256 - val_loss: 0.1890 - val_accuracy: 0.9162\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1721 - accuracy: 0.9270 - val_loss: 0.1821 - val_accuracy: 0.9211\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1734 - accuracy: 0.9258 - val_loss: 0.1996 - val_accuracy: 0.9137\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1713 - accuracy: 0.9269 - val_loss: 0.1940 - val_accuracy: 0.9137\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1720 - accuracy: 0.9271 - val_loss: 0.1730 - val_accuracy: 0.9316\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1594 - accuracy: 0.9340 - val_loss: 0.2182 - val_accuracy: 0.9063\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1582 - accuracy: 0.9326 - val_loss: 0.1538 - val_accuracy: 0.9383\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1525 - accuracy: 0.9375 - val_loss: 0.1704 - val_accuracy: 0.9316\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1553 - accuracy: 0.9369 - val_loss: 0.2250 - val_accuracy: 0.9074\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1537 - accuracy: 0.9360 - val_loss: 0.1721 - val_accuracy: 0.9232\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1413 - accuracy: 0.9424 - val_loss: 0.1532 - val_accuracy: 0.9369\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1425 - accuracy: 0.9417 - val_loss: 0.1436 - val_accuracy: 0.9365\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1395 - accuracy: 0.9420 - val_loss: 0.1618 - val_accuracy: 0.9320\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1362 - accuracy: 0.9447 - val_loss: 0.1572 - val_accuracy: 0.9358\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1339 - accuracy: 0.9446 - val_loss: 0.1441 - val_accuracy: 0.9432\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1408 - accuracy: 0.9428 - val_loss: 0.1595 - val_accuracy: 0.9390\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1190 - accuracy: 0.9513 - val_loss: 0.1556 - val_accuracy: 0.9362\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1203 - accuracy: 0.9513 - val_loss: 0.1587 - val_accuracy: 0.9386\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1090 - accuracy: 0.9569 - val_loss: 0.1460 - val_accuracy: 0.9432\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1151 - accuracy: 0.9540 - val_loss: 0.1475 - val_accuracy: 0.9463\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1144 - accuracy: 0.9538 - val_loss: 0.1376 - val_accuracy: 0.9435\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1070 - accuracy: 0.9574 - val_loss: 0.1438 - val_accuracy: 0.9435\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1150 - accuracy: 0.9535 - val_loss: 0.2065 - val_accuracy: 0.9144\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1112 - accuracy: 0.9554 - val_loss: 0.1354 - val_accuracy: 0.9491\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1025 - accuracy: 0.9580 - val_loss: 0.2002 - val_accuracy: 0.9214\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1069 - accuracy: 0.9576 - val_loss: 0.1235 - val_accuracy: 0.9502\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1076 - accuracy: 0.9562 - val_loss: 0.1248 - val_accuracy: 0.9509\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1041 - accuracy: 0.9586 - val_loss: 0.1613 - val_accuracy: 0.9362\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0973 - accuracy: 0.9611 - val_loss: 0.1582 - val_accuracy: 0.9372\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0963 - accuracy: 0.9624 - val_loss: 0.2007 - val_accuracy: 0.9242\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0906 - accuracy: 0.9651 - val_loss: 0.1258 - val_accuracy: 0.9460\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0933 - accuracy: 0.9632 - val_loss: 0.1208 - val_accuracy: 0.9526\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0874 - accuracy: 0.9656 - val_loss: 0.1389 - val_accuracy: 0.9477\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0901 - accuracy: 0.9640 - val_loss: 0.1164 - val_accuracy: 0.9562\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0937 - accuracy: 0.9627 - val_loss: 0.1140 - val_accuracy: 0.9593\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0914 - accuracy: 0.9647 - val_loss: 0.1250 - val_accuracy: 0.9516\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0897 - accuracy: 0.9647 - val_loss: 0.1121 - val_accuracy: 0.9548\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0861 - accuracy: 0.9678 - val_loss: 0.1318 - val_accuracy: 0.9463\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0825 - accuracy: 0.9677 - val_loss: 0.1390 - val_accuracy: 0.9432\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0871 - accuracy: 0.9664 - val_loss: 0.1887 - val_accuracy: 0.9316\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0725 - accuracy: 0.9716 - val_loss: 0.1240 - val_accuracy: 0.9544\n",
      "Epoch 92/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0787 - accuracy: 0.9704 - val_loss: 0.1041 - val_accuracy: 0.9604\n",
      "Epoch 93/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0691 - accuracy: 0.9727 - val_loss: 0.1032 - val_accuracy: 0.9597\n",
      "Epoch 94/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0710 - accuracy: 0.9721 - val_loss: 0.1705 - val_accuracy: 0.9365\n",
      "Epoch 95/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0678 - accuracy: 0.9743 - val_loss: 0.1383 - val_accuracy: 0.9456\n",
      "Epoch 96/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0829 - accuracy: 0.9675 - val_loss: 0.1194 - val_accuracy: 0.9558\n",
      "Epoch 97/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0736 - accuracy: 0.9714 - val_loss: 0.1241 - val_accuracy: 0.9519\n",
      "Epoch 98/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0828 - accuracy: 0.9675 - val_loss: 0.1708 - val_accuracy: 0.9327\n",
      "Epoch 99/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0642 - accuracy: 0.9757 - val_loss: 0.1786 - val_accuracy: 0.9425\n",
      "Epoch 100/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0660 - accuracy: 0.9747 - val_loss: 0.1545 - val_accuracy: 0.9453\n",
      "Epoch 101/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0607 - accuracy: 0.9765 - val_loss: 0.1377 - val_accuracy: 0.9474\n",
      "Epoch 102/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0585 - accuracy: 0.9768 - val_loss: 0.1383 - val_accuracy: 0.9523\n",
      "Epoch 103/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0651 - accuracy: 0.9750 - val_loss: 0.1171 - val_accuracy: 0.9558\n",
      "Epoch 104/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0604 - accuracy: 0.9777 - val_loss: 0.1234 - val_accuracy: 0.9555\n",
      "Epoch 105/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0698 - accuracy: 0.9741 - val_loss: 0.1288 - val_accuracy: 0.9516\n",
      "Epoch 106/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0561 - accuracy: 0.9794 - val_loss: 0.1059 - val_accuracy: 0.9604\n",
      "Epoch 107/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0616 - accuracy: 0.9767 - val_loss: 0.1123 - val_accuracy: 0.9586\n",
      "Epoch 108/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0497 - accuracy: 0.9813 - val_loss: 0.1000 - val_accuracy: 0.9656\n",
      "Epoch 109/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0600 - accuracy: 0.9770 - val_loss: 0.1371 - val_accuracy: 0.9541\n",
      "Epoch 110/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0730 - accuracy: 0.9730 - val_loss: 0.0992 - val_accuracy: 0.9635\n",
      "Epoch 111/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0483 - accuracy: 0.9815 - val_loss: 0.2664 - val_accuracy: 0.9130\n",
      "Epoch 112/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0520 - accuracy: 0.9802 - val_loss: 0.1413 - val_accuracy: 0.9523\n",
      "Epoch 113/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0500 - accuracy: 0.9819 - val_loss: 0.1095 - val_accuracy: 0.9593\n",
      "Epoch 114/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0596 - accuracy: 0.9785 - val_loss: 0.1155 - val_accuracy: 0.9628\n",
      "Epoch 115/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0517 - accuracy: 0.9814 - val_loss: 0.1403 - val_accuracy: 0.9505\n",
      "Epoch 116/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0461 - accuracy: 0.9832 - val_loss: 0.0974 - val_accuracy: 0.9656\n",
      "Epoch 117/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0623 - accuracy: 0.9765 - val_loss: 0.1195 - val_accuracy: 0.9579\n",
      "Epoch 118/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0519 - accuracy: 0.9803 - val_loss: 0.1246 - val_accuracy: 0.9572\n",
      "Epoch 119/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0495 - accuracy: 0.9817 - val_loss: 0.1364 - val_accuracy: 0.9533\n",
      "Epoch 120/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0488 - accuracy: 0.9827 - val_loss: 0.0986 - val_accuracy: 0.9649\n",
      "Epoch 121/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0363 - accuracy: 0.9870 - val_loss: 0.0927 - val_accuracy: 0.9677\n",
      "Epoch 122/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0593 - accuracy: 0.9763 - val_loss: 0.1309 - val_accuracy: 0.9537\n",
      "Epoch 123/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0571 - accuracy: 0.9782 - val_loss: 0.1010 - val_accuracy: 0.9625\n",
      "Epoch 124/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0441 - accuracy: 0.9845 - val_loss: 0.2083 - val_accuracy: 0.9260\n",
      "Epoch 125/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0482 - accuracy: 0.9827 - val_loss: 0.1043 - val_accuracy: 0.9642\n",
      "Epoch 126/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0364 - accuracy: 0.9873 - val_loss: 0.1448 - val_accuracy: 0.9579\n",
      "Epoch 127/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0612 - accuracy: 0.9774 - val_loss: 0.1131 - val_accuracy: 0.9642\n",
      "Epoch 128/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0410 - accuracy: 0.9847 - val_loss: 0.1348 - val_accuracy: 0.9558\n",
      "Epoch 129/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0377 - accuracy: 0.9868 - val_loss: 0.1188 - val_accuracy: 0.9611\n",
      "Epoch 130/500\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0454 - accuracy: 0.9831 - val_loss: 0.1199 - val_accuracy: 0.9649\n",
      "Epoch 131/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0465 - accuracy: 0.9829 - val_loss: 0.1197 - val_accuracy: 0.9611\n",
      "Epoch 132/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0339 - accuracy: 0.9875 - val_loss: 0.1193 - val_accuracy: 0.9604\n",
      "Epoch 133/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0507 - accuracy: 0.9807 - val_loss: 0.1137 - val_accuracy: 0.9604\n",
      "Epoch 134/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0406 - accuracy: 0.9850 - val_loss: 0.1607 - val_accuracy: 0.9512\n",
      "Epoch 135/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0410 - accuracy: 0.9856 - val_loss: 0.1191 - val_accuracy: 0.9604\n",
      "Epoch 136/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0469 - accuracy: 0.9828 - val_loss: 0.1395 - val_accuracy: 0.9558\n",
      "Epoch 137/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0383 - accuracy: 0.9858 - val_loss: 0.1155 - val_accuracy: 0.9597\n",
      "Epoch 138/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0363 - accuracy: 0.9863 - val_loss: 0.1206 - val_accuracy: 0.9614\n",
      "Epoch 139/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0394 - accuracy: 0.9862 - val_loss: 0.1148 - val_accuracy: 0.9639\n",
      "Epoch 140/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0306 - accuracy: 0.9888 - val_loss: 0.1495 - val_accuracy: 0.9495\n",
      "Epoch 141/500\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.0529 - accuracy: 0.9803Restoring model weights from the end of the best epoch: 121.\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0525 - accuracy: 0.9806 - val_loss: 0.1208 - val_accuracy: 0.9600\n",
      "Epoch 141: early stopping\n",
      "Number of iterations 3\n",
      "F1-scores:  [0.9488095238095238, 0.7921036397285626, 0.9443099273607748]\n",
      "Average F1-Score 0.8950743636329537\n",
      "Std Dev F1-Score 0.0728344656422867\n",
      "Error bar F1-Score 0.042050998344856774\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 10ms/step - loss: 0.5378 - accuracy: 0.7095 - val_loss: 0.4291 - val_accuracy: 0.7997\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4026 - accuracy: 0.8017 - val_loss: 0.3732 - val_accuracy: 0.8074\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3818 - accuracy: 0.8149 - val_loss: 0.4139 - val_accuracy: 0.7892\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3811 - accuracy: 0.8154 - val_loss: 0.3706 - val_accuracy: 0.8173\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3655 - accuracy: 0.8253 - val_loss: 0.3540 - val_accuracy: 0.8334\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3675 - accuracy: 0.8235 - val_loss: 0.3626 - val_accuracy: 0.8197\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3615 - accuracy: 0.8285 - val_loss: 0.3703 - val_accuracy: 0.8323\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3631 - accuracy: 0.8278 - val_loss: 0.3518 - val_accuracy: 0.8302\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3625 - accuracy: 0.8271 - val_loss: 0.3660 - val_accuracy: 0.8257\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3564 - accuracy: 0.8306 - val_loss: 0.3693 - val_accuracy: 0.8306\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3638 - accuracy: 0.8261 - val_loss: 0.3529 - val_accuracy: 0.8295\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3584 - accuracy: 0.8304 - val_loss: 0.4018 - val_accuracy: 0.8060\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3585 - accuracy: 0.8288 - val_loss: 0.4142 - val_accuracy: 0.8102\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3460 - accuracy: 0.8353 - val_loss: 0.3369 - val_accuracy: 0.8443\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3399 - accuracy: 0.8405 - val_loss: 0.3522 - val_accuracy: 0.8397\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3410 - accuracy: 0.8404 - val_loss: 0.3341 - val_accuracy: 0.8429\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3375 - accuracy: 0.8418 - val_loss: 0.3456 - val_accuracy: 0.8425\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3314 - accuracy: 0.8444 - val_loss: 0.4281 - val_accuracy: 0.7825\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3250 - accuracy: 0.8464 - val_loss: 0.3507 - val_accuracy: 0.8257\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3173 - accuracy: 0.8561 - val_loss: 0.3120 - val_accuracy: 0.8593\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3193 - accuracy: 0.8500 - val_loss: 0.3117 - val_accuracy: 0.8534\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3100 - accuracy: 0.8575 - val_loss: 0.3355 - val_accuracy: 0.8450\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3257 - accuracy: 0.8509 - val_loss: 0.2876 - val_accuracy: 0.8748\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2999 - accuracy: 0.8631 - val_loss: 0.3010 - val_accuracy: 0.8618\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2867 - accuracy: 0.8730 - val_loss: 0.2825 - val_accuracy: 0.8702\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2701 - accuracy: 0.8832 - val_loss: 0.2487 - val_accuracy: 0.8951\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2660 - accuracy: 0.8816 - val_loss: 0.2627 - val_accuracy: 0.8902\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2702 - accuracy: 0.8832 - val_loss: 0.4285 - val_accuracy: 0.7629\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3307 - accuracy: 0.8423 - val_loss: 0.3048 - val_accuracy: 0.8618\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2968 - accuracy: 0.8596 - val_loss: 0.3001 - val_accuracy: 0.8681\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2910 - accuracy: 0.8669 - val_loss: 0.2803 - val_accuracy: 0.8758\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2718 - accuracy: 0.8801 - val_loss: 0.2675 - val_accuracy: 0.8818\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2602 - accuracy: 0.8856 - val_loss: 0.2661 - val_accuracy: 0.8807\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2435 - accuracy: 0.8950 - val_loss: 0.2447 - val_accuracy: 0.8972\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2462 - accuracy: 0.8940 - val_loss: 0.2261 - val_accuracy: 0.8993\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2237 - accuracy: 0.9071 - val_loss: 0.1973 - val_accuracy: 0.9200\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2273 - accuracy: 0.9034 - val_loss: 0.2181 - val_accuracy: 0.9088\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2123 - accuracy: 0.9120 - val_loss: 0.2089 - val_accuracy: 0.9162\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2140 - accuracy: 0.9104 - val_loss: 0.1975 - val_accuracy: 0.9151\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2006 - accuracy: 0.9165 - val_loss: 0.1766 - val_accuracy: 0.9298\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1943 - accuracy: 0.9192 - val_loss: 0.1857 - val_accuracy: 0.9263\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1956 - accuracy: 0.9198 - val_loss: 0.2360 - val_accuracy: 0.8972\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1889 - accuracy: 0.9212 - val_loss: 0.2797 - val_accuracy: 0.8765\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1922 - accuracy: 0.9210 - val_loss: 0.1536 - val_accuracy: 0.9411\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1837 - accuracy: 0.9234 - val_loss: 0.1618 - val_accuracy: 0.9355\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1775 - accuracy: 0.9285 - val_loss: 0.1751 - val_accuracy: 0.9274\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1637 - accuracy: 0.9331 - val_loss: 0.1579 - val_accuracy: 0.9390\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1854 - accuracy: 0.9225 - val_loss: 0.2833 - val_accuracy: 0.8650\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1885 - accuracy: 0.9234 - val_loss: 0.1628 - val_accuracy: 0.9386\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1652 - accuracy: 0.9313 - val_loss: 0.3202 - val_accuracy: 0.8527\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1636 - accuracy: 0.9328 - val_loss: 0.2852 - val_accuracy: 0.8730\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1647 - accuracy: 0.9318 - val_loss: 0.1494 - val_accuracy: 0.9421\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1689 - accuracy: 0.9300 - val_loss: 0.1620 - val_accuracy: 0.9320\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1793 - accuracy: 0.9250 - val_loss: 0.2105 - val_accuracy: 0.9127\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1571 - accuracy: 0.9359 - val_loss: 0.1292 - val_accuracy: 0.9460\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1871 - accuracy: 0.9190 - val_loss: 0.3896 - val_accuracy: 0.8036\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2511 - accuracy: 0.8900 - val_loss: 0.2236 - val_accuracy: 0.9028\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2035 - accuracy: 0.9128 - val_loss: 0.1627 - val_accuracy: 0.9302\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1537 - accuracy: 0.9376 - val_loss: 0.1382 - val_accuracy: 0.9425\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1900 - accuracy: 0.9183 - val_loss: 0.1567 - val_accuracy: 0.9383\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1562 - accuracy: 0.9364 - val_loss: 0.3432 - val_accuracy: 0.8439\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2150 - accuracy: 0.9055 - val_loss: 0.1228 - val_accuracy: 0.9502\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1407 - accuracy: 0.9435 - val_loss: 0.4660 - val_accuracy: 0.8208\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2676 - accuracy: 0.8800 - val_loss: 0.2607 - val_accuracy: 0.8878\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2324 - accuracy: 0.8992 - val_loss: 0.1999 - val_accuracy: 0.9158\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2031 - accuracy: 0.9139 - val_loss: 0.1559 - val_accuracy: 0.9358\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1563 - accuracy: 0.9361 - val_loss: 0.1394 - val_accuracy: 0.9418\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1614 - accuracy: 0.9326 - val_loss: 0.1509 - val_accuracy: 0.9400\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1379 - accuracy: 0.9451 - val_loss: 0.3158 - val_accuracy: 0.8615\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1483 - accuracy: 0.9388 - val_loss: 0.1300 - val_accuracy: 0.9509\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1518 - accuracy: 0.9370 - val_loss: 0.1393 - val_accuracy: 0.9460\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1634 - accuracy: 0.9302 - val_loss: 0.1805 - val_accuracy: 0.9190\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1294 - accuracy: 0.9458 - val_loss: 0.1575 - val_accuracy: 0.9327\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1680 - accuracy: 0.9309 - val_loss: 0.1316 - val_accuracy: 0.9491\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1349 - accuracy: 0.9462 - val_loss: 0.1217 - val_accuracy: 0.9523\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1221 - accuracy: 0.9520 - val_loss: 0.1170 - val_accuracy: 0.9562\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1176 - accuracy: 0.9524 - val_loss: 0.1655 - val_accuracy: 0.9253\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1235 - accuracy: 0.9507 - val_loss: 0.4298 - val_accuracy: 0.8590\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1295 - accuracy: 0.9483 - val_loss: 0.1315 - val_accuracy: 0.9467\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1915 - accuracy: 0.9190 - val_loss: 0.1456 - val_accuracy: 0.9407\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1881 - accuracy: 0.9217 - val_loss: 0.1928 - val_accuracy: 0.9197\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1470 - accuracy: 0.9386 - val_loss: 0.1132 - val_accuracy: 0.9562\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1314 - accuracy: 0.9464 - val_loss: 0.1128 - val_accuracy: 0.9555\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1241 - accuracy: 0.9502 - val_loss: 0.1127 - val_accuracy: 0.9576\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1158 - accuracy: 0.9540 - val_loss: 0.1126 - val_accuracy: 0.9558\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1191 - accuracy: 0.9539 - val_loss: 0.2355 - val_accuracy: 0.8916\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1168 - accuracy: 0.9535 - val_loss: 0.1025 - val_accuracy: 0.9635\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1245 - accuracy: 0.9502 - val_loss: 0.1124 - val_accuracy: 0.9562\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1254 - accuracy: 0.9495 - val_loss: 0.1461 - val_accuracy: 0.9467\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1414 - accuracy: 0.9422 - val_loss: 0.1505 - val_accuracy: 0.9341\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1103 - accuracy: 0.9573 - val_loss: 0.1674 - val_accuracy: 0.9263\n",
      "Epoch 92/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1570 - accuracy: 0.9340 - val_loss: 0.1611 - val_accuracy: 0.9355\n",
      "Epoch 93/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1151 - accuracy: 0.9548 - val_loss: 0.0968 - val_accuracy: 0.9618\n",
      "Epoch 94/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1079 - accuracy: 0.9581 - val_loss: 0.1286 - val_accuracy: 0.9467\n",
      "Epoch 95/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1324 - accuracy: 0.9457 - val_loss: 0.1511 - val_accuracy: 0.9439\n",
      "Epoch 96/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1110 - accuracy: 0.9553 - val_loss: 0.1819 - val_accuracy: 0.9225\n",
      "Epoch 97/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1217 - accuracy: 0.9516 - val_loss: 0.1618 - val_accuracy: 0.9330\n",
      "Epoch 98/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0985 - accuracy: 0.9628 - val_loss: 0.0930 - val_accuracy: 0.9628\n",
      "Epoch 99/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1162 - accuracy: 0.9535 - val_loss: 0.1098 - val_accuracy: 0.9544\n",
      "Epoch 100/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1295 - accuracy: 0.9478 - val_loss: 0.0966 - val_accuracy: 0.9642\n",
      "Epoch 101/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0983 - accuracy: 0.9625 - val_loss: 0.0927 - val_accuracy: 0.9639\n",
      "Epoch 102/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1073 - accuracy: 0.9582 - val_loss: 0.0895 - val_accuracy: 0.9674\n",
      "Epoch 103/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0946 - accuracy: 0.9638 - val_loss: 0.1088 - val_accuracy: 0.9579\n",
      "Epoch 104/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1165 - accuracy: 0.9532 - val_loss: 0.1097 - val_accuracy: 0.9565\n",
      "Epoch 105/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1079 - accuracy: 0.9569 - val_loss: 0.1345 - val_accuracy: 0.9449\n",
      "Epoch 106/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1128 - accuracy: 0.9542 - val_loss: 0.0919 - val_accuracy: 0.9642\n",
      "Epoch 107/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0961 - accuracy: 0.9632 - val_loss: 0.0920 - val_accuracy: 0.9625\n",
      "Epoch 108/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1022 - accuracy: 0.9595 - val_loss: 0.0961 - val_accuracy: 0.9625\n",
      "Epoch 109/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0994 - accuracy: 0.9640 - val_loss: 0.1113 - val_accuracy: 0.9583\n",
      "Epoch 110/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1144 - accuracy: 0.9563 - val_loss: 0.2646 - val_accuracy: 0.8951\n",
      "Epoch 111/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0999 - accuracy: 0.9609 - val_loss: 0.1027 - val_accuracy: 0.9565\n",
      "Epoch 112/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1024 - accuracy: 0.9606 - val_loss: 0.1073 - val_accuracy: 0.9586\n",
      "Epoch 113/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1323 - accuracy: 0.9465 - val_loss: 0.1208 - val_accuracy: 0.9544\n",
      "Epoch 114/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0839 - accuracy: 0.9684 - val_loss: 0.0846 - val_accuracy: 0.9684\n",
      "Epoch 115/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1052 - accuracy: 0.9582 - val_loss: 0.1902 - val_accuracy: 0.9162\n",
      "Epoch 116/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0907 - accuracy: 0.9648 - val_loss: 0.0853 - val_accuracy: 0.9688\n",
      "Epoch 117/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1013 - accuracy: 0.9606 - val_loss: 0.1015 - val_accuracy: 0.9600\n",
      "Epoch 118/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0800 - accuracy: 0.9693 - val_loss: 0.1004 - val_accuracy: 0.9632\n",
      "Epoch 119/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0977 - accuracy: 0.9622 - val_loss: 0.0882 - val_accuracy: 0.9653\n",
      "Epoch 120/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0953 - accuracy: 0.9634 - val_loss: 0.0967 - val_accuracy: 0.9642\n",
      "Epoch 121/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0989 - accuracy: 0.9604 - val_loss: 0.0953 - val_accuracy: 0.9621\n",
      "Epoch 122/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0981 - accuracy: 0.9621 - val_loss: 0.0914 - val_accuracy: 0.9667\n",
      "Epoch 123/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0948 - accuracy: 0.9620 - val_loss: 0.0943 - val_accuracy: 0.9646\n",
      "Epoch 124/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0787 - accuracy: 0.9703 - val_loss: 0.0962 - val_accuracy: 0.9639\n",
      "Epoch 125/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0944 - accuracy: 0.9639 - val_loss: 0.1172 - val_accuracy: 0.9533\n",
      "Epoch 126/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0745 - accuracy: 0.9710 - val_loss: 0.0822 - val_accuracy: 0.9719\n",
      "Epoch 127/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0954 - accuracy: 0.9634 - val_loss: 0.1316 - val_accuracy: 0.9498\n",
      "Epoch 128/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0705 - accuracy: 0.9731 - val_loss: 0.0757 - val_accuracy: 0.9719\n",
      "Epoch 129/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0719 - accuracy: 0.9729 - val_loss: 0.1593 - val_accuracy: 0.9407\n",
      "Epoch 130/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1007 - accuracy: 0.9605 - val_loss: 0.0836 - val_accuracy: 0.9688\n",
      "Epoch 131/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0760 - accuracy: 0.9713 - val_loss: 0.1727 - val_accuracy: 0.9288\n",
      "Epoch 132/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0872 - accuracy: 0.9673 - val_loss: 0.0819 - val_accuracy: 0.9726\n",
      "Epoch 133/500\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0853 - accuracy: 0.9665 - val_loss: 0.0933 - val_accuracy: 0.9681\n",
      "Epoch 134/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0843 - accuracy: 0.9681 - val_loss: 0.1178 - val_accuracy: 0.9544\n",
      "Epoch 135/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1146 - accuracy: 0.9560 - val_loss: 0.1177 - val_accuracy: 0.9555\n",
      "Epoch 136/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0654 - accuracy: 0.9760 - val_loss: 0.0739 - val_accuracy: 0.9730\n",
      "Epoch 137/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0758 - accuracy: 0.9715 - val_loss: 0.0830 - val_accuracy: 0.9709\n",
      "Epoch 138/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0943 - accuracy: 0.9636 - val_loss: 0.0775 - val_accuracy: 0.9709\n",
      "Epoch 139/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0567 - accuracy: 0.9788 - val_loss: 0.0749 - val_accuracy: 0.9723\n",
      "Epoch 140/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0998 - accuracy: 0.9599 - val_loss: 0.1917 - val_accuracy: 0.9246\n",
      "Epoch 141/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1050 - accuracy: 0.9573 - val_loss: 0.0799 - val_accuracy: 0.9702\n",
      "Epoch 142/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0834 - accuracy: 0.9674 - val_loss: 0.1092 - val_accuracy: 0.9579\n",
      "Epoch 143/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0747 - accuracy: 0.9711 - val_loss: 0.1281 - val_accuracy: 0.9512\n",
      "Epoch 144/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0823 - accuracy: 0.9684 - val_loss: 0.2689 - val_accuracy: 0.8765\n",
      "Epoch 145/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1109 - accuracy: 0.9536 - val_loss: 0.0773 - val_accuracy: 0.9740\n",
      "Epoch 146/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0706 - accuracy: 0.9741 - val_loss: 0.1060 - val_accuracy: 0.9614\n",
      "Epoch 147/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0670 - accuracy: 0.9751 - val_loss: 0.1137 - val_accuracy: 0.9579\n",
      "Epoch 148/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0693 - accuracy: 0.9728 - val_loss: 0.1302 - val_accuracy: 0.9488\n",
      "Epoch 149/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0987 - accuracy: 0.9614 - val_loss: 0.2451 - val_accuracy: 0.8878\n",
      "Epoch 150/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1164 - accuracy: 0.9517 - val_loss: 0.0954 - val_accuracy: 0.9649\n",
      "Epoch 151/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0665 - accuracy: 0.9748 - val_loss: 0.0832 - val_accuracy: 0.9709\n",
      "Epoch 152/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0920 - accuracy: 0.9640 - val_loss: 0.0796 - val_accuracy: 0.9702\n",
      "Epoch 153/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0522 - accuracy: 0.9821 - val_loss: 0.0792 - val_accuracy: 0.9737\n",
      "Epoch 154/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0710 - accuracy: 0.9729 - val_loss: 0.0749 - val_accuracy: 0.9726\n",
      "Epoch 155/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0568 - accuracy: 0.9781 - val_loss: 0.0825 - val_accuracy: 0.9719\n",
      "Epoch 156/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0493 - accuracy: 0.9821 - val_loss: 0.0702 - val_accuracy: 0.9776\n",
      "Epoch 157/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0895 - accuracy: 0.9661 - val_loss: 0.1122 - val_accuracy: 0.9576\n",
      "Epoch 158/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0783 - accuracy: 0.9693 - val_loss: 0.0943 - val_accuracy: 0.9660\n",
      "Epoch 159/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0749 - accuracy: 0.9725 - val_loss: 0.0778 - val_accuracy: 0.9712\n",
      "Epoch 160/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0556 - accuracy: 0.9797 - val_loss: 0.1690 - val_accuracy: 0.9386\n",
      "Epoch 161/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0606 - accuracy: 0.9778 - val_loss: 0.0845 - val_accuracy: 0.9765\n",
      "Epoch 162/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0714 - accuracy: 0.9718 - val_loss: 0.2164 - val_accuracy: 0.9288\n",
      "Epoch 163/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0590 - accuracy: 0.9780 - val_loss: 0.1409 - val_accuracy: 0.9562\n",
      "Epoch 164/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0685 - accuracy: 0.9741 - val_loss: 0.1622 - val_accuracy: 0.9505\n",
      "Epoch 165/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0631 - accuracy: 0.9773 - val_loss: 0.0922 - val_accuracy: 0.9688\n",
      "Epoch 166/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0631 - accuracy: 0.9763 - val_loss: 0.1078 - val_accuracy: 0.9642\n",
      "Epoch 167/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0771 - accuracy: 0.9704 - val_loss: 0.0755 - val_accuracy: 0.9776\n",
      "Epoch 168/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0566 - accuracy: 0.9793 - val_loss: 0.0942 - val_accuracy: 0.9653\n",
      "Epoch 169/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0497 - accuracy: 0.9817 - val_loss: 0.0840 - val_accuracy: 0.9740\n",
      "Epoch 170/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0746 - accuracy: 0.9711 - val_loss: 0.1565 - val_accuracy: 0.9435\n",
      "Epoch 171/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0620 - accuracy: 0.9766 - val_loss: 0.0820 - val_accuracy: 0.9726\n",
      "Epoch 172/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0523 - accuracy: 0.9808 - val_loss: 0.0986 - val_accuracy: 0.9646\n",
      "Epoch 173/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0469 - accuracy: 0.9826 - val_loss: 0.1012 - val_accuracy: 0.9677\n",
      "Epoch 174/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0756 - accuracy: 0.9722 - val_loss: 0.0810 - val_accuracy: 0.9740\n",
      "Epoch 175/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0592 - accuracy: 0.9791 - val_loss: 0.1040 - val_accuracy: 0.9635\n",
      "Epoch 176/500\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0467 - accuracy: 0.9823Restoring model weights from the end of the best epoch: 156.\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0470 - accuracy: 0.9822 - val_loss: 0.0769 - val_accuracy: 0.9758\n",
      "Epoch 176: early stopping\n",
      "Number of iterations 4\n",
      "F1-scores:  [0.9488095238095238, 0.7921036397285626, 0.9443099273607748, 0.9617224880382774]\n",
      "Average F1-Score 0.9117363947342846\n",
      "Std Dev F1-Score 0.06936508041019802\n",
      "Error bar F1-Score 0.03468254020509901\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 10ms/step - loss: 0.5066 - accuracy: 0.7223 - val_loss: 0.4275 - val_accuracy: 0.7489\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4125 - accuracy: 0.7875 - val_loss: 0.4397 - val_accuracy: 0.7766\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3859 - accuracy: 0.8076 - val_loss: 0.3744 - val_accuracy: 0.8032\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3789 - accuracy: 0.8154 - val_loss: 0.3676 - val_accuracy: 0.8222\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3688 - accuracy: 0.8224 - val_loss: 0.3479 - val_accuracy: 0.8348\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3713 - accuracy: 0.8206 - val_loss: 0.3551 - val_accuracy: 0.8306\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3552 - accuracy: 0.8321 - val_loss: 0.3510 - val_accuracy: 0.8457\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3493 - accuracy: 0.8354 - val_loss: 0.3466 - val_accuracy: 0.8394\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3504 - accuracy: 0.8368 - val_loss: 0.4401 - val_accuracy: 0.7710\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3459 - accuracy: 0.8385 - val_loss: 0.3196 - val_accuracy: 0.8481\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3548 - accuracy: 0.8321 - val_loss: 0.3507 - val_accuracy: 0.8527\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4036 - accuracy: 0.7973 - val_loss: 0.4131 - val_accuracy: 0.7888\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3652 - accuracy: 0.8235 - val_loss: 0.3554 - val_accuracy: 0.8253\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3488 - accuracy: 0.8340 - val_loss: 0.3382 - val_accuracy: 0.8408\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3479 - accuracy: 0.8360 - val_loss: 0.3366 - val_accuracy: 0.8429\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3386 - accuracy: 0.8403 - val_loss: 0.3344 - val_accuracy: 0.8404\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3340 - accuracy: 0.8416 - val_loss: 0.3824 - val_accuracy: 0.8218\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3265 - accuracy: 0.8475 - val_loss: 0.3226 - val_accuracy: 0.8506\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3239 - accuracy: 0.8465 - val_loss: 0.3057 - val_accuracy: 0.8590\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3186 - accuracy: 0.8493 - val_loss: 0.3059 - val_accuracy: 0.8604\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3170 - accuracy: 0.8521 - val_loss: 0.3216 - val_accuracy: 0.8562\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3108 - accuracy: 0.8558 - val_loss: 0.3863 - val_accuracy: 0.8232\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3088 - accuracy: 0.8553 - val_loss: 0.3044 - val_accuracy: 0.8643\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2987 - accuracy: 0.8622 - val_loss: 0.3161 - val_accuracy: 0.8548\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3075 - accuracy: 0.8563 - val_loss: 0.3450 - val_accuracy: 0.8320\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3291 - accuracy: 0.8441 - val_loss: 0.3038 - val_accuracy: 0.8667\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3022 - accuracy: 0.8619 - val_loss: 0.3211 - val_accuracy: 0.8513\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2973 - accuracy: 0.8619 - val_loss: 0.3198 - val_accuracy: 0.8534\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2891 - accuracy: 0.8666 - val_loss: 0.3063 - val_accuracy: 0.8600\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3078 - accuracy: 0.8597 - val_loss: 0.2967 - val_accuracy: 0.8657\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2881 - accuracy: 0.8659 - val_loss: 0.3092 - val_accuracy: 0.8586\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2863 - accuracy: 0.8694 - val_loss: 0.2850 - val_accuracy: 0.8702\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2932 - accuracy: 0.8626 - val_loss: 0.3347 - val_accuracy: 0.8516\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2889 - accuracy: 0.8682 - val_loss: 0.4204 - val_accuracy: 0.8330\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2752 - accuracy: 0.8766 - val_loss: 0.2583 - val_accuracy: 0.8804\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2691 - accuracy: 0.8774 - val_loss: 0.2608 - val_accuracy: 0.8772\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2624 - accuracy: 0.8815 - val_loss: 0.2661 - val_accuracy: 0.8832\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2626 - accuracy: 0.8817 - val_loss: 0.2426 - val_accuracy: 0.8923\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2568 - accuracy: 0.8837 - val_loss: 0.2461 - val_accuracy: 0.8892\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2523 - accuracy: 0.8857 - val_loss: 0.2572 - val_accuracy: 0.8835\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2490 - accuracy: 0.8870 - val_loss: 0.2624 - val_accuracy: 0.8835\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2378 - accuracy: 0.8932 - val_loss: 0.2339 - val_accuracy: 0.8976\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2384 - accuracy: 0.8934 - val_loss: 0.2641 - val_accuracy: 0.8779\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2351 - accuracy: 0.8956 - val_loss: 0.2071 - val_accuracy: 0.9116\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2231 - accuracy: 0.8995 - val_loss: 0.2435 - val_accuracy: 0.8860\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2272 - accuracy: 0.9004 - val_loss: 0.2381 - val_accuracy: 0.8965\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2134 - accuracy: 0.9073 - val_loss: 0.2074 - val_accuracy: 0.9095\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2108 - accuracy: 0.9077 - val_loss: 0.2510 - val_accuracy: 0.8906\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2030 - accuracy: 0.9124 - val_loss: 0.1819 - val_accuracy: 0.9235\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2018 - accuracy: 0.9096 - val_loss: 0.1893 - val_accuracy: 0.9200\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1901 - accuracy: 0.9189 - val_loss: 0.2332 - val_accuracy: 0.9025\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1852 - accuracy: 0.9202 - val_loss: 0.1710 - val_accuracy: 0.9274\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1706 - accuracy: 0.9260 - val_loss: 0.1593 - val_accuracy: 0.9355\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1730 - accuracy: 0.9272 - val_loss: 0.1570 - val_accuracy: 0.9372\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1741 - accuracy: 0.9253 - val_loss: 0.1827 - val_accuracy: 0.9274\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1620 - accuracy: 0.9307 - val_loss: 0.1318 - val_accuracy: 0.9488\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1575 - accuracy: 0.9346 - val_loss: 0.2167 - val_accuracy: 0.9049\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1506 - accuracy: 0.9373 - val_loss: 0.2044 - val_accuracy: 0.9148\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1417 - accuracy: 0.9419 - val_loss: 0.1233 - val_accuracy: 0.9502\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1418 - accuracy: 0.9425 - val_loss: 0.1225 - val_accuracy: 0.9502\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1397 - accuracy: 0.9428 - val_loss: 0.1887 - val_accuracy: 0.9169\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1374 - accuracy: 0.9447 - val_loss: 0.1412 - val_accuracy: 0.9376\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1262 - accuracy: 0.9499 - val_loss: 0.1289 - val_accuracy: 0.9477\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1304 - accuracy: 0.9467 - val_loss: 0.1364 - val_accuracy: 0.9383\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1277 - accuracy: 0.9491 - val_loss: 0.1357 - val_accuracy: 0.9425\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1202 - accuracy: 0.9520 - val_loss: 0.1152 - val_accuracy: 0.9512\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1135 - accuracy: 0.9541 - val_loss: 0.1570 - val_accuracy: 0.9369\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1127 - accuracy: 0.9557 - val_loss: 0.1272 - val_accuracy: 0.9491\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1210 - accuracy: 0.9511 - val_loss: 0.1369 - val_accuracy: 0.9418\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1139 - accuracy: 0.9542 - val_loss: 0.1260 - val_accuracy: 0.9505\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1096 - accuracy: 0.9566 - val_loss: 0.1232 - val_accuracy: 0.9495\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1053 - accuracy: 0.9589 - val_loss: 0.1793 - val_accuracy: 0.9144\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1023 - accuracy: 0.9597 - val_loss: 0.1544 - val_accuracy: 0.9376\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1095 - accuracy: 0.9554 - val_loss: 0.1078 - val_accuracy: 0.9544\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2420 - accuracy: 0.9003 - val_loss: 0.2154 - val_accuracy: 0.9035\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1686 - accuracy: 0.9280 - val_loss: 0.1772 - val_accuracy: 0.9277\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1347 - accuracy: 0.9451 - val_loss: 0.2196 - val_accuracy: 0.9155\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1314 - accuracy: 0.9465 - val_loss: 0.1995 - val_accuracy: 0.9113\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1233 - accuracy: 0.9483 - val_loss: 0.1190 - val_accuracy: 0.9505\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1197 - accuracy: 0.9525 - val_loss: 0.2019 - val_accuracy: 0.9186\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2106 - accuracy: 0.9090 - val_loss: 0.2651 - val_accuracy: 0.8776\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1790 - accuracy: 0.9235 - val_loss: 0.1650 - val_accuracy: 0.9323\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1323 - accuracy: 0.9453 - val_loss: 0.1421 - val_accuracy: 0.9425\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1149 - accuracy: 0.9539 - val_loss: 0.1243 - val_accuracy: 0.9488\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1057 - accuracy: 0.9579 - val_loss: 0.1099 - val_accuracy: 0.9600\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1034 - accuracy: 0.9596 - val_loss: 0.1098 - val_accuracy: 0.9565\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0977 - accuracy: 0.9628 - val_loss: 0.1127 - val_accuracy: 0.9548\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0923 - accuracy: 0.9643 - val_loss: 0.0916 - val_accuracy: 0.9670\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1131 - accuracy: 0.9563 - val_loss: 0.1163 - val_accuracy: 0.9544\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0892 - accuracy: 0.9648 - val_loss: 0.1326 - val_accuracy: 0.9467\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0915 - accuracy: 0.9643 - val_loss: 0.1147 - val_accuracy: 0.9530\n",
      "Epoch 92/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0942 - accuracy: 0.9643 - val_loss: 0.0986 - val_accuracy: 0.9628\n",
      "Epoch 93/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0774 - accuracy: 0.9701 - val_loss: 0.0904 - val_accuracy: 0.9653\n",
      "Epoch 94/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0915 - accuracy: 0.9649 - val_loss: 0.1221 - val_accuracy: 0.9530\n",
      "Epoch 95/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0806 - accuracy: 0.9695 - val_loss: 0.0977 - val_accuracy: 0.9646\n",
      "Epoch 96/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0709 - accuracy: 0.9734 - val_loss: 0.0958 - val_accuracy: 0.9646\n",
      "Epoch 97/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0844 - accuracy: 0.9672 - val_loss: 0.1332 - val_accuracy: 0.9491\n",
      "Epoch 98/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0674 - accuracy: 0.9750 - val_loss: 0.0792 - val_accuracy: 0.9695\n",
      "Epoch 99/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1014 - accuracy: 0.9606 - val_loss: 0.1134 - val_accuracy: 0.9586\n",
      "Epoch 100/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0878 - accuracy: 0.9672 - val_loss: 0.0811 - val_accuracy: 0.9733\n",
      "Epoch 101/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0684 - accuracy: 0.9740 - val_loss: 0.1150 - val_accuracy: 0.9544\n",
      "Epoch 102/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0717 - accuracy: 0.9728 - val_loss: 0.0834 - val_accuracy: 0.9702\n",
      "Epoch 103/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0739 - accuracy: 0.9729 - val_loss: 0.0878 - val_accuracy: 0.9674\n",
      "Epoch 104/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1285 - accuracy: 0.9486 - val_loss: 0.1201 - val_accuracy: 0.9548\n",
      "Epoch 105/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0967 - accuracy: 0.9621 - val_loss: 0.0940 - val_accuracy: 0.9639\n",
      "Epoch 106/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0893 - accuracy: 0.9664 - val_loss: 0.0955 - val_accuracy: 0.9660\n",
      "Epoch 107/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0827 - accuracy: 0.9681 - val_loss: 0.2606 - val_accuracy: 0.8976\n",
      "Epoch 108/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0721 - accuracy: 0.9720 - val_loss: 0.1019 - val_accuracy: 0.9600\n",
      "Epoch 109/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0669 - accuracy: 0.9759 - val_loss: 0.1739 - val_accuracy: 0.9435\n",
      "Epoch 110/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0761 - accuracy: 0.9719 - val_loss: 0.1667 - val_accuracy: 0.9386\n",
      "Epoch 111/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0734 - accuracy: 0.9729 - val_loss: 0.0875 - val_accuracy: 0.9695\n",
      "Epoch 112/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0668 - accuracy: 0.9748 - val_loss: 0.0794 - val_accuracy: 0.9723\n",
      "Epoch 113/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0689 - accuracy: 0.9740 - val_loss: 0.1093 - val_accuracy: 0.9618\n",
      "Epoch 114/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0630 - accuracy: 0.9771 - val_loss: 0.0692 - val_accuracy: 0.9744\n",
      "Epoch 115/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0784 - accuracy: 0.9707 - val_loss: 0.0738 - val_accuracy: 0.9709\n",
      "Epoch 116/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0556 - accuracy: 0.9794 - val_loss: 0.1065 - val_accuracy: 0.9621\n",
      "Epoch 117/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0674 - accuracy: 0.9746 - val_loss: 0.0810 - val_accuracy: 0.9712\n",
      "Epoch 118/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0701 - accuracy: 0.9737 - val_loss: 0.0825 - val_accuracy: 0.9705\n",
      "Epoch 119/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0624 - accuracy: 0.9783 - val_loss: 0.0736 - val_accuracy: 0.9744\n",
      "Epoch 120/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0742 - accuracy: 0.9709 - val_loss: 0.0729 - val_accuracy: 0.9730\n",
      "Epoch 121/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0519 - accuracy: 0.9807 - val_loss: 0.0738 - val_accuracy: 0.9744\n",
      "Epoch 122/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0551 - accuracy: 0.9796 - val_loss: 0.0994 - val_accuracy: 0.9604\n",
      "Epoch 123/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0557 - accuracy: 0.9795 - val_loss: 0.0811 - val_accuracy: 0.9705\n",
      "Epoch 124/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0592 - accuracy: 0.9782 - val_loss: 0.0677 - val_accuracy: 0.9776\n",
      "Epoch 125/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0539 - accuracy: 0.9802 - val_loss: 0.0781 - val_accuracy: 0.9712\n",
      "Epoch 126/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0516 - accuracy: 0.9807 - val_loss: 0.1304 - val_accuracy: 0.9541\n",
      "Epoch 127/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0575 - accuracy: 0.9787 - val_loss: 0.0986 - val_accuracy: 0.9660\n",
      "Epoch 128/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0782 - accuracy: 0.9720 - val_loss: 0.0728 - val_accuracy: 0.9740\n",
      "Epoch 129/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0515 - accuracy: 0.9811 - val_loss: 0.0806 - val_accuracy: 0.9723\n",
      "Epoch 130/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0576 - accuracy: 0.9785 - val_loss: 0.0785 - val_accuracy: 0.9723\n",
      "Epoch 131/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0620 - accuracy: 0.9762 - val_loss: 0.0844 - val_accuracy: 0.9716\n",
      "Epoch 132/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0475 - accuracy: 0.9829 - val_loss: 0.1002 - val_accuracy: 0.9618\n",
      "Epoch 133/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0486 - accuracy: 0.9823 - val_loss: 0.0928 - val_accuracy: 0.9674\n",
      "Epoch 134/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0514 - accuracy: 0.9811 - val_loss: 0.0688 - val_accuracy: 0.9744\n",
      "Epoch 135/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0522 - accuracy: 0.9807 - val_loss: 0.0682 - val_accuracy: 0.9804\n",
      "Epoch 136/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0396 - accuracy: 0.9850 - val_loss: 0.0856 - val_accuracy: 0.9695\n",
      "Epoch 137/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0511 - accuracy: 0.9804 - val_loss: 0.0947 - val_accuracy: 0.9656\n",
      "Epoch 138/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0592 - accuracy: 0.9784 - val_loss: 0.0738 - val_accuracy: 0.9712\n",
      "Epoch 139/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0482 - accuracy: 0.9831 - val_loss: 0.0991 - val_accuracy: 0.9663\n",
      "Epoch 140/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0357 - accuracy: 0.9872 - val_loss: 0.1098 - val_accuracy: 0.9621\n",
      "Epoch 141/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0445 - accuracy: 0.9842 - val_loss: 0.0713 - val_accuracy: 0.9744\n",
      "Epoch 142/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0501 - accuracy: 0.9822 - val_loss: 0.0787 - val_accuracy: 0.9751\n",
      "Epoch 143/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0502 - accuracy: 0.9824 - val_loss: 0.0682 - val_accuracy: 0.9747\n",
      "Epoch 144/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0387 - accuracy: 0.9861 - val_loss: 0.0805 - val_accuracy: 0.9740\n",
      "Epoch 145/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0371 - accuracy: 0.9858 - val_loss: 0.0879 - val_accuracy: 0.9709\n",
      "Epoch 146/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0496 - accuracy: 0.9815 - val_loss: 0.0971 - val_accuracy: 0.9653\n",
      "Epoch 147/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0386 - accuracy: 0.9861 - val_loss: 0.0838 - val_accuracy: 0.9695\n",
      "Epoch 148/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0421 - accuracy: 0.9851 - val_loss: 0.0693 - val_accuracy: 0.9772\n",
      "Epoch 149/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0403 - accuracy: 0.9861 - val_loss: 0.3156 - val_accuracy: 0.9102\n",
      "Epoch 150/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0476 - accuracy: 0.9822 - val_loss: 0.1132 - val_accuracy: 0.9642\n",
      "Epoch 151/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0450 - accuracy: 0.9845 - val_loss: 0.0737 - val_accuracy: 0.9790\n",
      "Epoch 152/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0480 - accuracy: 0.9818 - val_loss: 0.0751 - val_accuracy: 0.9751\n",
      "Epoch 153/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0455 - accuracy: 0.9841 - val_loss: 0.0905 - val_accuracy: 0.9740\n",
      "Epoch 154/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0350 - accuracy: 0.9871 - val_loss: 0.0825 - val_accuracy: 0.9730\n",
      "Epoch 155/500\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.0339 - accuracy: 0.9888Restoring model weights from the end of the best epoch: 135.\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0338 - accuracy: 0.9889 - val_loss: 0.0781 - val_accuracy: 0.9751\n",
      "Epoch 155: early stopping\n",
      "Number of iterations 5\n",
      "F1-scores:  [0.9488095238095238, 0.7921036397285626, 0.9443099273607748, 0.9617224880382774, 0.9666269368295589]\n",
      "Average F1-Score 0.9227145031533395\n",
      "Std Dev F1-Score 0.06581251371960109\n",
      "Error bar F1-Score 0.029432250889433114\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 10ms/step - loss: 0.5258 - accuracy: 0.7136 - val_loss: 0.4391 - val_accuracy: 0.7892\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4064 - accuracy: 0.7945 - val_loss: 0.4314 - val_accuracy: 0.7566\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3847 - accuracy: 0.8081 - val_loss: 0.3741 - val_accuracy: 0.8173\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3663 - accuracy: 0.8227 - val_loss: 0.3768 - val_accuracy: 0.8190\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3801 - accuracy: 0.8123 - val_loss: 0.3633 - val_accuracy: 0.8267\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3732 - accuracy: 0.8208 - val_loss: 0.3584 - val_accuracy: 0.8285\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3696 - accuracy: 0.8193 - val_loss: 0.3524 - val_accuracy: 0.8337\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3670 - accuracy: 0.8224 - val_loss: 0.3755 - val_accuracy: 0.8246\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3734 - accuracy: 0.8181 - val_loss: 0.3564 - val_accuracy: 0.8246\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3593 - accuracy: 0.8228 - val_loss: 0.3636 - val_accuracy: 0.8246\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3658 - accuracy: 0.8210 - val_loss: 0.3551 - val_accuracy: 0.8320\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3633 - accuracy: 0.8235 - val_loss: 0.3544 - val_accuracy: 0.8408\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3449 - accuracy: 0.8355 - val_loss: 0.3409 - val_accuracy: 0.8408\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3494 - accuracy: 0.8321 - val_loss: 0.3534 - val_accuracy: 0.8369\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3410 - accuracy: 0.8399 - val_loss: 0.3482 - val_accuracy: 0.8369\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3375 - accuracy: 0.8418 - val_loss: 0.3353 - val_accuracy: 0.8457\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3322 - accuracy: 0.8408 - val_loss: 0.3499 - val_accuracy: 0.8401\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3331 - accuracy: 0.8423 - val_loss: 0.3625 - val_accuracy: 0.8281\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3255 - accuracy: 0.8470 - val_loss: 0.3162 - val_accuracy: 0.8537\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3259 - accuracy: 0.8491 - val_loss: 0.3340 - val_accuracy: 0.8415\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3170 - accuracy: 0.8509 - val_loss: 0.3173 - val_accuracy: 0.8562\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3170 - accuracy: 0.8521 - val_loss: 0.2988 - val_accuracy: 0.8639\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3125 - accuracy: 0.8556 - val_loss: 0.3085 - val_accuracy: 0.8615\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3210 - accuracy: 0.8470 - val_loss: 0.3023 - val_accuracy: 0.8597\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3020 - accuracy: 0.8603 - val_loss: 0.3591 - val_accuracy: 0.8264\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4202 - accuracy: 0.7848 - val_loss: 0.3905 - val_accuracy: 0.8180\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3293 - accuracy: 0.8432 - val_loss: 0.3723 - val_accuracy: 0.8260\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3024 - accuracy: 0.8588 - val_loss: 0.3743 - val_accuracy: 0.8236\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3423 - accuracy: 0.8440 - val_loss: 0.6087 - val_accuracy: 0.7124\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.6001 - accuracy: 0.7140 - val_loss: 0.5999 - val_accuracy: 0.7124\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5990 - accuracy: 0.7140 - val_loss: 0.5996 - val_accuracy: 0.7124\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5998 - accuracy: 0.7140 - val_loss: 0.6007 - val_accuracy: 0.7124\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5994 - accuracy: 0.7140 - val_loss: 0.6002 - val_accuracy: 0.7124\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5988 - accuracy: 0.7140 - val_loss: 0.5997 - val_accuracy: 0.7124\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5985 - accuracy: 0.7140 - val_loss: 0.5997 - val_accuracy: 0.7124\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5986 - accuracy: 0.7140 - val_loss: 0.6015 - val_accuracy: 0.7124\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5985 - accuracy: 0.7140 - val_loss: 0.5998 - val_accuracy: 0.7124\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5986 - accuracy: 0.7140 - val_loss: 0.5992 - val_accuracy: 0.7124\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5980 - accuracy: 0.7140 - val_loss: 0.5973 - val_accuracy: 0.7124\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5964 - accuracy: 0.7140 - val_loss: 0.5992 - val_accuracy: 0.7124\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5927 - accuracy: 0.7137 - val_loss: 0.5990 - val_accuracy: 0.7124\n",
      "Epoch 42/500\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.5192 - accuracy: 0.7188Restoring model weights from the end of the best epoch: 22.\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5191 - accuracy: 0.7185 - val_loss: 0.4723 - val_accuracy: 0.7489\n",
      "Epoch 42: early stopping\n",
      "Number of iterations 6\n",
      "F1-scores:  [0.9488095238095238, 0.7921036397285626, 0.9443099273607748, 0.9617224880382774, 0.9666269368295589, 0.7578027465667916]\n",
      "Average F1-Score 0.8952292103889148\n",
      "Std Dev F1-Score 0.08594540356222997\n",
      "Error bar F1-Score 0.035087064077507196\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 10ms/step - loss: 0.5457 - accuracy: 0.7091 - val_loss: 0.4360 - val_accuracy: 0.7713\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3962 - accuracy: 0.8017 - val_loss: 0.3793 - val_accuracy: 0.8109\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3715 - accuracy: 0.8161 - val_loss: 0.3813 - val_accuracy: 0.8127\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3701 - accuracy: 0.8194 - val_loss: 0.3728 - val_accuracy: 0.8176\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3597 - accuracy: 0.8246 - val_loss: 0.3571 - val_accuracy: 0.8278\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3563 - accuracy: 0.8289 - val_loss: 0.3662 - val_accuracy: 0.8194\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3557 - accuracy: 0.8292 - val_loss: 0.3528 - val_accuracy: 0.8323\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3483 - accuracy: 0.8322 - val_loss: 0.3563 - val_accuracy: 0.8376\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3388 - accuracy: 0.8388 - val_loss: 0.3306 - val_accuracy: 0.8401\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.3377 - accuracy: 0.8398 - val_loss: 0.3245 - val_accuracy: 0.8429\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3455 - accuracy: 0.8366 - val_loss: 0.3290 - val_accuracy: 0.8446\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3186 - accuracy: 0.8499 - val_loss: 0.3160 - val_accuracy: 0.8520\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3197 - accuracy: 0.8490 - val_loss: 0.3161 - val_accuracy: 0.8590\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3167 - accuracy: 0.8515 - val_loss: 0.3091 - val_accuracy: 0.8537\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3109 - accuracy: 0.8540 - val_loss: 0.2992 - val_accuracy: 0.8643\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3036 - accuracy: 0.8581 - val_loss: 0.3387 - val_accuracy: 0.8404\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3091 - accuracy: 0.8536 - val_loss: 0.3063 - val_accuracy: 0.8572\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3228 - accuracy: 0.8459 - val_loss: 0.3029 - val_accuracy: 0.8600\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5289 - accuracy: 0.7346 - val_loss: 0.4924 - val_accuracy: 0.7124\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5476 - accuracy: 0.7278 - val_loss: 0.5802 - val_accuracy: 0.7124\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4950 - accuracy: 0.7204 - val_loss: 0.4817 - val_accuracy: 0.7629\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4142 - accuracy: 0.7926 - val_loss: 0.3886 - val_accuracy: 0.8260\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3971 - accuracy: 0.8107 - val_loss: 0.4599 - val_accuracy: 0.7615\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3875 - accuracy: 0.8195 - val_loss: 0.3660 - val_accuracy: 0.8436\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3769 - accuracy: 0.8227 - val_loss: 0.3862 - val_accuracy: 0.8155\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3642 - accuracy: 0.8309 - val_loss: 0.3628 - val_accuracy: 0.8348\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3725 - accuracy: 0.8267 - val_loss: 0.4147 - val_accuracy: 0.7924\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3550 - accuracy: 0.8341 - val_loss: 0.3396 - val_accuracy: 0.8471\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3655 - accuracy: 0.8290 - val_loss: 0.3605 - val_accuracy: 0.8208\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3401 - accuracy: 0.8403 - val_loss: 0.3680 - val_accuracy: 0.8211\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3554 - accuracy: 0.8360 - val_loss: 0.4149 - val_accuracy: 0.8004\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3491 - accuracy: 0.8379 - val_loss: 0.3382 - val_accuracy: 0.8358\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3423 - accuracy: 0.8407 - val_loss: 0.3504 - val_accuracy: 0.8344\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3304 - accuracy: 0.8471 - val_loss: 0.3379 - val_accuracy: 0.8401\n",
      "Epoch 35/500\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.3427 - accuracy: 0.8385Restoring model weights from the end of the best epoch: 15.\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3413 - accuracy: 0.8393 - val_loss: 0.3443 - val_accuracy: 0.8334\n",
      "Epoch 35: early stopping\n",
      "Number of iterations 7\n",
      "F1-scores:  [0.9488095238095238, 0.7921036397285626, 0.9443099273607748, 0.9617224880382774, 0.9666269368295589, 0.7578027465667916, 0.7397444519166106]\n",
      "Average F1-Score 0.8730171020357285\n",
      "Std Dev F1-Score 0.09639319787470363\n",
      "Error bar F1-Score 0.03643320423638652\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 10ms/step - loss: 0.5308 - accuracy: 0.7266 - val_loss: 0.4177 - val_accuracy: 0.7832\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4055 - accuracy: 0.7920 - val_loss: 0.4562 - val_accuracy: 0.7590\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3838 - accuracy: 0.8103 - val_loss: 0.4041 - val_accuracy: 0.7769\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3788 - accuracy: 0.8104 - val_loss: 0.3961 - val_accuracy: 0.8029\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5366 - accuracy: 0.7382 - val_loss: 0.6017 - val_accuracy: 0.7124\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5946 - accuracy: 0.7140 - val_loss: 0.5856 - val_accuracy: 0.7124\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5921 - accuracy: 0.7140 - val_loss: 0.5994 - val_accuracy: 0.7124\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5927 - accuracy: 0.7113 - val_loss: 0.5967 - val_accuracy: 0.7124\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5891 - accuracy: 0.7140 - val_loss: 0.5834 - val_accuracy: 0.7124\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.5793 - accuracy: 0.7140 - val_loss: 0.5575 - val_accuracy: 0.7124\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5800 - accuracy: 0.7140 - val_loss: 0.5728 - val_accuracy: 0.7124\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5488 - accuracy: 0.7126 - val_loss: 0.5864 - val_accuracy: 0.7124\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4203 - accuracy: 0.7784 - val_loss: 0.4630 - val_accuracy: 0.7282\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3827 - accuracy: 0.8089 - val_loss: 0.3657 - val_accuracy: 0.8162\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3698 - accuracy: 0.8198 - val_loss: 0.3693 - val_accuracy: 0.8057\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3632 - accuracy: 0.8233 - val_loss: 0.3509 - val_accuracy: 0.8246\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3600 - accuracy: 0.8265 - val_loss: 0.3486 - val_accuracy: 0.8299\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3514 - accuracy: 0.8330 - val_loss: 0.3498 - val_accuracy: 0.8316\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3583 - accuracy: 0.8261 - val_loss: 0.3489 - val_accuracy: 0.8316\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3500 - accuracy: 0.8340 - val_loss: 0.4386 - val_accuracy: 0.7580\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3552 - accuracy: 0.8316 - val_loss: 0.3625 - val_accuracy: 0.8215\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3489 - accuracy: 0.8318 - val_loss: 0.3519 - val_accuracy: 0.8355\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3474 - accuracy: 0.8358 - val_loss: 0.3660 - val_accuracy: 0.8278\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3437 - accuracy: 0.8352 - val_loss: 0.3402 - val_accuracy: 0.8394\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3397 - accuracy: 0.8404 - val_loss: 0.3315 - val_accuracy: 0.8422\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3360 - accuracy: 0.8421 - val_loss: 0.3296 - val_accuracy: 0.8471\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3439 - accuracy: 0.8374 - val_loss: 0.3368 - val_accuracy: 0.8415\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3341 - accuracy: 0.8449 - val_loss: 0.3317 - val_accuracy: 0.8425\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3362 - accuracy: 0.8433 - val_loss: 0.3415 - val_accuracy: 0.8439\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3302 - accuracy: 0.8445 - val_loss: 0.3246 - val_accuracy: 0.8551\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3266 - accuracy: 0.8477 - val_loss: 0.3558 - val_accuracy: 0.8309\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3186 - accuracy: 0.8514 - val_loss: 0.3067 - val_accuracy: 0.8625\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3229 - accuracy: 0.8509 - val_loss: 0.3414 - val_accuracy: 0.8401\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3093 - accuracy: 0.8570 - val_loss: 0.3319 - val_accuracy: 0.8499\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3097 - accuracy: 0.8591 - val_loss: 0.3430 - val_accuracy: 0.8411\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3181 - accuracy: 0.8535 - val_loss: 0.3849 - val_accuracy: 0.8257\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3027 - accuracy: 0.8610 - val_loss: 0.3430 - val_accuracy: 0.8422\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3000 - accuracy: 0.8623 - val_loss: 0.3216 - val_accuracy: 0.8590\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2951 - accuracy: 0.8650 - val_loss: 0.2860 - val_accuracy: 0.8744\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3209 - accuracy: 0.8503 - val_loss: 0.2785 - val_accuracy: 0.8783\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3070 - accuracy: 0.8583 - val_loss: 0.3158 - val_accuracy: 0.8509\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3062 - accuracy: 0.8581 - val_loss: 0.2946 - val_accuracy: 0.8681\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2882 - accuracy: 0.8685 - val_loss: 0.2984 - val_accuracy: 0.8664\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2872 - accuracy: 0.8673 - val_loss: 0.2869 - val_accuracy: 0.8709\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2889 - accuracy: 0.8649 - val_loss: 0.2865 - val_accuracy: 0.8776\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2847 - accuracy: 0.8693 - val_loss: 0.2772 - val_accuracy: 0.8769\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3101 - accuracy: 0.8561 - val_loss: 0.3291 - val_accuracy: 0.8499\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3024 - accuracy: 0.8620 - val_loss: 0.3219 - val_accuracy: 0.8488\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2921 - accuracy: 0.8674 - val_loss: 0.3123 - val_accuracy: 0.8590\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2874 - accuracy: 0.8687 - val_loss: 0.3047 - val_accuracy: 0.8674\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3039 - accuracy: 0.8585 - val_loss: 0.2740 - val_accuracy: 0.8800\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2929 - accuracy: 0.8662 - val_loss: 0.2734 - val_accuracy: 0.8804\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2875 - accuracy: 0.8664 - val_loss: 0.3076 - val_accuracy: 0.8544\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2882 - accuracy: 0.8679 - val_loss: 0.2882 - val_accuracy: 0.8699\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2788 - accuracy: 0.8719 - val_loss: 0.3302 - val_accuracy: 0.8450\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2827 - accuracy: 0.8698 - val_loss: 0.3754 - val_accuracy: 0.8225\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2905 - accuracy: 0.8653 - val_loss: 0.2749 - val_accuracy: 0.8748\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2836 - accuracy: 0.8698 - val_loss: 0.2901 - val_accuracy: 0.8681\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3031 - accuracy: 0.8594 - val_loss: 0.2948 - val_accuracy: 0.8699\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2743 - accuracy: 0.8744 - val_loss: 0.2697 - val_accuracy: 0.8825\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2793 - accuracy: 0.8702 - val_loss: 0.2946 - val_accuracy: 0.8657\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2818 - accuracy: 0.8703 - val_loss: 0.2682 - val_accuracy: 0.8828\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2677 - accuracy: 0.8756 - val_loss: 0.2886 - val_accuracy: 0.8727\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5548 - accuracy: 0.7368 - val_loss: 0.5996 - val_accuracy: 0.7124\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5984 - accuracy: 0.7140 - val_loss: 0.5994 - val_accuracy: 0.7124\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5979 - accuracy: 0.7140 - val_loss: 0.5993 - val_accuracy: 0.7124\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5970 - accuracy: 0.7140 - val_loss: 0.5971 - val_accuracy: 0.7124\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5953 - accuracy: 0.7140 - val_loss: 0.5914 - val_accuracy: 0.7124\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5878 - accuracy: 0.7140 - val_loss: 0.5811 - val_accuracy: 0.7124\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5679 - accuracy: 0.7139 - val_loss: 0.5599 - val_accuracy: 0.7124\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5157 - accuracy: 0.7224 - val_loss: 0.4620 - val_accuracy: 0.7166\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4140 - accuracy: 0.7949 - val_loss: 0.3299 - val_accuracy: 0.8636\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3749 - accuracy: 0.8180 - val_loss: 0.3842 - val_accuracy: 0.8088\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3414 - accuracy: 0.8445 - val_loss: 0.3188 - val_accuracy: 0.8597\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3306 - accuracy: 0.8500 - val_loss: 0.3478 - val_accuracy: 0.8390\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3139 - accuracy: 0.8563 - val_loss: 0.3015 - val_accuracy: 0.8643\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3431 - accuracy: 0.8359 - val_loss: 0.3530 - val_accuracy: 0.8387\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3185 - accuracy: 0.8505 - val_loss: 0.2959 - val_accuracy: 0.8646\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3063 - accuracy: 0.8563 - val_loss: 0.3075 - val_accuracy: 0.8604\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3003 - accuracy: 0.8595 - val_loss: 0.2910 - val_accuracy: 0.8695\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3022 - accuracy: 0.8599 - val_loss: 0.2921 - val_accuracy: 0.8709\n",
      "Epoch 82/500\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.2939 - accuracy: 0.8625Restoring model weights from the end of the best epoch: 62.\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.2942 - accuracy: 0.8625 - val_loss: 0.3186 - val_accuracy: 0.8541\n",
      "Epoch 82: early stopping\n",
      "Number of iterations 8\n",
      "F1-scores:  [0.9488095238095238, 0.7921036397285626, 0.9443099273607748, 0.9617224880382774, 0.9666269368295589, 0.7578027465667916, 0.7397444519166106, 0.788607594936709]\n",
      "Average F1-Score 0.8624659136483511\n",
      "Std Dev F1-Score 0.09439007128214968\n",
      "Error bar F1-Score 0.033371929740144815\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 10ms/step - loss: 0.4905 - accuracy: 0.7544 - val_loss: 0.3934 - val_accuracy: 0.8029\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3823 - accuracy: 0.8131 - val_loss: 0.3890 - val_accuracy: 0.8116\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3847 - accuracy: 0.8137 - val_loss: 0.3825 - val_accuracy: 0.8225\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3738 - accuracy: 0.8212 - val_loss: 0.3622 - val_accuracy: 0.8250\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3686 - accuracy: 0.8242 - val_loss: 0.3833 - val_accuracy: 0.8141\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3704 - accuracy: 0.8259 - val_loss: 0.3579 - val_accuracy: 0.8271\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3630 - accuracy: 0.8284 - val_loss: 0.3571 - val_accuracy: 0.8267\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3594 - accuracy: 0.8303 - val_loss: 0.5015 - val_accuracy: 0.7268\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3595 - accuracy: 0.8317 - val_loss: 0.3604 - val_accuracy: 0.8288\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3524 - accuracy: 0.8360 - val_loss: 0.3754 - val_accuracy: 0.8092\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3579 - accuracy: 0.8328 - val_loss: 0.3429 - val_accuracy: 0.8418\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3476 - accuracy: 0.8379 - val_loss: 0.3512 - val_accuracy: 0.8425\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3471 - accuracy: 0.8388 - val_loss: 0.4084 - val_accuracy: 0.7952\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3459 - accuracy: 0.8406 - val_loss: 0.3321 - val_accuracy: 0.8534\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3339 - accuracy: 0.8473 - val_loss: 0.3255 - val_accuracy: 0.8499\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3363 - accuracy: 0.8446 - val_loss: 0.3440 - val_accuracy: 0.8464\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3266 - accuracy: 0.8497 - val_loss: 0.3399 - val_accuracy: 0.8387\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3237 - accuracy: 0.8509 - val_loss: 0.3240 - val_accuracy: 0.8450\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3178 - accuracy: 0.8547 - val_loss: 0.3237 - val_accuracy: 0.8551\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3165 - accuracy: 0.8548 - val_loss: 0.3088 - val_accuracy: 0.8646\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3161 - accuracy: 0.8553 - val_loss: 0.3161 - val_accuracy: 0.8541\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3176 - accuracy: 0.8521 - val_loss: 0.3206 - val_accuracy: 0.8551\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3072 - accuracy: 0.8611 - val_loss: 0.3294 - val_accuracy: 0.8471\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3101 - accuracy: 0.8578 - val_loss: 0.3384 - val_accuracy: 0.8576\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2984 - accuracy: 0.8675 - val_loss: 0.2867 - val_accuracy: 0.8727\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2969 - accuracy: 0.8632 - val_loss: 0.2902 - val_accuracy: 0.8709\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2939 - accuracy: 0.8655 - val_loss: 0.3341 - val_accuracy: 0.8418\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2885 - accuracy: 0.8657 - val_loss: 0.3163 - val_accuracy: 0.8572\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2843 - accuracy: 0.8681 - val_loss: 0.2757 - val_accuracy: 0.8748\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2680 - accuracy: 0.8769 - val_loss: 0.3051 - val_accuracy: 0.8593\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2570 - accuracy: 0.8853 - val_loss: 0.2548 - val_accuracy: 0.8828\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2505 - accuracy: 0.8886 - val_loss: 0.2552 - val_accuracy: 0.8839\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2430 - accuracy: 0.8912 - val_loss: 0.2561 - val_accuracy: 0.8899\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2406 - accuracy: 0.8932 - val_loss: 0.2460 - val_accuracy: 0.8955\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2464 - accuracy: 0.8897 - val_loss: 0.2358 - val_accuracy: 0.8972\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2218 - accuracy: 0.9020 - val_loss: 0.2368 - val_accuracy: 0.8948\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2199 - accuracy: 0.9039 - val_loss: 0.2257 - val_accuracy: 0.9071\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2136 - accuracy: 0.9057 - val_loss: 0.2174 - val_accuracy: 0.9018\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2050 - accuracy: 0.9127 - val_loss: 0.2125 - val_accuracy: 0.9106\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2001 - accuracy: 0.9135 - val_loss: 0.2021 - val_accuracy: 0.9120\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2074 - accuracy: 0.9111 - val_loss: 0.1956 - val_accuracy: 0.9190\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1845 - accuracy: 0.9209 - val_loss: 0.1683 - val_accuracy: 0.9267\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2012 - accuracy: 0.9144 - val_loss: 0.2216 - val_accuracy: 0.9032\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1727 - accuracy: 0.9299 - val_loss: 0.2417 - val_accuracy: 0.8895\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1687 - accuracy: 0.9294 - val_loss: 0.1485 - val_accuracy: 0.9369\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1633 - accuracy: 0.9327 - val_loss: 0.1570 - val_accuracy: 0.9379\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1691 - accuracy: 0.9294 - val_loss: 0.2235 - val_accuracy: 0.9021\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1460 - accuracy: 0.9419 - val_loss: 0.1724 - val_accuracy: 0.9260\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1532 - accuracy: 0.9366 - val_loss: 0.2263 - val_accuracy: 0.8972\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1422 - accuracy: 0.9418 - val_loss: 0.1307 - val_accuracy: 0.9484\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1508 - accuracy: 0.9397 - val_loss: 0.1396 - val_accuracy: 0.9456\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1385 - accuracy: 0.9431 - val_loss: 0.2151 - val_accuracy: 0.9106\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1372 - accuracy: 0.9446 - val_loss: 0.1412 - val_accuracy: 0.9446\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1385 - accuracy: 0.9454 - val_loss: 0.1964 - val_accuracy: 0.9134\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1360 - accuracy: 0.9464 - val_loss: 0.1242 - val_accuracy: 0.9537\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1405 - accuracy: 0.9448 - val_loss: 0.1400 - val_accuracy: 0.9449\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1206 - accuracy: 0.9516 - val_loss: 0.1345 - val_accuracy: 0.9477\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1214 - accuracy: 0.9525 - val_loss: 0.1717 - val_accuracy: 0.9249\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1313 - accuracy: 0.9491 - val_loss: 0.1689 - val_accuracy: 0.9302\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1109 - accuracy: 0.9574 - val_loss: 0.1154 - val_accuracy: 0.9576\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1264 - accuracy: 0.9492 - val_loss: 0.2371 - val_accuracy: 0.8927\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1241 - accuracy: 0.9504 - val_loss: 0.1415 - val_accuracy: 0.9467\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1192 - accuracy: 0.9523 - val_loss: 0.1178 - val_accuracy: 0.9558\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0990 - accuracy: 0.9619 - val_loss: 0.1085 - val_accuracy: 0.9607\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1058 - accuracy: 0.9583 - val_loss: 0.1056 - val_accuracy: 0.9586\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1120 - accuracy: 0.9584 - val_loss: 0.1539 - val_accuracy: 0.9390\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1076 - accuracy: 0.9590 - val_loss: 0.2066 - val_accuracy: 0.9155\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1016 - accuracy: 0.9590 - val_loss: 0.1787 - val_accuracy: 0.9288\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1101 - accuracy: 0.9576 - val_loss: 0.0953 - val_accuracy: 0.9649\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0951 - accuracy: 0.9636 - val_loss: 0.1091 - val_accuracy: 0.9583\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0974 - accuracy: 0.9628 - val_loss: 0.1519 - val_accuracy: 0.9372\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0983 - accuracy: 0.9616 - val_loss: 0.1277 - val_accuracy: 0.9516\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0975 - accuracy: 0.9626 - val_loss: 0.1731 - val_accuracy: 0.9253\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0959 - accuracy: 0.9631 - val_loss: 0.1189 - val_accuracy: 0.9533\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0889 - accuracy: 0.9654 - val_loss: 0.1060 - val_accuracy: 0.9614\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0976 - accuracy: 0.9626 - val_loss: 0.1861 - val_accuracy: 0.9186\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0863 - accuracy: 0.9665 - val_loss: 0.1125 - val_accuracy: 0.9565\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1107 - accuracy: 0.9585 - val_loss: 0.1206 - val_accuracy: 0.9548\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0947 - accuracy: 0.9636 - val_loss: 0.1110 - val_accuracy: 0.9555\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0875 - accuracy: 0.9667 - val_loss: 0.1109 - val_accuracy: 0.9586\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0970 - accuracy: 0.9624 - val_loss: 0.1065 - val_accuracy: 0.9586\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0853 - accuracy: 0.9665 - val_loss: 0.0903 - val_accuracy: 0.9667\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0923 - accuracy: 0.9647 - val_loss: 0.0852 - val_accuracy: 0.9695\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0726 - accuracy: 0.9718 - val_loss: 0.1528 - val_accuracy: 0.9435\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0807 - accuracy: 0.9691 - val_loss: 0.1102 - val_accuracy: 0.9628\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0723 - accuracy: 0.9735 - val_loss: 0.1315 - val_accuracy: 0.9481\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0880 - accuracy: 0.9659 - val_loss: 0.0883 - val_accuracy: 0.9702\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0880 - accuracy: 0.9657 - val_loss: 0.1170 - val_accuracy: 0.9579\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0852 - accuracy: 0.9683 - val_loss: 0.0965 - val_accuracy: 0.9656\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0652 - accuracy: 0.9756 - val_loss: 0.0842 - val_accuracy: 0.9716\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0874 - accuracy: 0.9661 - val_loss: 0.1022 - val_accuracy: 0.9600\n",
      "Epoch 92/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0902 - accuracy: 0.9649 - val_loss: 0.1234 - val_accuracy: 0.9526\n",
      "Epoch 93/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0735 - accuracy: 0.9725 - val_loss: 0.1124 - val_accuracy: 0.9590\n",
      "Epoch 94/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0781 - accuracy: 0.9705 - val_loss: 0.1173 - val_accuracy: 0.9558\n",
      "Epoch 95/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0704 - accuracy: 0.9740 - val_loss: 0.0957 - val_accuracy: 0.9670\n",
      "Epoch 96/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0692 - accuracy: 0.9748 - val_loss: 0.0891 - val_accuracy: 0.9663\n",
      "Epoch 97/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0783 - accuracy: 0.9701 - val_loss: 0.1732 - val_accuracy: 0.9397\n",
      "Epoch 98/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0718 - accuracy: 0.9739 - val_loss: 0.0995 - val_accuracy: 0.9674\n",
      "Epoch 99/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0690 - accuracy: 0.9739 - val_loss: 0.1060 - val_accuracy: 0.9572\n",
      "Epoch 100/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0860 - accuracy: 0.9660 - val_loss: 0.0954 - val_accuracy: 0.9656\n",
      "Epoch 101/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0749 - accuracy: 0.9704 - val_loss: 0.0952 - val_accuracy: 0.9660\n",
      "Epoch 102/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0628 - accuracy: 0.9778 - val_loss: 0.0876 - val_accuracy: 0.9639\n",
      "Epoch 103/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0670 - accuracy: 0.9751 - val_loss: 0.0927 - val_accuracy: 0.9660\n",
      "Epoch 104/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0637 - accuracy: 0.9766 - val_loss: 0.1142 - val_accuracy: 0.9579\n",
      "Epoch 105/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0717 - accuracy: 0.9729 - val_loss: 0.1035 - val_accuracy: 0.9600\n",
      "Epoch 106/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0735 - accuracy: 0.9718 - val_loss: 0.0869 - val_accuracy: 0.9653\n",
      "Epoch 107/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0615 - accuracy: 0.9772 - val_loss: 0.2329 - val_accuracy: 0.9204\n",
      "Epoch 108/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0736 - accuracy: 0.9729 - val_loss: 0.1434 - val_accuracy: 0.9400\n",
      "Epoch 109/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0667 - accuracy: 0.9753 - val_loss: 0.0933 - val_accuracy: 0.9660\n",
      "Epoch 110/500\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.0536 - accuracy: 0.9807Restoring model weights from the end of the best epoch: 90.\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0539 - accuracy: 0.9806 - val_loss: 0.0877 - val_accuracy: 0.9670\n",
      "Epoch 110: early stopping\n",
      "Number of iterations 9\n",
      "F1-scores:  [0.9488095238095238, 0.7921036397285626, 0.9443099273607748, 0.9617224880382774, 0.9666269368295589, 0.7578027465667916, 0.7397444519166106, 0.788607594936709, 0.9519287833827893]\n",
      "Average F1-Score 0.8724062325077332\n",
      "Std Dev F1-Score 0.09332749985524677\n",
      "Error bar F1-Score 0.03110916661841559\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 10ms/step - loss: 0.5293 - accuracy: 0.7056 - val_loss: 0.4513 - val_accuracy: 0.7096\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4048 - accuracy: 0.7936 - val_loss: 0.3806 - val_accuracy: 0.8092\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3765 - accuracy: 0.8118 - val_loss: 0.3697 - val_accuracy: 0.8222\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3723 - accuracy: 0.8153 - val_loss: 0.4115 - val_accuracy: 0.7783\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3654 - accuracy: 0.8203 - val_loss: 0.3626 - val_accuracy: 0.8232\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3654 - accuracy: 0.8204 - val_loss: 0.3621 - val_accuracy: 0.8239\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3615 - accuracy: 0.8255 - val_loss: 0.3521 - val_accuracy: 0.8320\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3697 - accuracy: 0.8217 - val_loss: 0.6067 - val_accuracy: 0.7124\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.6001 - accuracy: 0.7140 - val_loss: 0.6014 - val_accuracy: 0.7124\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5989 - accuracy: 0.7140 - val_loss: 0.5999 - val_accuracy: 0.7124\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5989 - accuracy: 0.7140 - val_loss: 0.6000 - val_accuracy: 0.7124\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5990 - accuracy: 0.7140 - val_loss: 0.5999 - val_accuracy: 0.7124\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5986 - accuracy: 0.7140 - val_loss: 0.5997 - val_accuracy: 0.7124\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.5986 - accuracy: 0.7140 - val_loss: 0.6020 - val_accuracy: 0.7124\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5987 - accuracy: 0.7140 - val_loss: 0.5999 - val_accuracy: 0.7124\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5985 - accuracy: 0.7140 - val_loss: 0.6030 - val_accuracy: 0.7124\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5984 - accuracy: 0.7140 - val_loss: 0.5982 - val_accuracy: 0.7124\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5984 - accuracy: 0.7140 - val_loss: 0.6000 - val_accuracy: 0.7124\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5982 - accuracy: 0.7140 - val_loss: 0.5983 - val_accuracy: 0.7124\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5961 - accuracy: 0.7140 - val_loss: 0.5959 - val_accuracy: 0.7124\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5552 - accuracy: 0.7034 - val_loss: 0.5100 - val_accuracy: 0.6612\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5210 - accuracy: 0.7061 - val_loss: 0.4936 - val_accuracy: 0.7124\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4461 - accuracy: 0.7561 - val_loss: 0.3883 - val_accuracy: 0.8008\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3838 - accuracy: 0.8068 - val_loss: 0.3531 - val_accuracy: 0.8330\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3659 - accuracy: 0.8195 - val_loss: 0.3568 - val_accuracy: 0.8365\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3468 - accuracy: 0.8323 - val_loss: 0.3481 - val_accuracy: 0.8383\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3487 - accuracy: 0.8334 - val_loss: 0.3359 - val_accuracy: 0.8365\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3352 - accuracy: 0.8403 - val_loss: 0.3601 - val_accuracy: 0.8302\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3302 - accuracy: 0.8427 - val_loss: 0.3247 - val_accuracy: 0.8495\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3240 - accuracy: 0.8471 - val_loss: 0.3379 - val_accuracy: 0.8439\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3186 - accuracy: 0.8491 - val_loss: 0.3132 - val_accuracy: 0.8597\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3182 - accuracy: 0.8513 - val_loss: 0.3187 - val_accuracy: 0.8544\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3056 - accuracy: 0.8578 - val_loss: 0.2984 - val_accuracy: 0.8636\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3477 - accuracy: 0.8512 - val_loss: 0.4608 - val_accuracy: 0.8260\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.6004 - accuracy: 0.7147 - val_loss: 0.5889 - val_accuracy: 0.7124\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5763 - accuracy: 0.7140 - val_loss: 0.5857 - val_accuracy: 0.7124\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5352 - accuracy: 0.7136 - val_loss: 0.5135 - val_accuracy: 0.7124\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5057 - accuracy: 0.7103 - val_loss: 0.4995 - val_accuracy: 0.7124\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4484 - accuracy: 0.7583 - val_loss: 0.3910 - val_accuracy: 0.8222\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3837 - accuracy: 0.8134 - val_loss: 0.3897 - val_accuracy: 0.7902\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3670 - accuracy: 0.8251 - val_loss: 0.3659 - val_accuracy: 0.8253\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3543 - accuracy: 0.8306 - val_loss: 0.3500 - val_accuracy: 0.8362\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3479 - accuracy: 0.8308 - val_loss: 0.3489 - val_accuracy: 0.8443\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3314 - accuracy: 0.8436 - val_loss: 0.3102 - val_accuracy: 0.8551\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3096 - accuracy: 0.8566 - val_loss: 0.3261 - val_accuracy: 0.8429\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3122 - accuracy: 0.8538 - val_loss: 0.2908 - val_accuracy: 0.8681\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2988 - accuracy: 0.8610 - val_loss: 0.3053 - val_accuracy: 0.8608\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2972 - accuracy: 0.8608 - val_loss: 0.3057 - val_accuracy: 0.8593\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2889 - accuracy: 0.8667 - val_loss: 0.2929 - val_accuracy: 0.8660\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.2826 - accuracy: 0.8679 - val_loss: 0.2869 - val_accuracy: 0.8674\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2787 - accuracy: 0.8731 - val_loss: 0.3062 - val_accuracy: 0.8576\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2843 - accuracy: 0.8706 - val_loss: 0.2967 - val_accuracy: 0.8572\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2771 - accuracy: 0.8705 - val_loss: 0.2809 - val_accuracy: 0.8695\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2762 - accuracy: 0.8724 - val_loss: 0.2666 - val_accuracy: 0.8741\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2712 - accuracy: 0.8762 - val_loss: 0.2703 - val_accuracy: 0.8758\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2695 - accuracy: 0.8753 - val_loss: 0.2906 - val_accuracy: 0.8639\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2681 - accuracy: 0.8766 - val_loss: 0.2752 - val_accuracy: 0.8762\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2628 - accuracy: 0.8781 - val_loss: 0.2637 - val_accuracy: 0.8758\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2602 - accuracy: 0.8799 - val_loss: 0.2940 - val_accuracy: 0.8657\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2555 - accuracy: 0.8802 - val_loss: 0.2601 - val_accuracy: 0.8776\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2588 - accuracy: 0.8801 - val_loss: 0.2703 - val_accuracy: 0.8737\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2541 - accuracy: 0.8826 - val_loss: 0.2821 - val_accuracy: 0.8688\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2548 - accuracy: 0.8836 - val_loss: 0.3019 - val_accuracy: 0.8632\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2507 - accuracy: 0.8859 - val_loss: 0.2551 - val_accuracy: 0.8832\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2528 - accuracy: 0.8861 - val_loss: 0.2636 - val_accuracy: 0.8811\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2500 - accuracy: 0.8840 - val_loss: 0.2404 - val_accuracy: 0.8927\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2452 - accuracy: 0.8882 - val_loss: 0.2719 - val_accuracy: 0.8734\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2384 - accuracy: 0.8921 - val_loss: 0.2680 - val_accuracy: 0.8783\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2456 - accuracy: 0.8886 - val_loss: 0.2539 - val_accuracy: 0.8843\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2416 - accuracy: 0.8900 - val_loss: 0.2316 - val_accuracy: 0.8965\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2367 - accuracy: 0.8921 - val_loss: 0.2445 - val_accuracy: 0.8899\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2317 - accuracy: 0.8938 - val_loss: 0.2807 - val_accuracy: 0.8660\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2347 - accuracy: 0.8913 - val_loss: 0.2341 - val_accuracy: 0.8906\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2315 - accuracy: 0.8940 - val_loss: 0.2301 - val_accuracy: 0.8955\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2306 - accuracy: 0.8937 - val_loss: 0.2400 - val_accuracy: 0.8835\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2248 - accuracy: 0.8988 - val_loss: 0.2274 - val_accuracy: 0.8962\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2328 - accuracy: 0.8942 - val_loss: 0.3065 - val_accuracy: 0.8534\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2524 - accuracy: 0.8854 - val_loss: 0.3258 - val_accuracy: 0.8579\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2468 - accuracy: 0.8885 - val_loss: 0.2440 - val_accuracy: 0.8892\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2293 - accuracy: 0.8949 - val_loss: 0.3215 - val_accuracy: 0.8590\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2319 - accuracy: 0.8933 - val_loss: 0.2372 - val_accuracy: 0.8916\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2170 - accuracy: 0.9012 - val_loss: 0.2206 - val_accuracy: 0.8997\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2187 - accuracy: 0.8999 - val_loss: 0.2376 - val_accuracy: 0.8902\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2214 - accuracy: 0.8991 - val_loss: 0.2386 - val_accuracy: 0.8951\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2222 - accuracy: 0.8975 - val_loss: 0.2530 - val_accuracy: 0.8902\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2201 - accuracy: 0.9010 - val_loss: 0.2237 - val_accuracy: 0.8972\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2138 - accuracy: 0.9029 - val_loss: 0.2152 - val_accuracy: 0.9046\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2251 - accuracy: 0.8969 - val_loss: 0.2350 - val_accuracy: 0.8930\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2123 - accuracy: 0.9040 - val_loss: 0.2274 - val_accuracy: 0.8955\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2114 - accuracy: 0.9042 - val_loss: 0.2164 - val_accuracy: 0.9000\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2137 - accuracy: 0.9049 - val_loss: 0.2239 - val_accuracy: 0.8993\n",
      "Epoch 92/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2096 - accuracy: 0.9063 - val_loss: 0.2146 - val_accuracy: 0.9004\n",
      "Epoch 93/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2170 - accuracy: 0.9024 - val_loss: 0.2402 - val_accuracy: 0.8920\n",
      "Epoch 94/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2117 - accuracy: 0.9050 - val_loss: 0.2391 - val_accuracy: 0.8885\n",
      "Epoch 95/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2079 - accuracy: 0.9082 - val_loss: 0.2309 - val_accuracy: 0.8913\n",
      "Epoch 96/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2041 - accuracy: 0.9105 - val_loss: 0.2194 - val_accuracy: 0.8962\n",
      "Epoch 97/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2022 - accuracy: 0.9086 - val_loss: 0.2191 - val_accuracy: 0.9021\n",
      "Epoch 98/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2028 - accuracy: 0.9088 - val_loss: 0.2130 - val_accuracy: 0.9018\n",
      "Epoch 99/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2054 - accuracy: 0.9081 - val_loss: 0.2140 - val_accuracy: 0.9007\n",
      "Epoch 100/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1959 - accuracy: 0.9131 - val_loss: 0.2126 - val_accuracy: 0.9032\n",
      "Epoch 101/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1975 - accuracy: 0.9130 - val_loss: 0.2418 - val_accuracy: 0.8969\n",
      "Epoch 102/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1946 - accuracy: 0.9146 - val_loss: 0.2091 - val_accuracy: 0.9018\n",
      "Epoch 103/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1928 - accuracy: 0.9146 - val_loss: 0.2089 - val_accuracy: 0.9032\n",
      "Epoch 104/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1952 - accuracy: 0.9144 - val_loss: 0.2110 - val_accuracy: 0.9063\n",
      "Epoch 105/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1924 - accuracy: 0.9151 - val_loss: 0.2233 - val_accuracy: 0.8965\n",
      "Epoch 106/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1900 - accuracy: 0.9157 - val_loss: 0.2116 - val_accuracy: 0.9028\n",
      "Epoch 107/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2159 - accuracy: 0.9079 - val_loss: 0.2358 - val_accuracy: 0.8913\n",
      "Epoch 108/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1902 - accuracy: 0.9170 - val_loss: 0.2060 - val_accuracy: 0.9053\n",
      "Epoch 109/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3181 - accuracy: 0.8445 - val_loss: 0.3674 - val_accuracy: 0.8246\n",
      "Epoch 110/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3717 - accuracy: 0.8232 - val_loss: 0.3743 - val_accuracy: 0.8071\n",
      "Epoch 111/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3561 - accuracy: 0.8293 - val_loss: 0.3354 - val_accuracy: 0.8604\n",
      "Epoch 112/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3158 - accuracy: 0.8551 - val_loss: 0.4568 - val_accuracy: 0.7415\n",
      "Epoch 113/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3511 - accuracy: 0.8276 - val_loss: 0.3841 - val_accuracy: 0.8215\n",
      "Epoch 114/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3336 - accuracy: 0.8373 - val_loss: 0.3082 - val_accuracy: 0.8629\n",
      "Epoch 115/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2992 - accuracy: 0.8551 - val_loss: 0.3344 - val_accuracy: 0.8373\n",
      "Epoch 116/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2927 - accuracy: 0.8608 - val_loss: 0.3256 - val_accuracy: 0.8401\n",
      "Epoch 117/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2627 - accuracy: 0.8778 - val_loss: 0.2614 - val_accuracy: 0.8790\n",
      "Epoch 118/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2577 - accuracy: 0.8775 - val_loss: 0.2678 - val_accuracy: 0.8737\n",
      "Epoch 119/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2512 - accuracy: 0.8815 - val_loss: 0.2661 - val_accuracy: 0.8818\n",
      "Epoch 120/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2387 - accuracy: 0.8893 - val_loss: 0.2490 - val_accuracy: 0.8881\n",
      "Epoch 121/500\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.2366 - accuracy: 0.8896 - val_loss: 0.4685 - val_accuracy: 0.7980\n",
      "Epoch 122/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2621 - accuracy: 0.8731 - val_loss: 0.2731 - val_accuracy: 0.8692\n",
      "Epoch 123/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2395 - accuracy: 0.8894 - val_loss: 0.2675 - val_accuracy: 0.8828\n",
      "Epoch 124/500\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.2358 - accuracy: 0.8903Restoring model weights from the end of the best epoch: 104.\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2358 - accuracy: 0.8903 - val_loss: 0.2409 - val_accuracy: 0.8902\n",
      "Epoch 124: early stopping\n",
      "Number of iterations 10\n",
      "F1-scores:  [0.9488095238095238, 0.7921036397285626, 0.9443099273607748, 0.9617224880382774, 0.9666269368295589, 0.7578027465667916, 0.7397444519166106, 0.788607594936709, 0.9519287833827893, 0.8457538994800693]\n",
      "Average F1-Score 0.8697409992049667\n",
      "Std Dev F1-Score 0.08889854455125547\n",
      "Error bar F1-Score 0.028112188145591854\n"
     ]
    }
   ],
   "source": [
    "###Collect F-Score 10 times\n",
    "import sklearn\n",
    "from tqdm.notebook import tqdm\n",
    "def calc_f1_score(X_train_scaled,X_test_scaled,y_train,y_test,earlystop):\n",
    "  classifier = Sequential()\n",
    "  classifier.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train_scaled.shape[1], X_train_scaled.shape[2])))\n",
    "  classifier.add(LSTM(units = 50))\n",
    "  classifier.add(Dense(units = 1,activation='sigmoid'))\n",
    "  classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  classifier.fit(X_train_scaled, y_train[:,0], epochs = 500, batch_size = 64,validation_data=(X_test_scaled,y_test[:,0]),callbacks=[earlystop])\n",
    "  y_pred = classifier.predict(X_test_scaled)\n",
    "  y_pred= (y_pred>=0.5).astype(int)\n",
    "  return(sklearn.metrics.f1_score(y_test[:,0],y_pred))\n",
    "\n",
    "f1_score_list=[]\n",
    "for i in tqdm(range(10)):\n",
    "  f1_score_list=f1_score_list+[calc_f1_score(X_train_scaled,X_test_scaled,y_train,y_test,earlystop)]\n",
    "  print(\"Number of iterations\",len(f1_score_list))\n",
    "  print(\"F1-scores: \",f1_score_list)\n",
    "  print(\"Average F1-Score\",np.mean(f1_score_list))\n",
    "  print(\"Std Dev F1-Score\",np.std(f1_score_list))\n",
    "  print(\"Error bar F1-Score\",np.std(f1_score_list)/np.sqrt(len(f1_score_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average F1-Score 0.8697409992049667\n",
    "# Std Dev F1-Score 0.08889854455125547\n",
    "# Error bar F1-Score 0.028112188145591854"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "LSTM_baseline_exp1_exp5_v2.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "17bd55d11dfc4e1e8cf951035a87b051": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fdd65fcdb24b4b4abfa75d106c35a25a",
       "IPY_MODEL_7f31a8d7abb9466d87c300efe71e33cf",
       "IPY_MODEL_a1a8492fe46b434f85ae75c46cf3610e"
      ],
      "layout": "IPY_MODEL_5518ed50327b43df9322057dfcd408ce"
     }
    },
    "5518ed50327b43df9322057dfcd408ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "655b452cfbfe4b62888d6c1f00c0271f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79741ebc40764fbe94751e07ebe9a0de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f31a8d7abb9466d87c300efe71e33cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79741ebc40764fbe94751e07ebe9a0de",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_809c6f839c3a411c8ce78534a319a78a",
      "value": 10
     }
    },
    "809c6f839c3a411c8ce78534a319a78a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8f9bdcf769454cd3adbac838523fb84b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1a8492fe46b434f85ae75c46cf3610e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bcfda5a8a5194640afb5e089b170d1ea",
      "placeholder": "",
      "style": "IPY_MODEL_655b452cfbfe4b62888d6c1f00c0271f",
      "value": " 10/10 [49:09&lt;00:00, 285.56s/it]"
     }
    },
    "bcfda5a8a5194640afb5e089b170d1ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd0debb5fd8043c195076e62deeef43b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fdd65fcdb24b4b4abfa75d106c35a25a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f9bdcf769454cd3adbac838523fb84b",
      "placeholder": "",
      "style": "IPY_MODEL_dd0debb5fd8043c195076e62deeef43b",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
