{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf90328",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a3e5a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f41f71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('ct_data.npz')\n",
    "X_train = data['X_train']; X_val = data['X_val']; X_test = data['X_test']\n",
    "y_train = data['y_train']; y_val = data['y_val']; y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbefde9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40754, 384)\n",
      "(5785, 384)\n",
      "(6961, 384)\n",
      "(40754,)\n",
      "(5785,)\n",
      "(6961,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8681f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.12519785, -1.12777191, -1.13034601, ..., -0.79845267,\n",
       "       -0.82308178, -0.82000318])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da959cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2496., 3445., 6825., 6440., 5313., 4498., 3392., 3361., 3358.,\n",
       "        1626.]),\n",
       " array([-1.86793865, -1.45849298, -1.0490473 , -0.63960163, -0.23015596,\n",
       "         0.17928972,  0.58873539,  0.99818106,  1.40762674,  1.81707241,\n",
       "         2.22651809]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2c70744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.41596628,  1.34203676])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(y_val,[10,90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "615964ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.0137800121400327, 2.0894818515397255)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(y_val),np.max(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e207dead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median -0.3911123099382918 [-0.9379748   0.37444705] -0.2160085093241599\n"
     ]
    }
   ],
   "source": [
    "print(\"median\",np.median(y_val),np.percentile(y_val,[25,75]),np.mean(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325e9fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2ba01a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.13868774539957e-15\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd887f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2160085093241599\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89963a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train mean:  -9.13868774539957e-15\n",
      "y_val mean:  -0.2160085093241599\n",
      "\n",
      "The mean of training positions in y_train is Zero: True\n",
      "\n",
      "The mean of the 5,785 positions in the y_val array is not Zero: True\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train mean: \",np.mean(y_train))\n",
    "print(\"y_val mean: \",np.mean(y_val))\n",
    "print('\\nThe mean of training positions in y_train is Zero:',np.isclose(np.mean(y_train), 0))\n",
    "print('\\nThe mean of the 5,785 positions in the y_val array is not Zero:', not np.isclose(np.mean(y_val),0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "590e7277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012903383410668334\n"
     ]
    }
   ],
   "source": [
    "##Estimated mean of y_val with std. error\n",
    "print(np.std(y_val)/np.sqrt(5785))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67285cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_val\n",
      "Mean with standard error -0.2160085093241599 ± 0.012903383410668334\n",
      "\n",
      "y_train 1st 5785 \n",
      "Mean with standard error -0.44247687859693674 ± 0.01192627246273395\n"
     ]
    }
   ],
   "source": [
    "print('\\ny_val\\nMean with standard error', np.mean(y_val),'±', np.std(y_val)/np.sqrt(5785))\n",
    "print('\\ny_train 1st 5785 \\nMean with standard error', np.mean(y_train[:5785]),'±', np.std(y_train[:5785])/np.sqrt(5785))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fbea21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04f0b7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.44247687859693674"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_train[:5785])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2ae4a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01192627246273395"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(y_train[:5785])/np.sqrt(5785)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dc2565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9814208579483531\n",
      "0.9999877311903766\n",
      "0.907102593171408\n"
     ]
    }
   ],
   "source": [
    "print(np.std(y_val))\n",
    "print(np.std(y_train))\n",
    "print(np.std(y_train[:5785]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba9e4aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40754, 384)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Standard dev is more reliable in sense it also accounts for more extreme cases and because\n",
    "##of larger size standard error will become very less\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3937737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 290.,  636., 1019.,  983.,  774.,  758.,  363.,  325.,  325.,\n",
       "         312.]),\n",
       " array([-2.01378001, -1.60345383, -1.19312764, -0.78280145, -0.37247527,\n",
       "         0.03785092,  0.44817711,  0.85850329,  1.26882948,  1.67915567,\n",
       "         2.08948185]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d99703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92581b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns with constant values across all rows:  [ 59  69 179 189 351]\n"
     ]
    }
   ],
   "source": [
    "print(\"columns with constant values across all rows: \",np.where(np.sum(np.abs(np.diff(X_train,axis=0)),axis=0)==0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5986375e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 59,  69, 179, 189, 351], dtype=int64),)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_val_counts_per_col=np.array([len(np.unique(X_train[:,i])) for i in range(X_train.shape[1])])\n",
    "np.where(unique_val_counts_per_col==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23e7f842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate columns to be removed:  [ 69  78  79 179 188 189 199 287 351 359]\n"
     ]
    }
   ],
   "source": [
    "print(\"duplicate columns to be removed: \",np.delete(range(X_train.shape[1]),np.unique(X_train,True,axis=1)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7baefdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 48  j: 78\n",
      "i: 49  j: 79\n",
      "i: 59  j: 69\n",
      "i: 59  j: 179\n",
      "i: 59  j: 189\n",
      "i: 59  j: 351\n",
      "i: 69  j: 179\n",
      "i: 69  j: 189\n",
      "i: 69  j: 351\n",
      "i: 169  j: 199\n",
      "i: 178  j: 188\n",
      "i: 179  j: 189\n",
      "i: 179  j: 351\n",
      "i: 189  j: 351\n",
      "i: 271  j: 287\n",
      "i: 343  j: 359\n"
     ]
    }
   ],
   "source": [
    "for i in range(X_train.shape[1]-1):\n",
    "    for j in range(i+1,X_train.shape[1]):\n",
    "        if((X_train[:,i]==X_train[:,j]).all()):\n",
    "            print(\"i:\",i,\" j:\",j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e057c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(arr,given_delete_cols=np.array([])):\n",
    "    if(given_delete_cols.size!=0):\n",
    "        delete_cols=given_delete_cols\n",
    "    else:\n",
    "        unique_val_counts_per_col=np.array([len(np.unique(arr[:,i])) for i in range(arr.shape[1])])\n",
    "        delete_cols1=np.where(unique_val_counts_per_col==1)[0]\n",
    "        delete_cols2=np.delete(range(arr.shape[1]),np.unique(arr,True,axis=1)[1])\n",
    "        print(\"columns index with same values in each row: \",delete_cols1)\n",
    "        print(\"duplicate columns index except first one: \",delete_cols2)\n",
    "        delete_cols=np.append(delete_cols1,delete_cols2)\n",
    "        delete_cols=np.sort(np.unique(delete_cols))\n",
    "        print(\"List of all columns to be deleted: \",delete_cols)\n",
    "        \n",
    "    arr=np.delete(arr,delete_cols,axis=1)\n",
    "    return(delete_cols,arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f90997c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns index with same values in each row:  [ 59  69 179 189 351]\n",
      "duplicate columns index except first one:  [ 69  78  79 179 188 189 199 287 351 359]\n",
      "List of all columns to be deleted:  [ 59  69  78  79 179 188 189 199 287 351 359]\n"
     ]
    }
   ],
   "source": [
    "delete_cols,X_train=preprocessing(X_train)\n",
    "_,X_val=preprocessing(X_val,delete_cols)\n",
    "_,X_test=preprocessing(X_test,delete_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66309a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40754, 373)\n",
      "(5785, 373)\n",
      "(6961, 373)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddbba583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40754, 373)\n",
      "(5785, 373)\n",
      "(6961, 373)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e263d0",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "156d8a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_linear(Xin):\n",
    "    return np.hstack([np.ones((Xin.shape[0],1)), Xin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f536b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(yy_true,yy_pred):\n",
    "    return(np.sqrt((np.transpose(yy_true-yy_pred)@(yy_true-yy_pred))/(len(yy_true))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c049eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_linreg(X,yy,alpha):\n",
    "    X=phi_linear(X)\n",
    "    regularisation_ip_matrix=np.eye(X.shape[1])*np.sqrt(alpha)\n",
    "    regularisation_ip_matrix[0][0]=0\n",
    "    regularisation_op_vector=np.zeros(X.shape[1])\n",
    "    X_updated=np.vstack([X,regularisation_ip_matrix])\n",
    "    yy_updated=np.append(yy,regularisation_op_vector)\n",
    "    w_fit=np.linalg.lstsq(X_updated, yy_updated, rcond=None)[0]\n",
    "    return(w_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "919fb4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_fit_lstsq=fit_linreg(X=X_train,yy=y_train,alpha=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8df52d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(374,)\n"
     ]
    }
   ],
   "source": [
    "print(w_fit_lstsq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70917876",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_fit_gradopt,bb_fit_gradopt=fit_linreg_gradopt(X=X_train,yy=y_train,alpha=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e1dec0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5785, 374)\n",
      "(374,)\n"
     ]
    }
   ],
   "source": [
    "print(phi_linear(X_val).shape)\n",
    "print(w_fit_lstsq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71084201",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_train_pred_lstsq=phi_linear(X_train)@w_fit_lstsq\n",
    "yy_val_pred_lstsq=phi_linear(X_val)@w_fit_lstsq\n",
    "\n",
    "yy_train_pred_gradopt=phi_linear(X_train)@np.append(bb_fit_gradopt,w_fit_gradopt)\n",
    "yy_val_pred_gradopt=phi_linear(X_val)@np.append(bb_fit_gradopt,w_fit_gradopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3dc93e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3567565397204054\n",
      "0.35675590264260904\n",
      "0.4230521968394697\n",
      "0.42305976593027966\n"
     ]
    }
   ],
   "source": [
    "print(RMSE(yy_true=y_train,yy_pred=yy_train_pred_lstsq))\n",
    "print(RMSE(yy_true=y_train,yy_pred=yy_train_pred_gradopt))\n",
    "\n",
    "print(RMSE(yy_true=y_val,yy_pred=yy_val_pred_lstsq))\n",
    "print(RMSE(yy_true=y_val,yy_pred=yy_val_pred_gradopt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3bc4b2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error:\n",
      "\n",
      "fit_linreg:\t 0.3567565397204054\n",
      "fit_linreg_gradopt:\t 0.35675590264260904\n",
      "\n",
      "test error:\n",
      "\n",
      "fit_linreg:\t 0.4230521968394697\n",
      "fit_linreg_gradopt:\t 0.42305976593027966\n"
     ]
    }
   ],
   "source": [
    "print(\"train error:\\n\")\n",
    "print(\"fit_linreg:\\t\",RMSE(yy_true=y_train,yy_pred=yy_train_pred_lstsq))\n",
    "print(\"fit_linreg_gradopt:\\t\",RMSE(yy_true=y_train,yy_pred=yy_train_pred_gradopt))\n",
    "\n",
    "print(\"\\ntest error:\\n\")\n",
    "print(\"fit_linreg:\\t\",RMSE(yy_true=y_val,yy_pred=yy_val_pred_lstsq))\n",
    "print(\"fit_linreg_gradopt:\\t\",RMSE(yy_true=y_val,yy_pred=yy_val_pred_gradopt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a456003e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(RMSE(yy_true=y_val,yy_pred=yy_val_pred_lstsq),RMSE(yy_true=y_val,yy_pred=yy_val_pred_gradopt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d58cf25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09105351, -0.06086155, -0.10609567,  0.07530311])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_fit_lstsq[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c478131a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06092799, -0.10608243,  0.07530472])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_fit_gradopt[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e17ccbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d57774a5",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d191d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logreg_gradopt(X, yy, alpha):\n",
    "    D = X.shape[1]\n",
    "    args = (X, yy, alpha)\n",
    "    init = (np.zeros(D), np.array(0))\n",
    "    ww, bb = minimize_list(logreg_cost, init, args)\n",
    "    return ww, bb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be58c6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 20 # number of thresholded classification problems to fit\n",
    "mx = np.max(y_train); mn = np.min(y_train); hh = (mx-mn)/(K+1)\n",
    "thresholds = np.linspace(mn+hh, mx-hh, num=K, endpoint=True)\n",
    "X_train_prob=np.empty((X_train.shape[0],K), dtype=float)\n",
    "X_val_prob=np.empty((X_val.shape[0],K), dtype=float)\n",
    "comb_weights_matrix=np.empty((X_val.shape[1],K), dtype=float)\n",
    "comb_bias_vector=np.empty((K),dtype=float)\n",
    "\n",
    "for kk in range(K):\n",
    "    labels = (y_train > thresholds[kk]).astype(int)\n",
    "    # ... fit logistic regression to these labels\n",
    "    w_fit_gradopt,bb_fit_gradopt=fit_logreg_gradopt(X=X_train,yy=labels,alpha=30)\n",
    "    \n",
    "    yy_train_pred=phi_linear(X_train)@np.append(bb_fit_gradopt,w_fit_gradopt)\n",
    "    sigma_yy_train_pred = 1/(1 + np.exp(-yy_train_pred))\n",
    "    \n",
    "    yy_val_pred=phi_linear(X_val)@np.append(bb_fit_gradopt,w_fit_gradopt)\n",
    "    sigma_yy_val_pred = 1/(1 + np.exp(-yy_val_pred))\n",
    "    \n",
    "    X_train_prob[:,kk]=sigma_yy_train_pred\n",
    "    X_val_prob[:,kk]=sigma_yy_val_pred\n",
    "    comb_weights_matrix[:,kk]=w_fit_gradopt\n",
    "    comb_bias_vector[kk]=bb_fit_gradopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8491ca44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40754, 373)\n",
      "(5785, 373)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94dd21e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40754, 20)\n",
      "(5785, 20)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_prob.shape)\n",
    "print(X_val_prob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9aabc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(373, 20)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "print(comb_weights_matrix.shape)\n",
    "print(comb_bias_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ea0feab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40754.000000</td>\n",
       "      <td>40754.000000</td>\n",
       "      <td>40754.000000</td>\n",
       "      <td>40754.000000</td>\n",
       "      <td>40754.000000</td>\n",
       "      <td>40754.000000</td>\n",
       "      <td>4.075400e+04</td>\n",
       "      <td>4.075400e+04</td>\n",
       "      <td>4.075400e+04</td>\n",
       "      <td>4.075400e+04</td>\n",
       "      <td>4.075400e+04</td>\n",
       "      <td>4.075400e+04</td>\n",
       "      <td>4.075400e+04</td>\n",
       "      <td>4.075400e+04</td>\n",
       "      <td>4.075400e+04</td>\n",
       "      <td>4.075400e+04</td>\n",
       "      <td>4.075400e+04</td>\n",
       "      <td>4.075400e+04</td>\n",
       "      <td>4.075400e+04</td>\n",
       "      <td>4.075400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.982677</td>\n",
       "      <td>0.942828</td>\n",
       "      <td>0.902710</td>\n",
       "      <td>0.862615</td>\n",
       "      <td>0.808999</td>\n",
       "      <td>0.715291</td>\n",
       "      <td>6.256574e-01</td>\n",
       "      <td>5.542284e-01</td>\n",
       "      <td>4.916093e-01</td>\n",
       "      <td>4.290383e-01</td>\n",
       "      <td>3.685772e-01</td>\n",
       "      <td>3.143025e-01</td>\n",
       "      <td>2.715815e-01</td>\n",
       "      <td>2.321478e-01</td>\n",
       "      <td>1.929133e-01</td>\n",
       "      <td>1.536781e-01</td>\n",
       "      <td>1.143942e-01</td>\n",
       "      <td>7.520732e-02</td>\n",
       "      <td>3.587366e-02</td>\n",
       "      <td>6.649639e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.109850</td>\n",
       "      <td>0.221254</td>\n",
       "      <td>0.279751</td>\n",
       "      <td>0.327792</td>\n",
       "      <td>0.356688</td>\n",
       "      <td>0.413487</td>\n",
       "      <td>4.446834e-01</td>\n",
       "      <td>4.604467e-01</td>\n",
       "      <td>4.619035e-01</td>\n",
       "      <td>4.583562e-01</td>\n",
       "      <td>4.471008e-01</td>\n",
       "      <td>4.306929e-01</td>\n",
       "      <td>4.068513e-01</td>\n",
       "      <td>3.834556e-01</td>\n",
       "      <td>3.651938e-01</td>\n",
       "      <td>3.377897e-01</td>\n",
       "      <td>2.901127e-01</td>\n",
       "      <td>2.341524e-01</td>\n",
       "      <td>1.494659e-01</td>\n",
       "      <td>3.956078e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.033927</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.940699e-07</td>\n",
       "      <td>9.223223e-08</td>\n",
       "      <td>2.594487e-08</td>\n",
       "      <td>1.424864e-07</td>\n",
       "      <td>6.327138e-08</td>\n",
       "      <td>1.375004e-08</td>\n",
       "      <td>1.327526e-08</td>\n",
       "      <td>9.023735e-09</td>\n",
       "      <td>2.347304e-08</td>\n",
       "      <td>1.004399e-08</td>\n",
       "      <td>2.536761e-10</td>\n",
       "      <td>8.675458e-10</td>\n",
       "      <td>1.834467e-10</td>\n",
       "      <td>3.354006e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.999229</td>\n",
       "      <td>0.998507</td>\n",
       "      <td>0.995068</td>\n",
       "      <td>0.990530</td>\n",
       "      <td>0.913212</td>\n",
       "      <td>0.216123</td>\n",
       "      <td>3.511556e-02</td>\n",
       "      <td>8.716533e-03</td>\n",
       "      <td>4.412144e-03</td>\n",
       "      <td>2.047843e-03</td>\n",
       "      <td>8.105429e-04</td>\n",
       "      <td>2.317392e-04</td>\n",
       "      <td>2.010748e-04</td>\n",
       "      <td>1.591693e-04</td>\n",
       "      <td>1.304027e-04</td>\n",
       "      <td>6.692936e-05</td>\n",
       "      <td>1.764025e-05</td>\n",
       "      <td>2.730961e-05</td>\n",
       "      <td>3.002534e-05</td>\n",
       "      <td>1.137260e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.999698</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.998931</td>\n",
       "      <td>0.997876</td>\n",
       "      <td>0.992156</td>\n",
       "      <td>0.981000</td>\n",
       "      <td>9.551520e-01</td>\n",
       "      <td>8.852578e-01</td>\n",
       "      <td>4.270761e-01</td>\n",
       "      <td>9.031579e-02</td>\n",
       "      <td>2.102908e-02</td>\n",
       "      <td>6.986960e-03</td>\n",
       "      <td>5.369905e-03</td>\n",
       "      <td>4.441847e-03</td>\n",
       "      <td>3.379293e-03</td>\n",
       "      <td>1.512520e-03</td>\n",
       "      <td>7.450374e-04</td>\n",
       "      <td>3.736079e-04</td>\n",
       "      <td>3.619093e-04</td>\n",
       "      <td>6.241249e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.999895</td>\n",
       "      <td>0.999831</td>\n",
       "      <td>0.999747</td>\n",
       "      <td>0.999672</td>\n",
       "      <td>0.999655</td>\n",
       "      <td>0.998829</td>\n",
       "      <td>9.945150e-01</td>\n",
       "      <td>9.901159e-01</td>\n",
       "      <td>9.848821e-01</td>\n",
       "      <td>9.738093e-01</td>\n",
       "      <td>9.575189e-01</td>\n",
       "      <td>9.144810e-01</td>\n",
       "      <td>7.314641e-01</td>\n",
       "      <td>2.815004e-01</td>\n",
       "      <td>6.513714e-02</td>\n",
       "      <td>1.693389e-02</td>\n",
       "      <td>1.005436e-02</td>\n",
       "      <td>4.925124e-03</td>\n",
       "      <td>3.893212e-03</td>\n",
       "      <td>2.299984e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.999963e-01</td>\n",
       "      <td>9.999944e-01</td>\n",
       "      <td>9.999933e-01</td>\n",
       "      <td>9.999888e-01</td>\n",
       "      <td>9.999941e-01</td>\n",
       "      <td>9.999869e-01</td>\n",
       "      <td>9.999564e-01</td>\n",
       "      <td>9.999414e-01</td>\n",
       "      <td>9.999502e-01</td>\n",
       "      <td>9.998324e-01</td>\n",
       "      <td>9.991079e-01</td>\n",
       "      <td>9.937297e-01</td>\n",
       "      <td>9.749431e-01</td>\n",
       "      <td>5.661798e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  40754.000000  40754.000000  40754.000000  40754.000000  40754.000000   \n",
       "mean       0.982677      0.942828      0.902710      0.862615      0.808999   \n",
       "std        0.109850      0.221254      0.279751      0.327792      0.356688   \n",
       "min        0.033927      0.000762      0.000005      0.000021      0.000009   \n",
       "25%        0.999229      0.998507      0.995068      0.990530      0.913212   \n",
       "50%        0.999698      0.999487      0.998931      0.997876      0.992156   \n",
       "75%        0.999895      0.999831      0.999747      0.999672      0.999655   \n",
       "max        0.999998      0.999997      0.999997      0.999999      1.000000   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  40754.000000  4.075400e+04  4.075400e+04  4.075400e+04  4.075400e+04   \n",
       "mean       0.715291  6.256574e-01  5.542284e-01  4.916093e-01  4.290383e-01   \n",
       "std        0.413487  4.446834e-01  4.604467e-01  4.619035e-01  4.583562e-01   \n",
       "min        0.000002  2.940699e-07  9.223223e-08  2.594487e-08  1.424864e-07   \n",
       "25%        0.216123  3.511556e-02  8.716533e-03  4.412144e-03  2.047843e-03   \n",
       "50%        0.981000  9.551520e-01  8.852578e-01  4.270761e-01  9.031579e-02   \n",
       "75%        0.998829  9.945150e-01  9.901159e-01  9.848821e-01  9.738093e-01   \n",
       "max        1.000000  9.999963e-01  9.999944e-01  9.999933e-01  9.999888e-01   \n",
       "\n",
       "                 10            11            12            13            14  \\\n",
       "count  4.075400e+04  4.075400e+04  4.075400e+04  4.075400e+04  4.075400e+04   \n",
       "mean   3.685772e-01  3.143025e-01  2.715815e-01  2.321478e-01  1.929133e-01   \n",
       "std    4.471008e-01  4.306929e-01  4.068513e-01  3.834556e-01  3.651938e-01   \n",
       "min    6.327138e-08  1.375004e-08  1.327526e-08  9.023735e-09  2.347304e-08   \n",
       "25%    8.105429e-04  2.317392e-04  2.010748e-04  1.591693e-04  1.304027e-04   \n",
       "50%    2.102908e-02  6.986960e-03  5.369905e-03  4.441847e-03  3.379293e-03   \n",
       "75%    9.575189e-01  9.144810e-01  7.314641e-01  2.815004e-01  6.513714e-02   \n",
       "max    9.999941e-01  9.999869e-01  9.999564e-01  9.999414e-01  9.999502e-01   \n",
       "\n",
       "                 15            16            17            18            19  \n",
       "count  4.075400e+04  4.075400e+04  4.075400e+04  4.075400e+04  4.075400e+04  \n",
       "mean   1.536781e-01  1.143942e-01  7.520732e-02  3.587366e-02  6.649639e-03  \n",
       "std    3.377897e-01  2.901127e-01  2.341524e-01  1.494659e-01  3.956078e-02  \n",
       "min    1.004399e-08  2.536761e-10  8.675458e-10  1.834467e-10  3.354006e-08  \n",
       "25%    6.692936e-05  1.764025e-05  2.730961e-05  3.002534e-05  1.137260e-04  \n",
       "50%    1.512520e-03  7.450374e-04  3.736079e-04  3.619093e-04  6.241249e-04  \n",
       "75%    1.693389e-02  1.005436e-02  4.925124e-03  3.893212e-03  2.299984e-03  \n",
       "max    9.998324e-01  9.991079e-01  9.937297e-01  9.749431e-01  5.661798e-01  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(X_train_prob).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a457d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5785.000000</td>\n",
       "      <td>5785.000000</td>\n",
       "      <td>5785.000000</td>\n",
       "      <td>5785.000000</td>\n",
       "      <td>5785.000000</td>\n",
       "      <td>5785.000000</td>\n",
       "      <td>5785.000000</td>\n",
       "      <td>5.785000e+03</td>\n",
       "      <td>5.785000e+03</td>\n",
       "      <td>5.785000e+03</td>\n",
       "      <td>5.785000e+03</td>\n",
       "      <td>5.785000e+03</td>\n",
       "      <td>5.785000e+03</td>\n",
       "      <td>5.785000e+03</td>\n",
       "      <td>5.785000e+03</td>\n",
       "      <td>5.785000e+03</td>\n",
       "      <td>5.785000e+03</td>\n",
       "      <td>5.785000e+03</td>\n",
       "      <td>5.785000e+03</td>\n",
       "      <td>5.785000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.967476</td>\n",
       "      <td>0.910550</td>\n",
       "      <td>0.864714</td>\n",
       "      <td>0.810935</td>\n",
       "      <td>0.734464</td>\n",
       "      <td>0.620936</td>\n",
       "      <td>0.535513</td>\n",
       "      <td>4.567663e-01</td>\n",
       "      <td>3.908278e-01</td>\n",
       "      <td>3.229879e-01</td>\n",
       "      <td>2.721036e-01</td>\n",
       "      <td>2.377271e-01</td>\n",
       "      <td>2.079071e-01</td>\n",
       "      <td>1.717133e-01</td>\n",
       "      <td>1.292789e-01</td>\n",
       "      <td>1.138860e-01</td>\n",
       "      <td>8.934006e-02</td>\n",
       "      <td>5.240937e-02</td>\n",
       "      <td>2.630148e-02</td>\n",
       "      <td>3.382601e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.147854</td>\n",
       "      <td>0.271228</td>\n",
       "      <td>0.322167</td>\n",
       "      <td>0.369987</td>\n",
       "      <td>0.403657</td>\n",
       "      <td>0.444805</td>\n",
       "      <td>0.455355</td>\n",
       "      <td>4.567606e-01</td>\n",
       "      <td>4.444747e-01</td>\n",
       "      <td>4.237793e-01</td>\n",
       "      <td>4.060992e-01</td>\n",
       "      <td>3.861854e-01</td>\n",
       "      <td>3.609729e-01</td>\n",
       "      <td>3.280979e-01</td>\n",
       "      <td>3.019494e-01</td>\n",
       "      <td>2.899669e-01</td>\n",
       "      <td>2.511645e-01</td>\n",
       "      <td>1.890342e-01</td>\n",
       "      <td>1.234145e-01</td>\n",
       "      <td>1.009850e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.093373</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>7.618075e-07</td>\n",
       "      <td>1.581560e-07</td>\n",
       "      <td>6.034584e-07</td>\n",
       "      <td>7.588535e-07</td>\n",
       "      <td>8.876350e-08</td>\n",
       "      <td>6.331857e-08</td>\n",
       "      <td>6.059797e-08</td>\n",
       "      <td>1.442158e-07</td>\n",
       "      <td>3.288447e-08</td>\n",
       "      <td>3.369352e-09</td>\n",
       "      <td>4.088757e-09</td>\n",
       "      <td>1.958319e-09</td>\n",
       "      <td>2.492860e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.998233</td>\n",
       "      <td>0.992010</td>\n",
       "      <td>0.963635</td>\n",
       "      <td>0.453864</td>\n",
       "      <td>0.038493</td>\n",
       "      <td>0.015533</td>\n",
       "      <td>3.477645e-03</td>\n",
       "      <td>2.262666e-03</td>\n",
       "      <td>1.080167e-03</td>\n",
       "      <td>4.937496e-04</td>\n",
       "      <td>1.324951e-04</td>\n",
       "      <td>1.225286e-04</td>\n",
       "      <td>1.375143e-04</td>\n",
       "      <td>1.040552e-04</td>\n",
       "      <td>3.989572e-05</td>\n",
       "      <td>1.517537e-05</td>\n",
       "      <td>1.232757e-05</td>\n",
       "      <td>1.560477e-05</td>\n",
       "      <td>8.945908e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.999711</td>\n",
       "      <td>0.999527</td>\n",
       "      <td>0.998957</td>\n",
       "      <td>0.997778</td>\n",
       "      <td>0.988476</td>\n",
       "      <td>0.949995</td>\n",
       "      <td>0.776712</td>\n",
       "      <td>2.162530e-01</td>\n",
       "      <td>5.241705e-02</td>\n",
       "      <td>1.495176e-02</td>\n",
       "      <td>6.578736e-03</td>\n",
       "      <td>2.175846e-03</td>\n",
       "      <td>2.092773e-03</td>\n",
       "      <td>1.627394e-03</td>\n",
       "      <td>1.265629e-03</td>\n",
       "      <td>7.633897e-04</td>\n",
       "      <td>4.899015e-04</td>\n",
       "      <td>1.745821e-04</td>\n",
       "      <td>1.929607e-04</td>\n",
       "      <td>5.289673e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.999886</td>\n",
       "      <td>0.999830</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>0.999750</td>\n",
       "      <td>0.999590</td>\n",
       "      <td>0.996955</td>\n",
       "      <td>0.989243</td>\n",
       "      <td>9.754697e-01</td>\n",
       "      <td>9.577633e-01</td>\n",
       "      <td>8.827827e-01</td>\n",
       "      <td>7.496525e-01</td>\n",
       "      <td>4.263872e-01</td>\n",
       "      <td>2.149717e-01</td>\n",
       "      <td>1.083084e-01</td>\n",
       "      <td>2.911292e-02</td>\n",
       "      <td>9.194530e-03</td>\n",
       "      <td>1.019559e-02</td>\n",
       "      <td>5.349820e-03</td>\n",
       "      <td>2.711845e-03</td>\n",
       "      <td>2.010986e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>9.998860e-01</td>\n",
       "      <td>9.998502e-01</td>\n",
       "      <td>9.996663e-01</td>\n",
       "      <td>9.997829e-01</td>\n",
       "      <td>9.996138e-01</td>\n",
       "      <td>9.989864e-01</td>\n",
       "      <td>9.990768e-01</td>\n",
       "      <td>9.996761e-01</td>\n",
       "      <td>9.991302e-01</td>\n",
       "      <td>9.979802e-01</td>\n",
       "      <td>9.815159e-01</td>\n",
       "      <td>9.366307e-01</td>\n",
       "      <td>1.403792e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  5785.000000  5785.000000  5785.000000  5785.000000  5785.000000   \n",
       "mean      0.967476     0.910550     0.864714     0.810935     0.734464   \n",
       "std       0.147854     0.271228     0.322167     0.369987     0.403657   \n",
       "min       0.093373     0.002350     0.000014     0.000121     0.000026   \n",
       "25%       0.999275     0.998233     0.992010     0.963635     0.453864   \n",
       "50%       0.999711     0.999527     0.998957     0.997778     0.988476   \n",
       "75%       0.999886     0.999830     0.999779     0.999750     0.999590   \n",
       "max       0.999996     0.999994     0.999991     0.999996     1.000000   \n",
       "\n",
       "                5            6             7             8             9   \\\n",
       "count  5785.000000  5785.000000  5.785000e+03  5.785000e+03  5.785000e+03   \n",
       "mean      0.620936     0.535513  4.567663e-01  3.908278e-01  3.229879e-01   \n",
       "std       0.444805     0.455355  4.567606e-01  4.444747e-01  4.237793e-01   \n",
       "min       0.000017     0.000010  7.618075e-07  1.581560e-07  6.034584e-07   \n",
       "25%       0.038493     0.015533  3.477645e-03  2.262666e-03  1.080167e-03   \n",
       "50%       0.949995     0.776712  2.162530e-01  5.241705e-02  1.495176e-02   \n",
       "75%       0.996955     0.989243  9.754697e-01  9.577633e-01  8.827827e-01   \n",
       "max       1.000000     0.999920  9.998860e-01  9.998502e-01  9.996663e-01   \n",
       "\n",
       "                 10            11            12            13            14  \\\n",
       "count  5.785000e+03  5.785000e+03  5.785000e+03  5.785000e+03  5.785000e+03   \n",
       "mean   2.721036e-01  2.377271e-01  2.079071e-01  1.717133e-01  1.292789e-01   \n",
       "std    4.060992e-01  3.861854e-01  3.609729e-01  3.280979e-01  3.019494e-01   \n",
       "min    7.588535e-07  8.876350e-08  6.331857e-08  6.059797e-08  1.442158e-07   \n",
       "25%    4.937496e-04  1.324951e-04  1.225286e-04  1.375143e-04  1.040552e-04   \n",
       "50%    6.578736e-03  2.175846e-03  2.092773e-03  1.627394e-03  1.265629e-03   \n",
       "75%    7.496525e-01  4.263872e-01  2.149717e-01  1.083084e-01  2.911292e-02   \n",
       "max    9.997829e-01  9.996138e-01  9.989864e-01  9.990768e-01  9.996761e-01   \n",
       "\n",
       "                 15            16            17            18            19  \n",
       "count  5.785000e+03  5.785000e+03  5.785000e+03  5.785000e+03  5.785000e+03  \n",
       "mean   1.138860e-01  8.934006e-02  5.240937e-02  2.630148e-02  3.382601e-03  \n",
       "std    2.899669e-01  2.511645e-01  1.890342e-01  1.234145e-01  1.009850e-02  \n",
       "min    3.288447e-08  3.369352e-09  4.088757e-09  1.958319e-09  2.492860e-07  \n",
       "25%    3.989572e-05  1.517537e-05  1.232757e-05  1.560477e-05  8.945908e-05  \n",
       "50%    7.633897e-04  4.899015e-04  1.745821e-04  1.929607e-04  5.289673e-04  \n",
       "75%    9.194530e-03  1.019559e-02  5.349820e-03  2.711845e-03  2.010986e-03  \n",
       "max    9.991302e-01  9.979802e-01  9.815159e-01  9.366307e-01  1.403792e-01  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_val_prob).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "230aebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_fit_lstsq1=fit_linreg(X=X_train_prob,yy=y_train,alpha=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f82efe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_train_pred_lstsq1=phi_linear(X_train_prob)@w_fit_lstsq1\n",
    "yy_val_pred_lstsq1=phi_linear(X_val_prob)@w_fit_lstsq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9cba5c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1544115042995604\n",
      "0.25424772980465987\n"
     ]
    }
   ],
   "source": [
    "print(RMSE(yy_true=y_train,yy_pred=yy_train_pred_lstsq1))\n",
    "print(RMSE(yy_true=y_val,yy_pred=yy_val_pred_lstsq1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65261326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.1544115042995604\n",
      "Validation RMSE:  0.25424772980465987\n"
     ]
    }
   ],
   "source": [
    "print(\"Training RMSE: \",RMSE(yy_true=y_train,yy_pred=yy_train_pred_lstsq1))\n",
    "print(\"Validation RMSE: \",RMSE(yy_true=y_val,yy_pred=yy_val_pred_lstsq1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8eea96",
   "metadata": {},
   "source": [
    "## Q4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44073e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc8bb268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_nn_gradopt(X, yy,K,alpha):\n",
    "    D = X.shape[1]\n",
    "    args = (X, yy, alpha)\n",
    "    ## Following GlorotInit initialisation\n",
    "    init = (np.random.normal(loc=0,scale=np.sqrt(2/(K+1)),size=K), \n",
    "            np.array(0),np.random.normal(loc=0,scale=np.sqrt(2/(K+D)),size=(K,D)),np.zeros(K))\n",
    "    ww, bb, V, bk = minimize_list(nn_cost, init, args)\n",
    "    return ww, bb, V, bk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191a38e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bca90390",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fitting the model\n",
    "ww_fit_nn, bb_fit_nn, V_fit_nn, bk_fit_nn=fit_nn_gradopt(X=X_train,yy=y_train,K=20,alpha=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82150679",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Predictions\n",
    "params=(ww_fit_nn, bb_fit_nn, V_fit_nn, bk_fit_nn)\n",
    "yy_train_pred_nn=nn_cost(params,X_train,yy=None,alpha=30)\n",
    "yy_val_pred_nn=nn_cost(params,X_val,yy=None,alpha=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7481e922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14003433452158495\n",
      "0.2702886385000156\n"
     ]
    }
   ],
   "source": [
    "##Performance\n",
    "print(RMSE(yy_true=y_train,yy_pred=yy_train_pred_nn))\n",
    "val_nn_RMSE=RMSE(yy_true=y_val,yy_pred=yy_val_pred_nn)\n",
    "print(RMSE(yy_true=y_val,yy_pred=yy_val_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "443371ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30422822771944025\n"
     ]
    }
   ],
   "source": [
    "yy_test_pred_nn=nn_cost(params,X_test,yy=None,alpha=30)\n",
    "print(RMSE(yy_true=y_test,yy_pred=yy_test_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dad81261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.14003433452158495\n",
      "Validation RMSE:  0.2702886385000156\n"
     ]
    }
   ],
   "source": [
    "##Performance\n",
    "print(\"Training RMSE: \",RMSE(yy_true=y_train,yy_pred=yy_train_pred_nn))\n",
    "val_nn_RMSE=RMSE(yy_true=y_val,yy_pred=yy_val_pred_nn)\n",
    "print(\"Validation RMSE: \",val_nn_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b3e7a67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##fitting same model 10 times and then taking avg across performances\n",
    "# train_RMSE_list=[]\n",
    "# val_RMSE_list=[]\n",
    "# for i in range(3):\n",
    "#     ##Fitting the model\n",
    "#     ww_fit_nn, bb_fit_nn, V_fit_nn, bk_fit_n=fit_nn_gradopt(X=X_train,yy=y_train,K=20,alpha=30)\n",
    "    \n",
    "#     ##Predictions\n",
    "#     params=(ww_fit_nn, bb_fit_nn, V_fit_nn, bk_fit_nn)\n",
    "#     yy_train_pred_nn=nn_cost(params,X_train,yy=None,alpha=30)\n",
    "#     yy_val_pred_nn=nn_cost(params,X_val,yy=None,alpha=30)\n",
    "    \n",
    "#     ##Performance\n",
    "#     train_RMSE_list=train_RMSE_list+[RMSE(yy_true=y_train,yy_pred=yy_train_pred_nn)]\n",
    "#     val_RMSE_list=val_RMSE_list+[RMSE(yy_true=y_val,yy_pred=yy_val_pred_nn)]\n",
    "#     print(train_RMSE_list)\n",
    "#     print(val_RMSE_list)\n",
    "\n",
    "# print(\"average training error: \",np.mean(train_RMSE_list))\n",
    "# print(\"average val error: \",np.mean(val_RMSE_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa213468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e2758cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_nn_gradopt1(X, yy,K,alpha):\n",
    "    D = X.shape[1]\n",
    "    args = (X, yy, alpha)\n",
    "    ## Following GlorotInit initialisation\n",
    "    init = (w_fit_lstsq1[1:], \n",
    "            w_fit_lstsq1[0],comb_weights_matrix.T,comb_bias_vector)\n",
    "    ww, bb, V, bk = minimize_list(nn_cost, init, args)\n",
    "    return ww, bb, V, bk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e4840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f0a81c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fitting the model\n",
    "ww_fit_nn1, bb_fit_nn1, V_fit_nn1, bk_fit_nn1=fit_nn_gradopt1(X=X_train,yy=y_train,K=20,alpha=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0256b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Predictions\n",
    "params1=(ww_fit_nn1, bb_fit_nn1, V_fit_nn1, bk_fit_nn1)\n",
    "yy_train_pred_nn1=nn_cost(params1,X_train,yy=None,alpha=30)\n",
    "yy_val_pred_nn1=nn_cost(params1,X_val,yy=None,alpha=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f0f3b3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13962037078979167\n",
      "0.2683138681266855\n"
     ]
    }
   ],
   "source": [
    "##Performance\n",
    "print(RMSE(yy_true=y_train,yy_pred=yy_train_pred_nn1))\n",
    "print(RMSE(yy_true=y_val,yy_pred=yy_val_pred_nn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1dcaee87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.13962037078979167\n",
      "Validation RMSE:  0.2683138681266855\n"
     ]
    }
   ],
   "source": [
    "##Performance\n",
    "print(\"Training RMSE: \",RMSE(yy_true=y_train,yy_pred=yy_train_pred_nn1))\n",
    "print(\"Validation RMSE: \",RMSE(yy_true=y_val,yy_pred=yy_val_pred_nn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b58c6c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.09674219 -1.06340694  0.13128641  0.81785585 -1.8579202   0.09702058\n",
      "  0.10893049  0.1371555  -1.16466112  0.10728441  0.12150821  0.10771016\n",
      "  0.1436864   0.12312926  0.0708245  -1.3225307   2.31433516  0.06789376\n",
      "  0.11313603 -1.20903445] \n",
      "\n",
      "weights obtained from LR\n",
      " [ 6.97123863e-03  6.95914470e-03  7.38662065e-03  1.19046433e+00\n",
      "  1.22965858e+00 -7.13423394e-01  2.05042631e-02  1.06794438e+00\n",
      "  1.57713470e-03  7.58391495e-01  2.25517861e+00  7.07615282e-05\n",
      "  8.92235390e-03 -2.66433744e-03  3.46359293e-03  4.93270599e-03\n",
      "  1.84330836e+00  1.74559487e-01  1.29214040e+00 -8.99902482e-04]\n"
     ]
    }
   ],
   "source": [
    "print(ww_fit_nn,\"\\n\\nweights obtained from LR\\n\",ww_fit_nn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a6baac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  4.,  0.,  0., 13.,  0.,  1.,  0.,  0.,  1.]),\n",
       " array([-1.8579202 , -1.44069467, -1.02346913, -0.60624359, -0.18901806,\n",
       "         0.22820748,  0.64543302,  1.06265855,  1.47988409,  1.89710963,\n",
       "         2.31433516]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ww_fit_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9e23a63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  0., 12.,  0.,  1.,  0.,  4.,  0.,  1.,  1.]),\n",
       " array([-0.71342339, -0.41656319, -0.11970299,  0.17715721,  0.47401741,\n",
       "         0.77087761,  1.06773781,  1.36459801,  1.66145821,  1.95831841,\n",
       "         2.25517861]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAMWklEQVR4nO3dfYhlhXnH8e+vrtJqLBp2NEbdTgIiWCkoQ2oqpCEmxWqo+cOCQqxNLUsLaU0ptJsG6r/2hdCWloZFbSy1psVolZikbtMEKSTSWbOJmjXRpluz1WYnFTRpClZ4+sdcYR1n5t6998zLM/v9wDD35dw5z+HMfvfsuS+bqkKS1M+PbPUAkqTpGHBJasqAS1JTBlySmjLgktTUrs1c2e7du2t+fn4zVylJ7R08ePB7VTW38vZNDfj8/DyLi4ubuUpJai/Jf6x2u6dQJKkpAy5JTRlwSWrKgEtSUwZckpoy4JLU1NiAJ7krybEkTx532x8leTrJ15M8kOSsDZ1SkvQGkxyBfxK4esVtB4BLq+qngG8BHx14LknSGGMDXlWPAi+uuO2Rqnp1dPUrwAUbMJskaR1DvBPzV4C/W+vOJHuBvQB79uwZYHUnj/l9D2/Jeo/cfu2WrFfSiZnpScwkHwNeBe5Za5mq2l9VC1W1MDf3hrfyS5KmNPUReJKbgfcDV5X/L5skbbqpAp7kauB3gZ+tqh8OO5IkaRKTvIzwXuDLwMVJjia5Bfhz4EzgQJJDST6xwXNKklYYewReVTeucvOdGzCLJOkE+E5MSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWpqbMCT3JXkWJInj7vtzUkOJHlm9P3sjR1TkrTSJEfgnwSuXnHbPuALVXUR8IXRdUnSJhob8Kp6FHhxxc3XAXePLt8NfGDYsSRJ40x7DvzcqnoBYPT9nLUWTLI3yWKSxaWlpSlXJ0laacOfxKyq/VW1UFULc3NzG706STppTBvw7yY5D2D0/dhwI0mSJjFtwB8Cbh5dvhl4cJhxJEmTmuRlhPcCXwYuTnI0yS3A7cD7kjwDvG90XZK0iXaNW6CqblzjrqsGnkWSdAJ8J6YkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJampmQKe5LeSPJXkyST3JvnRoQaTJK1v6oAnOR/4TWChqi4FTgFuGGowSdL6Zj2Fsgv4sSS7gNOB52cfSZI0iakDXlX/Cfwx8BzwAvBSVT2ycrkke5MsJllcWlqaflJJ0uvMcgrlbOA64G3AW4Ezknxw5XJVtb+qFqpqYW5ubvpJJUmvM8splPcC/15VS1X1f8D9wM8MM5YkaZxZAv4ccEWS05MEuAo4PMxYkqRxZjkH/hhwH/A48MToZ+0faC5J0hi7ZnlwVd0G3DbQLJKkE+A7MSWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpqZkCnuSsJPcleTrJ4STvHGowSdL6ds34+D8FPl9V1yc5DTh9gJkkSROYOuBJfhx4F/DLAFX1CvDKMGNJksaZ5RTK24El4K+SfDXJHUnOWLlQkr1JFpMsLi0tzbA6SdLxZgn4LuBy4C+r6jLgf4B9Kxeqqv1VtVBVC3NzczOsTpJ0vFkCfhQ4WlWPja7fx3LQJUmbYOqAV9V/Ad9JcvHopquAbwwylSRprFlfhfIbwD2jV6B8G/jQ7CNJkiYxU8Cr6hCwMMwokqQT4TsxJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTc0c8CSnJPlqks8MMZAkaTJDHIHfChwe4OdIkk7ATAFPcgFwLXDHMONIkia1a8bH/wnwO8CZay2QZC+wF2DPnj0zrk7aeeb3Pbwl6z1y+7Vbsl4NZ+oj8CTvB45V1cH1lquq/VW1UFULc3Nz065OkrTCLKdQrgR+IckR4FPAe5L8zSBTSZLGmjrgVfXRqrqgquaBG4B/rqoPDjaZJGldvg5ckpqa9UlMAKrqS8CXhvhZkqTJeAQuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTBlySmjLgktSUAZekpgy4JDVlwCWpKQMuSU1NHfAkFyb5YpLDSZ5KcuuQg0mS1rdrhse+Cvx2VT2e5EzgYJIDVfWNgWaTJK1j6iPwqnqhqh4fXf4+cBg4f6jBJEnrG+QceJJ54DLgsVXu25tkMcni0tLSEKuTJDFAwJO8Cfg08JGqennl/VW1v6oWqmphbm5u1tVJkkZmCniSU1mO9z1Vdf8wI0mSJjHLq1AC3AkcrqqPDzeSJGkSsxyBXwncBLwnyaHR1zUDzSVJGmPqlxFW1b8AGXAWSdIJ8J2YktSUAZekpgy4JDVlwCWpKQMuSU0ZcElqyoBLUlMGXJKaMuCS1JQBl6SmDLgkNWXAJampWf5PzE01v+/hLVv3kduv3bJ1n2y2aj+7jzfXVv553iob8TvmEbgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpoy4JLUlAGXpKYMuCQ1ZcAlqSkDLklNGXBJasqAS1JTMwU8ydVJvpnk2ST7hhpKkjTe1AFPcgrwF8DPA5cANya5ZKjBJEnrm+UI/B3As1X17ap6BfgUcN0wY0mSxklVTffA5Hrg6qr61dH1m4CfrqoPr1huL7B3dPVi4JvTj7shdgPf2+ohBrKTtgV21va4LdtTl235iaqaW3njLP8jT1a57Q1/G1TVfmD/DOvZUEkWq2phq+cYwk7aFthZ2+O2bE/dt2WWUyhHgQuPu34B8Pxs40iSJjVLwP8VuCjJ25KcBtwAPDTMWJKkcaY+hVJVryb5MPCPwCnAXVX11GCTbZ5te3pnCjtpW2BnbY/bsj213papn8SUJG0t34kpSU0ZcElq6qQLeJI3JzmQ5JnR97PXWO5IkieSHEqyuNlzrmfcRxhk2Z+N7v96ksu3Ys5JTLAt707y0mg/HEry+1sx5ySS3JXkWJIn17i/034Zty2d9suFSb6Y5HCSp5LcusoybfbN61TVSfUF/CGwb3R5H/AHayx3BNi91fOuMtcpwL8BbwdOA74GXLJimWuAz7H8Wv0rgMe2eu4ZtuXdwGe2etYJt+ddwOXAk2vc32K/TLgtnfbLecDlo8tnAt/q+mdm5ddJdwTO8tv97x5dvhv4wNaNMpVJPsLgOuCva9lXgLOSnLfZg05gR30cQ1U9Cry4ziJd9ssk29JGVb1QVY+PLn8fOAycv2KxNvvmeCdjwM+tqhdgeccC56yxXAGPJDk4+jiA7eJ84DvHXT/KG38ZJ1lmO5h0zncm+VqSzyX5yc0ZbUN02S+TardfkswDlwGPrbir5b6Z5a3021aSfwLesspdHzuBH3NlVT2f5BzgQJKnR0clW22SjzCY6GMOtoFJ5nyc5c+B+EGSa4B/AC7a6ME2SJf9Mol2+yXJm4BPAx+pqpdX3r3KQ7b9vtmRR+BV9d6qunSVrweB7772T6PR92Nr/IznR9+PAQ+w/M/97WCSjzDo8jEHY+esqper6gejy58FTk2ye/NGHFSX/TJWt/2S5FSW431PVd2/yiIt982ODPgYDwE3jy7fDDy4coEkZyQ587XLwM8Bqz4bvwUm+QiDh4BfGj2zfgXw0munjbaZsduS5C1JMrr8DpZ/Z/970ycdRpf9Mlan/TKa807gcFV9fI3FWu6bHXkKZYzbgb9PcgvwHPCLAEneCtxRVdcA5wIPjH4/dwF/W1Wf36J5X6fW+AiDJL82uv8TwGdZflb9WeCHwIe2at71TLgt1wO/nuRV4H+BG2r0soHtJsm9LL86Y3eSo8BtwKnQa7/ARNvSZr8AVwI3AU8kOTS67feAPdBv3xzPt9JLUlMn4ykUSdoRDLgkNWXAJakpAy5JTRlwSWrKgEtSUwZckpr6f0a78YWRqw+MAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ww_fit_nn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e55a9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be4b294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c74ea2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##fitting same model 10 times and then taking avg across performances\n",
    "# train_RMSE_list1=[]\n",
    "# val_RMSE_list1=[]\n",
    "# for i in range(10):\n",
    "#     ##Fitting the model\n",
    "#     ww_fit_nn1, bb_fit_nn1, V_fit_nn1, bk_fit_nn1=fit_nn_gradopt1(X=X_train,yy=y_train,K=20,alpha=30)\n",
    "    \n",
    "#     ##Predictions\n",
    "#     params1=(ww_fit_nn1, bb_fit_nn1, V_fit_nn1, bk_fit_nn1)\n",
    "#     yy_train_pred_nn1=nn_cost(params1,X_train,yy=None,alpha=30)\n",
    "#     yy_val_pred_nn1=nn_cost(params1,X_val,yy=None,alpha=30)\n",
    "    \n",
    "#     ##Performance\n",
    "#     train_RMSE_list1=train_RMSE_list1+[RMSE(yy_true=y_train,yy_pred=yy_train_pred_nn1)]\n",
    "#     val_RMSE_list1=val_RMSE_list1+[RMSE(yy_true=y_val,yy_pred=yy_val_pred_nn1)]\n",
    "\n",
    "# print(\"average training error: \",np.mean(train_RMSE_list1))\n",
    "# print(\"average val error: \",np.mean(val_RMSE_list1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86082028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84c1b850",
   "metadata": {},
   "source": [
    "## Q5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "402e74af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_reg_nn(X_train,yy_train,X_val,yy_val,K,alpha):\n",
    "    D = X_train.shape[1]\n",
    "    args = (X_train, yy_train, alpha)\n",
    "    \n",
    "    ## Following GlorotInit initialisation\n",
    "    init = (np.random.normal(loc=0,scale=np.sqrt(2/(K+1)),size=K), \n",
    "            np.array(0),np.random.normal(loc=0,scale=np.sqrt(2/(K+D)),size=(K,D)),np.zeros(K))\n",
    "    \n",
    "    ww_fit_nn, bb_fit_nn, V_fit_nn, bk_fit_nn = minimize_list(nn_cost, init, args)\n",
    "    params=(ww_fit_nn, bb_fit_nn, V_fit_nn, bk_fit_nn)\n",
    "    \n",
    "    yy_val_pred_nn=nn_cost(params,X_val,yy=None,alpha=alpha)\n",
    "    return(RMSE(yy_true=yy_val,yy_pred=yy_val_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e1fbbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2708707794692373"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_reg_nn(X_train=X_train,yy_train=y_train,X_val=X_val,yy_val=y_val,K=20,alpha=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0570d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def POI_acquisition(alpha_grid,posterior_mean,posterior_std,best_performance_value):\n",
    "    probs = norm.cdf((posterior_mean - best_performance_value) / (posterior_std+1E-9))\n",
    "    return(alpha_grid[np.argmax(probs)])\n",
    "\n",
    "def bayes_optimiser(X_train,yy_train,X_val,yy_val,baseline_performance_value,alpha_grid,num_iter,verbose=False):\n",
    "    training_locs=np.random.choice(alpha_grid, 3)\n",
    "    testing_locs=np.setdiff1d(alpha_grid,training_locs)\n",
    "    \n",
    "    #K=20 refers to 20 hidden units in hidden layer\n",
    "    RMSE_arr=np.array(list(map(lambda x:fit_reg_nn(X_train,yy_train,X_val,yy_val,K=20,alpha=x),training_locs)))\n",
    "    performance_arr=baseline_performance_value-RMSE_arr    \n",
    "    \n",
    "    i=1\n",
    "    while(i<=num_iter and len(testing_locs)>0):\n",
    "        posterior_mean,posterior_cov=gp_post_par(X_rest=testing_locs, X_obs=training_locs, yy=performance_arr)\n",
    "        posterior_std = np.sqrt(np.diag(posterior_cov))\n",
    "        \n",
    "        next_alpha=POI_acquisition(testing_locs,posterior_mean,posterior_std,np.max(performance_arr))\n",
    "        next_RMSE=fit_reg_nn(X_train,yy_train,X_val,yy_val,K=20,alpha=next_alpha)\n",
    "        \n",
    "        training_locs=np.append(training_locs,next_alpha)\n",
    "        testing_locs=np.setdiff1d(testing_locs,next_alpha)\n",
    "        performance_arr=np.append(performance_arr,baseline_performance_value-next_RMSE)\n",
    "        RMSE_arr=np.append(RMSE_arr,next_RMSE)\n",
    "        \n",
    "        if(verbose):\n",
    "            print(\"trial number: \"+str(i)+\" alpha: \"+str(next_alpha)+\" RMSE: \"+str(next_RMSE))\n",
    "        i=i+1\n",
    "    \n",
    "    return(training_locs,RMSE_arr,training_locs[np.argmin(RMSE_arr)],np.min(RMSE_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11acf42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "342872fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial number: 1 alpha: 17.04 RMSE: 0.2768022652073188\n",
      "trial number: 2 alpha: 0.0 RMSE: 0.26587020591107535\n",
      "trial number: 3 alpha: 0.02 RMSE: 0.2770755872986901\n",
      "trial number: 4 alpha: 49.980000000000004 RMSE: 0.2925902388177989\n",
      "trial number: 5 alpha: 26.060000000000002 RMSE: 0.26832570224465363\n"
     ]
    }
   ],
   "source": [
    "alpha_history,RMSE_history,best_alpha,best_RMSE=bayes_optimiser(X_train=X_train,yy_train=y_train,X_val=X_val,yy_val=y_val,\n",
    "                                                                baseline_performance_value=val_nn_RMSE,\n",
    "                                                                alpha_grid=np.arange(0,50,0.02),num_iter=5,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ff6a7dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "54423f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05827332443759188\n",
      "0.2641690945749721\n",
      "0.2937430639214382\n"
     ]
    }
   ],
   "source": [
    "##Fitting the model\n",
    "ww_fit_nn_best_alpha, bb_fit_nn_best_alpha, V_fit_nn_best_alpha, bk_fit_nn_best_alpha=fit_nn_gradopt(X=X_train,yy=y_train,\n",
    "                                                                                                     K=20,alpha=best_alpha)\n",
    "##Predictions\n",
    "params_best_alpha=(ww_fit_nn_best_alpha, bb_fit_nn_best_alpha, V_fit_nn_best_alpha, bk_fit_nn_best_alpha)\n",
    "yy_train_pred_nn_best_alpha=nn_cost(params_best_alpha,X_train,yy=None,alpha=best_alpha)\n",
    "yy_val_pred_nn_best_alpha=nn_cost(params_best_alpha,X_val,yy=None,alpha=best_alpha)\n",
    "yy_test_pred_nn_best_alpha=nn_cost(params_best_alpha,X_test,yy=None,alpha=best_alpha)\n",
    "\n",
    "##Performance\n",
    "print(RMSE(yy_true=y_train,yy_pred=yy_train_pred_nn_best_alpha))\n",
    "val_nn_RMSE_best_alpha=RMSE(yy_true=y_val,yy_pred=yy_val_pred_nn_best_alpha)\n",
    "print(RMSE(yy_true=y_val,yy_pred=yy_val_pred_nn_best_alpha))\n",
    "print(RMSE(yy_true=y_test,yy_pred=yy_test_pred_nn_best_alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "81108e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2936897070574244\n"
     ]
    }
   ],
   "source": [
    "ww_fit_nn_best_alpha, bb_fit_nn_best_alpha, V_fit_nn_best_alpha, bk_fit_nn_best_alpha=fit_nn_gradopt(X=X_train,yy=y_train,\n",
    "                                                                                                     K=20,alpha=best_alpha)\n",
    "params_best_alpha=(ww_fit_nn_best_alpha, bb_fit_nn_best_alpha, V_fit_nn_best_alpha, bk_fit_nn_best_alpha)\n",
    "yy_test_pred_nn_best_alpha=nn_cost(params_best_alpha,X_test,yy=None,alpha=best_alpha)\n",
    "print(RMSE(yy_true=y_test,yy_pred=yy_test_pred_nn_best_alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9a83d837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07526859423435905\n",
      "0.24290555682810655\n"
     ]
    }
   ],
   "source": [
    "best_alpha=4.08\n",
    "##Fitting the model\n",
    "ww_fit_nn_best_alpha, bb_fit_nn_best_alpha, V_fit_nn_best_alpha, bk_fit_nn_best_alpha=fit_nn_gradopt(X=X_train,yy=y_train,\n",
    "                                                                                                     K=20,alpha=best_alpha)\n",
    "##Predictions\n",
    "params_best_alpha=(ww_fit_nn_best_alpha, bb_fit_nn_best_alpha, V_fit_nn_best_alpha, bk_fit_nn_best_alpha)\n",
    "yy_train_pred_nn_best_alpha=nn_cost(params_best_alpha,X_train,yy=None,alpha=best_alpha)\n",
    "yy_val_pred_nn_best_alpha=nn_cost(params_best_alpha,X_val,yy=None,alpha=best_alpha)\n",
    "\n",
    "##Performance\n",
    "print(RMSE(yy_true=y_train,yy_pred=yy_train_pred_nn_best_alpha))\n",
    "val_nn_RMSE_best_alpha=RMSE(yy_true=y_val,yy_pred=yy_val_pred_nn_best_alpha)\n",
    "print(RMSE(yy_true=y_val,yy_pred=yy_val_pred_nn_best_alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59395fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fab0fcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial number: 1 alpha: 2.8000000000000003 RMSE: 0.2509295991251492\n",
      "trial number: 2 alpha: 1.1400000000000001 RMSE: 0.2574672848854981\n",
      "trial number: 3 alpha: 5.32 RMSE: 0.2607859872844001\n",
      "trial number: 4 alpha: 0.0 RMSE: 0.2746088777956945\n",
      "trial number: 5 alpha: 7.04 RMSE: 0.24547757820512459\n",
      "trial number: 6 alpha: 8.14 RMSE: 0.2674002193714472\n",
      "trial number: 7 alpha: 16.46 RMSE: 0.2648551003706191\n",
      "trial number: 8 alpha: 49.980000000000004 RMSE: 0.2802393763772188\n",
      "trial number: 9 alpha: 22.52 RMSE: 0.27355808873502296\n",
      "trial number: 10 alpha: 5.74 RMSE: 0.2569678341618683\n",
      "trial number: 11 alpha: 10.82 RMSE: 0.2544934323119925\n",
      "trial number: 12 alpha: 41.1 RMSE: 0.2777965501293198\n",
      "trial number: 13 alpha: 10.84 RMSE: 0.26416598180101386\n",
      "trial number: 14 alpha: 5.42 RMSE: 0.23938652390918072\n",
      "trial number: 15 alpha: 5.5600000000000005 RMSE: 0.2588229553477866\n",
      "trial number: 16 alpha: 14.94 RMSE: 0.2574056863754749\n",
      "trial number: 17 alpha: 9.42 RMSE: 0.26305307724269994\n",
      "trial number: 18 alpha: 18.6 RMSE: 0.26232086544601\n",
      "trial number: 19 alpha: 0.02 RMSE: 0.2639069041845759\n",
      "trial number: 20 alpha: 25.94 RMSE: 0.2745442384457986\n",
      "trial number: 21 alpha: 4.78 RMSE: 0.2544220979480071\n",
      "trial number: 22 alpha: 45.300000000000004 RMSE: 0.27898452080037306\n",
      "trial number: 23 alpha: 36.72 RMSE: 0.27295924346088213\n",
      "trial number: 24 alpha: 13.72 RMSE: 0.26919729419029514\n",
      "trial number: 25 alpha: 4.76 RMSE: 0.2566638135713389\n",
      "trial number: 26 alpha: 4.74 RMSE: 0.24291968358895843\n",
      "trial number: 27 alpha: 4.72 RMSE: 0.25511429232819144\n",
      "trial number: 28 alpha: 0.04 RMSE: 0.2777600701979263\n",
      "trial number: 29 alpha: 7.48 RMSE: 0.2517641764165875\n",
      "trial number: 30 alpha: 19.66 RMSE: 0.2839665069808424\n",
      "trial number: 31 alpha: 7.78 RMSE: 0.25649563051712687\n",
      "trial number: 32 alpha: 5.36 RMSE: 0.2484789569396371\n",
      "trial number: 33 alpha: 8.38 RMSE: 0.2608706463471098\n",
      "trial number: 34 alpha: 49.96 RMSE: 0.28387651753487725\n",
      "trial number: 35 alpha: 30.54 RMSE: 0.27084996678670487\n",
      "trial number: 36 alpha: 4.46 RMSE: 0.26495764605414135\n",
      "trial number: 37 alpha: 11.78 RMSE: 0.2545595248507404\n",
      "trial number: 38 alpha: 38.0 RMSE: 0.2707191371138616\n",
      "trial number: 39 alpha: 9.06 RMSE: 0.2604079462874095\n",
      "trial number: 40 alpha: 13.76 RMSE: 0.264625919093174\n",
      "trial number: 41 alpha: 4.32 RMSE: 0.24498201011060308\n",
      "trial number: 42 alpha: 4.34 RMSE: 0.23637011527172833\n",
      "trial number: 43 alpha: 26.12 RMSE: 0.2768322540667426\n",
      "trial number: 44 alpha: 42.86 RMSE: 0.2794790894972488\n",
      "trial number: 45 alpha: 33.7 RMSE: 0.26902756649151316\n",
      "trial number: 46 alpha: 0.06 RMSE: 0.2671514579868101\n",
      "trial number: 47 alpha: 4.36 RMSE: 0.25190087095400326\n",
      "trial number: 48 alpha: 7.42 RMSE: 0.2608282205442609\n",
      "trial number: 49 alpha: 16.14 RMSE: 0.2808057761873889\n",
      "trial number: 50 alpha: 3.84 RMSE: 0.2522125450070664\n",
      "trial number: 51 alpha: 3.8200000000000003 RMSE: 0.2580617208934791\n",
      "trial number: 52 alpha: 8.08 RMSE: 0.2642237456588091\n",
      "trial number: 53 alpha: 36.92 RMSE: 0.2820670583838114\n",
      "trial number: 54 alpha: 29.740000000000002 RMSE: 0.27094142296959234\n",
      "trial number: 55 alpha: 0.08 RMSE: 0.2662372372554471\n",
      "trial number: 56 alpha: 49.94 RMSE: 0.2831786566276408\n",
      "trial number: 57 alpha: 22.54 RMSE: 0.26944440680801834\n",
      "trial number: 58 alpha: 4.0600000000000005 RMSE: 0.2535613856083081\n",
      "trial number: 59 alpha: 8.52 RMSE: 0.2567342758700397\n",
      "trial number: 60 alpha: 4.0200000000000005 RMSE: 0.2512427962134893\n",
      "trial number: 61 alpha: 44.42 RMSE: 0.27884721873073026\n",
      "trial number: 62 alpha: 12.0 RMSE: 0.2639863982996992\n",
      "trial number: 63 alpha: 4.0 RMSE: 0.25786977997588684\n",
      "trial number: 64 alpha: 26.46 RMSE: 0.26757440904788243\n",
      "trial number: 65 alpha: 0.1 RMSE: 0.24486202380279412\n",
      "trial number: 66 alpha: 0.12 RMSE: 0.2620702715858088\n",
      "trial number: 67 alpha: 19.82 RMSE: 0.26798233741454625\n",
      "trial number: 68 alpha: 32.26 RMSE: 0.27159570221134227\n",
      "trial number: 69 alpha: 3.7 RMSE: 0.23501771067780647\n",
      "trial number: 70 alpha: 3.5 RMSE: 0.2528896297056628\n",
      "trial number: 71 alpha: 0.14 RMSE: 0.24729414033522876\n",
      "trial number: 72 alpha: 0.16 RMSE: 0.26661910222310653\n",
      "trial number: 73 alpha: 39.660000000000004 RMSE: 0.27762731053195705\n",
      "trial number: 74 alpha: 3.8000000000000003 RMSE: 0.2563656483570658\n",
      "trial number: 75 alpha: 14.6 RMSE: 0.2565314271044898\n",
      "trial number: 76 alpha: 8.24 RMSE: 0.2621424329842403\n",
      "trial number: 77 alpha: 23.78 RMSE: 0.2818729683675956\n",
      "trial number: 78 alpha: 16.3 RMSE: 0.25985141322263944\n",
      "trial number: 79 alpha: 12.38 RMSE: 0.2659985779263514\n",
      "trial number: 80 alpha: 3.54 RMSE: 0.25089903872628255\n",
      "trial number: 81 alpha: 3.56 RMSE: 0.2566754127643148\n",
      "trial number: 82 alpha: 32.62 RMSE: 0.27420267746653854\n",
      "trial number: 83 alpha: 49.92 RMSE: 0.29437157967170086\n",
      "trial number: 84 alpha: 18.12 RMSE: 0.26524711270346635\n",
      "trial number: 85 alpha: 0.18 RMSE: 0.26757504560776446\n",
      "trial number: 86 alpha: 7.0600000000000005 RMSE: 0.25527492621056114\n",
      "trial number: 87 alpha: 28.44 RMSE: 0.27580828274638225\n",
      "trial number: 88 alpha: 3.88 RMSE: 0.2512262486891084\n",
      "trial number: 89 alpha: 12.780000000000001 RMSE: 0.2653565970907916\n",
      "trial number: 90 alpha: 7.08 RMSE: 0.26137638729370366\n",
      "trial number: 91 alpha: 44.44 RMSE: 0.29218283232387704\n",
      "trial number: 92 alpha: 3.52 RMSE: 0.24629055197209504\n",
      "trial number: 93 alpha: 36.2 RMSE: 0.27634151984088984\n",
      "trial number: 94 alpha: 3.48 RMSE: 0.2635633492485651\n",
      "trial number: 95 alpha: 18.8 RMSE: 0.2748571307804493\n",
      "trial number: 96 alpha: 0.2 RMSE: 0.2627982861235839\n",
      "trial number: 97 alpha: 7.72 RMSE: 0.26127769039555976\n",
      "trial number: 98 alpha: 13.4 RMSE: 0.25578762163897456\n",
      "trial number: 99 alpha: 3.6 RMSE: 0.25649495572970044\n",
      "trial number: 100 alpha: 10.64 RMSE: 0.2588030825839108\n"
     ]
    }
   ],
   "source": [
    "alpha_history,RMSE_history,best_alpha,best_RMSE=bayes_optimiser(X_train=X_train,yy_train=y_train,X_val=X_val,yy_val=y_val,\n",
    "                                                                baseline_performance_value=val_nn_RMSE,\n",
    "                                                                alpha_grid=np.arange(0,50,0.02),num_iter=100,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8627eb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3895d930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23501771067780647"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de9561b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
