{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JYsWwiwnPzi",
    "outputId": "8029905c-91de-4380-ba5f-807ba2f1ecbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 21 13:19:04 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   40C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdNIB899nhlq",
    "outputId": "7990a127-c05e-456f-d75b-f12e31303dc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#mounting google drive on colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfSazzTdnmaM"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXN_d9Evntel"
   },
   "outputs": [],
   "source": [
    "X_train=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_X_trainv7_exp1_strat.npy\")\n",
    "y_train=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_y_trainv7_exp1_strat.npy\").astype(int)\n",
    "\n",
    "X_test=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_X_testv7_exp1_strat.npy\")\n",
    "y_test=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_y_testv7_exp1_strat.npy\").astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NVkzHpArmQFD",
    "outputId": "0e101c62-3edd-4f06-f2d4-35bcb281c0a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/scipy/signal/spectral.py:1966: UserWarning: nperseg = 256 is greater than input length  = 50, using nperseg = 50\n",
      "  .format(nperseg, input_length))\n"
     ]
    }
   ],
   "source": [
    "def calc_freq_signal(arr):\n",
    "    freqs, psd = signal.welch(arr, fs=10)\n",
    "    return psd\n",
    "\n",
    "X_train_f=np.apply_along_axis(calc_freq_signal, 1, X_train)\n",
    "X_test_f=np.apply_along_axis(calc_freq_signal, 1, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6MFvsoGCeuLr"
   },
   "outputs": [],
   "source": [
    "X_train_1d=np.gradient(X_train,axis=1)\n",
    "X_test_1d=np.gradient(X_test,axis=1)\n",
    "X_train=np.dstack([X_train,X_train_1d])\n",
    "X_test=np.dstack([X_test,X_test_1d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X86rj9C3fCRa",
    "outputId": "d4bf7eff-cffa-4d0f-bf9d-3c40f4fe4f57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21256, 50, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yR5fAIqKH8vV"
   },
   "outputs": [],
   "source": [
    "def custom_scaler(X, range=(0, 1),min=None,max=None):\n",
    "    mi, ma = range\n",
    "    if(min==None):\n",
    "      min=X.min()\n",
    "      max=X.max()\n",
    "      print(\"\\nTrain_Scaling:- min=\",min,\" max=\",max)\n",
    "    X_std = (X - min) / (max - min)\n",
    "    X_scaled = X_std * (ma - mi) + mi\n",
    "    return min,max,X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JceKGdin-e6",
    "outputId": "c1ce67af-78ef-4ad8-b17d-7c074c3636ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train_Scaling:- min= -23.713684702675817  max= 31.485281374238568\n",
      "\n",
      "Train_Scaling:- min= -24.82483202959873  max= 27.77992367859456\n",
      "\n",
      "Train_Scaling:- min= -9.741382183644802  max= 12.104502946593886\n",
      "\n",
      "Train_Scaling:- min= -17.405683792063165  max= 17.232860997377067\n",
      "Frequency signals scaling:-------------\n",
      "\n",
      "Train_Scaling:- min= 0.0  max= 416.8466535787175\n",
      "\n",
      "Train_Scaling:- min= 0.0  max= 935.9266404552648\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "#X_train contains 8 signals x1,x2,y1,y2,x1d,2d,y1d,y2d\n",
    "X_train_scaled=copy.copy(X_train)\n",
    "X_test_scaled=copy.copy(X_test)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,0:2]=custom_scaler(X_train_scaled[:,:,0:2],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,0:2]=custom_scaler(X_test_scaled[:,:,0:2],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,2:4]=custom_scaler(X_train_scaled[:,:,2:4],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,2:4]=custom_scaler(X_test_scaled[:,:,2:4],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,4:6]=custom_scaler(X_train_scaled[:,:,4:6],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,4:6]=custom_scaler(X_test_scaled[:,:,4:6],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,6:8]=custom_scaler(X_train_scaled[:,:,6:8],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,6:8]=custom_scaler(X_test_scaled[:,:,6:8],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "\n",
    "print(\"Frequency signals scaling:-------------\")\n",
    "#X_train contains 8 signals x1f,x2f,y1f,y2f\n",
    "X_train_scaled_f=copy.copy(X_train_f)\n",
    "X_test_scaled_f=copy.copy(X_test_f)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled_f[:,:,0:2]=custom_scaler(X_train_scaled_f[:,:,0:2],range=(0,1))\n",
    "_,_,X_test_scaled_f[:,:,0:2]=custom_scaler(X_test_scaled_f[:,:,0:2],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled_f[:,:,2:4]=custom_scaler(X_train_scaled_f[:,:,2:4],range=(0,1))\n",
    "_,_,X_test_scaled_f[:,:,2:4]=custom_scaler(X_test_scaled_f[:,:,2:4],range=(0,1),min=min_temp,max=max_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L7JWtkWdfSCb",
    "outputId": "535dcdf1-f9c7-4434-f482-51ddbbe6a959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21256, 50, 8)\n",
      "(21256, 26, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(X_train_scaled_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "u8CMIO_ToBr9"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Part 2 - Building the RNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "\n",
    "input_1 = Input((X_train_scaled.shape[1], X_train_scaled.shape[2]))\n",
    "input_2 = Input((X_train_scaled_f.shape[1], X_train_scaled_f.shape[2]))\n",
    "\n",
    "x1=LSTM(units = 100, return_sequences = True)(input_1)\n",
    "x1=LSTM(units = 50)(x1)\n",
    "\n",
    "x2=LSTM(units = 100, return_sequences = True)(input_2)\n",
    "x2=LSTM(units = 50)(x2)\n",
    "\n",
    "x = layers.concatenate([x1, x2])\n",
    "\n",
    "output_layer = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "classifier=keras.Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "\n",
    "\n",
    "# Compiling the LSTM\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "uf-jNI2KZJUu"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_strat_v2.h5\",\n",
    "                             monitor=\"val_accuracy\",\n",
    "                             mode=\"max\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', # value being monitored for improvement\n",
    "                          min_delta = 0, #Abs value and is the min change required before we stop\n",
    "                          patience = 20, #Number of epochs we wait before stopping \n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True) #keeps the best weigths once stopped\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop,checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcUvZBOYoFNC",
    "outputId": "1dac06a4-23e4-473e-fd81-bce29016126e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "329/333 [============================>.] - ETA: 0s - loss: 0.5537 - accuracy: 0.7120\n",
      "Epoch 1: val_accuracy improved from -inf to 0.71229, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_strat_v2.h5\n",
      "333/333 [==============================] - 11s 17ms/step - loss: 0.5532 - accuracy: 0.7120 - val_loss: 0.5138 - val_accuracy: 0.7123\n",
      "Epoch 2/200\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.5145 - accuracy: 0.7203\n",
      "Epoch 2: val_accuracy improved from 0.71229 to 0.73660, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_strat_v2.h5\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5142 - accuracy: 0.7205 - val_loss: 0.5022 - val_accuracy: 0.7366\n",
      "Epoch 3/200\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.5150 - accuracy: 0.7183\n",
      "Epoch 3: val_accuracy did not improve from 0.73660\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5149 - accuracy: 0.7183 - val_loss: 0.4976 - val_accuracy: 0.7105\n",
      "Epoch 4/200\n",
      "333/333 [==============================] - ETA: 0s - loss: 0.5103 - accuracy: 0.7229\n",
      "Epoch 4: val_accuracy did not improve from 0.73660\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5103 - accuracy: 0.7229 - val_loss: 0.5229 - val_accuracy: 0.7127\n",
      "Epoch 5/200\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.4980 - accuracy: 0.7296\n",
      "Epoch 5: val_accuracy improved from 0.73660 to 0.73910, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_strat_v2.h5\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4980 - accuracy: 0.7296 - val_loss: 0.4996 - val_accuracy: 0.7391\n",
      "Epoch 6/200\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.5058 - accuracy: 0.7268\n",
      "Epoch 6: val_accuracy improved from 0.73910 to 0.74232, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_strat_v2.h5\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5058 - accuracy: 0.7268 - val_loss: 0.4848 - val_accuracy: 0.7423\n",
      "Epoch 7/200\n",
      "330/333 [============================>.] - ETA: 0s - loss: 0.5051 - accuracy: 0.7254\n",
      "Epoch 7: val_accuracy did not improve from 0.74232\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5054 - accuracy: 0.7251 - val_loss: 0.4939 - val_accuracy: 0.7127\n",
      "Epoch 8/200\n",
      "330/333 [============================>.] - ETA: 0s - loss: 0.4999 - accuracy: 0.7279\n",
      "Epoch 8: val_accuracy did not improve from 0.74232\n",
      "333/333 [==============================] - 6s 17ms/step - loss: 0.5005 - accuracy: 0.7274 - val_loss: 0.4927 - val_accuracy: 0.7337\n",
      "Epoch 9/200\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.4992 - accuracy: 0.7269\n",
      "Epoch 9: val_accuracy improved from 0.74232 to 0.74303, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_strat_v2.h5\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4992 - accuracy: 0.7268 - val_loss: 0.4859 - val_accuracy: 0.7430\n",
      "Epoch 10/200\n",
      "333/333 [==============================] - ETA: 0s - loss: 0.4965 - accuracy: 0.7310\n",
      "Epoch 10: val_accuracy did not improve from 0.74303\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.4965 - accuracy: 0.7310 - val_loss: 0.4920 - val_accuracy: 0.7370\n",
      "Epoch 11/200\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.4963 - accuracy: 0.7320\n",
      "Epoch 11: val_accuracy did not improve from 0.74303\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.4961 - accuracy: 0.7321 - val_loss: 0.4825 - val_accuracy: 0.7423\n",
      "Epoch 12/200\n",
      "329/333 [============================>.] - ETA: 0s - loss: 0.4907 - accuracy: 0.7370\n",
      "Epoch 12: val_accuracy did not improve from 0.74303\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.4907 - accuracy: 0.7371 - val_loss: 0.5056 - val_accuracy: 0.7051\n",
      "Epoch 13/200\n",
      "329/333 [============================>.] - ETA: 0s - loss: 0.4919 - accuracy: 0.7344\n",
      "Epoch 13: val_accuracy did not improve from 0.74303\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.4917 - accuracy: 0.7344 - val_loss: 0.4876 - val_accuracy: 0.7244\n",
      "Epoch 14/200\n",
      "329/333 [============================>.] - ETA: 0s - loss: 0.4891 - accuracy: 0.7339\n",
      "Epoch 14: val_accuracy did not improve from 0.74303\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4887 - accuracy: 0.7341 - val_loss: 0.4757 - val_accuracy: 0.7359\n",
      "Epoch 15/200\n",
      "330/333 [============================>.] - ETA: 0s - loss: 0.4824 - accuracy: 0.7358\n",
      "Epoch 15: val_accuracy improved from 0.74303 to 0.74589, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_strat_v2.h5\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4822 - accuracy: 0.7361 - val_loss: 0.4691 - val_accuracy: 0.7459\n",
      "Epoch 16/200\n",
      "330/333 [============================>.] - ETA: 0s - loss: 0.4576 - accuracy: 0.7531\n",
      "Epoch 16: val_accuracy improved from 0.74589 to 0.78342, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_strat_v2.h5\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.4576 - accuracy: 0.7531 - val_loss: 0.4068 - val_accuracy: 0.7834\n",
      "Epoch 17/200\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.4008 - accuracy: 0.7887\n",
      "Epoch 17: val_accuracy did not improve from 0.78342\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.4010 - accuracy: 0.7887 - val_loss: 0.4367 - val_accuracy: 0.7445\n",
      "Epoch 18/200\n",
      "329/333 [============================>.] - ETA: 0s - loss: 0.3668 - accuracy: 0.8171\n",
      "Epoch 18: val_accuracy improved from 0.78342 to 0.79164, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_strat_v2.h5\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3664 - accuracy: 0.8173 - val_loss: 0.4483 - val_accuracy: 0.7916\n",
      "Epoch 19/200\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.3441 - accuracy: 0.8331\n",
      "Epoch 19: val_accuracy did not improve from 0.79164\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.3437 - accuracy: 0.8333 - val_loss: 0.3875 - val_accuracy: 0.7891\n",
      "Epoch 20/200\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.3187 - accuracy: 0.8516\n",
      "Epoch 20: val_accuracy improved from 0.79164 to 0.88099, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_strat_v2.h5\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3191 - accuracy: 0.8513 - val_loss: 0.2591 - val_accuracy: 0.8810\n",
      "Epoch 21/200\n",
      "330/333 [============================>.] - ETA: 0s - loss: 0.3072 - accuracy: 0.8552\n",
      "Epoch 21: val_accuracy did not improve from 0.88099\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.3075 - accuracy: 0.8549 - val_loss: 0.2996 - val_accuracy: 0.8681\n",
      "Epoch 22/200\n",
      "333/333 [==============================] - ETA: 0s - loss: 0.2890 - accuracy: 0.8644\n",
      "Epoch 22: val_accuracy did not improve from 0.88099\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2890 - accuracy: 0.8644 - val_loss: 0.2477 - val_accuracy: 0.8792\n",
      "Epoch 23/200\n",
      "329/333 [============================>.] - ETA: 0s - loss: 0.2890 - accuracy: 0.8640\n",
      "Epoch 23: val_accuracy did not improve from 0.88099\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2888 - accuracy: 0.8640 - val_loss: 0.3351 - val_accuracy: 0.8588\n",
      "Epoch 24/200\n",
      "329/333 [============================>.] - ETA: 0s - loss: 0.2807 - accuracy: 0.8658\n",
      "Epoch 24: val_accuracy did not improve from 0.88099\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2809 - accuracy: 0.8659 - val_loss: 0.2404 - val_accuracy: 0.8803\n",
      "Epoch 25/200\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.2817 - accuracy: 0.8662\n",
      "Epoch 25: val_accuracy improved from 0.88099 to 0.88992, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_strat_v2.h5\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2818 - accuracy: 0.8662 - val_loss: 0.2371 - val_accuracy: 0.8899\n",
      "Epoch 26/200\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.2715 - accuracy: 0.8710\n",
      "Epoch 26: val_accuracy did not improve from 0.88992\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2714 - accuracy: 0.8711 - val_loss: 0.3419 - val_accuracy: 0.8549\n",
      "Epoch 27/200\n",
      "329/333 [============================>.] - ETA: 0s - loss: 0.2735 - accuracy: 0.8691\n",
      "Epoch 27: val_accuracy did not improve from 0.88992\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2733 - accuracy: 0.8694 - val_loss: 0.2461 - val_accuracy: 0.8803\n",
      "Epoch 28/200\n",
      "330/333 [============================>.] - ETA: 0s - loss: 0.2733 - accuracy: 0.8688\n",
      "Epoch 28: val_accuracy did not improve from 0.88992\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2731 - accuracy: 0.8688 - val_loss: 0.2325 - val_accuracy: 0.8799\n",
      "Epoch 29/200\n",
      "333/333 [==============================] - ETA: 0s - loss: 0.2741 - accuracy: 0.8678\n",
      "Epoch 29: val_accuracy did not improve from 0.88992\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2741 - accuracy: 0.8678 - val_loss: 0.3232 - val_accuracy: 0.8553\n",
      "Epoch 30/200\n",
      "333/333 [==============================] - ETA: 0s - loss: 0.2756 - accuracy: 0.8655\n",
      "Epoch 30: val_accuracy did not improve from 0.88992\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2756 - accuracy: 0.8655 - val_loss: 0.3109 - val_accuracy: 0.8631\n",
      "Epoch 31/200\n",
      "333/333 [==============================] - ETA: 0s - loss: 0.2670 - accuracy: 0.8695\n",
      "Epoch 31: val_accuracy did not improve from 0.88992\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2670 - accuracy: 0.8695 - val_loss: 0.2541 - val_accuracy: 0.8742\n",
      "Epoch 32/200\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.2736 - accuracy: 0.8673\n",
      "Epoch 32: val_accuracy did not improve from 0.88992\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2736 - accuracy: 0.8673 - val_loss: 0.2305 - val_accuracy: 0.8813\n",
      "Epoch 33/200\n",
      "330/333 [============================>.] - ETA: 0s - loss: 0.2824 - accuracy: 0.8648\n",
      "Epoch 33: val_accuracy did not improve from 0.88992\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2819 - accuracy: 0.8651 - val_loss: 0.2402 - val_accuracy: 0.8749\n",
      "Epoch 34/200\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.2704 - accuracy: 0.8698\n",
      "Epoch 34: val_accuracy did not improve from 0.88992\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2713 - accuracy: 0.8694 - val_loss: 0.4068 - val_accuracy: 0.8113\n",
      "Epoch 35/200\n",
      "333/333 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.8368\n",
      "Epoch 35: val_accuracy did not improve from 0.88992\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.3301 - accuracy: 0.8368 - val_loss: 0.2401 - val_accuracy: 0.8824\n",
      "Epoch 36/200\n",
      "329/333 [============================>.] - ETA: 0s - loss: 0.2798 - accuracy: 0.8653\n",
      "Epoch 36: val_accuracy did not improve from 0.88992\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2796 - accuracy: 0.8653 - val_loss: 0.2353 - val_accuracy: 0.8810\n",
      "Epoch 37/200\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.2621 - accuracy: 0.8737\n",
      "Epoch 37: val_accuracy did not improve from 0.88992\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2622 - accuracy: 0.8736 - val_loss: 0.2292 - val_accuracy: 0.8888\n",
      "Epoch 38/200\n",
      "333/333 [==============================] - ETA: 0s - loss: 0.2634 - accuracy: 0.8742\n",
      "Epoch 38: val_accuracy did not improve from 0.88992\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2634 - accuracy: 0.8742 - val_loss: 0.2268 - val_accuracy: 0.8888\n",
      "Epoch 39/200\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.2680 - accuracy: 0.8726\n",
      "Epoch 39: val_accuracy did not improve from 0.88992\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2680 - accuracy: 0.8726 - val_loss: 0.2484 - val_accuracy: 0.8828\n",
      "Epoch 40/200\n",
      "333/333 [==============================] - ETA: 0s - loss: 0.2761 - accuracy: 0.8669\n",
      "Epoch 40: val_accuracy did not improve from 0.88992\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2761 - accuracy: 0.8669 - val_loss: 0.2325 - val_accuracy: 0.8849\n",
      "Epoch 41/200\n",
      "330/333 [============================>.] - ETA: 0s - loss: 0.2593 - accuracy: 0.8751\n",
      "Epoch 41: val_accuracy improved from 0.88992 to 0.89028, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_strat_v2.h5\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2593 - accuracy: 0.8751 - val_loss: 0.2226 - val_accuracy: 0.8903\n",
      "Epoch 42/200\n",
      "329/333 [============================>.] - ETA: 0s - loss: 0.2692 - accuracy: 0.8714\n",
      "Epoch 42: val_accuracy did not improve from 0.89028\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2686 - accuracy: 0.8718 - val_loss: 0.2292 - val_accuracy: 0.8849\n",
      "Epoch 43/200\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.2605 - accuracy: 0.8736\n",
      "Epoch 43: val_accuracy improved from 0.89028 to 0.89635, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_strat_v2.h5\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2602 - accuracy: 0.8738 - val_loss: 0.2292 - val_accuracy: 0.8964\n",
      "Epoch 44/200\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.2592 - accuracy: 0.8764\n",
      "Epoch 44: val_accuracy improved from 0.89635 to 0.89671, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_strat_v2.h5\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2591 - accuracy: 0.8764 - val_loss: 0.2302 - val_accuracy: 0.8967\n",
      "Epoch 45/200\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.2613 - accuracy: 0.8747\n",
      "Epoch 45: val_accuracy improved from 0.89671 to 0.89957, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_strat_v2.h5\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2614 - accuracy: 0.8746 - val_loss: 0.2142 - val_accuracy: 0.8996\n",
      "Epoch 46/200\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.2546 - accuracy: 0.8784\n",
      "Epoch 46: val_accuracy did not improve from 0.89957\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2546 - accuracy: 0.8783 - val_loss: 0.2601 - val_accuracy: 0.8860\n",
      "Epoch 47/200\n",
      "329/333 [============================>.] - ETA: 0s - loss: 0.2605 - accuracy: 0.8765\n",
      "Epoch 47: val_accuracy did not improve from 0.89957\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2599 - accuracy: 0.8768 - val_loss: 0.2195 - val_accuracy: 0.8917\n",
      "Epoch 48/200\n",
      "330/333 [============================>.] - ETA: 0s - loss: 0.2489 - accuracy: 0.8839\n",
      "Epoch 48: val_accuracy did not improve from 0.89957\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2488 - accuracy: 0.8838 - val_loss: 0.2355 - val_accuracy: 0.8903\n",
      "Epoch 49/200\n",
      "333/333 [==============================] - ETA: 0s - loss: 0.2507 - accuracy: 0.8824\n",
      "Epoch 49: val_accuracy did not improve from 0.89957\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2507 - accuracy: 0.8824 - val_loss: 0.2576 - val_accuracy: 0.8756\n",
      "Epoch 50/200\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.2475 - accuracy: 0.8849\n",
      "Epoch 50: val_accuracy did not improve from 0.89957\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2475 - accuracy: 0.8849 - val_loss: 0.2316 - val_accuracy: 0.8849\n",
      "Epoch 51/200\n",
      "330/333 [============================>.] - ETA: 0s - loss: 0.2362 - accuracy: 0.8889\n",
      "Epoch 51: val_accuracy did not improve from 0.89957\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2359 - accuracy: 0.8892 - val_loss: 0.2285 - val_accuracy: 0.8949\n",
      "Epoch 52/200\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.2559 - accuracy: 0.8809\n",
      "Epoch 52: val_accuracy did not improve from 0.89957\n",
      "333/333 [==============================] - 6s 19ms/step - loss: 0.2559 - accuracy: 0.8809 - val_loss: 0.2445 - val_accuracy: 0.8863\n",
      "Epoch 53/200\n",
      "333/333 [==============================] - ETA: 0s - loss: 0.2751 - accuracy: 0.8686\n",
      "Epoch 53: val_accuracy did not improve from 0.89957\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2751 - accuracy: 0.8686 - val_loss: 0.2415 - val_accuracy: 0.8899\n",
      "Epoch 54/200\n",
      "329/333 [============================>.] - ETA: 0s - loss: 0.2760 - accuracy: 0.8702\n",
      "Epoch 54: val_accuracy did not improve from 0.89957\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2752 - accuracy: 0.8707 - val_loss: 0.2285 - val_accuracy: 0.8978\n",
      "Epoch 55/200\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.2635 - accuracy: 0.8769\n",
      "Epoch 55: val_accuracy did not improve from 0.89957\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2635 - accuracy: 0.8769 - val_loss: 0.2483 - val_accuracy: 0.8906\n",
      "Epoch 56/200\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.2523 - accuracy: 0.8840\n",
      "Epoch 56: val_accuracy improved from 0.89957 to 0.91458, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_strat_v2.h5\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2520 - accuracy: 0.8842 - val_loss: 0.1955 - val_accuracy: 0.9146\n",
      "Epoch 57/200\n",
      "329/333 [============================>.] - ETA: 0s - loss: 0.2381 - accuracy: 0.8956\n",
      "Epoch 57: val_accuracy improved from 0.91458 to 0.92459, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_strat_v2.h5\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2379 - accuracy: 0.8957 - val_loss: 0.1902 - val_accuracy: 0.9246\n",
      "Epoch 58/200\n",
      "330/333 [============================>.] - ETA: 0s - loss: 0.2359 - accuracy: 0.9008\n",
      "Epoch 58: val_accuracy improved from 0.92459 to 0.93638, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_strat_v2.h5\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2358 - accuracy: 0.9009 - val_loss: 0.1749 - val_accuracy: 0.9364\n",
      "Epoch 59/200\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.2953 - accuracy: 0.8588\n",
      "Epoch 59: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2952 - accuracy: 0.8589 - val_loss: 0.2934 - val_accuracy: 0.8706\n",
      "Epoch 60/200\n",
      "329/333 [============================>.] - ETA: 0s - loss: 0.2850 - accuracy: 0.8652\n",
      "Epoch 60: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2848 - accuracy: 0.8653 - val_loss: 0.2556 - val_accuracy: 0.8753\n",
      "Epoch 61/200\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.2735 - accuracy: 0.8669\n",
      "Epoch 61: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2736 - accuracy: 0.8668 - val_loss: 0.2424 - val_accuracy: 0.8749\n",
      "Epoch 62/200\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.2632 - accuracy: 0.8705\n",
      "Epoch 62: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2633 - accuracy: 0.8704 - val_loss: 0.2389 - val_accuracy: 0.8803\n",
      "Epoch 63/200\n",
      "333/333 [==============================] - ETA: 0s - loss: 0.2624 - accuracy: 0.8701\n",
      "Epoch 63: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2624 - accuracy: 0.8701 - val_loss: 0.2289 - val_accuracy: 0.8778\n",
      "Epoch 64/200\n",
      "329/333 [============================>.] - ETA: 0s - loss: 0.2808 - accuracy: 0.8660\n",
      "Epoch 64: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2807 - accuracy: 0.8659 - val_loss: 0.2468 - val_accuracy: 0.8788\n",
      "Epoch 65/200\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.2601 - accuracy: 0.8741\n",
      "Epoch 65: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2602 - accuracy: 0.8741 - val_loss: 0.2407 - val_accuracy: 0.8806\n",
      "Epoch 66/200\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.2641 - accuracy: 0.8713\n",
      "Epoch 66: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2641 - accuracy: 0.8712 - val_loss: 0.2365 - val_accuracy: 0.8785\n",
      "Epoch 67/200\n",
      "330/333 [============================>.] - ETA: 0s - loss: 0.2542 - accuracy: 0.8782\n",
      "Epoch 67: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2539 - accuracy: 0.8785 - val_loss: 0.1944 - val_accuracy: 0.9257\n",
      "Epoch 68/200\n",
      "330/333 [============================>.] - ETA: 0s - loss: 0.2652 - accuracy: 0.8725\n",
      "Epoch 68: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2650 - accuracy: 0.8726 - val_loss: 0.2528 - val_accuracy: 0.8849\n",
      "Epoch 69/200\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.2554 - accuracy: 0.8766\n",
      "Epoch 69: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2556 - accuracy: 0.8765 - val_loss: 0.2429 - val_accuracy: 0.8781\n",
      "Epoch 70/200\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.4151 - accuracy: 0.7902\n",
      "Epoch 70: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.4151 - accuracy: 0.7902 - val_loss: 0.6508 - val_accuracy: 0.7127\n",
      "Epoch 71/200\n",
      "330/333 [============================>.] - ETA: 0s - loss: 0.5634 - accuracy: 0.7091\n",
      "Epoch 71: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5631 - accuracy: 0.7088 - val_loss: 0.5336 - val_accuracy: 0.7127\n",
      "Epoch 72/200\n",
      "333/333 [==============================] - ETA: 0s - loss: 0.5119 - accuracy: 0.7083\n",
      "Epoch 72: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5119 - accuracy: 0.7083 - val_loss: 0.5136 - val_accuracy: 0.6951\n",
      "Epoch 73/200\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.4035 - accuracy: 0.7986\n",
      "Epoch 73: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.4036 - accuracy: 0.7985 - val_loss: 0.4042 - val_accuracy: 0.7777\n",
      "Epoch 74/200\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.3290 - accuracy: 0.8416\n",
      "Epoch 74: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.3290 - accuracy: 0.8416 - val_loss: 0.2816 - val_accuracy: 0.8574\n",
      "Epoch 75/200\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.3229 - accuracy: 0.8441\n",
      "Epoch 75: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.3229 - accuracy: 0.8442 - val_loss: 0.2748 - val_accuracy: 0.8710\n",
      "Epoch 76/200\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.3002 - accuracy: 0.8528\n",
      "Epoch 76: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.3003 - accuracy: 0.8526 - val_loss: 0.2598 - val_accuracy: 0.8717\n",
      "Epoch 77/200\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.3316 - accuracy: 0.8364\n",
      "Epoch 77: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.3312 - accuracy: 0.8367 - val_loss: 0.2796 - val_accuracy: 0.8653\n",
      "Epoch 78/200\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.2889 - accuracy: 0.8590Restoring model weights from the end of the best epoch: 58.\n",
      "\n",
      "Epoch 78: val_accuracy did not improve from 0.93638\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2888 - accuracy: 0.8591 - val_loss: 0.2841 - val_accuracy: 0.8653\n",
      "Epoch 78: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "history=classifier.fit([X_train_scaled,X_train_scaled_f], y_train[:,0], epochs = 200, batch_size = 64,validation_data=([X_test_scaled,X_test_scaled_f],y_test[:,0]),callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7puZMrQ6rZ8B",
    "outputId": "5a112f46-3928-4fde-afc0-5e3bb1a34830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 1s 6ms/step - loss: 0.1749 - accuracy: 0.9364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17485809326171875, 0.9363831281661987]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate([X_test_scaled,X_test_scaled_f],y_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "pXaIqqGvsq2-",
    "outputId": "af856f8e-f53b-4c18-d158-01d7b07481e1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3oAAAE9CAYAAABdkRCFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3iUVfbA8e+dySST3gskhEDoJVSRoojoKlgQC4JiXdfe/bkuruvqurpr23V1F3sviFhBQQEVEaVI6L2FloQ0QnqfeX9/3EmfNMgkmeR8nifPJDPvTG4oeee859xzlGEYCCGEEEIIIYToPEztvQAhhBBCCCGEEK1LAj0hhBBCCCGE6GQk0BNCCCGEEEKITkYCPSGEEEIIIYToZCTQE0IIIYQQQohORgI9IYQQQgghhOhkPNp7AS0VFhZmxMXFtfcyhBBCtIENGzZkGYYR3t7rcBdyjhRCiK6hOedHtwv04uLiSExMbO9lCCGEaANKqcPtvQZ3IudIIYToGppzfpTSTSGEEEIIIYToZCTQE0IIIYQQQohORgI9IYQQQgghhOhk3G6PnhBCdAXl5eUkJydTUlLS3ktpE1arlZiYGCwWS3svRQghRAfXlc6Rp3J+lEBPCCE6oOTkZPz9/YmLi0Mp1d7LcSnDMDh+/DjJycn06tWrvZcjhBCig+sq58hTPT9K6aYQQnRAJSUlhIaGduoTWCWlFKGhoV3iyqwQQohT11XOkad6fpRATwghOqjOfgKrqSv9rEIIIU5dVzlvnMrPKYGeEEIIp3Jycnj55Zdb/LwLLriAnJwcF6xICCGEaH/ucn6UQE8IIYRTDZ3IKioqGn3ekiVLCAoKctWyhBBCiHblLudHacYihBDuzm6D8mLw8mvVl50zZw4HDhxg+PDhWCwWrFYrwcHB7N69m7179zJ9+nSOHj1KSUkJ9957L7fccgsAcXFxJCYmUlBQwNSpUznjjDNYvXo10dHRLFy4EG9v71ZdpxBCiFaQsRssVgiOa++VdHjucn6UjJ4QQri7omw4vg/sjV9JbKmnn36a+Ph4Nm/ezHPPPcfGjRt58cUX2bt3LwBvv/02GzZsIDExkZdeeonjx4/Xe419+/Zx5513smPHDoKCgvj8889bdY1CCCFaga0C3r8Elj7S3itxC+5yfpSMnhBCdHB/+3oHO1PzGj7AVqY/LOtANe/63aDuATx28eAWrWPMmDG12ju/9NJLfPnllwAcPXqUffv2ERoaWus5vXr1Yvjw4QCMGjWKQ4cOteh7CiGEaANJK6AgDQoy2nslLdbkOfIktPQc2VHPjxLoCSFEp2G49NV9fX2rPv/pp5/4/vvvWbNmDT4+PkyaNMlp+2cvL6+qz81mM8XFxS5doxBCiJOweZ6+LZFGWiejo54fJdATQogOrsmrinmpUJAOIfFgDWi17+vv709+fr7Tx3JzcwkODsbHx4fdu3ezdu3aVvu+Qggh2lBxDuxeXP25m2lpdUprcJfzowR6Qgjh7gxHJq+V9+iFhoYyYcIEhgwZgre3N5GRkVWPTZkyhVdffZWBAwfSv39/xo4d26rfWwghRBvZ8SXYSqHXWXB4tT6ndJEZdSfLXc6PyjBcW+rT2kaPHm0kJia29zKEEMKldu3axcCBA5t3cG4yFGZCQDT4Rbh2YS7k7GdWSm0wDGN0Oy3J7cg5UgjRYm/+DkrzIGEm/PA3+HMqePo2/bx21KJzZCdwsudH6bophBDuriqjZ2vfdQghhHAvWfsh+TcYdhV4B+v73LB8UzgngZ4QQrg915RuCiGE6OS2fKy7NSfMBG/HIG9pyNJpSKAnhBDuzkV79IQQQnRidjts/QTiJ0NAN7A6Aj3J6HUaEugJIYS7k9JNIYQQLXVoFeQe1WWbIBm9TkgCPSGEcHuS0RNCCNFCm+eBVyAMuFB/3dEzeuUlsP+H9l6FW5FATwgh3F1lRs+QjJ4QQohmKM2HXYtg8HSweOv7OnpGb/tn8OFlcOJQe6/EbUigJ4QQbq9jZPT8/PwASE1N5YorrnB6zKRJk5D2/0II0c62fQblRTB8dvV9XoGA6rgZvdwUfZtztH3XcRLa6/wogZ4QQri7qoyeXX+0s+7du/PZZ5+19zKEEEI4Yxiw9hWISoAeY6rvN5nAGtBxM3oF6fo2L7V913EK2vr8KIGeEEK4PaP601ZsyDJnzhzmzp1b9fXjjz/Ok08+yTnnnMPIkSMZOnQoCxcurPe8Q4cOMWTIEACKi4uZNWsWAwcO5NJLL6W4uLjV1ieEEOIkHPgRsvbAuDtBqdqPWYM6bkavMtDLb/9Az13Ojx6t/opCCCHallEz0KsAs6VVXnbmzJncd9993HnnnQAsWLCApUuXcs899xAQEEBWVhZjx45l2rRpqLpvFhxeeeUVfHx82LVrF1u3bmXkyJGtsjYhhBAnae0r4BcJgy+t/5h3UMfN6BVm6tu8VAht36W4y/lRAj0hhOjovp0Dadsafry8yFGyaehN9aoZv9qjhsLUpxs9ZMSIEWRkZJCamkpmZibBwcFERUVx//338/PPP2MymUhJSSE9PZ2oqCinr/Hzzz9zzz33AJCQkEBCQkLTaxNCCOEamXth/3I4+xHw8Kr/uDtk9OqWbjZ1jjwZTZwj3eX8KIGeEEJ0BkrpzJ4BOL94eFJmzJjBZ599RlpaGjNnzuSjjz4iMzOTDRs2YLFYiIuLo6SkpPW+oRBCCNdZ9wqYvWDUjc4f9w6C/GNtu6bmMAwoyNCfd5A9eu5wfpRATwghOromMm9k7AJl0pm9wB7gG9Zq33rmzJncfPPNZGVlsXLlShYsWEBERAQWi4UVK1Zw+PDhRp8/ceJE5s2bx+TJk9m+fTtbt25ttbUJIYRogaJs2PwxJMwAv3Dnx3TUjF5ZgT7HQf1AtKlzpIu4w/lRAj0hhHB3hl2X4JTT6iMWBg8eTH5+PtHR0XTr1o3Zs2dz8cUXM3ToUEaPHs2AAQMaff7tt9/OjTfeyMCBAxk4cCCjRo1q1fUJIYRopo3vQUUxjL2j4WMq9+gZRv1GLe2pMpsXFAu5ybX3prcTdzg/SqAnhBCdgTIDqlW7blbatq1670NYWBhr1qxxelxBQQEAcXFxbN++HQBvb2/mz5/f6msSQgjRArZy+O0N6HUWRA5u+DhrENjKdPbM07ft1teUykCv+wjIOQJG65/rTkZHPz/KeAUhhHB3hl1feTV5tPvQdCGEEB3QzoWQl9J4Ng/AO1jfdrTyzcpGLN2G61sXXNTsjCTQE0IId2c4OrCYPOTkJ4QQor4N70JIb+h7XuPHeQfp2442YqEqo+cI9DpIRq+jc2mgp5SaopTao5Tar5Sa08AxVyqldiqldiil5rlyPUII0Tk59lKYzGBIRk8IIUQNdjukboI+54Kpibf+Vkeg1xEzesoMkUP113JRs1lctkdPKWUG5gK/A5KB9UqpRYZh7KxxTF/gYWCCYRgnlFIRrlqPEEK4G8MwGhy0WudAqjJ6Fe456sDoABvrhRCiU8o5pLtWRg5p+tgOm9FLB99w3VXa7AX2iuafI93cqZwfXZnRGwPsNwwjyTCMMmA+cEmdY24G5hqGcQLAMIwMF65HCCHchtVq5fjx4838BV8jo+eGe/QMw+D48eNYrdb2XooQQnQ+abr5B1HNCPQ6akavMBP8IvS5LqAb1pKMFpwj3depnh9d2XUzGjha4+tk4PQ6x/QDUEr9CpiBxw3D+M6FaxJCCLcQExNDcnIymZmZjR9oGJCbAdZSwICSfDjhfg2VrVYrMTEx7b0MIYTofNK361mr4QObPrYjZ/T8HIV/AdHE7P+Q5G7Dmj5HdgKncn5s73cDHkBfYBIQA/yslBpqGEatf11KqVuAWwBiY2Pbeo1CCNHmLBYLvXr1avrAilJ4chxMflTP0lv2F5hzBKyBrl+kEEKIji9tO4TEg6dP08d6BQKq42X0CjIgYpD+PKA7luT1zTtHdnGuLN1MAXrU+DrGcV9NycAiwzDKDcM4COxFB361GIbxumEYow3DGB0eHu6yBQshhNuxlelbswW8Q/TnRdnttx4hhBAdS/q25pVtgm7WYg3oWBk9w9CBXmVGz78b5B3rEEPTOzpXBnrrgb5KqV5KKU9gFrCozjFfobN5KKXC0KWcSS5ckxBCdC62cn1r9gQfR6BXLIGeEEIIoCRXDxhvTiOWStagjpXRKz4B9nLwi9RfB0SDrVQuajaDywI9wzAqgLuApcAuYIFhGDuUUk8opaY5DlsKHFdK7QRWAH80DOO4q9YkhBCdTmWgZ/KokdE70X7rEUII0XGkO5rdRw1t/nO8gzpWRq9yhl7VHr1u+javbqGgqMule/QMw1gCLKlz319rfG4ADzg+hBBCtJRdMnpCCCEakO7ouOnOGb2CdH3rW92MBYC8VOiW0D5rchMuHZguhBDCxapKN2vs0SuWjJ4QQgggbRt4B0NA9+Y/p8Nm9Bylm/6OjF5+avusx41IoCeEEO6sqnTT4miLrWTfghBCCC19u87mtWSweEfN6FWWbvpF6nEReRLoNUUCPSGEcGf2Ghk9k1mPVZDSzQ5DKTVFKbVHKbVfKTXHyeM9lVI/KKW2KqV+UkrF1HjseqXUPsfH9W27ciGE27Pb9B69luzPg+qMXkfpalmYAWav6rFBZg8d7OUda991uQEJ9IQQwp3VHK8Aep+eZPQ6BKWUGZgLTAUGAVcppQbVOex54H3DMBKAJ4B/Op4bAjwGnA6MAR5TSgW31dqFEJ1AdhJUFDd7f55RGdhZg/S5pbzYhYtrgYIMRxavRlYyoLs0Y2kGCfSEEMKd2Sr0rdlT33qHSEav4xgD7DcMI8kwjDJgPnBJnWMGAT86Pl9R4/HzgeWGYWQbhnECWA5MaYM1CyE6i7Rt+rYZM/SKyiq4/JXVPPH1Tr2nDzrOfu+C9OqyzUoB3SFfMnpNkUBPCCHcWWVGz+RoouwdLBm9jiMaOFrj62THfTVtAS5zfH4p4K+UCm3mc4UQrpa+A755oLohiDtJ3w7KDGH9Gz3Mbje4b/5mNh7JYeORE4793nSchiw1h6VX8u8ue/SaQQI9IYRwZzXHK4Au3ZSMnjt5EDhLKbUJOAtIAWwteQGl1C1KqUSlVGJmZqYr1ihE11NRCiv+Aa9NhMS3YON77b2ilkvfAWH9wGJt9LBnl+5h2c50wvw8ycgr0aWb0HEasjSU0SvNg9L89lmTm5BATwgh3FlV6aZjj553iAxM7zhSgB41vo5x3FfFMIxUwzAuMwxjBPCI476c5jy3xmu8bhjGaMMwRoeHh7fm+oXompIT4bWzYOUzMORy6DYMdi5q71U17Pu/wU9P178/bXuTZZufJh7l1ZUHuPr0WK4c3YOM/FLsXh0oo2e3QdHx6tEKlSrHRUhDlka5dGC6EEIIF3PWjKUsHyrKwMOz/dYlANYDfZVSvdBB2izg6poHKKXCgGzDMOzAw8DbjoeWAv+o0YDlPMfjQojWYhiw7TPIOQSFx6EoS5cJHloFflFw9QLodz6s/i8s+wtkH4SQXu296tqOrINf/q0/7zUReo7XnxdlQ15yo41YfjuYzZ+/3MaEPqH8bdpgPv7tCBV2g2zDmzDoGBm9wiww7M4zeqAbsoT3a/t1uQnJ6AkhhDuz15ijBx1vE30XZhhGBXAXOmjbBSwwDGOHUuoJpdQ0x2GTgD1Kqb1AJPCU47nZwN/RweJ64AnHfUKI1rJvGXzxB/jxSdj0ARz9DcoKYMytcOdaHeQBDLxY3+76uv3W6oxhwLJHdFAa2EPvJaycrZq+Q982kNFLyy3h1g8S6RHsw8tXj8JiNhEZoEs808u89UEdIaNXNUOvTkavami6ZPQaIxk9IYRwZ7Yac/RAZ/RAB3r+kc6fI9qMYRhLgCV17vtrjc8/Az5r4LlvU53hE0K0tk0fgE8Y3LsFvPwaPi44DqISdKA34R7XrSdzD3xyLcx4ByIHN338ji8geT1cMleX7c+/CtbMhTPu041YACKdz9D7cO1hcovL+fS28QT66PNHZaB3rMSTwaiOkdGrbILj20hGTzRIMnpCCOHO6gZ63pWBniR/hBCiQYVZsOdbGDar8SCv0qBpkPybazs9/voSZO2BH/7e9LHlJfD94zqQG3YVDLgA+l+g9xXmHNH783zDnV7ws9kNPtuQzFn9wukTUf2zRzkCvbT8MrAGdLCMXp1Az+KtK1hkj16jJNATQgh3VjVeoU5GT0YsCCFEw7bMB3sFjLimeccPdIy43PWNa9ZTkAnbFugM495vIXlD48f/9roO6M77O5jM+r6pz+jbb+dA+rYG9+et2pdJWl4JV47uUev+MD9PTArSKztvdoSMXqEjo1c30AMIiJYRC02QQE8IIdxZ3fEKjozep6u28P3O9HZalBBCdGCGocs2o0dDxMDmPSe8n55Ht8tJ982ibB1cbf745IOjxLf1hbvZn+rf4yueavjYwuPw8/PQ9zyIP7v6/qBYOOtPsGcxHNva4P68BYlHCfH15JyBtbN9HmYT4f5epOWW6Fl6HSKjlwGe/uDpW/+xgO6QL4FeYyTQE0IId1Z3vIIjo3fgyFEWbpEToBCiC2uoKVXKRsjc3fxsXqVB0+Dwr7rss5LdDl/eButega9ug+f6wIeXw8b3oSS3ea9bUQrr39SBW/RImHAvHPgBjqx1fvzKZ3TTmN85KfEcdyeEDwQMpxm97MIylu9MZ/rwaDw96ocBkQFW0vNLO05Gz9kMvUr+3SSj1wQJ9IQQwp3VHa9g8cEwexJEAXvTZJCsEJ2WrRw+u6nhYKCr2/ElPNsbVj5X/7FNH4CHNwy5rGWvOXCabvW/e3H1fb/8G/YthanPwR9+gLG3Q9Y+WHQ3zJ/dvNfd/rkuURx7O4ZhwJib9f66H5+sf+yhX/QA91HXQ8SA+o+bLTDtJQjpDT0n1Hv4q00plNsMrjwtxulSIgOspHe0jF5DgV5ANBRm6nFCwikJ9IQQwp3VHa+gFHZrMEHkk5RVQLnN3n5rE0K4zvbPYftntYOOzqCsEBbdAx9eUfvj5+d1yWVzHNsKX90BHlZY8WTtsQhlRfrPbvB0sAa2bG1RQyGoZ/XrJa3UJZZDrtDBWcxovWfu3i1w5v/peXz5TZTQGwasfRnCB/Jlbl9Oe+p7NhwrgzMe0M8/+HP1sevfhPcvgeBecPYjDb9mjzFwzyYIqr0HzzAMFiQeZVhMIAOiApz/iAFW0jrSHr3GMnoBMmKhKRLoCSGEO6vbdROo8AoiWBVQbjM4fLywnRYmhHAZw9BDvAFyDrfvWlrbry/Bxvf08PKi4/oj9yj8+HfdQKUpBZkw/2rdkfGOtRA9Cr64tXqu3K6voTSv5WWbAErp8s2kn/QohM9vgtC+cPGL+rGaxw2+VH++b1njr3n4V0jbxvpuM3ng061kFZTxzyW7MEbfqEsTf3xKZ6y+vg8W/x/ET4abfwDfsBYvf3tKHrvT8plRpwlLTVGBVnKLy6nwCtQZveYG165SkFF/hl6lqhELUr7ZkC4X6P20J4NZr6+huMzW3ksRQohTZysHZaruugaUWYIIUgUA7EkraK+VCSFcJWmFnpNm9tKdFzuLvGOw+iUdJN3yE9yyQn/cvlqXIS55EI4faPj5FWWw4DpdzjfrIwjuCTM/Ai9/+HiWbmKy6QOdEXNS1tgsAy/RlRRvT9HZwSvfdz6eIXIIBMTA3u8af721r1BiCeKa3+I4o08Yj140iMTDJ/hhX57OCh5dC69OgA3v6CzfVfNbnol0+CTxCF4eJi4e1r3BYyL8vQDIx1dvDSgvPqnv1SoqSnWw2eAePcfPIQ1ZGtTlAr1ym8HapGy2pTRzg6wQQnRktrLqsk2HYksgQegAb2+67NMTotP59SXwi4Ihl3euQG/Fk3rkwTmP1b7fZIbLXgeTh86iOduTZRjw7R/hyGo9QLz7CH1/QDeYNU+XUH54mS6HHDG7dgauJaJH6UxbcbbO5DnbJwf69fudDwd+1DPvnMk+iLF7MW8UT2LCgBjeuG40143rSa8wX55bugfb8GshsAfkHIXL34JzH6t1Ua8lSsptLNycytQhUQR6Wxo8LipQz9I7YTiC1/bcp1c5LF0yeietywV6I2KDANh4pIFOTEII4U7sFdWjFRyKzIEEqwI8TIp9GRLoCdGppG3TGb3Tb4WwPrq0sbQTZO7TtsGmj2DMLRDSq/7jgTG6yUjqpvqjB0py4fvHYMO7cMb9MPSK2o/HjNLPPbZZV0AMu/rk12kywbl/g989AQkzGj+2/1QoL9INVOooKbex8dOnqTBMHOl9Fa9eMwqrxYzFbOL/zuvHnvR8Fm7PghsWwx2r6/9MLbR0Rxr5JRX1ZufVVTk0/bjNW9/RUOfStlAZ6Pk2kNGzBoLFB3KT225NbsajvRfQ1sL8vOgZ6sMmCfSEEJ2BrRzMtX+VF5gC6E4+g7sHsEc6bwrRuaz+H3j6wejfw/7v9X25R5s/D64jMgxY9hfd6XHigw0fN+gSGHk9/Pqinh8XlQDrXoW1r0JpLiTMgsmPOn/usFl6LEJJLgRGn9p6h81s8pAVuzPYnxrNTR7emPZ+C33PBXRDlCXb0pi7ZB2fFn/JlsDJ/OP687CYq3MvFwzpxtDoJP61bC8XPngWXh4nl8WrZBgGH6w5TI8Qb8b2Dm302AhHoJdRXhnotWdGz9HIpqHSTaWg53g9v3DCfdXNWUSVLpfRAxgZG8zGIzm6ha0QQrgzW1m9jF6e8sdT2Rjfw4tDx4sorZA9yUJ0CrnJutPmyOt0UBQUq+93p/LN8uL6DT72f68bnJw1RzdRacyUf0JYX/j0RvhPgp4p1+tMuGUlXPZa46WN4++CyY10q2wlKTnF3DlvI08tO8j3pYPI2LCQuT/u46c9GVz52hrunLeRq1iKrypl9OwnagV5ACaT4qEp/UnJKWbeulP/u/166zESD5/g1onxmEyNl6wGWD3wtphJLdUBX7uWbhY2UboJMPVZsJXq/Zvyvr6eLhroBZGZX0ryiXbcYCqEEK3BXlFvj14Oem/FiDADm93gYJZ03hSiU1j3qn4zO/Z2/XV7B3otfWNdfAKe6aUDtKWPwJF1uiph2V/03LfRv2/6NTx99X41ZdJZsttX68Yr3Yef3M/gAo8v2oHdMFhw6zisgy8kwp7J18u/54Z31nMwq5DnpsVzjfoW+k2FyEFOX+OMPmGMjw/lfz/up6C04qTXUlBawVOLdzIkOoCrxsQ2ebxSiqhAK0eLHRcQ2zWjV1m6Gd7wMaHxMOlh2P0N7FzYNutyI10y0BsRq68WyT49IYTbs5XVK92s3ETfN0A3LJDyTSHaUcauls2Aa0hJLiS+qztSVgZ4vhGOzpvtMGLh+7/BaxNbtj8w7xhUFIOnD/z2Orx9HjwXD5m79Z43D8+mXwOgWwI8dABmvAuRg09q+a6ybEcay3emc9+5/RjTK4SJF+oxDp+cncPcq0ey4sFJzFA/oIpPwJkPNPg6Sin+NGUAxwvLeHNV0kmv578/7CM9r5QnLhmCuYlsXqXIAC8OFzouILZVRq+0AFI2gr3G7NeCdPAOafrfxbi7oNswWPJHKMp27TrdTJcM9AZE+eNtMbPpSAcYBCmEEKfCVl6vdDPL5gNAtGcxZpNiX3onaNQghLva9pmeAZe27dReZ/PHUJYP4++uvs9k0kFfQxm9ijJ47SydQXtjMnx0pR4kvvGDU1tL8gb45QVI2wrLG9gT50yJo+P5lH/CH/fDZW9C3Jkw/BoYcNGprakDKCyt4PFFOxgQ5c9NZzgayvhHQveRBB75gQsTuuHvYdf7LHueoQebN2JYjyDOGRDBR+uOUGGzN3qsM/sz8nnrl4NcOTqGkbFNlMTWEBlg5WCBGVAtz+hVlMK8WfDx1ZC1r+nj07bDNw/AvwbAG2fDK+P1/xm7rfFh6TWZPWDa/3RjomUt+PfYBXTJQM/DbCIhJlAasggh3J+T0s3MCl8APMtyiQv1YY+MWBCi/ZQ5Sqe3f97wMXuXwed/aDzrd2gVhMTXL1FsLNDL2qs7TQZEg1eAnje2ezF8fa9+Q34y7DZYfL/eNzX695D4dnVTmKZUBnrWQP2RMEOXXU6fe/LjDjqQF5bvJTW3hKcuHVp7313/qZCcqIe5b/1E/z2ceX+zXnPG6Bgy80tZfeB4i9ZiGAaPLdqBj6eZP01pYAREA6ICrKTll2NYA1qW0TMMWPwA7P0WDq6El8fCt3NqZ9kMQ89CTHwH3jpPzwjc9CEMvAgu/Bdg6BEac8foDF+dQK/BOdjdEmDCvbD5QziwokU/b2fWJQM9gJE9g9mRmkdJuTQpEEK4MVsZmGsHemnlOtCjKJv+Uf7sk0BPiPZT5sio7/ii4UBuxVOw7VM4cajh10ndBNEj69/fWKCXsUvfXvgvuO4ruO0XuOjfYNh0EHgy1r8Jx7bAlH/A+f+E8AGw8O7mteEvzdO3Xic38LsjyC8p5855G7ngxVXMXbGfo9lFAOxIzeWd1Ye4+vRYRvWskz3rdz5g6ADol//obqHx5zTr+03qH4G/1YOvNqe0aJ1LtqXx6/7jPHh+f0L9vFr03MgAK2UVduxeQS3L6K17TQdtZz4I92yGEdfCb6/Bf0fCD0/oBjr/GqC//uY+3QX1vKfg/3bDpa/CaX+A29fAjPfAwwp5KXrovMMHaw4x/Ill/HawgfLMs/4EoX30hQxbeYt+5s6q6wZ6scFU2A0ZnC6EcG+28nqBXmqZo1tacTZ9I/w5nF0kF7WEaC+VgV7OEZ2hqCt1s866gc76OJOfrt/0Vg4BrykotuFZehk79ZDx0D7V90U49rSl72j+z1C1jjT48UmInwyDLwOLVb9BL0iHb//U9PNrZvTcUPKJIq54ZQ3fbU/DYlY8t3QPZz67gstfWc198zcT7GPhT+c7yZ5FJeis6g9/h+wDetZfMzOYVouZC4Z0Y+n2tIazWXUUllbw5OKdDOoWwOzTe7bkR9TLdQxNL7O0IKOX9BMs/TP0vxDOfgT8wuHi/8CtqyBqKKz6FxxZA3FnwEUvwJ2/wd0bdCdUn5Dq1zGZYPB0/bzrFsHkvwCQkVfCM9/tobTCzr3zN5FTVFZ/Df2xze0AACAASURBVBYrjLtT71nNT2vxz90ZddlAr2pw+mEp3xRCuDEne/RySw2yLNFwcBX9Iv0xDNifIfv0hGgXZYUQ3Ev/P93xRf3HNzqyFx7ekNJAoJe6Sd82FOiBnqVXV8ZOCO1bu5lFaB+9lpMJ9Jb+WZd8XvB8daDSfQRM/KMuSdy5qPHnVwYN1oCWf+82kJRZwM3vJ3Lpy7/ywdrD5JVUZ4U2HjnB9Lm/kppbzLs3nsbCu85g1UNn89CU/hSUVLAvo4C/XjyYQB9L/RdWSmf1CjN0+e2gS1q0rukjoikss7F8V3qzjn9qyS7S8kr4+/TBzW7AUlNkgM4AFpv9m5fRy06CBddDWD/HiIsa4UXUEB2wPXQQHtgFV7ylS37D+zce7JpM0PusqpmH/1iyi7IKO/+9agRZBaX88bOt9cakGYbB4j26gqWouKhlP3Qn1eUGpleqHJwunTeFEG7NXq7fJNaQX1LOxu6XcN7hlxl6ui7p2puez5Bo97yKLoRbKyvU2ZzwAbDjS/jd36vfCJcVwtZPdSfNE4cazuilbtLjBKIS6j8W5MjY5BypPzQ9YyfEnFb7PrOHfpPd0kDvwI96n+Gkh3VL+5omPgh7v4Nv7ofYcTqb40xJrg5oPVpWSngyCksreGH5XqaPiG7yd19BaQX//XEfb/9yEKuHmehgbx79ajv/WLyLixK6MaBbAM98t5vIAC/m3zKWPhH+APQI8eGOSX24Y1IfThSWEezbSHfI/hfq/YwT7m181p8Tp/cKoVuglYWbUpg2rHujxy7fmc68dUe4dWJvRvUMafTYhkQ6hqYXKF9CSmp0dLVV6FEYx7aAbyj4hIFvmA7wlYKrPgYv//ovqFTtrF0LrU06zlebU7lnch8uHtad9LwSnly8i/fXHOb68XEAlNvszPl8G8U7srjQE7LzCvCR+eldN6MHMjhdCNEJ1NmjZxgGBaUV7Im+DCw+xOx9H4tZsVc6bwrRPsoK9Oy3IZfp8suj66of2/Gl7qQ58nqIHqW7WDprkpK6CcL6g5df/ccamqVXmu88+AOIHKKDwOaylcPiB/Wsuwn31X/cbIFpL0FRFuxqJKtXktusss2sglLWHDjOgsSj/HvZHu7/ZDN//nIb6w9lN/s921u/HOTNXw5y2Sur+WS98z2MNrvBl5uSmfz8T7y2Monpw6P58cFJfHvvmSy6awLTR3Rn8bZj/P2bnSREB/LVHROqgry6Gg3yAPqcAzd+p4fdt5DJpJg2vDsr92aSXeikZNEhI7+EP32+lUHdAnjgvH4t/j6VIvx1oJdr+FZn9Ox2+PoeWPeKvsCYtQ92fa1LMnOT9b66kF4n/T2zCkp5deUBTtT5+cptdv66cDsxwd7cPkmXIN90Ri8mD4jgqcW72JGaS2FpBTe9l8jnG5PpHaUDyhLJ6AFdOKMHunzzy00ppOQUExPs097LEUKIlrNV1CrdLCyzYTfA0y8Ehs3CtOkjRoRMYa80ZBGifZQWQIiv7rzoYdXlmz3H6cc2vKsDuNixUJAGa/6n283HjKp+vmFA6kbo8zvnr+8XoV+37iy9zD36NsLJQO6IQbDlY90NsTmZlj3f6r1lMz/S+6CcCXcElMWNzDEryWuybHN3Wh7T5/5KSbkeJ2BS0C3QmxNFZcxbd4SeoT5cPjKGy0ZGN/jeLbuwjNd/TmJiv3AMw+BPn28j8dAJ/j59CFaLmZJyG19sTOGNVUkczCokISaQ164dVTVnGSAhJoiEmCAeuXAQ25JzGdkzCC+PlmXialGq+u/9JEwfHs1rK5NYvDWVa8fF1XvcMAz++OlWCksreOmq4ae0Vk8PE6G+nmTbfXS5rWHA0odh80c6oztpTvXBdpv+aO4MxAY8tXgXX25K4Y2fk3hs2mAuTuiGUor3Vh9ib3oBb1w3Gm9P/TMppXjuigQueGkVd8/bhK+XBzuP5fH0ZUNJKCmFH6G4pOSU1tNZdOlAb2TV4PQcCfSEEO7JXq6bLTjkO/aU+FstMPBWSHyba71W8Ey6+8+oEsItlRXqTJyXP/Q9D3YuhClP6yHhyevh/H/oIKCyxDIlsXagl5cChZnOO26Cfm5gj/oZvcrSTKcZvRoNWXqd2fTPsOFdXX7af2rDx3h4gsW38T1dzcjoPb90DxazidevHU3PUB+6BXrj6WGisLSC77an8dmGZP69fC8vfL+Xf185jEtHxNR7jVd+2k9RWQV/uXAg8eF+vPj9Xl76cT87UvM4f3AUH6w9TFZBKUOjA/nf1SO4YEg3TA3sZfPz8mBcfGija24LA7sF0D/Sny83pTgN9D5Ye5iVezN54pLBDWYdWyIywEpmubeuGln2F1j3qh5Mfladpjsmc4tLUevamZrHV5tTmD68OwezCrnn400s3JTCXZP78MLyvZzdP5xzB9YesxDq58ULM4cz+811eHmYeP3aUZwzMJL9v+l/92Ulxae0ppNiGLqTqE/IKf+ZtJYuHehVDk7fePhE4zXPhgFvngN9z4dJzegqJYQQbcVWViujl19SAYC/1QMiBkDvszk7eRH3551FYWkFvl5d+te+EG2vrBA8HSWXQy7TpY2Hf4Vd3+j/uwmz9GMB0eAXpffpnX5r9fMba8RSKSgWThxmW3IuP+/L5JLh3YnJ2AUWHwiKq3985BB925xA78RhvT/vrIeafvPqHdz4mIWS3EYziBsOZ/P9rgz+eH5/Jvarvc/P18uDy0fFcPmoGI5mF/F/n25hzufbGBAVwMBu1VnC1Jxi3ltzmEtHxNAvUgc8D5zXn+GxQdz/yRZe+H4vE/uFc9vE3oyLD0W50fy+6SOieea73Rw5XkRsaHWCYl96Pk8t3sWk/uFcO7blXTadiQq0kprhrb9Y8z9dcnreky6Zd/js0t0EWC38bdoQ/KwevPPrQf61bC8/7M7A08PE49MGO/17Gh8fxjs3nEZUoJUBUfrfgNVLZ5xLS9sg0Cs+AZs+gsxdOoOeuUePEBk+G6a/7Prv3wxd+ozf7MHpKRv0x4nDcOYD9VqZCyFEu7FV1PqdVJ3Rc/x6H3s7fvOuZKrpN/ZlnMXwHkHtsUohuibDqN6jB/qCscUXNs+DPUtg4MW6qQU4snqj63feTNmos/aVwZkzQbHYUjZyzVvryC0u5/lle1gcuJZo/3j8UNQLz/wiwCcU0rc3/TNs+lDfjrim6WO9g5vO6DWwj8swDJ79bg9hfp7cOCGu0W/TI8SHuVeP5MKXVnH7hxtYdPcZBFj178GXftgHBtx3bt9az5k8IJJl908kv6S8VTJe7WHa8O48891uFm5O4e5z+nKisIwP1h7m3dWH8PXy4NkrElotcI0MsHLkiKNMd/BlcNF/mhXk5RaV85eF20nKLCDUz4swX09C/TyJDfVl1mk9ag+SB1YfyOKnPZk8PHVAVcfSP5zZm/MHR/H0t7sZGx9Kz1DfBr/fpP61M31Wbx0Al7VFoPfLf+DX/4BvuG62lHClDv42fwT9L9BD4NtZlw70QA9Of+PnJErKbVgtDVyp2v65vi3Kgv3fN166IIQQbalOM5a8qoye474+v6M8sBc3nviOvem3SaAnRFsqLwaM6kDP0wf6T9H74wBG3VD7+OhRsPub2nvnUjfpPXUN7Y0DCry741dygkBzKW/cOoFV+zKJXH2QpQXDePHZFYyIDSI6yJvuQd5EB3kTF+ZLfORgVFMNWWwVsOkDCmMncfVHRxkZm89tZ8VXdWWsxzuoKqNnGAavrDxA8oli/nHpUP14I6WbP+/LYt3BbB6/eBA+nk2/PQ3392Lu7JHMen0tf/x0C69eM4oDmYUsSDzK9ePj6BFSf0tOZIC14bW7geggb07vFcLnG5PJLipj/m9HKS63MXlABP93Xr+qJiqtITLAi1eLBvPPma9hSbi8WaWIBzILuPm9RI6eKGJ8fBg5xeUcyCggq6CU0go7K/dk8L+rR1a93zYMg2e+3U23QGtV98xKPUJ8mDu7gXLlRnh76yxkeZmL9+gZhs7Ox0+Ga7+svr+iTDeq+fpevffWN8y162iCBHqOwenbU3IZHeeknMBu112x+p6nr6ptnieBnhCi47CXg6lmRk8HegGVGT2TCfPYWxm5dA5bDqyF0T3aY5VCdE2Vw9I9a3TLHHK5voAc0hvi6pRNxozWtykboO/vHI1YNjU6dy2/pJy5m8qYA7x5SST9eoUwJsIOq3MYOmIs/fP92Z6Sy7Id6ZTZ7FXP+4e3P5fzG/N/TWJsfDj9Iv3qZ4P2L4f8YzySP5tDqpDtKbl8tO4Is07rwe2T4ukW6F37eO8gyNqPYRg8t3QPL/90AE+ziScvGYJJocvavOo3Y7HbDZ5bupvoIG+uOj22iT/UaqfFhfDw1AE8uXgXb6xKYvPRHKwWM3ee3afpJ7up6SOiefiLbXyw5jCXDI/mlom96R/V+hnKqAArJXiRHjeFmGZUsv28N5M7523E02xi3s1jOa3Ge2rDMPhw3RH+unA7v393PW9cNxpfLw++3Z7GluRcnr0ioeFkSwt5W3WAX17qpHtta0rfoecHjr+n9v0ennDpa/D6WfDNfXDlBy4pd22urhfolZfocokhlwHVg9Nf/GEfUQFWsgvLyHK0dr3pjF5cFJCEKf+YrksOiYfEt5rfpUoIIVytzsD0Ws1YHEwjZlO09G/0O/wxMKOtVyhE1+Us0Otzrn4/Mf6u+m8Au48AlN6n1/d3cOKg7nrYwP68sgo7d3y0kaIcf7BAPy9Hx0tHpm7g8LG8Ha+bvNjtBlmFpaTmlLAnLQ9j42C8ji3m7W9W8JgRxfAeQdx3bl/O6hdeFfBl/PQayghkh984vrlpPIYBL/+0n3nrjjD/t6NceVoMd0zqQ/cgR8DnHYxRksPT3+3mtZVJ9Az14fDxItLySujui65AcJLR+3Z7GttT8nh+xrAWd4u86YxebDh8gme+24PNbnDPOX0J83P9nL72cvnIGEwKJvYLrx9ot6LIQJ0dTM8rabRhoWEYvPPrIZ5cvJN+kf68ef3oescrpbh2bE/8vMw8+OlWrnlrHW9cN5rnlu6hX6Qfl4+s31DnZJks+u++otzFGb1di/RsywFOyjMjB8HZj8D3j8HWBTBspmvX0oiuF+glvgVL/6w/H3IZYX5ejIgNYm3ScUJ9vQhx1BKn5ZZwz8ebMAd+yBSzFVO/81FhffX8kO2fw5ib2/fnEEIIcAR6Nbtu1mjGUskaQGLQFMblfK1ndLXBsGIhBLoRC1SXboL+/3fPRufHe/nrLpnJ6/XXlY1YokdSWmFjb1oB2UVl5BSVkV1Yxi/7sli1L4uXLp4Iy6nuvJmxS9/WGK1gMiki/K1E+Ft1CXf3KfDGs3x+aQBLbIN5bWUSN7yznpGxQdx3bj+yjx3k4tSf+MJnBvNvP5NQR/D09OUJ3DW5Dy//dIBP1h9lwfpkZp7WgzvOjifKGkRFwXFeW5nEtWN78rtBkVz39m8cyS6iu1lfhKob6FXY7Pxr+R76Rvhx6YjoFv8RK6V49ooEdv/vV3KLy7n5zJOf5eYOPD1MzDyt+VnPkxXpKANNy62fGTMMg13H8vl6ayrfbE3laHYx5w2K5IWZwxtt+HXpiBh8PD24e94mzv33SnKKynnzutGYG+h4elIcFz5tri7d3LkIYseDX7jzx8ffrRNLS/4IcWdAYMv/bbeGrhfojbkFdnwFi+6B7sMhpDdf3D4eoFbJgs1u8PWmw4z/+he+tQ3no/d28PdLBtMnYrCurZdATwjREdQr3SzHbFL4eNa+Kl4RPghLzpcU56ThHdY6XdmEEE1wFug1JXqUHkTtKNs0zF68uNWDD9f/SFZB7WHSZpNiztQBTBvfG1bUmKWXsVM3RvGLbPj7hA8EFGFFB7hu0gxmnRbLpxuOMvfH/Vz39m/cbf4Cs8XgohsewrtOhiwm2Id/XDqUOybFM3fFAT7+7QifrD/KYyH5zDbK+MPYbjxyyWCOZOuh1Ueyixjr7xhgXSfQ+2JTCkmZhbx6zaiTfsPvb7Xw1R0TKCirqFXNIE5elCOjl5ZXO2D6NPEor648wIHMQswmxYQ+Ydx/bj+mD49ucERFTecPjuKtG0Zzy/sbGBMXwjl1xiacMsc8P1u5C0s3s/bpTptTnmn4GJMZpr8Cr54Bn8yGnhNqP95rIvQ733VrdOh6gZ7ZAle8rf/gP70BblqOcnJ122xSTA9KAvLwGTGD3dvzuOn9RJadPhOvH/8KmXshvF+bL18IIaoYBthrD0wvKKnAz8uj3l4bzwB91TEvO10CPSHaSqmT0k0ntiXn8tG6wwT5eDKhOI4zS3JYtW4tUZt+prA8hhd/OsTk/hFcOjKaqAArQT6ehPh6EuhtqQ6OgmJrZ/QiBjW+N8jTR+8TdHTe9PQwMfv0nlwxKobP1h/mop9+xd79LLwj+zb4EjHBPvzzssqAbz87N5nBAx6ZHIVSiu5B3phNiiPHiyAyTz/JWrsh1PKd6fQM9eH8wY0Epc0Q6GOp6tooTl2wjwVPDxMZNQK9DYezeejzrQzpHsiT04cwdUhUVaa3Jc7sG86KByfh62Vu/fEWZr0euysDvV2L9O3Aixs/LjQeLvwXfPewDg5rsvhIoOcyQT10lD3/Klj2KFzwrPPjtn8Bnn5Mvng2r40oZubra3gmZSh/VWbYMg/OfbzW4cVlNvJLy/Hz8sDb4oJ/vEIIUZPNUQpVp3SzVtmmg5cj0Cs8kdEmSxNCUL1Hz6vxQO9vX+9gS3IOCsUKuy9LveCrRV/xhGUPOyIvZMXMScSFNZEVrAz0DEMHegnN2BcUObh6sLqDl4eZ2WFJUHoMRj3V9GugOyQ+fXkCZX3HwxdvoopzIKA7FrOJ7kFWndkrydUHW2s3Y0nKLGBgVIC8Z+pglFJEBnhVZfSKyip4YMEWooO8+fiWsfid4kzWyoxhq3Mkb4wKFwZ6OxdB9OjmlWMOv1p/tBNT04ecPKXUFKXUHqXUfqXUHCeP36CUylRKbXZ8/MGV66llwAUw9k747TXYubD+4xVlOmIfcCFYvBnTK4Tbz4rn7S3FZESeAVs+Abut6vDEQ9mMe/oHxjz1A4P+upTef17CkMeWcu6/V7JwcwqGYbTe2m3l8PJ4WPtK672mEML92BxlXDUyenklzkuXfIJ0eUxJTnqbLE0IQbNKNxMPZZN4+ASPXDCQPU9OYcFfbsRu8eWxntvwVSWMGX9O00EeVAd6ucm6u2XEwKafEzlYdw6sXCfoQPHX/4BPmPNGE43w9HPMBKwxND02xMcR6Dnm69Uo3Sy32Tl8vIje4S0obRVtJtLfSlquDvSe/nY3h48X8fyMYacc5LmUyYwNE0ZFWdPHnoycI3Bsc9PZvA7CZYGeUsoMzAWmAoOAq5RSg5wc+olhGMMdH2+6aj1Onfu4roVfeLf+RVdT0gp99WnwZVV33XduP4ZGB/J8+kjIT4WDKwFYtiON2W+uI9jHkycuGczDUwdw99l9mHlaD7w8TNw7fzOXvryaDYebGMzeXPuWQcYOWPlMdVmIEKLrsTsyenX26DnL6PkGRwFQlp/VJksTQlAj0Gs4o/faz0kE+Vi48rQeKKUI9LViih5JwLFf9QENdNysJygWirMh+Tf9dYSzt1x1RA4GDMjYXX3f3u/g0CqYNKfljZsqyzJLqoemVwd6lRm96kDvaHYRFXaD3uGNZzxF+4gMtJKRX8ov+7J4f81hfj+hF2N7h7b3sppkUxYMm4syeru+1reDprnm9VuZKzN6Y4D9hmEkGYZRBswHGh4E0x48PPV+PQW8eias+CeUOGrIt3+ufxnFT6463NPDxAszh/NdxQgKlR/G5o+Zt+4It324gQHdAvjstnFcNy6OW8+K54Hz+vPoRYP4+q4zeO6KBFJzirn8ldXc/fEmVu3LJCWnGLv9JLN8m+eBxVdfMdvwzqn/OQgh3FNV6WbtOXoBTgK94JAI7IbCXiiBnhBtpmq8gvOM1f6MfJbvTOe6cXG1h4RHj9K3Fh8I79+87xXk6MS4d5m+jRjQ9HMqg8EMR/mmrVxvaQntW3+Ye3N4B+vbWhk9X7ILyygtcNxXI9BLytSBcLxk9DqkqAArx3KLeeizLfQO9+WhKc38t9jObCYLylWlmzsXQeRQvb/VDbgy9xoNHK3xdTJwupPjLldKTQT2AvcbhnHUyTGuExwHN6+AH56AlU/D+jfgjPth9xIYfElV955KfSL8eOjC4Xz5zenM2L6Q59ZPZmL/eF6ePbL2L2kHk0kxY3QPLhjajddWHuD1VUl8vSUVAKvFRFyoLwOi/Dl7QARnD4ggoKluUYVZ+mrb6bdB2jZY/V847WawuKjWWQjRcTkL9ErL8bfWH57r7+NFDr6oouNttTohRFkBKDN4OD9Hv/5zEl4eJq4fV6dBUuXg9G7DdPe+5ghyvMa+ZeDfvTroakxwLx1MVu7T2/AuHN8Hsz6u9Xul2ZwGenqmWn5uNl5mz1p/FgcydSAsGb2OKSrASkm5nbS8Ej6/fXyrDTV3NZvyrD4/tqb8NDi6DiY9fEovs+VoDnGhvm3SPKi9i2y/Bj42DKNUKXUr8B4wue5BSqlbgFsAYmNdMDskNB6ufA9SNuiAb9lf9P1DLnd6+OzTY3l069WYU1Ywt9u3nHbdu1jMjSdHfb08eOC8/vz+jF7sOpbPwaxCkjILOJhVyC/7j/PV5lQsZsW4+DDOGxRJfLgf3p5mvC1mrBYTIb6eet/Nts90l73hV0PRcXjvYtj0gYx7EKIrclq66bwZi8mkyFMBmEuy22p1QoiyQl226aTRSHpeCV9uSmHWabH1OxdGOwK95pZtQnVGrzhbD2VvDpNJ7+VL36FLK3/6J8SdCf2nNv/71uTlrwPb4tqlmwBFecfBK6DWn0VSZiFhfrp7qOh4Khum3DGpDyNim3HhoIOwmz0x28uosNnxaOL9eYvs/gYwTqlss8JmZ+bra5h9ek8evagZ5dWnyJWBXgrQo8bXMY77qhiGUfPS8puA0/aXhmG8DrwOMHr06FbsalJH9Ci4biEcWAEpidDrLKeHKaX403WXkPr5z4zb9z4qYzt0S2jWtwjy8WRcfCjj4qtrnO12g01HT7BsRzpLd6Txl6+213uep4eJeyb34Y69H2HqNlzX1RsGxIyBX1/SJRYnc/VNCOG+qjJ6uvLAMIwGAz2AAnMgnqWttFdYCNG0soIGyzbf/vUgNrvBzWc6KQEL6AaXvqYHLTeXb7jOllWUNK8RS6XIwbDrG1j1L30B+bwnGx/L0BilwDuodkYvVAd6ZQUn6s3QS8oqkGxeB3bOwAj+edlQLh8Z095LaRHDZMFTVVBYZiPQuxUDvZ2LdFlzeDPKohuQlFVISbmdIdEBTR/cClwZ6K0H+iqleqEDvFlArf6iSqluhmEcc3w5DdjlwvU0X/zZ+qMR/lYL/pc9Af/9Br79E9y4pP4vxt/egFX/Bv8onTUMide3fc4Fn5Cqw0wmxaieIYzqGcKcqQNIyiokI6+UknIbxeU2ists/LA7ncXLl3OX11YOn/44PUF/v4kPwrwrYesCGDG79f8shBAdV53xCsXlNmx2Az8v5xd9iizBRFakttXqhBBlhU4DvbyScuatPcIFQ7tVBUL1DJvVsu+llM7qZe1tXiOWShGDYeP7sGYuJMyC7sNb9n3r8g6uFegFelsI9LZgL84B/9qB3oHMwlOenydcx8fTg6vGuKCSzsUMsxeelFNYWtG62eKUDbqi7hRGgWxP0U2JhnQPbOLI1uGyQM8wjAql1F3AUsAMvG0Yxg6l1BNAomEYi4B7lFLTgAogG7jBVetxCe8gmPwofHOfbt4y9Irqxza+D0sehJjT9C/5I+t02SUGBETDle9X1+DXoI6sIf6bB4gfcCGc82jV/ZePiuHIx+9TvseDS1Z2Y0rRVkbGBnMspxczrH1Ri//BnI29OXdwdy44yQGWQgg3U2e8Qn5JBUCDGb0yzyB8SzvG9TQhuoRS5xm9j9cdIb+0glsnxrfu96sK9FqY0QMwedR633HSrEG1um6CLt805edBeFTVfTlFZWQXltE7TDJ6opV5eOJJBYWlFa33mnabztD7nFrX0e0peVgtpjbLZLt0j55hGEuAJXXu+2uNzx8GTm1HY3sbeR0kvg3L/6pr2j19dUC36B6IPweu+ri6PXF5ib4a8NVt8PYUmPo0jL5JXxmoKNPNYH55QXfUXPW8LnGYcI9+rq2c2OTFVPSfyszAYbz5y0Hmr9d9a1J9LuYZ+7+Jz/yeR78ayeOLdjChTxgXJ3Tj4mHd3WbzrBCiheyOk5hjj15+ic7wNRTo2awhBObl6bJvGU4shOuVFep9azXsTc/njVVJTOgTytCYVr6qH9QTUBDWgu6IUUN0yeeEeyGwFUr0vIOhqHZ339hQHzyy88Har+q+A5UdNyOk46ZoXcrshYUKCloz0CvN17de9ZudtcT21FwGdQvAbGqbc3B7N2NxfyYzTH0W3pkCv/wHokfCl7dCz/Ew88PaM2gsVoibALeshC9ugcX/B0fXw7g7dGB4bDOMuBbOfwq+vheWPwp+Ebp8Y//3UJiJx8jZPNx/IDdO6EW5zU5EgBdepinw8jc8alrCjGvvZNG2DL7eksofP9vK6z8nMXf2SPpFnto/TCFEB1SV0dOBXp4jo9dg917vUCzYsBXnYvYJaosVCtG1lRVAQPeqL5fuSOOBTzbj7enBIxe4oBHD2Nshdhx4NlAO6ox3MNy7BfxaqYTSO1h37qwhNsQHb3sBdq/AqrleVR03JaMnWpny8MJLFVNYamu9F22FQM9uN9iZmsflI6NbaVFNc+Ucva6j5zgYOgN+fREWXA9RCXDV/IZ/0fqEwNULdHvWrZ/AaxMh54gODC/5n87kXfoa9JoIC++Efcth80d6o7Wjk1ZUoJUeIT54eZh1sHn2n1EZOxm473X+NGUAqx46m3duOI0TrDVcoQAAIABJREFUReVM+98vLFh/FMNwXR8bIUQ7qDNeoanSTeUXpo/LTnf92gQASqkpSqk9Sqn9Sqk5Th6PVUqtUEptUkptVUpd4Lg/TilVrJTa7Ph4te1XL06ZY4+e3W7w7+V7ufWDDfSJ9Oebu89gUHcXNGMI6wsJM1r+PP+o1svyewfV6roJOtALoIhCVZ29S8osxGJWxAR7t873FcJBOUo32yOj99WmlKqLGHUdOl5IQWkFg6PbZn8eSKDXes79m65vD+0D13wO1iZ+gZtMMGkOXPMZjP493L4aBl5c/biHF8z8SG+oXnAd7PkOEmY23Flz8KV6E/XKZ+DwapRSnD0ggiX3nsHI2GAe+nwr93+yuXX/0Qsh2led8QrVpZvOf09Y/B2B3ok0169NoJQyA3OBqcAg4CqlVN00zl+ABYZhjEA3LXu5xmMHDMMY7vi4rU0WLVpXWSHlZh9u+WADL/2wjytGxfDJLWOr2tZ3St7BelSDvTqbEhfogbcqI9tWHdQlZRYQF+rbuu3vhQDMlupmLK2mGYHelqM53PfJZl5Yvtfp49tT84C2a8QCEui1nsBouHMt3LSsVkfNJvU5Fy56QbdSrssaoINGv0j9hm7YVY2/1oXP6wHwn99c1fEqwt/KBzedzgO/68eiLalc8cpqKmz25q9PCNFxtTCjZw2MAKAoJ9P1axMAY4D9hmEkGYZRBswHLqlzjAFUXhkMBKQtamdSVsCWjAp+3J3O36YN5rkrEjr/vnlrEGDoYM8h1lf/bsosrz0svXe47M8Trc/sacVCBYVlrgj0Gg7Snl+2B4Bf92dhs9evotuRkoun2UTfyLYrV5ZArzUFxYJXK//l+UXADYth1jy9YboxXv5w+VtQkKb3/DlKNc0mxT3n9OXZK4axOy2fNUnHG38dIYR7qBfoNd6MxTdYB3pluVK62UaigaM1vk523FfT48A1SqlkdPOyu2s81stR0rlSKXWmS1cqWp/dDmWFHMyD4T2CuH58HKorNEHydgzWrtF5M8pL7ydOK9Udgsttdo5kF8kMPeESHp5WF5Ru6mxcQxm91QeyWLUvi5GxQZwoKmdHam69Y7an5jKgmz+WNsxiS6DnDgKjYcCFzTs2eiSc8xjsWgQb3q310EUJ3fD38mDhZrlgLESn4GS8glLg6+k80AsI1ZUD5flysacDuQp41zCMGOAC4AOllAk4BsQ6SjofAOYppZzuCVBK3aKUSlRKJWZmSra2w6goBgwO5sGYXqfWkt2tVAZ6NWbpmcv0m96jxfp31dHsIsptBr3DJKMnWp/JwxMv1Xalm4Zh8PzSPUQFWPnf1SNRCn7em1nvmO0peQxuw7JNkECvcxp3F8RPhu/mwLGtVXdbLWamDIniu+1plJS3YiciIUT7qBqvoAO7/JIK/Lw8MDXQtjkoMJhSwwOjTutz4TIpQI8aX8c47qvpJmABgGEYawArEGYYRqlhGMcd928ADgD9cMIwjNcNwxhtGMbo8PDwVv4RxEkr0+MD8uxWTu/Vgi0d7s7b0dG3ZkMWRxnnoUL9uyqparSCZPRE69NdNyvarOvmj7sz2Hgkh3vO6Uv3IG+GdA/k5721z7PJJ4rJLS5nSLQLmjA1QgK9zshkgumv6qtqb0+BLZ9UPXTJ8GgKSitYsTvj/9l77/C4yjP9//NOH82MuizbkpuMDQaMKQ6YHkpIyAaySTak94UQ0ttukl+STbLJZnfT9ptACmksCYRASAibQCAh9GIwxhhjXGVsWW7qmqLp7++P9xxpJI2kURuVeT7X5WuKzjl6wZ455z7389zPDC5QEIQpYYij1xtPjTxaAfB5XHQTQsU6i7E6AZ4BVimlViilPJiwlbuHbHMAuARAKbUGI/TalFJ1VpgLSqkmYBXQXLSVC5PHujDsw8sZy6tmeDFFJI+jZwu9Pb2mP7G53aQSrpTRCsJ04PROX+qmZ/C/2WxW8637drK8pow3rzdzKM9fVcvmA1397RQA21rNZ6CYQSwgQm/+EqqHqx+ExafCH66Buz8KqT7OXllDbdAr5ZuCMB/IE8YyUn+eTdhRgTshQq8YaK3TwEeA+4CXMOmaLyqlvqaUutLa7NPA1Uqp54HfAO/VZhbOBcBWpdQW4HfAtVpr+YubS1iOXnVV9ag3YOYdeYWe6W9q7fPQ05di77EoNQEPFWUl9P9FKB4ujwljmeoePU/ImCk5/OmFw+w4EuaTr1rd33t3weo60lnNk3sH2iS2HerB6VAcv7C4c61lYPp8pnwRvPtuePAb8Nh3oXUzzjf/L1esW8QtGw+MefdfEIRZjl262d+jlxpT6EVdFfiTXaNuI0wdWut7MCErue99Oef5duDcPPvdCdw57QsUpo1kXxgPsGzRFA0inyv4rNLN+PDSzTBltHTGaG6PsFKCWITpwunFTYpIjqM2aRK9w8o2U5ks371/JycsDHHFKYv73z99aRUBj5NHd7dz2UkLAdjW2suqBcGip+6Kozffcbrg0n+Dd/wOeg/BLy/nyrX1JNNZ7tsms7QEYU5jl27m9OiNNEPPJu6uoiw9PA1MEISp5eVDpkXiuMYSE3ouD7gDw3r0tHIQxceBzhjNbVEZrSBMH04PDjTxRGLqjpkIDxJ67ZEEn73jeV7uiPGZy44f1BvvcTk4e2UNj+w2gSwmiKWHtUUclG4jQq9UWPUquPQrED3GqRURllaXcffzUr4pCHOaCZRuprxVhLIi9ARhumk+ZMaYrFmWZ07ufMdfNbxHz1sBKJ4/2E1HNClCT5g+XKbKJZmIT90xLaGXzmT5xWP7uOjbD/GnrYe57pUruWTNgmGbn7+qjv0dMfZ3RDnSG6cjmuTkGRB6UrpZSlQ3AaA69/H6Uxdzw4N7OBaOsyDkG2NHQRBmJf1Cz5zUIomxhV7WV00FEcikjeMvCMK00HLEOHoVFSUUxGLjrxzm6Cl/BdUpDw/vNC6HlG4K04bTC0Ay0Td1x0yE6dU+3vz9x9h5NMz5q2r5tytO4rgRkmMvWG0SkB/Z3c7CcnOdXezETRBHr7SwhB5dRuhlNfx56+GZXZMgCBMnmwIUOJxora0evTH6boO1APT1yogFQZgu0pksx9qtIAZPCQqaoY5eohd8FSytLmPHEZNeKMPShWnDcvRSyakt3Xz6UJpwPMVP3nUGN7//zBFFHsDymjKWVPt5ZFcb21p7UArWLBKhJ0wnoUXmLkdnM8ctCHHionJJ3xSEuUwm2e/mJdJZUhk9pqPnDBih19spPbqCMF1sP9yLO2O5CZ4SLFH0V+Yp3SxnaXUZAG6nYkmVf4YWJ8x7rPNiOjl1pZvZeC8daR/vPmc5rz5pIUrln1dro5Ti/FV1PLm3gy0t3aysC1LmKX4VjQi9UsLhgOoV0LkPgNefupgtLd3s74jO8MIEQZgQmXR/f16vlS42lqPnLTflJJFOmaUpCNPFxuZOylQcrZzg8s70coqPr3J46qbl6AEsqwngcsolqDBNWKWbjmySRHpqhqbrRJgIfurLC/88X7CqjkgizaO72zh5cfHdPBChV3pUDQi9K9aZKNi/SPqmIMxNsqlBQSwA5WM4ev5KI/TiPUend22CUMJs3NfJIl8a5QnCGHf+5yX5wlh8lSytMUKvqbYEXU6heFilmx7SRBNTIPSyWRzJiBF648i1OOe4GpwORVYzI0EsIEKv9Khugq59oDWLK/0sqvCx06qXFwRhjpFJgmOw0BurdDNYbWb6pMJt07s2QShRslnNMy93sjSowVuifWj+SkjHIWWVr8Z7Bzl60p8nTCuWozdlQ9NTURSasPZTX1G40Cv3uTltiZkredJiEXpCMaheAakYRMzd/Ka6AHvbpXRTEOYkOaWb4QJLNyuqzUyvdETCWARhOth1LExPX4pF/kxp9ueBcfTAJG9m0pAMg6/cGhjt4LSllTO7PmF+0+/opYhMhdBLGEPElG6OL6n+kjX1+NwOTpqBxE2Q8QqlR/UK89jZDKGFNNUGuWtLK1rrMRtLBUGYZWSSw0o3x3L0yoNBwtoPsY5pX958QSl1BfBnrXV2ptcizH42NncCUONJgSp1odc10KPoq6Am6GXTF19FwOOcubUJ8x8rjMWjpsjRi/cCkHIGCHrHJ53++fwVXLFuEeVjJWJPE+LolRpVttAzfXpNdQHC8TRtkVEiaDv2QmoKh04KgjA1ZFM5pZuFOXoOh6JHhXD2dU778uYRbwF2K6X+Wyl1wkwvRpjdPL2vk8UVPny6rzRHK4AJYwEj9OI91numdC3odcmNZWF6sUo3vVPs6LnLxl9+6XY6aKwqm/waJogIvVKjcikop3H0GKiTb24boXzz5cfh+vWw8cfFWqEgCIWSSfXfuSzU0QMIOyrxJLrG3E4waK3fCZwG7AVuUko9qZS6RikVmuGlCbMMrTUb93VyVlMNKhkpXaFnO3rx7mFCTxCmnZzSzSkJY0kYR88TmHv/hkXolRpON1QuMYEsDCRf5RV60Xa48wOgs3DspWKuUhCEQsikwGmEXW88jVIQLGBOT5+7Al+qe8zthAG01r3A74DbgEXAG4DNSqmPzujChFnFrqMR2iMJNjRVQzIqPXp9Xf0XySL0hKLRH8aSmZrSTcvRKwtVTf5YRUaEXilS3dTv6DVU+vG6HDS3RQZvk83C76+BWCdULe/fXhCEWUQ219FLEfS4cDjGLolKeqoIZHqme3XzBqXUlUqpPwAPAW7gTK315cA64NMzuTZhdvHobpNme/6quhIXenlKN70zE0YhlCBTHMairZsVwQoResJcoLqpv0fP4VCsqA3QPDR58/H/gb0PwGu+CSsuhM69M7BQQRBGJZMaNF6hkLJNgLSvigotQm8cvAn4ntZ6rdb6W1rrYwBa6xjwgZldmjCbeGR3O8ctCLK40m8JvRIt3fSWmzaRPindFGaAKQ5jiUdMBUx5RfWkj1VsROiVIlUrTN18zIQxrKwLDnb09j8Jf/86nPRGWP9+IwxjHeYLWxCE2UNO6WY4nhoziMVG+2vxkyCTkNEqBfIV4Gn7hVLKr5RaDqC1fmBmliTMNuKpDBubOzh/Va2piklGSneOnlLG1csTxiII045VulnmSBNJTl7oRXvN9W9Vdc2kj1VsROiVItVN5rFrIHmzpauPRDoD0Q743fuhahlc8f/Ml3XNSrO9lG8KwuwikxwUxlKoo6cC5mQV7jw2bUubZ9wB5I5WyFjvCUI/m17uIpHOcsGqOjOvFkq3dBNM8ma/0FNSuikUD6t0M+jKTomj1xfpJqq91FfMvc+zCL1SpHr4iIVMVnOgIwaPfw+ix+DNN4HP+lK2haEIPUGYXWQnVrrpDtUC0Nt5dNqWNs9waa2T9gvruWcG1yPMQh7d3YbbqTjLDmKB0hZ6/iordbPXiDyHXHIKRcJy9AKuzJSkbqZiPdawdO+kj1Vs5FNXilQtN4+20Ks1pSV726Kw6z5YcQEsWpezfc6QdUEQZg+ZVM7A9BTBAks3fRULAOjrPjJtS5tntCmlrrRfKKVeD7TP4HqEWcgju9tZv6yaMo/LlG1C6fbogRF6tqPnEzdPKCJWpUvAme0fPTQZMn29RLSfBSHfpI9VbETolSJuP4QW58zSM3cc21t2QPsuWHXZ4O09ZYO2FwRhljBI6BXu6PkrjdCL97RN29LmGdcCX1BKHVBKtQD/CnxwhtckzCKOheO8dLiX81cbt3xA6JWyo5dTuin9eUIxcTjA4SLgmJrxCjrRS8xRht/jnILFFZfCrgqE+UfOiIWQz82CkJey/Q+anw0VemD69DokeVMQZhXZ1IR69ELVCwFIR8SUKgSt9V5gg1IqaL2OjLGLUGI8vsd8li5YVWfe6C/dLHVHr1uEnjAzOL34nWmiUxDG4kiGSTnn5me5oKsCpVQA6NNaZ5VSq4ETgHu11qlpXZ0wfVQvh91/7X/ZVBdgWfvjRgDa4SuDtl8BO+4p3voEQRibTAocLuKpDMlMlvICSzerquvIaEVWhF7BKKX+ATgJ8CllZhVqrb82o4sSZg2P7mqnOuDhxEVWiaIIPRPGEu8xfXqVS2d6NUKp4fLgd2SnZI6eOxUh426cgkUVn0JLNx/BnNwagPuBdwE3TdeihCJQ3QSRo5AwN6ZX17g5Kbklv5sHUL0SYu0DMcmCIMw8GePo2T0IhTp6Pq+HHoKovo7pXN28QSn1Y+AtwEcBBbwZWDajixJmDVprHtndznnH1eJwmJsAUrqJcfTQ0H1AHD2h+Di9+B1TM0fPm4mivaEpWFTxKVToKWsw7BuBH2qt34y5synMVeyAla6XATjHsR0fKcJLLsq/vSRvCsLsw+rRC8dNcUWhQg+g11GOK945XSubb5yjtX430KW1/ipwNrB6htckzBJ2HAnTHkmY+Xk2krppCT0g0SujFYTi4/TgVelJp25msxq/7sPpn5v/hgsWekqps4F3AH+23pt7HYnCAEOE28mxp+nTHnb51hW0vSAIs4CsKd3sd/S8hZVuAkSdlXiT3dO1svlG3HqMKaUWAylg0QyuR5hFPLrbhBqdb/fnQX+1DHPUBZgS/JUDz8XRE4qNy4NPmR49rfWED9MZTRAkhts/N/8NFyr0PgF8HviD1vpFpVQT8OD0LUuYduxZel37QGvqjz7C49mT2NM1QtulvX2HCD1BmDVYA9PtHoTxOHp97kr8aRF6BfJ/SqlK4FvAZuBl4NYZXZEwa3h0dzur64MsrMiJXpfSzQFHD0ToCcXH6cWr0mgNseTEXb1jnV04lcYbnJv/hgu6KtBaPww8DKCUcgDtWuuPTefChGnGVwFlNcah69iDu3c/j3IJvrZo/u09AQgtEkdPEGYLWkM2PaR0s3BHL+WtItT34nStbt5gnfMe0Fp3A3cqpf4E+LTW0rAsEE9l2Livk3dtGNKymYyCw9WfiluSiNATZhKXB3fK3ASNJtIEvBMbNNDVaXrZ/aGqMbacnRTk6CmlblVKlVvpm9uA7Uqpz07v0oRpp7rJDE3ffT8AeyvPMUPTR9x+JXTKiAVBmBVkrQZzp5vecYaxAGR91VToXiMYhRHRWmeBG3JeJ0TkCTZP7+skmc4O7s8DI/Q8AbASWksSX27p5tzsbxLmME4PHms4wGSSN7u7jNALlldPybKKTaGlmydqrXuBfwTuBVZgkjeFuUzVigGhV7eG4IImmttHGQ9VvUIcPUGYLWSS5tHh7u/RK3S8AoAO1OJSWeKRrulY3XzjAaXUm5Qq5at2IR/PvNyJ06E4a0XN4B8kI6U9WgGkR0+YWZwe3BihN5lAlnCPOUeGKuaxowe4lVJujNC725qfJ7eB5zrVTdDTAvufgFWvoqkuwIGOGKlMNv/2NSsh2gbx3uKuUxCE4WSsflqnh4gl9ILjcPRcQeNA9HQcmfKlzUM+CNwBJJRSvUqpsFJKvggF9rZFWFLlx+8Zkk8nQg9cXnBbPYoi9IRi4/LimgJHLxo2Qs9dNjf/DRcq9H6CaT4PAI8opZYBcpKb61SvALRxBlZdRlNdkHRW09IZG2F7Sd4UhFlDv9BzE0mkKPM4cToKN5zcISP0Ip0i9MZCax3SWju01h6tdbn1WmrRBJrbojTV5RF0dulmqWO7eiL0hGLjHBB6k5mlF49YoWVzNEG30DCW7wPfz3lrv1JqhIFrwpzBFm6eECzdQJPTlG2OeOLqF3p7YfGpRVqkIAh5yVpCz+EikkgTHGejub9yAQB93cememXzDqXUBfne11o/Uuy1CLOHbFazrz06vD8PROjZ+Kugt3Vwv54gFAOXB6d1nowmJy70klGrJXs+Cz2lVAXwb4B9snsY+BogDelzGXto+sqLwOlmZa0Rd3vbIlxK/fDtxdEbTjoJ934WLvxXKF8806sRSgm7R8/pIRwfv9ALVC0EIBVum+qVzUdyw8d8wJnAs8DFM7McYTbQ2t1HIp0dwdGLQHlj8Rc127CTN+foRbIwh3F6cGTNeXIypZuZPlvozc0ijkJLN38BhIGrrD+9wC/H2kkp9Rql1E6l1B6l1OdG2e5NSimtlFpf4HqEqSBQC6/4Z9hwHQAVZW5qgx6aRxuxEFxoAlwEQ/tOePYm2CtjJYUikxlI3Ywk0uPqzwMorzY3c1Lh9qle2bxDa31Fzp9XAScDkmJT4jS3m3NlU20e5y4RAW+J9+iBKdl0B8BZeFCUIEwJOUJvoqWb6UwWlQybF3O057bQK4OVWus35bz+qlJqy2g7KKWcmEjqVwEHgWeUUndrrbcP2S4EfBzYWPiyhSlBKfiH7wx6q6k2OHryZs1K6JARC/0krP9XyVH+nwnCdJAd6NGLTqB0s6K8koR2Q0yE3gQ4CKyZ6UUIM8veY+Z7X3r0RqFqOVQunelVCKWIy4vK2I7exFI3O6JJAvSRdnhxuebmTMxCHb0+pdR59gul1LlA3xj7nAns0Vo3a62TwG3A6/Ns9+/AfwHxAtciTCNNdYGRHT2QEQtDsQVeIjyz6xBKjyHjFcYr9BxOB70qSDbWPQ2Lm18opX6glPq+9ed64FFg80yvS5hZmtsjhHwuaoN5LgCT0TnrAEwpF38R3nfPTK9CKEWcXlTGBJVN1NE72hsnRB8Z99z9LBd6ZXAtcLPVqwemZOU9Y+zTALTkvD4InJW7gVLqdGCJ1vrPMoB9drBmUTm3PdNCS2eMJdVlwzeoXgnRY2bEggxAhYQVPitCTyg2/aWbngmVbgL0OctxxKUCsQA25TxPA7/RWj8+U4sRZgfNbVFW1gUZNl4xm4WUOHoAuP3mjyAUG5cHMgkCXteEhd6RnjhB1Tdn+/Og8NTN54F1Sqly63WvUuoTwNaJ/mKllAP4LvDeAra9BrgGYOlSKQGYTjY0maGvTzV3jCD0rECWrn2waF0RVzZLkdJNYaboD2MxqZuhcTp6AElPBe6EZGoVwO+AuNY6A6Y1QSlVprUeYRaNUAo0t0U557ia4T9IWVUxIvQEYeZweiCTJOhzTjiM5Wg4wWL6cPjnrtArtHQTMAJPa23Pz/vUGJu3AktyXjda79mEMA3tDymlXgY2AHfnC2TRWt+otV6vtV5fV1c3niUL42TVgiDVAQ9PNXfm36BmpXmUPj1Df+mmCD2hyFg9etrhIhKfmKOX9Vbiz/SSzeqpXt184wEg15bwA3+bobUIs4BIIs2R3jgrR+rPAyndFISZxGlKqiu8esKO3rHeOCHVh7NUhN4QxprM+wywSim1QinlAd4K3G3/UGvdo7Wu1Vov11ovB54CrtRab8p/OKEYOByKs1ZU81RzR/4N7JEM0qdnsEs2pXRTKDaWo5fERTqrCXrHn2qnyqooJ0JHNDnVq5tv+LTW/XdzrOd5Sh6EUmFf2yiJmyL0BGHmcXkBqHRniU4wjOVob5xKZxzHHC7dnIzQG/UWsNY6DXwEuA94Cbhda/2iUuprSqkrJ/F7hWlmQ1MNrd19tHTmqUryBiFYL0LPxhZ4SRF6QpGxevRiafM1PhFHzx2soZIoh3vGytYqeaJWTzkASqkzGDuQTJjH2OnUKxeMMEMPpHRTEGYSpxF6FZ6Jz9E72pugXPXN6TmQo14ZKKXC5Bd0isFlLHnRWt8D3DPkvS+PsO0rxzqeUBzG7tNbKULPRko3hZnCKt2MZSyh53WO+xD+8lrKVIIjHd2c0lg5pcubZ3wCuEMpdQhz/lsIvGVmlyTMJHvbojgULKvJc45MSo+eIMw41uzGcneWaHLiqZsB5rbQG9XR01qHtNblef6EtNbjv30szAnG7NOrbpIePRsJYxFmCqt0M5oyVfQTKd0MVi0AoKP96NStax6itX4GOAH4ECaFeo3W+tlC9lVKvUYptVMptUcp9bk8P1+qlHpQKfWcUmqrUuq1OT/7vLXfTqXUq6fqv0eYPHvbIjRWleF15bnBYp8X5vDFoSDMeazSzZA7O6kePb+OzenP8mRKN4V5yph9ehUNZsRCdmI1z/MK6dETZgqrdDOStoXe+O+9lVXUAtDbeWzq1jUPUUp9GAhorbdprbcBQaXUdQXs5wRuAC4HTgTeppQ6cchmX8S0NpyG6WX/obXvidbrk4DXAD+0jifMAprbojTVjeDYSemmIMw8VhhLuTs7odLNRDpDNBbFpdMi9IT5x6h9ej6rxCsusexSuinMGLajZ/XohSbQo6fKqswxetqmbl3zk6u11v2T5bXWXcDVBex3JrBHa92stU4CtwGvH7KNBuxO/wrgkPX89cBtWuuE1nofsMc6njDDZLOafe0RmmpHCFuR0k1BmHksRy/oyhJPZUlnsuPavS2cIGS3YovQE+Ybdp/ek/lcPb+5OKRPBi0PhLFEQEtEvVBErB698CQcPfuzHO8dwb0XbJwqZyq25ax5CtivAWjJeX3Qei+XrwDvVEodxPS0f3Qc+wozwOHeOPFUlpULRnL0JHVTEGYcK4wl5DICL5ocXxXa0d4EQWWZHSWauinMYwb69PIJPdvR6x7+s1Kjv2RTD5zcBaEYZIzQi1iTESaSumkLvXR0hH5cweYvwG+VUpcopS4BfgPcO0XHfhtwk9a6EXgt8Cul1LjOzUqpa5RSm5RSm9raxJ2dbvYeMxUcIzt61nlBHD1BmDmsMJaAywi88fbpHeuNExRHT5iv2H16G5s70UOdKrt0s0+EHskI2Ndk0qcnFBNL6PWah0k5es54N4m09NyOwr8Cf8cEsVwLvEABydNAK7Ak53Wj9V4uHwBuB9BaPwn4gNoC98Xa70at9Xqt9fq6uroCliVMhuY2a7TCiD16UXC4+0vHBEGYAazPX5lzgkIvnCCkLKHnE0dPmIfYfXoHu4aMi7IdPSndNL15wXrzXJI3hWJilW72JhVup8LrmsDXuSdIVrmoVBGO9iSmeIHzB611FtgIvIzpk7sYMx92LJ4BVimlViilPJhwlbuHbHMAuARAKbUGI/TarO3eqpTyKqVWAKuApyf/XyNMlub2KEEAYk9jAAAgAElEQVSvi7rQCEIuGRU3TxBmGqt0M+C0gsvGKfQiifS8cPRkRIIwIrl9eoPm6dk9eqVeuplJQ7oPQmsgfFgcPaG42I5eEgJeFzktZIWjFGlvBZWpKK3dfSzNNxOshFFKrcaUVr4NaAd+C6C1vqiQ/bXWaaXUR4D7ACfwC631i0qprwGbtNZ3A58GfqqU+iQmmOW92pRRvKiUuh3YDqSBD2utxXadBTS3RVlZFxj5M5eMSn+eIMw0LtNG7XdYPXqJ8X19RhNpKhxx80KEnjAfWV0/0Kd31fqcCiIp3TTYfRihReZRhJ5QTDIpQNEb1xMr27TxV1ERjXC4p2/sbUuPHcCjwOu01nsALEFWMFrrezAhK7nvfTnn+Xbg3BH2/QbwjXGuWZhm9rZF+m+E5iUZEUdPEGYapy30jMAbr6MXTaSpdlmVLhLGIsxHlFJsaMrTp+f2gcsnjp49UqHcEnpSuikUk0wSnG7CycykhJ4rUE0lEQ51i9DLwxuBw8CDSqmfWkEsE7BOhflCLJnmcE+cptpRhFwiAl5x9ARhRrGEnk8ZgTfeHr1oMkOVc+47eiL0hFEZsU/PVyk9eraw63f0ROgJRSSbBqeHSDw9oRl6No6yamqdMVq741O4uPmB1vourfVbgROAB4FPAAuUUj9SSl02s6sTZoLmNpOu3FQ3ipCTHj1BmHmsMBafwxJ6yfE7epXOuBGMczhYSYSeMCp2ecoTe9sH/8BfJaWbiSGlm0kp3RSKSCYJDpdpGJ9k6WaVIyqO3ihoraNa61u11ldg0i+fwyRxCiVGc7st9Cwhl81CashnR3r0BGHmscJYvEwsjCWazJgevTns5oEIPWEMVi0I0lDp509bDw/+gb8S4j0zs6jZQr/QWzj4tSAUg0wKnG6iiTRBn3vix/FXUa6lR69QtNZd1jiDS2Z6LULxaW6LoBSssEs3t/wavtkIf/nCQJWL9OgJwsxjhbG4SeFQEyjdTKQpF6EnzHeUUvzTGY08tqed1tw7/r5KcfTs0s3gAjNLT0o3hWKSTYHTQ3gKHD2/jnG0Kzx8ZqYgCIPY2xalodKPz+00bxzdDjoLT/0Qvn86PP1TSPSKoycIM43Vo6cySQJe14RSN4PEROgJ859/OqMRreHOZw8OvOmXHr1+YecNgSckYSxCccmkTOnmJHv07HEprmQvvfHx3fEUhFKjuS0yuD8vchSqVsC1j0L9SXDPZyDWIY6eIMw0ltAjkyTkdREe5/ktlsyYOXpzOHETROgJBbCkuoxzVtZwx7MtZLPWHX9/laRu2qWanpBJWJPSTaGYZFJop4e+1ORSN22hV6mkfFMQRkNrzb726ODEzcgxCNbDwrXwnv+Dt9wCDeth2Tkzt1BBEEApI/bSCYI+14RKN8u0OHpCiXDV+iW0dPaxcV+necNXaRwsa2hzSWKHr3iD5otAhJ5QTDJJssoIvMBUCD0ZsSAIo9IZTRJLZlhaXTbwZuSoKd8Hc2G55nVw9QNwwj/MzCIFQRjA6YVMiqDXNYEwljT+bEwcPaE0ePVJCwl5XdyxqcW84beGppdyIEsiMhC76wlK6aZQXLJpMg4j8EJT5OjJiAVBGBm7T72hyj/wpu3oCYIw+3C6IZMg4HURHofQS2eyxFNZvNmoOHpCaeD3OLni1MXcs+0wvfGUcfSgtPv0EuGBhntvUMJYhOKSSZLBCLzgFPToVcuIBUEYFXuebKMt9FJxSPRAsG4GVyUIwoi4vJBOEBpn6WYsZYJbPBkRekIJcdX6JcRTWf689XD/xWFJJ28mI0bggRF8UropFJNMijQm+W8qevSW+BMcFqEnCCNysCsGQGOVVboZPWYexdEThNmJ0wOZpCndHEcYSzSRxkMKVzYpQk8oHdY1VrBqQZDbN7XklG6WsNBLRAZqt73lUropFJdsmrQy8/Mm5eh5y0E5aPDGOSSlm4IwwNEX4f4vgjV2pLWrj5DXRYXfmlsZEaEnCLMay9ELet3j6tGLJjIEsG58So+eUCoopbhq/RKeO9DN/ph1oitpR29o6aY4ekIRySRJaePoTapHz+EAXyX17r7BszIFodTZdic88QMTuIIp3Rzcn2fe7w9jEQRhdmGHsfhMGEt/cvwYRBNpgsoWeuLoCSXEP57WgNOhuGtH1LxR6j16Q0s3ZeC0UCwyKVJT0aMH4K+ixhHlaG+cTIEnQkGY9/RYs2N7WgETxtKYV+iJoycIsxIrjCXoNTdFo8nCXL1oMk0IEXpCCVIX8nLxCQv4zVbLvSr50k3rC8AbAp2BtJS+CUUikyKpzVf4pHr0APxVVBAlndW0hRNTsDhBmAfYQq/3IFprDnb1DfTnAUTazGNAwlgEYVaSU7oJpiSzEGIJa1g6iNATSo83nd7AkWiWjKus+KWbyRh8/zTY+/fi/t68a4nklG5aXwSSvCkUi2yKhLbm6HkmL/SC2ty8kfJNQbDoscYJ9R6ity9NJJGmoXKIo+evNq6BIAizDzuMxap6iSQKm/0cTaYJKRO+JEJPKDleefwCQl4XYQLFd/R6DkJnMxx8tri/Nx+J8MAXgC34ktKnJxSJTJKkdhDwOHE41OSO5a/ClzYzMQ/3iNATBLIZ6D1knvccpKU/cXOI0JOyTUGYvdjjFayql3CByZvRQY6ehLEIJYbP7eQ1Jy/kWMpPJlbkHr2oVSpjx1rPFNnsEEfPepRAFqFYZNIkMs7J9+cB+KtwJ4zQk1l6goARcVnrorC3dZRh6RLEIgizFqenP4wFKDh5M5pIE5IwFqGUef2pDXTqAD2dkxBcnftg1/3j2yfWbh4jMyz0UlYYTW6PHkjpplA8sini2jn5/jwAfxUq0UOF1yEjFgQBBvrzlBN6WnOGpef26ImjJwizGqcHMon+9oZCZ+lFk2np0RNKm7NX1tDnDNHX2zHxgzzxA7jjPeNLqozOEqFnC7r+1E3ri0Bm6QnFIpOkL+Mg6JuC/iBraPpx5Wnp0RMEGOjPW7jWOHpdffjdTqrKrM+b1qbCRBw9QZi9uLyQThKagKNX6UyYGz1u/9g7zGJE6AkTwulQVFbX4Uz00NNXWHPrMHoPQSo2vnLHmCUsZ7p0016zLfCkdFMoNpk0fRnH5Gbo2dhCL5SaUI/e37Yf5VhYnEBhHmE7eks3QPgIhzrDNFb5Ucrqh01GzPlLhJ4gzF4sR8+ufClY6CUzVDrj5tpOTbIHfoYRoSdMmIaFiygnyn0vHpnYASLWfnbfXSH0O3rj2Gc6sENXhpVuhvnZo818/vdbZ2ZdQumQSdKXVVNTullWDcDysgStXeMTekd74/zzzZv4ycPNk1+HIMwWeg6CtwLqjgedIdZ1aHh/HkjppiDMZlxeyCQJeMdZuplIU+FMzPkgFhChJ0yCugULKVMJ7nnu5YkdIGwNm7WHzhaC3aOX6IHUDDoIw0o37dTNCPduO8Jdzx0iK4OnhelCa8imiKWnLowFYHV5mq5Yik/c9hy98cKc+od3mZsuLxzsmfw6BGG20HMQKhqhvBEA3X1whGHp4ugJwqzF6YF0Eo/LgdflGEfpZoaQis/5/jwQoSdMAuWvBGB78wGO9Y5TdGUzAyfK8fTb2Y4ejM8JnGr6SzeHCL1EhH3tUfpSmf7mfUGYcqw0wGhmihw9S+i9comLT166mv/bepjL/+dRnt7XOeauttDbdqiHjNzcEOYLttCraACgPHlseBALiKMnCLMZq3QTIOh1ES5Q6MWSacpV38C13RxGhJ4wcayLwxBR/rT18Pj2jXWAzpjn4xF6sQ5wWM3w4+nTi3VCx97Ctx8LO3TFvtvjcIA7QCLaTWc0CcDOo9KvJ0wTGeO2RdOO/ibzSWF9lp2JHj5+6SruuPZsnA7FW298km/dt4NUJpt/GVnNY7vbKfe5iCUz7G2TMCJhntDv6Bmht0h1DBmWbt1oFKEnCLMXl9fcGM1mCfpcRMcRxlJGnzh6QonjM47eqbVw9/OHxrdvOKevbzyCLdoGtavN8/H06T3wNfjxeVMn9hJDevSs55HegQHyu0ToCdNF1gi9lHb29x5MCl+FeewzczFPX1rFPR8/nzed3sgND+7l+w/szrvb8we76elL8d5zVwCwVco3hflAMgp9nUbo+SpIuwIsVh3DSzeVE/zVM7dOQRBGx+kxj1YgS+HjFTIE6Btoz5nDiNATJo7lAly63M2Wlm72d0QL3zdX6BXq6GltHL36E83r8QjE7gMmIe33V/e7IZPCdvRybX1vkL6oudB1OxU7j4jQE6YJ699wiimao+dwGrFnCT0wZS7fevM6Lj5hAb99poV0Hlfv4Z1tOBS85+xllHmcvHCwe9g2gjDn6Gk1jxVLQCki3noWqs4hYSxHIVBnqjkEQZiduLzmMZMcV+lmNJHGn42JoyeUOFaP3obFTpSCGx7cU/i+duKmr6JwoRfvNhb8gjXWMcYR4hI5CmW10PosPPKtwvcbiUQYlGPwfBVPkFSsB4eCs1bUiKMnTB/9Qs81NaWbYG7c5Ag9m6vWL+FYOMEju4c76I/sbuOUxkpqgl5Obqhga6s4esI8wJ6hV2GCWDqdtTQ4OqgLege2iRyTIBZBmO3Yjl46OT5HL5HGl41J6qZQ4lilm1UqxgcvWMntmw7yxy2the1rJ27Wry3cmYtaM/TKG82Hbzylm5GjsOZ1sO7tRugd2Fj4vvlIRMydntz5Kt4Q2XiYxqoyTmoop7ktOmJvkyBMiozpA01PlaMHIwq9i09YQE3Aw+3PHBz0fncsyfMt3Vy4ug6AUxoq2H6oV/7NC3Mfe4aeFcRyhBoaHJ0DM/TAnFOkP08QZje5pZs+F9Hk2EJPa000mcabjUkYi1Di2H098W4+fdlq1i+r4gu/f4HmQgIZwodNb0NFY+GCzR6tEKgxJTOFCsRM2qR1Buvh8v8yv/P3V09uuHkyMjAs3cYbQiUjLK8NcHx9iGQmO75yVkEoFCt1M6ld0y70PC4HbzitgQd2HKUjkuh//7E97WQ1XGAJvbWNFSTSWXGyhblPz0FTsRFaBMD+VBXVuhvSyYFtom0i9ARhtmOXbqYL79FLpLN4s3EUWko3hRLH6TLOWl8XbqeD77/tNNwuBx++9Tniqczo+0aOQmghBOvMc11ALLs9WqGs1pTMFCoQo22ANidlXzm88aemNOfezxW2fz4SvcOadLUniDsdo6k2wOp68+Ww84ikEArTQL+j55qaOXowotADePP6JaQymru2DIQuPbyzjQq/m3WN5obPKY3G4Zd5esKcp+egEXlOk/C8O16BA21uUAJks1bpZt0MLlIQhDHpd/SSBH2F9ejFkhmCWOOxJIxFKHl8ldBnAhgWV/r57lXreOlwL1//8/bR9wsfMcIrWG9mnCR6x/5d/Y5e7fgcvaHzjpZugPM/DVt+Dc0PF3aModilmzn0OfyUEWNFbYDjFgRxKBmxIEwTOWEsIa97ao45itA7fmGIdUsquWNTC1prtNY8sruN846rxeU0p5HlNWWEfC7p0xPmPj0t/f15sWSa3QmreqXXak2Id5vkW3H0BGF2kyP0Ql4XyXSWRHp0IyKaSBNUttCTHj2h1PFXmJOexcUn1HPNBU38+qkD/Hm02Xq2oxewmtkLCWQZ5uiNU+iFFg68d96nAAUHnirsGENJRobVbnenvQSJs7w2gM/tZHlNgN0i9ITpIDsQxjKljl6827gVebhqfSM7joR5obWHnUfDHO1N9PfnASilOKWxQhw9Ye5jz9ADDnX3cUjXmPd7LUe7/+ahhLEIwqymv3Qz2T+KKJoYQ+gl0zmOnpRuCqVOjqNn89lXH89pSyv5/O+3Eo7nGWWgtXH0QgsHTpSFCj1PCNw+IxDjQ3omRiLfSdlTZqKzO/LPBxuTRGSYpd+R8uBVKZqqjMOyqj4ojp4wPViOXhonAa9zao7prwKdHdFdv2LdYrwuB7dvauHhnaZs+vzVtYO2WdtQyY4jvWPeMRWEWUs2a5w7S+i1dPVxRFuz8uyQlqFVIoIgzE6GzNEDxhyaPsjRkzCW0VFKvUYptVMptUcpNawhSil1rVLqBaXUFqXUY0qpE6dzPcI0kKfcy+108LUrT6Y3nubWjQeG7xPrtMpecoReIWWYsXYTxAI5+xXQp2eflAND7r7WrIT2iQq98LAwliMJI/AW+81F7vH1IV5uj47drygI48USetrhxuuaQqEHI5ZvlvvcXH7yQv645RD3bz/K8fUhFlX4B21zSmMFqYxmx2G5wSHMUaJtpge2YgkArV19RPGT9ZYPlG7a/eEi9ARhdpMTxmKPIgqPEcgSTWTE0SsEpZQTuAG4HDgReFseIXer1nqt1vpU4L+B707XeoRpwl85qHTTZm1jBecdV8vPH9s3/O6+PUMvVD9woizU0SuzHIR+J7CAWXrho8Z5dPsGv1+7Cjr2FBYEM5RkeNgXQGvMfIk4UyaAZfXCEFkNewtJIRWE8WCFsbg93jE2HAdjCD0wM/XC8TTP7u/igiFuHhihB0ifnjB36R+tYBy9g119uJ0KVdE4MEhdSjcFYW7Q7+ilCFr97JFCHD0JYymIM4E9WutmrXUSuA14fe4GWuvcGqEAMIErbmFGyVO6aXPthSs5Fk7wh81DZuvZyWWhRWbEgnIWJvRi7SaIBQbcuUIdvXx3XmtWmV678JGxj5GL1nlLN1ui1scpaYTd8VbypsTNC1OONV7B7Z5KoWeVp40i9DY01dBYZVy8C1cPv8htqPRTHfDwwsH83wmCMOsZMiy9tbuPxZV+VHkD9OaUbjq98yKoQRDmNUPm6AFEEnlainKIJjMEVNy8mAef8ekUeg1AS87rg9Z7g1BKfVgptRfj6H0s34GUUtcopTYppTa1tY1jSLYw/fgrTWpmqm/w+0/9mHP/egVrF5fzk0eayWRzNHw4p7/B4TDirRBnLtqR4+hZIRCFCMTIUeMeDqX2OPM43j69VB/ozKDa7UxWsy9sfZwSRugtrw3gdip2HRVHT5hiLEfPU2RHz+FQvPec5dSFvKxfXjXs50op1jZUsFUCWYS5il2e2e/oxWio9Jvh6f1hLMfM+St3gLogCLOPnDCWoNXPPnbpZpqQlG5OHVrrG7TWK4F/Bb44wjY3aq3Xa63X19XJ3JpZxUgXhzvvQR3bzsfPKmdfe5T7X8xxzfpLN60UzOCCsZ05rQf36AXG0ds3mqMH4+/Tsxy73C+AQ919dKetLxRrELvb6aCpNsiuI+LoCVOM1aPn9hZX6AF84LwVPPm5i/G58/cGntJYwe5jEfqS0psqzEF6DpqbeD4zF7K1q8+42OWN5jyVTljnFCnbFIRZz6AwFlO6WVDqpupDO9wDQnEOM51CrxVYkvO60XpvJG4D/nEa1yNMB9bJcFD5ZjYLh54D4KKaTpbXlPGjh/ei7V648BHwVYDbCnIIFDAqIRE2Lobt6HnKzMl4rKHpWg/cfR1KeQO4/KZPbzxYQi5X6L3cESWC9d+THBB2qxeGJHlzlvOf9+7gl4/vm+lljA+rdNM3pULP/iyPLvSUUv2z8/JxSmMlmaxm+2Fx9YQ5iD1DTyniqQzHwgkaKsugfLH5eW+rEXwSxCIIs5+cMJZCSzdjiQxBFZ8Xbh5Mr9B7BlillFqhlPIAbwXuzt1AKbUq5+U/ABOMQBRmDPviMDeQpX1Xf0S7s30n11ywkq0He3hyb4f5efiISdy0CdaPLfT6h6XnOLqFDE1PhCEVy39Sdjig5riJO3o5pZv72qNEtRX2khgo1Ty+PsjBrr4x43yFmUFrTfVT32Tbn388+tzH2YZVujmlQs/pNkmyYwi9segPZJHyTWEukjND73CP6dNprLJKN8EEsoijJwhzg5wwljK3E6UgMkbpZiSRptIZR82DIBaYRqGntU4DHwHuA14Cbtdav6iU+ppS6kprs48opV5USm0BPgW8Z7rWI0wT+Ry91mfNo3JA20u88fQGaoNefvTwXvP+0J65oCXYRku/tIelB3KS/goZmm7/fKS7r7XHjb9Hr9/RG/gSaG6LkrWFX2LAwVtlBbLsPiZ9erORtnCCN/Ag73Pfz6fv2MK2uZIWaZVuen3+MTYcJ3nGpYyX+nIfC0JeGZwuzE1yhN7BrhgADXbpJkD3fnM+EqEnCLOfnNJNh0MR9LgIj3HjPZZMU+GIz4sgFpjmHj2t9T1a69Va65Va629Y731Za3239fzjWuuTtNanaq0v0lq/OJ3rEaaBfH09rZvAWwGNZ8KxHfjcTj5w3goe3d3OV+5+kZ5jB3gpEuAHD+zm3hcOm9LNTDLvmIZ+bKFXVjPwXqBu7N6+3FEO+ahZBd0HTN9FoSSG9+jta49SV2OtLZnr6FnJm9KnNyvZ1xahgggnOvaz2J/l6ps3cSwcn+lljY0l9Hy+Ke4f8FdOWuiBcfVkxIKhgHmy37NmyW5RSu1SSnXn/CyT87O7h+4rTDGpPnNOsRM3u0wgg+nRs0o3Dz8PaBF6gjAXyAljAQh4XWM6etFEhpCUbgqCRb7SzYOboOE0WLAG2l4CrXnHhqUsrynj1qf344u38/BhJ9/56y4+dMtm7tpjfehG67eL5XP06sdO64zkJHzmo3YV6Cx0No9+nFz6SzcH9+gtqasAl2+Qo7ekugyf2yF9erOUg8fa8KgMDp3h55c56I6l+OCvnp31Q+7T1knL7519jh7A2oZKDnTESj6QpZB5slrrT1o3O08FfgD8PufHffbPtNZXIkwvdqqm5d5tO9RDwONkYbnP9IX7q/v7z6VHTxDmAA4XoEw6PBD0uYgmxxB6yTQh1TeoPWcuI0JPmBzeCkANlG4mY3D0RWg4wwi9eA9EjlLuc/PQZy9i1/93Nl6V4oOvPZtdX7+cd5+9jNt3mA9gOjyKaOt39IaUbvZ19bsbeRmrdLPGGrEwnj49q//QLt1MprO0dMZoqg2YL4YcR8/pUKxaEJJZerOUo0cP9T9fEd3Gd69ax3MHuvnCH14YCA+ahSQTxnX0+6fa0Zsaofe+85az9VMn4/fkT+YsIcacJzuEtwG/KcrKhOEMmaH3xN4OzlxRPRA+VNEAR14wz0XoCcLsRynj6llVW0Gvq6DxCmX0iaMnCIAJNPGVDzh6R7aaGXMN66HuBPPesZcGtreGk6vyRXhcDr565Um8dsM6AH56z5PERrrTEusAd5m5q2pjB7OMVr4ZPgIO90CJ6VBqJjBLb0jp5oHOGFkNK2oDRvwlBou61fUhdkrp5qyksz3n5kLLRi5fu4hPXLqK329u5eYn98/cwsYglTQnrbJZ2KNHy9OU3/YGfD+/cNhnoQQpaJ4sgFJqGbAC+HvO2z5rhuxTSilJpZ5ueqyB6BWNHOmJ09wW5ZyVOTcXyxsgbZV2S+mmIMwNnJ5+QyDkcxEZo0cvmsgQ0H2DchjmMq6ZXoAwD/BXDTh6BzeZx8b1A+EqbTtg5UXmuSX07NRNpRTvvOQVsBmOHWnhHT/byGUnLqQtnKAtkqAtHGdZdYD/UG04c908GDjRRo4N9E8MZazBtr5ys5b2sUcsZLKa/7jnJU5v3s0/ALgDALzcHgXMgHS8oUGpmwCr64Pcufkg3bEklWWeMX+PUDyindZNgtrj4eDTkM3ysYtXsa21h6//eTsnN1RwxrIRbhKMQTaraemKsawmMIUrNiSTpnQzOF2OXqTNhCSNhyMvwN+/Drv+Ym7CXPDZgUZ4oRDeCvxOa51b77pMa92qlGoC/q6UekFrvXfojkqpa4BrAJYuXVqc1c5Heg4CCsoX88RW891wznE5feHlORo9IEJPEOYETs9A6abXxZGe0fvwo8k0Ph2TMBZB6MeXE+DQugkqlhoRFlxgLhzbdgxsa/fMhXLGK/irQDl558l+th/q5b/+soPfPnOAFw52E09l+e2mFnbvexkdGCL0+oemj+LoRY6MHMRiU7tqTEcvncnymTue5+eP7ePIsTYSDr9xMzFBLIBVuhkaVLoJZpYewA5x9WYV2awmHrZKgo+/3JQZt+3A4VB8582nsqjCz4dv2UxHZBxBPTn86OG9XPTth9g9DWW7qWSChHYR9E2xkFr9atPTcOOFcPDZwvbRGu7+KPz4PDjwJFz8JfjYFtjwoXkxbHaSjGee7FsZUraptW61HpuBh4DT8u2otb5Ra71ea72+rm6cAl0YoKfF3Bh0eXlibweVZW7WLMy52LNHLHhCg6tLBEGYvbi8g8JYxhp31RdP4stK6aYgDOCvHCjdPPgsNJxunisFdWvgWI7QC1uzynL7GxwOCC5gpT/K5i+9ihe/+mpe/NpreOizF3HXh8/loxcfR6r3KC2JISdW23EYbcTCSMPSc7Fn6Y3Qk5VMZ/nob57jD8+18pnLVrN+kZvujJdfPWVK+5rbo1SVuY1b5w0O9PBZnNpYidfl4HfPHhx9HUJROdwbJ5i1/q6Ov9w8tmwEoKLMzY/eeTpdsSQfu+05Mtnx9ev1JTP8/LF9ZDXTUgKaTiVI4+wfADtlLN0AH7gfHE745Wtg0y9HH3sC0PwQbL4Z1n8APv48XPCZeVPyMgWMOU8WQCl1AlAFPJnzXpVSyms9rwXOBbYXZdWlijVaQWvNk3s7OLupBocjpxrEHrEgZZuCMHcY4uiNNV6BlLl5L2EsgmDjqzSlm5Fj0HPAlG3a1B3fn7wJQPiouRs69EIwUAeRNgJeFwHv4IvXT166mgZPjKePOfjb9pyeqn5HbzShN3iwbXskwRN727np8X18896XjBtXu8oI1VjHsN3jqQzX/vpZ7t12hC+97kQ+cvEq1tY5ybpDfPXuF3mquYOX26OmbBPylm5WBTy8c8My/vBca3+Z50R4vqWbt//0qZIIdtlxpJc7NrVw+zMt3Pb0AW7ZuJ97XjhMdpyCazRebo9SifV3tfh0E/RjCT2AkxZX8O//eDKP7+nge3/dNa5j3/bMATqjSU5aXM6dmw/SGx8lMGgC9As97zRU328K6KsAACAASURBVC9aB9c8DMvPhz99Au7+CKRGKXV56kfm8/uab47cC1uiFDhPFowAvE0PTgBaA2xSSj0PPAj8p9ZahN50Ygm9A50xWrv7OOe4IVUktqMnQSyCMHdwec0ILwZ69EYKW8tmNY7k8BFacxnp0RMmj7/KCCV7UHpDjtBbsAae7TG9eeWLRi6lHGVUgkNBFb04grV8/Lbn+N2HzmHNonLwBtHuMlpb9vPY0wdwOhRupwOXU+FQio7eKO+MtnPvy5qf/fBx9nfE6Igm+4+rFPxhcyt/vKyRRWBcvZzy0J6+FNfd8ixP7O3gG284mXectcysJxlhQW0Ny6JlXHfLZrJac/EJlpgckrpp88ELm/j1U/u5/sE9fPvN68b1vxfgib3tXP2/m4gmM/znvTv4xXtfMe5jzBXiqQzv/NnTtOcpmfzMZav5yMWrpuT37GuPUqUiZD1BHC6PcbMOPDVom6vWL2Hz/i6uf3APpy6p5NITx77AS6az3PhIM69YXsWXX3cSV1z/GL9/9iDvPXfFlKwbIJ1KksRFaKodPZuyanjHHfDQN+GRb5lAoyv+Z/h27Xtg933wys9LmeYIaK3vAe4Z8t6Xh7z+Sp79ngDWTuvihAGiHdC1H054HY/vMTf9zllZM3gbu0dPHD1BmDs43f2lm0GvC60hlswMMxUAYqkMQWXmZ86XyhQResLksYcsH9wEymkcARs7ebNthxF64SMQWjT8GMEFcGyEm9XJKCod51Vnn8R/b3TzgZue4cwV1Wxp6ebmRIDntu/kc8+/MGy3BXTxLp9mR9iPr87JpWvqWb0wxPH1IVbXB+nuS/H2nz7FdfeF+QNAxx5YdjYALx7q4bpbNtPa1ce3/2kdbzqjceDAiTBOX4ifvmk9r7/hccLxtOnPg7yOHsCCkI93nLWM/33yZT568XHjCuj42/ajXHfrZpZVl3H+qjp+8fg+nt3fNeGQkNnOH7e00h5JcMPbT+fUpZU4FDiV4ut/fonv/W03ZzXV8Irl1ZP+PS+3R1nriKDKrGMtOQt2/Mkq9x24kPvKlSfx4qFePvHbLdz5oXM4fuHod/nu2tLK4Z44//HGtaxtrOC0pZXc/OR+3n328sFlYJMgm06SxkVoOhw9G4cTLv4iJKPGtVv/flh0yuBtNv7YlMWsf//0rUMQisGzv4RsCta9jSf+1k59uXfge93GDv0SoScIcwend9AcPYBIIp1X6EUTaYJYFSwSxiIIFr5KyKZh3yNQf+LgJvUFa8yjHcgSPpK/7CVQZy6w89np1rD0UPVCfvae9SQzWZ5q7uT4hSE8lYu4sEHz+Ocu5tF/uYi/f/pC/vrJC7j34+dz3z+vBuBTb7yAW6/ewH/90yl84LwVnLeqlgXlPlbXh7j16g206lqSuOhqMULz9mdaeOMPnyCRyvLbD24YLPLAOHbecprqglz/9tNxOxVrG63B8Z6gqe/ODh8Ufe2FTbgciuv/PnbCp80ft7TywV8/y5qFIW7/4Nl85tWrqQ16+M79Ows+xlxCa83PHt3HmkXlvHbtQhoq/Syq8LOg3Mc33nAyjVV+Pv6b5+iOJcc+2Bi83BFlkSeO8ucIPRhUvgngczv56bvXU+Zx8v6bnsnrNNpkspofP7yXExeV88rVpof0PWcvp7k9yuN72ye9ZptsOkkKJ2XuIsypu/BfjMP3l88P/nz2dcGWW2Dtm+XCV5g+2nZBrHN6f0c6Cc/8DFZejK47nif3dnDuylrU0LRmlxde9e9w6tundz2CIEwdOWEsdrvDSCMWool0jqM3P0o3RegJk8dviZzWTYPLNsEIOH+VmaWntSnPzE3ctAnWm7up+WZ4Ra3eubJaTm6o4OkvXMpTX7iEn7xrPQsXL6Uy001DpZ8l1WU01QVZVR9izaJyqrJdA8cegdX1IW655lxaWMjzW57hE7c9x7/cuZX1y6v408fO44xleZyjRLjf0r9wdR0vfOXVXGhd1Pd/MeQp31xQbly93z/Xyv6O0Xv14qkMP3hgN5/47RZesbyKW67eQFXAQ5nHxYdeeRxP7O3giT3DhcPDu9rY8B8P8Ifn5mbwy0O72th9LMLV568YdpEV8rm5/m2n0xZJ8Jk7tk56oHlze5RaZ3Sgr2zxqebO35DyTYCFFT5+9p71dEQTXHPzJuKp4UIe4L4Xj9DcFuW6i1b2r//ytQupDXr43yemLpQlk06RwTVlDuGo+KuMs7f/Mdj+x4H3N98MqRicde30r0GY+xzaAo9+F7LZwveJdpgE2JteN3KfqNbw5A8LT4nNx/Y/mqCwDdex62iEjmiSs4eWbdqc+zFYnDf8VBCE2ciQMBaAyAhD06OJDAEsoSdhLIJgYV8o6+zgIBYYSN5s22kEUio2gtAbZVSC5ejZA9IHXdwG6kYOY7F7/sZwG1bVh6hfcTLL9CHu2nKIj1x0HDe//yxqgyP0HCXCg74AfLmuil3Tnad8E8Z29dKZLL95+gCv/NZDfOevu3jtyYu46X1nDgrdeMdZS1lY7uPb9+8cJHY2vdzJB3+1ic5okk/d/jy3P9OS71fMan72aDP15V5ed0r+uYhrGyv4/OVr+NtLR7npiZcn/HvSmSwtnTEqCRu3Csxdv8WnDXP0bE5prOS7V53K5gPdfO7O4UJTa80PH9rDitoAl588UJ7sdTl525lLeWDHUVo6YxNab19yiLBMJ8k63BM61oQ4/T1QfzLc/yVI9UEmDRtvNIEtQ8s5BSEXrU3p788uhQe+Cke3Fb7vxh+bc8axF+GvX8q/zZM3wH2fh6dvnMT6boCaVbDyEh63bqCNKPQEQZhbOD39YSxjOnrJNCFx9ARhCL7KgedDHT2ABSeY5M0hw9IH0T/8PE8gS9QWenlOvMEFpqwnk+dDG7aF3tgBGsGGNSx3HOMP157JZ159PM7RnJJkZOQmXVsAJvInYy4o9/H2s5YOcvXSmSwHOmLc9Vwrl33vET7/+xdYXOnjtms2cMM7Th8sJDHC8qOXHMfmA908tNMI4+2HennfTc+wuMLP3z9zIeevquNf7tzaPwJiLvDioR4e39PBe89Zgcc18lfT+85dzqVrFvDNe3awrbVnQr/rUHecVEYTyIbBn+PaLjnTOA8juAevXbuIz1y2mru2HOI79++itbuPZNo4FI/sbmdbay/XXtg07N/P289aikMpfr1x4O8jncnyp62H+K+/7BjRIQT477/s4LR/v58ncko/dSZFVhWxxdrhhNf8p0nVfeJ62PF/0HsQNlxXvDUIc49oB/zmrfCXzw3cEOgcNu89P4kwPP0TOOF15t/Z0zfCzr8M3mbP3wYEYM8EqxhaNsKh52DDteBw8MTeDpbVlNFYJXPyBGFe4PIMlG5aPXrhER29NEHml9CTMBZh8tilm54Q1K4e/vO6E8ww6sPPm9f5UjftUQn5ZuLZLl9Z7fCfBeoAbVy/oU5h5KgRoYWkAdasQmVTnBbqBUYZOJxOmjtDI30B2M27eUo3bT504Upu3XiAd/38aQBau/v657QdXx/ip+9ez6VrFgzvD8nhqvVL+MnDzXz7/p0sqynj3b94mqDXxa/++SwaKv3c+K4z+PAtm/nSXdtIpbO8/7zREx8PdsUIed1UlBXRJRrCzx/dR5nHydvPXDrqdkopvvVP63jt9x/lw7du5v8+eh7lvvGte19HFAdZPKnewSMBlm6AJ75vLvysYJ6hfPii49jbFuX6B/dw/YPGma0OeEhnsiws9/GG0xqH7bOows+rT6rnt8+0cM35Tdz9/CF+/tg+DnaZE8qh7j7+5y2nDvs7/8u2w/zwob343A6uuflZbrtmAyc3VEA2hXYU+et7xflw4uvhse9C1QrzZ/Wri7sGYe6w/0n43fvNd/Pl/w2nvRP+Y7EJvSqETb80543zPgULT4Z9j8Ifr4MPPWG+69v3wB3vhwUnQuVSOPrixNb51A/NeWLd20hnsmxs7uB16/JXFAiCMAfJCWMJec21wsiOXoaAHcYyT0o3RegJk8d29BpOM8PPh2InbzY/ZB5HSt2EkUs3XT7w5EmqDOYIxGFC70j+MtF81FqR/e27oWblyNvZAs4zktAb3dED4+p9+rLV/PmFIyytLuPKdYtZWl3G8toAZyyrGt1NtHA7HXz8klV8+o7nef31j+N2OfjVBzbQUOkHjOv3o3eewcd+8xxf+9N2trX2cOLicpbVBFhWU0ZlmZvN+7t4dHc7j+1pZ39HjAq/m//31lN55fELTHneUz80d9Ld5phPNXcQ8LhY21gx5vrGy5GeOHc/f4h3blhWkNisCnj4wdtO4y03PsXn7tzKDW8/fVRhPJR9bRHK///27js+yjJb4PjvSSeFhIRQQgKhaehVqmADRFfBLlZE0V101XXXdd3r3bWsute9u3bXFXtBvOpaWNaGoK6A9N6LgHRCKCG9PfeP804ymcykl8nkfD+ffCbzTskzyZt557zPec4hG4MtS90Et4IsS3wGehJo9mfywCQOnszjSGY+h0/lcfRUPpcPSfY5G3njyFQ+W3+IkX9eQEFxCUO7tOEPF/Vm26FT/G3eNrq1jebucWWtI3amZ3HvB+sYkBLH89cMYsrMJUx9bRkfzhgFxYXYoLBqv956M/5PMqtyZCNMfEJm+pTy5qPb5Ez69K/LKjHHJEHGj1U/tihfUjK7joXkIbLtilfhpbPg45/DlW/ITGFwCEx5Vypmbp8nRbBqsk+e+Ak2/wtG3QVhUWzce4JT+UUV2yoopZovt2IsUeHy/pDtI9DLyZfUTRscgQlpgmNsA9BAT9VdZDxgINlHbzdX5U1XoOctlTIiTnp1eU3dzJDZPG8f5Ctrmu5RJr9SCT3kMmM7MNH3/fIz5bKq1M1KZvQAbhvbndvGVhJQVsMlgzrx4nc7OXQyjzenDaNHu/JjCgsJ4vlrB/GHTzcyd+0BPlq9v8JzRIUFM6JbAjeM6MKHK/cx7Y3l3DPuNH7ZfiNB8x+BNqkcSL6QP83dxOcbDhEdHsInd4yu8LNK5RwDE1Q2y1tNbyzeTYm13FLFzKO7oanx3Hf+6fz58y28uXh3jfrU7c7IISnMWS/nnroZ1Rbiu8PeZZU+PiQ4SALiGhjeNZ4L+sqJh+ljupW2x5jQuz27M3J46uttpLaNZPLATuQUFDHjnZWEBhtevG4wSXGtePuWYVzxjx+44dWlPF9UABFN0LeuTRcY+1tY/rJWHlS+5Z6QNN9xD5dvt5PQvXozemtny4m6S18s25Z4OlzwP/Cvu+HF0XKsuHGO7JOxyVLMK+sItO5IflEx2w9n0SepdeUngJbNBAwMuxWgtDKurs9TKoC4F2OJqHyNXlZ+EVHkYsOjaYRSZ41CAz1Vd+ExcO3/+Q70XJU3M/dBaKT3tMegIKfFgo8ZPW/r86D8jJ6nrMO+x+QpMh4iE2RGrzKuIis+UzerntGrL8FBhnenD6eguMTnepKQ4CD+fFk/Hr+0L8dzCvnpWA57MrJJP5VP/+Q4BnWOIzRYZqCuG96F33+0jifnbaNb+y+5CFi3dAFT3o+ixFruPLcH7y79iV+8s5JP7xhdsQeNtfDmJAnybppb7deRlV/Eu0v3MLFvB1Lia7Yu5tYx3Vi26xiPfbaZQZ3bMCClegHmrqPZpMUVQyblUzdB0je3fSGvpwazhFUxxvDi9UO8bn/8sr7sPZbDbz9cR3KbVrz1wx62H8nirZuHkeTM0nZLjOaNaWdwzcwlWAohuInWD4y9F8b8WmfzWorju2HBo3Dxs+Vb51Qm3Wn/4jrJ55LQo3zlVm9KimHRM9BxIHQ7p/xtg6fCjvmweQ5c9BSkjpbtsSlyeXIvRVHtmfHOKhZsOcK4Xu14eHLf0kyHcvKzYOVbko4cK+nWi3dkkNYhxnchLqVU8+NWjCU8JJiw4CCfa/RyCopJMLmYAFmfB1qMRdWX084vnwLnzlV5EySV0teH5+h23mfmso96X58HpZU4KwR61koxlmoUYimV0KPqs82lqZs+ZrRca/R8VN2sb+1aR1SraIAxhvioMAamxDF5YCemj+nGsK7xpUEeQKuwYJ66eiAPT+pD1HHpKZi3Zzmjuicw756z+M2E03numkH8mJ7FfR96aW+wbzkcXg+7F0LmwWq/hg9X7CUzr4jpY7pV+zEuQUGGv101gHYxEdzx7ipO5hRW63G7M7LpGe304vPcb7uMgpwMKfTQSMJDgvnHDUPoGBvBtS8v5dM1B/jN+NMY07P8etH+yXHMvHEooaaY4KZKKzFGg7yWZNMcWP+BtM+prvTNcpl4evntCT0g91jlffE2fQLHfpSTCZ7HCmPgspkw7QsYenPZdidQsyf28sc5G1mw5QiXDExi0Y4Mxj/5HS//50eKij3aOqx7D/JPUjx8Bl9sOMhlf1/Ewh1HazxTr5Tyc27FWEBm9bLyvX9WyM4vItbkYXxlbTVDGuipxtHOWafnreKmS3Q776mbOUfLAjpP4TEQ0qri2r78U1CUW7NAr31fKRhTUEkJfNdMna+zPaWpmw0/o9cQjDFMHZXK6GgJ1IaE7uGV6weWzrSN6tGW+yam8e/1B3l14a7yD171ppw5w8oZ92ooKbG8+cMeBqbEMbhzm6of4EVcZBjPXzuIw5l5/OaDtVX21ysoktYKqZFO43PPGb2+V0hRobn3NMrMrEt8VBiv3XQGrcKCGderPbef7aQT718FH0wr7TE5ukdbTmsbTmr7mqXHKlUrriInR7ZU/zHpWyV7I9ajsFJpiryPypvWwsKnpNVB2sXe7xPaquL6WSfQ+2H1Wt5d+hMzzu7O01MGMe/XYxnVPYHHPtvMxc8v4sVvd/L2kj18sno/mYtfIyPmdM79v2x+8c4q0rPyeeji3vzKbZ2sUioAuBVjAWmx4LOPXkERrYPyyk7aBwAN9FTjKJ3RqyTwimrnPXUzO0PWTnljDEQnVpzRc12vbjEWgL6XyYzdln/7vk9VgV5IOASFNGqAUO+y0gnLOQxJgwguzpNm925+PrYb5/dpz58/38KSHzMoKbHs3HeQonX/ZEXcRNJbdSN3zT+r9aO+3XaEXUezmTY6tU5DHtS5Dfc7/fU+WlVxLaK7vcdzKLGQFO5U1vIM9EIjYPILUq7964fqNK6a6p4YzcLfncvMG4aU9YvcMhc2fgTvXS9FKoAwigkJkIXiys+5Ar30zZXfz92RzXKyxLM4V2mg5yNz4sdv4dB6GH2398JevkTEUhgSw7Ztm5k8MInfTpCZxOQ2kbx841D+cf0QTuYU8MQXW/jDJxuY+f4ntD6+kWeOjSAhKowXrxvMt/eew02ju1ZoZ6OUauZCwqXPs9OGKyo8hKx87y2NsvOLpY+epm4qVUOuFJ6qZvSyj0CJW4pNQQ4UZsv6OV+ivKR8Zrl69tUgDafzKDkDvXa27/tUlbppjLxB1Efq5sF1sGdx3Z+npg6vl8sh0+TSI2XLGMNfrxxAl4RIpr+5ggGPfMWrL/4vIcW5/DV9OO+cGkz4gWXc+MwnvLZwF0ez8vHl9UW7ad86nAv7eanEWpUDa8rNDEwblcrgznE89tlmTuQU+HzY7qPSv7BdSI4UjonwMjOWMgxGzIDlr8DuRTUfWx1Eh4eUBXkgH4pDI2HPQvj0Dvn/KC6A4KZrhaFaiOJCSHdm8mo6o+eqtuyuTRcwwZUEet9IUa5+V9ZomP/Zls7Owjj6Rmfylyv6l/v/McYwsW8HFt1/LpsfmcjyB8Yx+4ydlASFccOt9/LR7aO5oF/HalU7Vko1Q8HOSVFnnV5MeOWpm1EmL2BaK4AGeqqxtOstH6rjUnzfJ7odlBRB3omybTmuZuk+ZvRcj/OcCcyqfrP0UkFBMOBq+bDha41ZaTGWSt4EwmKqrLpZJWulB9WsK73Pcjakg+vkstfFUpFy/8oKd4mJCGXmDUMYmBLHpAFJ3Nt2CfkJvZj14O1Mnf4rgoxlVP5iHpm7iVH/s4AfdmZUeI7th0/x/faj3DCiS7m1gtVSkA1vTYYvfl+6KSjI8Ogl/TiZW8gTX2z1+dBdTqDXxmQ51V59/Oxz/xvapMKcX1aezuvL8T3w9cN1//tl7JQy8+f9UdZKffOo/J9ooKca2tHtUs0yIk5m9KpIiwak4uapA2Xp+u6CQyXY89U0ff8q6ZkXGlHpjziSmcena/bzuw/XMeYvC7jxtWWcCG3PoNZZhId4n5EzxtAqLJjEVhC7/SOCel1Ez9TKe3YqpQJAaaBXVnnTV9XNnIJiotAZPaVqLjpRFtAPnlrJfbxU0Mx2Aj1fxVhAKq4d2ympdi6nahHoAfSfIlP86z/wfrsrJdNXHz2QILCuqZt7Fkmrh4Is+M9f6vZcNXVovfxOI+Oh0xDYVzHQA+jRLoZ3pg/nsRGW+JMbCR82jeDgIOJT+0FiL37Rdj3z7hlLSptW3PXeatJPlZ/Ze33xbsJCgrhmUCKsetv3uh1v1s6WEwIeaaW9k1ozbVQqs5f9xKqfjnt96K6j2cS2CiWi8KTvAkIgfRsvflYKQ3z7ePXH5jLvD9Jc/MWRsOWzmj8eZPYuY6ekvJ35axhyE3z/N8g8IDMfSjWkwxvksvdkWSPqrbqxp6Pb5NLbjB74LnpVUiKz9EmDfT61tZYn521j2OPzufu9NXy+4SC9OrTmoYt7M7BvP4Iz9/l8bKkt/5bXMuj6qu+rlGr+XMscnIIsla3Ry8ovItLmVH4yv5nRQE81ns7DK//ncfXEcy/IkuPMBFU2ozfydpkt/Pe9ZWecsw7LWRzP9VdVadtDWjKsne397HXBKSn+ElxJZ5Kwegj0Vr4B4bEw4FpY8VrNgqC6OrQeOvST75OHSupWZa9n1Vuy2Ln/VWXb+lwCP/1Az8hsXrhuMJm5hfz6/TWUlMjv9EROAR+t2sclA5NIWPWczJo9Nxhmng2Ln5dAxpeSEljyD/n+5E8V0mR/Nf40OrSO4IGPN1SstIdU3ExtGyXV/6raP7qdJScnfnihrA9kdRzZItUK+0+RdOX3roE5d9Z8vzh1QIoKJXSXtOAL/wY9xgO27CylUg3l8AbZz3pNkuvVWafnnHz54kgcX248VLE4UkIPeT/z3J6xXd5fO1VsQQIS5D3+2Waenb+dywZ1Yu6dZ7L6jxOYeeNQWVvXtouc/Knqf2z1O9A6GbqdXfVrUUo1f8FOuxRnRk/W6HkP9PLy8wm3+VqMRakG4Zp9y3QrplE6o1fJGr02qXDOf8G2z6U0NzjN0tvXrg/agClwZJMEPJ7ys6o+0xNex9TNnGPSa2rA1TDuIXmTmv9I7Z+vJgpy5AOXK9DrNASwcGC17/uve1/O+LsHTb0vkcdtmkNah9Y8NKkP328/yt+/lTP57y3fS15hCbcObCVBVNpFMP5PMpv61QPwZG/48gHvP3PnfBmj68OnawbBER0ewoMX92bzwUzeWLy7wsN3H82ha0Kk/J5bVTKj5zLhT9C6k6SKvjIOVs+qOpVz4ZNSHfD8x+HW+XDmPTJr+eJo2P519VLgoCzAdxWxCA6BK1+H0y+UNhBKNaTDG2V9dYe+cr066/TSt1IcHMGMfx/l52+v5Na3VnDgRG7Z7QndoTAHTnmkx+9fJZedKs7olZRY/vjpRl7+fhdTR3bhr1cOoG+n2PLr6kp76VVSjOnkPti5AAZeqy1ClGopQpxAz5nRi6kkdbPKXsnNkAZ6yn+0ToKQCCk4MetKCXZOOTM7vtoruAyfAR0HwGf3OSlGh2pWiMVdn8vkLLZnUZbcE9IjrqqxxHSQIHH+I7Wb2VvzriwaHnKTVCkd9UsJYH2kUNarI5sk2OrQX667zq57WacHyN8o/yQM8UjJbZcmlVY3fgzAlDNSmDQgiSfnbWPxjqO8tXg3I7sl0HPzC7LebMKjMPou+Pl/4JcrZXbwh+clKPK05O8Q0xHO+p1cT6+4Hm9i3w6cc3oiT83bxsGTZR8y8wqLOXAyl65to2U/qSx10yUiVsZ1/uOyD3x6OzyZJoFokZeiL8d+lNTfoTdDVIIcZMY9BNOc9M1Zl0vAuO2rqgM+V4qbK9ADOQBdM1tmTZVqSIc3StuZ6PZl6/SqUHxkMztKkuicEM39F6SV9rJ7fdEuikus78qb+1diQyP54nBr1u07wak8KZZQXGK5/6N1vL1kDz8f242HJvUpX6zIxWmxUC6F39Oa2YCVQE8p1TK41rMXl6Vu5hWWUOgl46e0NZYWY1GqAYRHw+1LZC3SoQ3w/o0SLAWHVX12JThE1lPlZMC8B8tm9GojMh5Omygf1oudykyFefDedXB8t3zgr8x5D8qM1vd/g2cHwYrXS8v6VslaSdtMHgbt+8i2UXdKcDnvj9WfCaqtQ04hFteMXmQ8tOkK+3w0S171FsR3hy6jK97mpG9y6hDGGB6/rB9dEqKY9sZyDpzM445+xTLLdcYtEN+17HFte8jfMjEN/nUX5J0su+3IZjkjf8Z0mWkICi2rCujGGMPDk/pSVGKZ+PT33PbWCl5buIv5m49gLaS2jZRAr7qpvZHxMPIO+OVymDoXup8ngejcX1X8myx8SsY16s7y27uMksdf9LTsn+9eKamqlTVmz9gpFTdjalGVVKm6yM6QWbf2fSQzol3vas3oZe3dwMaiJJ64vD+/OKs7X90zlqGp8Tz8r01c8sIivjoUJXd0C/RyCoo4vGUxKwu68ItZa5j0/CL6PfQVQx/9mglPfcf7K/Zx93k9uf+CNIyvLI3SQO8n77eXlMCadyB1TPn3G6VUYPNI3YwOl6U32V5m9YIKdEZPqYYV3xXO+wPcswGu+6cETP2vrl4KZtJAWa+36k2Z5altoAcw4Bppwr5zgXxA+PjnUt7+0n9A93Mqf2xMe7j8ZZi+QIKgub+Cl8b4Dpbc7VksaYlDbirbFh4js1d7FsL2r2r/mqrj0HpZGxjnVo0ueWhZWpW7I1vgp8Uw+Ebvfx+39E2QN9fnrx2EC55BDwAAG6pJREFUBVLiWzF6z4sSxIz9bcXHhkbA5L/LB80v/6ts+5IXZdZ3yDQ5S5fQw+uMHkDnhEjeunkYE/t0YOvhUzwydxN3vCuvo1ubUEmvrU7qpjtjoOsYSZ88635YMwv+89ey20/slVmDwTd67+EYEg5Dp8Fdq2DS87KmaNZVvtckZuwoW5+nVGNyFWJxnXBql1Zl5c2V2/YQW3iEmOQ+jOgm6fYp8ZG8Me0MnpkykJO5hfx8ziHyCOWH5cvYciiTWUv3cN5f5hGXuZWjcX2ZfesIXrphCL+bmMa5aYm0jQ7noYt7c8/403wHeSBrYU2w7xm9PQvlRN3gG2vxy1BKNVuexVgiJNA75VGQpaCohIgSZ1lGABVjqaSihFJNKCgYeo6Tr5o4+78ksDixp26BXo9xsi5wzbuwY76kTk54FPpdUf3nSB4CN38h6Y1fPgCvToCz7oMx9/ou5rLydQm0+lxafvuQmyTImfegjK2h1pe4CrG4f6DqNERmNzMPSHqtyzePSXqDr+p17dJkVm7TJzD8NgD6JMUy+9YRJJxYi/n4X3DOA74L7SQPkcbJC5+SoDFpMKz7Pwn8o5w1m4mnw8G1Pl/O8G4JDHc+cO4/kcvSHzM4nJlPnzinWWpkDYv1uDv7fvng+M2jUjK+/1Ww6BnAyrgrExwKg2+Q38+r4yQ11v1365Kxo2x2VanG5GqU3t7Z/xJ7yez6qUPQuuIMc25BMa9+/AVDgDGjx5S7zRjD5IGduLh/Eot3ZpDxQQo5B7dyzdPfA3BV0lHCjxUxcfyF0L2S9diVCQ6RtbS+Ar3V78h7a6+La/f8SqnmydeMXkH5QC87v4ho4yz10GIsSvmpsEi4+Gn5vk2X2j9PSBj0vUKCtGUvwYg7KqbiVYcxksJ4+2IJEr/9M7x2vvcqmu5FWMIiy98WHArjHpQz6t/UotS/J29n5UuK5cOdZ2DRaahcuq/T27scNs+BUXdVXhG1z6UyS7n0pdLCOkM6x5G68gmpsjryjsrHefbvJRiacxcsfgaK8qSRuUtimgRbhbk+n6L0ZcS14rLBycw4uztB+U6vxppWZXVnDEx6TlLBPr0DNvxTUlkHXFN5v0h3HfpBUIj3GdPiQnlt7uvzlGoshzfK/2i0sybZ1RfPxzq9J+dtJSpT0jEjOvb2ep+gIMOZPdvSqXtfzmqbySOT+/DaTUN5YoSTIu+lEEuNxCZ7D/SKC2HzXHkvDm1Vt5+hlGpePIqxuAI9zxYL2QVFROMK9AIndVNn9FTg6X6urPWL71635xl4LSybCX0vl9m8uoiIhctmwmnnw9x74B9jYOy9cnY5oYcEDWtnlxVh8abXJEk7+v6vklrpWQAFJFhc/opT9dPI85ogyMuUaqYn98ll/im4cQ50GVn22IydUg3PM9Dr0E/WnO1bIeO1Fr5+UNYNVhWoDZ4qfas+v0+am3c/V57vp8XwsyelV11lQsIlhfPVcTJb1u0caNer7PbE0wErjZ079q/8uTx/T1Dz1M0K4wuDq9+W2doPb5bf9Zn3VP/xoRGy9slbVdPje8AWa6CnmsbhDWVpmyAzeiAp293PLXfXxTuO8urCXbyZfBKOR0gl5Mok9CBk62fcOCxZZuI+WS3/i3F1ODkHEujtXVJx+6H1UJgt7VKUUi2LZzEWV+qmxxq9nIJiokyeXAmgYiwa6KnA5B4M1FbSQLhzpXz4CKqnye++l0PKCJkBmv+wfMV1gZ7jJUXUvQiLJ2MkOMo8IMFi607lU1v3r4L3p0oxguAwZ9bOmbkLi5LeUbGdJBVz2xfSxmD6/LI0TVchFs+AKTRCyqu7ZvS2z5OG7hf+teo89tYd4Rffy+zAuvdh/YewY54E4dVdK+Oewjnyl+VvczVlTt9as0Av1wn0qlN1syqt2sB1H8Cr58NpE2RNXU0kDZKZXGvLp8x6q7ipVGMoLpIiR2dML9sWnSjp7B4zeqt/Os6tb62gW2I0I2OOQnDPqlPLE3pItd0Te+T/5cAqeV+q61rU2GTYeECyE9zHsHeZXKYMr9vzK6WaH4/UzRgfM3pZ+UXE6IyeUi1MTT+0V0dsJ7jxEzi2Syou7vha1gIW5si6r8oEh8KVb8DrF8AHU2Ha5zJDtvJ1+Px3kmo1fb4UUKnM6nck2Nz0aVmZ/kPrZeau7ekV799pCKx9T1Kgvn4I4rv5nnn0pn0fGP+wVCTdv0LWT7rOslXHuX+QVFpXPy+XhO5SgOGo94IsPuUel8u6pG66a5MKd6+tXRPzToOlgNDxXfJ7dSkN9BpgH1SqMsd2Spp0+75Ya9l1NJuubaMwib3KVd7cdCCTqa8tIyE6nFnThxPyytbq9Xd07dMZO6VoUfqW+lk7F5ssAeSpQ/I+67J3qZwYc1XmVEq1HJ6pm86MnmcvvZz84rLUTZ3RU0rVWXxXGHarfBXlS+Pv9n2rflx4DFz7gfRim3UlpJ4JGz6Ukv+XvVxWqKQyA66Bxc9L+4q0n0nQdWi9rMMJ8RKsdBoqKaEL/gRHNsIVr9csUHMJCoKUYbV4XHDFIA/kDTy+m9cWC5Wqr9RNd6ERtXtckrMuaf+qioFeq/j6mXVUqibcKm6+9cMeHpyzkQHJsTwX25mUQ3Mx1rIjPZsbXl1KVHgIs6YPp31YAWTuc9Kpq+DeSy88Wnp3JtVxfR6UVQs+uc8j0FtWu/cdpVTz5zoB68zoRflor5CVX0SUyaUkpBVBvgrmNUNajEUpfxASXrHaZWVad5R0wcIcKQJy9u/lenWCPJDAadxDcuZ+1Zuy7dD6skbpnlyN0xc9I6mGvf2oWXfi6T5bLPiUe0ze/KtaI9gY2vWSlhGe6/QydmjapmoahzdCUAjZrbvz3ILtnN4+huM5hczcEo7Jz+Sj75Zx/StLMQZmTR9OSnyknKiC6qXNRybIuuVjO8tSwutaiAXceuntLdt2cp8EoCkj6v78SqnmpzTQkxm9qDDv7RVyCiR1syQscNI2QWf0lGq+2veGm7+UYK+qVE1vTjtfGp1/+4QUOck+4ruUf0IPKU2efxLGPVx/axbrQ2IabP1c0jK8zUZ6k3NMZsv8oT9dcKj83isEejuh29lNMSLV0h3eCG1P441lBzmaVcDMG4fSv1MsixecgEWv88lX88kNH8p7t42gW6KT4uSaVXetm62MMfKekrFD/hdjUyC6Xd3H3dqZxXOvvFm6Pk9n9JRqkTz66AUHGaLCgiukbmbnF9Ha5AVUDz3QGT2lmrf2vWsX5IF82Br/iAR4n9wu23wFekFBkuLZe7L/Va5LTJPqlMe8tKzwJfd4/a3Pqw9Jg+HAGikiAZCfBacO6Po81TQOb6SgbS9e+m4n43q1Y3DnNoQEBzF21FgA/jDM8M8ZI+nV0a3XVPoWKXpQVcVNl4QecjLjwCrJEqgPEa1lptB9Rm/vMghppf0olWqpPIqxgKzTq9heQdboBQVQDz3QQE+pli15qLRtcJUkr+zD0KUvwlVvNc64asK1Jqgm6/Ryj/vX2rekQVL+3ZX+duxHudRATzW23ONwci9LsjqQmVfEr8e7rbmLSoCoRHqaffRo55HedGQLtD2t6oqbLgk9JCA7vrt+0jZdYlM8ZvSWSup5bdYUK6WaP49iLCC99LzN6MWYXEyEzugppQLJeQ9K5cq4LnI2vLlp2xMwNVunl3PMv2b0XB90XembrtlJXaOnGtvhTQDM2h3DRf070jvJ4+x2Ylq5ypul0rdWrxCLi3vhIdca4PrgHugV5EjbGE3bVKrlCgqWzzjuM3peA71iYkweRmf0lFIBpW0POP8xGHVnU4+kdkJbSbpYTWf0/CnQS+gp5Zz3r5LrrtYK7h+GlWoMhzcCsLYwhXvGn1bx9na9JKiztmxbfpb072xXjfV5LqUnMQx0HFj78XqKTS5L3TywStotdNZCLEq1aMFhpcVYwEndrNAwXWb0AqmHHmgxFqUUwIgZTT2CuklMq/6MnrVSddOfUjeDguTD7gFXoLdTCkv4Q1VQ1aJk711LgY1h7OC+dE/0ksKUmAYFp2TWLC5Ftrn6WFanEIuLKy25bU9ZW1dfYpMh7yTkZUraJkDyGfX3/Eqp5ickDI7vgd2LABhUspUt2eFAWd9Paa+QF1A99EADPaVUIEg8XRrPFxdBVf1vCrLlzF599tCrD50GwdKZso4gY4euz1NNIuPHVey3Kdw1zstsHpS1T0jfIpUyV78NC58GE+S7PYs34THQpmv1GqzXRGmLhX1SiKXtaf51Ukcp1fhaxcPmOfIF3AsUEQSZ50DrJAByCoqJsjk6o6eUUn4nMQ1KCuH4LmfNXiVyj8ulP6VughRkKc6HI5sk0OtzaVOPSLUwRcUlrDT9CO2czMg2kd7v5Jq1++EFmHOXVIdNPgMmPQttutTsB978Rf3PWsc6s4wn98qMXtrP6vf5lVLNz9Q5cGxX6dVPvlvKJXseg13fw4CrAcjNyyWMwoBrr9CggZ4xZiLwDBAMvGKt/R+P238NTAeKgHTgZmvtnoYck1IqALlX3qwy0Dsml/52lj/JKciyc74Eo1qIRTWykOAgLrn3JfKLSnzfKTIeYjrCj99IH85L/i79HmvTkzKmQ22H6psrnfTHb+X/KGV4/f8MpVTzEtdZvhzbtyVyYvfTxO7+HuMEeuSfkssAK8bSYIGeMSYYeAEYD+wDlhtj5lhrN7ndbTUw1FqbY4yZAfwFuLqhxqSUClBtnTSz9C3Q6+LK75vjBHr+lrrZJlVmGdd9INc10FNNwBhDRGgVLRKueluKnHQZ2TiDqono9hAUAhs+kusa6CmlPERHhLOsJI2zdvyHvNxCYluFSlEp0NTNGhgG7LDW/ghgjHkPmAyUBnrW2m/c7r8EuL4Bx6OUClTh0RDbuXoFWfw1ddMYSd/cuUCua6Cn/FWKHxc3CQqWNTcnfpL/8YQqZviVUi1OUlwES0p6M+HU25z98GyyI9qTXHgMQgm4YiwN2V6hE7DX7fo+Z5svtwCfe7vBGHObMWaFMWZFenp6PQ5RKRUwEk+rXosFf03dhLL0TRNcLs1EKVUDrnV6ycOkoq1SSrmZNCCJ666+DoDHB5/kkkGdGNvZaaweYDN6fvEOaIy5HhgK/K+32621M621Q621QxMTExt3cEqp5iExDY5uh5Liyu+X45rR88NAz9U4vU0qBIc26VCUarZclTe1UbpSygtjDN37DoeIOM4J38ojk/ty/znO+4YGetW2H0hxu57sbCvHGDMOeACYZK3N97xdKaWqJTENivLguyegqJK3ktxjkpoREtZ4Y6uupEFyqWmbStWea0ZP1+cppXwJCpKCUru/l+sFrmIsGuhV13KgpzGmqzEmDJgCzHG/gzFmEPASEuQdacCxKKUCXd/LofdkCfT+PrJsrZun3OP+tz7PpXWSBHtdxzT1SJRqvrqOkTToTkOaeiRKKX+WeiYc3w0n9rpV3dRAr1qstUXAL4Evgc3A+9bajcaYR4wxk5y7/S8QDXxgjFljjJnj4+mUUqpyYZFw1Vtw/T8BC29fCu9PhVOHyt8v55j/BnoAt30Lo+5s6lEo1Xx1Oxtu+0beE5RSyhfXSdU9i8qqbgZYMZYG7aNnrf0M+Mxj2x/dvh/XkD9fKdUC9RgHM36Axc/C93+Txsm3fF1WlCH3mH8WYlEBqRr9ZJ8CznGuRgLtrLVxzm1Tgf92bnvUWvtm44xaKaVagHZ9ICJO0jdbO2v0AizQ84tiLEopVa9CI+Cs++Cip2D/Stj4Udlt/py6qQKKWz/ZC4DewDXGmN7u97HW3mOtHWitHQg8B3zkPDYeeBAYjrQretAYozuuUkrVl6AgSd/cvVBSN8OiA65Sb2C9GqWUctd/CnQcAF8/BIW5si3nmH9W3FSBqLSfrLW2AHD1k/XlGmC28/35wDxr7TFr7XFgHjCxQUerlFItjWudXvrmgFufBxroKaUCWVAQTHhM0jeX/B1KSiDvhKZuqsZS7X6yxpguQFfAVUWoJo/VXrNKKVUbqWfK5e6FGugppVSz03UMpF0E3z8JGTvAlmjqpvJHU4APrbVVNIKsSHvNKqVULbnW6RUXBNz6PNBATynVEox/RHrsffYbua6pm6pxVKufrGMKZWmbNX2sUkqp2nCt0wOd0VNKqWYpoTsMuw12/Ueua+qmahxV9pMFMMakAW2AH9w2fwlMMMa0cYqwTHC2KaWUqk8a6CmlVDM39reSngGauqkaRTX7yYIEgO9Za63bY48Bf0KCxeXAI842pZRS9SmAA70G7aOnlFJ+IzIezv1v+Pw+iE1u6tGoFqKqfrLO9Yd8PPY14LUGG5xSSilZp9c6GWJTqr5vM6OBnlKq5Rh2K/SaBDHtm3okSimllPIHQUEwYyGERjX1SOqdBnpKqZZFgzyllFJKuQvQJR26Rk8ppZRSSimlAowGekoppZRSSikVYDTQU0oppZRSSqkAo4GeUkoppZRSSgUYDfSUUkoppZRSKsBooKeUUkoppZRSAUYDPaWUUkoppZQKMBroKaWUUkoppVSA0UBPKaWUUkoppQKMBnpKKaWUUkopFWCMtbapx1Ajxph0YE8dn6YtcLQehtOYdMyNQ8fcOHTMjSMQxtzFWpvYVINpbvQY2azomBuHjrnhNbfxQmCMucrjY7ML9OqDMWaFtXZoU4+jJnTMjUPH3Dh0zI1Dx6xqozn+DXTMjUPH3Dia25ib23ih5YxZUzeVUkoppZRSKsBooKeUUkoppZRSAaalBnozm3oAtaBjbhw65sahY24cOmZVG83xb6Bjbhw65sbR3Mbc3MYLLWTMLXKNnlJKKaWUUkoFspY6o6eUUkoppZRSAavFBXrGmInGmK3GmB3GmPubejzeGGNeM8YcMcZscNsWb4yZZ4zZ7ly2acoxejLGpBhjvjHGbDLGbDTG3O1s99txG2MijDHLjDFrnTE/7GzvaoxZ6uwj/2eMCWvqsbozxgQbY1YbY+Y61/19vLuNMeuNMWuMMSucbX67XwAYY+KMMR8aY7YYYzYbY0b685iNMac7v1/XV6Yx5lf+PGYAY8w9zv/eBmPMbOd/0q/350DWHI6P0PyOkXp8bFx6jGx4eoxsHPVxjGxRgZ4xJhh4AbgA6A1cY4zp3bSj8uoNYKLHtvuB+dbansB857o/KQJ+Y63tDYwA7nB+t/487nzgXGvtAGAgMNEYMwJ4AnjKWtsDOA7c0oRj9OZuYLPbdX8fL8A51tqBbmWB/Xm/AHgG+MJamwYMQH7ffjtma+1W5/c7EBgC5AAf48djNsZ0Au4Chlpr+wLBwBSax/4ccJrR8RGa3zFSj4+NS4+RDU+PkQ2s3o6R1toW8wWMBL50u/574PdNPS4fY00FNrhd3wp0dL7vCGxt6jFWMf5PgfHNZdxAJLAKGI40owzxts809ReQjLwZnQvMBYw/j9cZ026grcc2v90vgFhgF84a5uYwZo9xTgAW+fuYgU7AXiAeCHH25/P9fX8O1K/mdHx0xtdsj5F6fGzQseoxsuHHq8fIxhlnvRwjW9SMHmW/NJd9zrbmoL219qDz/SGgfVMOpjLGmFRgELAUPx+3k+KxBjgCzAN2AiestUXOXfxtH3kauA8oca4n4N/jBbDAV8aYlcaY25xt/rxfdAXSgded9J9XjDFR+PeY3U0BZjvf++2YrbX7gb8CPwEHgZPASvx/fw5Uzfn4CH68r7vT42OD02Nkw9NjZCOor2NkSwv0AoKVMN4vy6UaY6KBfwK/stZmut/mj+O21hZbmcpPBoYBaU08JJ+MMRcBR6y1K5t6LDV0prV2MJISdocxZqz7jX64X4QAg4EXrbWDgGw80jn8cMwAOLn6k4APPG/ztzE7ayEmIx8akoAoKqbjKVVj/ravu+jxsWHpMbLR6DGyEdTXMbKlBXr7gRS368nOtubgsDGmI4BzeaSJx1OBMSYUOYjNstZ+5Gz2+3EDWGtPAN8g0+BxxpgQ5yZ/2kdGA5OMMbuB95DUlGfw3/ECpWelsNYeQXLih+Hf+8U+YJ+1dqlz/UPkoObPY3a5AFhlrT3sXPfnMY8Ddllr0621hcBHyD7u1/tzAGvOx0fw731dj4+NQ4+RjUOPkY2jXo6RLS3QWw70dCrWhCHTt3OaeEzVNQeY6nw/Fcnx9xvGGAO8Cmy21j7pdpPfjtsYk2iMiXO+b4WsmdiMHNCucO7mN2O21v7eWptsrU1F9t0F1trr8NPxAhhjoowxMa7vkdz4DfjxfmGtPQTsNcac7mw6D9iEH4/ZzTWUpaSAf4/5J2CEMSbSef9w/Z79dn8OcM35+Ah+vK/r8bFx6DGycegxstHUzzGyqRcbNvYXcCGwDck1f6Cpx+NjjLORfNxC5MzJLUie+XxgO/A1EN/U4/QY85nIlPc6YI3zdaE/jxvoD6x2xrwB+KOzvRuwDNiBTO+HN/VYvYz9bGCuv4/XGdta52uj63/On/cLZ3wDgRXOvvEJ0KYZjDkKyABi3bb5+5gfBrY4/39vA+H+vD8H+ldzOD4642xWx0g9PjbJ+PUY2bDj1mNk44y5zsdI4zyRUkoppZRSSqkA0dJSN5VSSimllFIq4Gmgp5RSSimllFIBRgM9pZRSSimllAowGugppZRSSimlVIDRQE8ppZRSSimlAowGeko1MGNMsTFmjdvX/fX43KnGmA319XxKKaVUY9JjpFINJ6Tquyil6ijXWjuwqQehlFJK+SE9RirVQHRGT6kmYozZbYz5izFmvTFmmTGmh7M91RizwBizzhgz3xjT2dne3hjzsTFmrfM1ynmqYGPMy8aYjcaYr4wxrZz732WM2eQ8z3tN9DKVUkqpGtNjpFJ1p4GeUg2vlUdaytVut5201vYDngeedrY9B7xpre0PzAKedbY/C3xnrR0ADAY2Ott7Ai9Ya/sAJ4DLne33A4Oc5/lFQ704pZRSqg70GKlUAzHW2qYeg1IBzRiTZa2N9rJ9N3CutfZHY0wocMham2CMOQp0tNYWOtsPWmvbGmPSgWRrbb7bc6QC86y1PZ3rvwNCrbWPGmO+ALKAT4BPrLVZDfxSlVJKqRrRY6RSDUdn9JRqWtbH9zWR7/Z9MWVrb38GvICc2VxujNE1uUoppZoTPUYqVQca6CnVtK52u/zB+X4xMMX5/jrge+f7+cAMAGNMsDEm1teTGmOCgBRr7TfA74BYoMIZU6WUUsqP6TFSqTrQsxdKNbxWxpg1bte/sNa6yke3McasQ844XuNsuxN43RjzWyAdmOZsvxuYaYy5BTkrOQM46ONnBgPvOAc6AzxrrT1Rb69IKaWUqh96jFSqgegaPaWaiLP+YKi19mhTj0UppZTyJ3qMVKruNHVTKaWUUkoppQKMzugppZRSSimlVIDRGT2llFJKKaWUCjAa6CmllFJKKaVUgNFATymllFJKKaUCjAZ6SimllFJKKRVgNNBTSimllFJKqQCjgZ5SSimllFJKBZj/B/huUtKPj+EAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def display_learning_curves(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    ax1.plot(history.history[\"loss\"])\n",
    "    ax1.plot(history.history[\"val_loss\"])\n",
    "    ax1.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "    ax2.plot(history.history[\"accuracy\"])\n",
    "    ax2.plot(history.history[\"val_accuracy\"])\n",
    "    ax2.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "display_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzJ3rz1JZlM7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "L0VKJswYTc4O"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "temp=tf.keras.models.load_model(\"./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_strat_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9bgdUJETn0g",
    "outputId": "e56b1df7-ab36-4c9e-bb45-8e04c945378a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2798/2798 [==============================] - 16s 5ms/step - loss: 0.1749 - accuracy: 0.9364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17485842108726501, 0.9363831281661987]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.evaluate([X_test_scaled,X_test_scaled_f], y_test[:,0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbTiJwqAZhcj",
    "outputId": "6071b479-c2bc-4f66-922f-bfd75e3b0680"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 2s 7ms/step - loss: 0.1749 - accuracy: 0.9364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17485809326171875, 0.9363831281661987]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.evaluate([X_test_scaled,X_test_scaled_f], y_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "RD4YF1AuT2tn"
   },
   "outputs": [],
   "source": [
    "y_pred = temp.predict([X_test_scaled,X_test_scaled_f])\n",
    "y_pred= (y_pred>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjx-DjHUWp52",
    "outputId": "fbe3b9c0-1f9d-44be-b90c-f7fde54d20f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "ipevqB9rXDeW"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rSeo2ltUXffg",
    "outputId": "ec1d4b76-c107-41c8-a485-72b8307644a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1931,   63],\n",
       "       [ 115,  689]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eM1TBa2IXtj2",
    "outputId": "2fd78132-a789-445d-ec6e-8e5d6a2360c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9363831308077198"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9V2DcARYNq6",
    "outputId": "ed69a273-729a-466b-a02a-d9f75d8253e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8856041131105399"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwAjeUnMYQ1O",
    "outputId": "30b3109e-b1e1-476f-f46d-f6a224ba45c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96      1994\n",
      "           1       0.92      0.86      0.89       804\n",
      "\n",
      "    accuracy                           0.94      2798\n",
      "   macro avg       0.93      0.91      0.92      2798\n",
      "weighted avg       0.94      0.94      0.94      2798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test[:,0],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "cec7ba07af6041609cc62a20e1a21909",
      "6fccd6ca93114ae482cc12c6bc8427e6",
      "35f2a4db4d974ea39230bb12543b0b1c",
      "93a328fbdc954390b26f6dd0386bc1a1",
      "81cacd2f5c56425c8619138a24f6cb5e",
      "c3950c775a6e4a52acf6753c64e4e54d",
      "fed147ef48db480c9d3f35d0e77323c1",
      "39a01d56f9594c539ee84a08b265300e",
      "0cfb27c8ba5f4ddcb12d1bcefa9fed26",
      "26e310b233ba45e7941c14a34a69fcbe",
      "1b321eb832624af9b61a7c36958f353f"
     ]
    },
    "id": "2ZeRsStHjxkG",
    "outputId": "9ef0673c-972d-4132-98ff-360adc154457"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.020505428314208984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec7ba07af6041609cc62a20e1a21909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "333/333 [==============================] - 10s 16ms/step - loss: 0.5729 - accuracy: 0.7094 - val_loss: 0.5369 - val_accuracy: 0.7127\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5184 - accuracy: 0.7136 - val_loss: 0.5062 - val_accuracy: 0.7177\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5136 - accuracy: 0.7216 - val_loss: 0.5043 - val_accuracy: 0.7437\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5117 - accuracy: 0.7253 - val_loss: 0.5009 - val_accuracy: 0.7395\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5068 - accuracy: 0.7247 - val_loss: 0.4921 - val_accuracy: 0.7405\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4995 - accuracy: 0.7314 - val_loss: 0.4835 - val_accuracy: 0.7391\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4972 - accuracy: 0.7329 - val_loss: 0.5143 - val_accuracy: 0.7309\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4938 - accuracy: 0.7345 - val_loss: 0.4824 - val_accuracy: 0.7473\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4977 - accuracy: 0.7289 - val_loss: 0.4827 - val_accuracy: 0.7341\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4968 - accuracy: 0.7317 - val_loss: 0.4812 - val_accuracy: 0.7341\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4919 - accuracy: 0.7361 - val_loss: 0.4821 - val_accuracy: 0.7380\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4946 - accuracy: 0.7360 - val_loss: 0.4849 - val_accuracy: 0.7320\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4947 - accuracy: 0.7306 - val_loss: 0.4930 - val_accuracy: 0.7373\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4920 - accuracy: 0.7352 - val_loss: 0.4819 - val_accuracy: 0.7420\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4912 - accuracy: 0.7338 - val_loss: 0.4895 - val_accuracy: 0.7294\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4914 - accuracy: 0.7358 - val_loss: 0.4825 - val_accuracy: 0.7345\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4885 - accuracy: 0.7357 - val_loss: 0.4904 - val_accuracy: 0.7266\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4661 - accuracy: 0.7440 - val_loss: 0.3884 - val_accuracy: 0.7909\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.3906 - accuracy: 0.7892 - val_loss: 0.3186 - val_accuracy: 0.8503\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.3323 - accuracy: 0.8387 - val_loss: 0.2680 - val_accuracy: 0.8674\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.3371 - accuracy: 0.8346 - val_loss: 0.2924 - val_accuracy: 0.8663\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2921 - accuracy: 0.8603 - val_loss: 0.2570 - val_accuracy: 0.8828\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2880 - accuracy: 0.8624 - val_loss: 0.2783 - val_accuracy: 0.8703\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2963 - accuracy: 0.8576 - val_loss: 0.2476 - val_accuracy: 0.8781\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2786 - accuracy: 0.8655 - val_loss: 0.2516 - val_accuracy: 0.8756\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2879 - accuracy: 0.8640 - val_loss: 0.2567 - val_accuracy: 0.8756\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2666 - accuracy: 0.8717 - val_loss: 0.2497 - val_accuracy: 0.8806\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2718 - accuracy: 0.8713 - val_loss: 0.2593 - val_accuracy: 0.8778\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2756 - accuracy: 0.8670 - val_loss: 0.3067 - val_accuracy: 0.8556\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2730 - accuracy: 0.8715 - val_loss: 0.2442 - val_accuracy: 0.8785\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2757 - accuracy: 0.8677 - val_loss: 0.2758 - val_accuracy: 0.8767\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2776 - accuracy: 0.8664 - val_loss: 0.2618 - val_accuracy: 0.8813\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2635 - accuracy: 0.8722 - val_loss: 0.2357 - val_accuracy: 0.8853\n",
      "Epoch 34/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2632 - accuracy: 0.8731 - val_loss: 0.4602 - val_accuracy: 0.8095\n",
      "Epoch 35/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2719 - accuracy: 0.8690 - val_loss: 0.2364 - val_accuracy: 0.8792\n",
      "Epoch 36/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2658 - accuracy: 0.8720 - val_loss: 0.2528 - val_accuracy: 0.8846\n",
      "Epoch 37/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2752 - accuracy: 0.8653 - val_loss: 0.2418 - val_accuracy: 0.8788\n",
      "Epoch 38/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2672 - accuracy: 0.8676 - val_loss: 0.2530 - val_accuracy: 0.8731\n",
      "Epoch 39/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2681 - accuracy: 0.8674 - val_loss: 0.2560 - val_accuracy: 0.8763\n",
      "Epoch 40/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2789 - accuracy: 0.8629 - val_loss: 0.2377 - val_accuracy: 0.8774\n",
      "Epoch 41/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2702 - accuracy: 0.8687 - val_loss: 0.2392 - val_accuracy: 0.8771\n",
      "Epoch 42/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2656 - accuracy: 0.8687 - val_loss: 0.2408 - val_accuracy: 0.8738\n",
      "Epoch 43/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2653 - accuracy: 0.8699 - val_loss: 0.2396 - val_accuracy: 0.8835\n",
      "Epoch 44/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2656 - accuracy: 0.8685 - val_loss: 0.2891 - val_accuracy: 0.8670\n",
      "Epoch 45/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2670 - accuracy: 0.8684 - val_loss: 0.2410 - val_accuracy: 0.8749\n",
      "Epoch 46/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2703 - accuracy: 0.8676 - val_loss: 0.2307 - val_accuracy: 0.8803\n",
      "Epoch 47/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2699 - accuracy: 0.8691 - val_loss: 0.2828 - val_accuracy: 0.8495\n",
      "Epoch 48/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2709 - accuracy: 0.8706 - val_loss: 0.2538 - val_accuracy: 0.8788\n",
      "Epoch 49/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2619 - accuracy: 0.8712 - val_loss: 0.2587 - val_accuracy: 0.8828\n",
      "Epoch 50/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2706 - accuracy: 0.8673 - val_loss: 0.2336 - val_accuracy: 0.8849\n",
      "Epoch 51/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2681 - accuracy: 0.8665 - val_loss: 0.2602 - val_accuracy: 0.8695\n",
      "Epoch 52/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2630 - accuracy: 0.8727 - val_loss: 0.2323 - val_accuracy: 0.8849\n",
      "Epoch 53/500\n",
      "330/333 [============================>.] - ETA: 0s - loss: 0.2598 - accuracy: 0.8743Restoring model weights from the end of the best epoch: 33.\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2594 - accuracy: 0.8745 - val_loss: 0.2378 - val_accuracy: 0.8799\n",
      "Epoch 53: early stopping\n",
      "Number of iterations 1\n",
      "F1-scores:  [0.794888178913738]\n",
      "Average F1-Score 0.794888178913738\n",
      "Std Dev F1-Score 0.0\n",
      "Error bar F1-Score 0.0\n",
      "Epoch 1/500\n",
      "333/333 [==============================] - 11s 16ms/step - loss: 0.5577 - accuracy: 0.7120 - val_loss: 0.5145 - val_accuracy: 0.7134\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5184 - accuracy: 0.7189 - val_loss: 0.5321 - val_accuracy: 0.7127\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5088 - accuracy: 0.7248 - val_loss: 0.4965 - val_accuracy: 0.6905\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4584 - accuracy: 0.7582 - val_loss: 0.4487 - val_accuracy: 0.7670\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.3559 - accuracy: 0.8329 - val_loss: 0.3415 - val_accuracy: 0.8495\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.3079 - accuracy: 0.8592 - val_loss: 0.2421 - val_accuracy: 0.8914\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2867 - accuracy: 0.8714 - val_loss: 0.2348 - val_accuracy: 0.9035\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2734 - accuracy: 0.8769 - val_loss: 0.2356 - val_accuracy: 0.8903\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2477 - accuracy: 0.8861 - val_loss: 0.2213 - val_accuracy: 0.9064\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2382 - accuracy: 0.8931 - val_loss: 0.2066 - val_accuracy: 0.9060\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2232 - accuracy: 0.9008 - val_loss: 0.3474 - val_accuracy: 0.8488\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2357 - accuracy: 0.8952 - val_loss: 0.2090 - val_accuracy: 0.9021\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2122 - accuracy: 0.9063 - val_loss: 0.1966 - val_accuracy: 0.9053\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2093 - accuracy: 0.9074 - val_loss: 0.1646 - val_accuracy: 0.9307\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2240 - accuracy: 0.8988 - val_loss: 0.2385 - val_accuracy: 0.8803\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2031 - accuracy: 0.9106 - val_loss: 0.1750 - val_accuracy: 0.9210\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1910 - accuracy: 0.9164 - val_loss: 0.1640 - val_accuracy: 0.9249\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2050 - accuracy: 0.9092 - val_loss: 0.1613 - val_accuracy: 0.9325\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1967 - accuracy: 0.9146 - val_loss: 0.1847 - val_accuracy: 0.9174\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2056 - accuracy: 0.9066 - val_loss: 0.2311 - val_accuracy: 0.9031\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1903 - accuracy: 0.9155 - val_loss: 0.1573 - val_accuracy: 0.9314\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1955 - accuracy: 0.9147 - val_loss: 0.1652 - val_accuracy: 0.9285\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1863 - accuracy: 0.9196 - val_loss: 0.1478 - val_accuracy: 0.9367\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1874 - accuracy: 0.9179 - val_loss: 0.1693 - val_accuracy: 0.9325\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1832 - accuracy: 0.9200 - val_loss: 0.1521 - val_accuracy: 0.9375\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1812 - accuracy: 0.9203 - val_loss: 0.1767 - val_accuracy: 0.9214\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1836 - accuracy: 0.9210 - val_loss: 0.1759 - val_accuracy: 0.9278\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1759 - accuracy: 0.9246 - val_loss: 0.1518 - val_accuracy: 0.9335\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1756 - accuracy: 0.9234 - val_loss: 0.1534 - val_accuracy: 0.9353\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1908 - accuracy: 0.9154 - val_loss: 0.1601 - val_accuracy: 0.9321\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1846 - accuracy: 0.9182 - val_loss: 0.2030 - val_accuracy: 0.9153\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1785 - accuracy: 0.9226 - val_loss: 0.1724 - val_accuracy: 0.9174\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1721 - accuracy: 0.9253 - val_loss: 0.1396 - val_accuracy: 0.9364\n",
      "Epoch 34/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1758 - accuracy: 0.9232 - val_loss: 0.1593 - val_accuracy: 0.9296\n",
      "Epoch 35/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1733 - accuracy: 0.9248 - val_loss: 0.1388 - val_accuracy: 0.9396\n",
      "Epoch 36/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1601 - accuracy: 0.9310 - val_loss: 0.1456 - val_accuracy: 0.9403\n",
      "Epoch 37/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1553 - accuracy: 0.9348 - val_loss: 0.1285 - val_accuracy: 0.9492\n",
      "Epoch 38/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1631 - accuracy: 0.9281 - val_loss: 0.1452 - val_accuracy: 0.9432\n",
      "Epoch 39/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1635 - accuracy: 0.9310 - val_loss: 0.1763 - val_accuracy: 0.9217\n",
      "Epoch 40/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1600 - accuracy: 0.9311 - val_loss: 0.1495 - val_accuracy: 0.9335\n",
      "Epoch 41/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1512 - accuracy: 0.9349 - val_loss: 0.1353 - val_accuracy: 0.9471\n",
      "Epoch 42/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1472 - accuracy: 0.9372 - val_loss: 0.1432 - val_accuracy: 0.9335\n",
      "Epoch 43/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1484 - accuracy: 0.9363 - val_loss: 0.1447 - val_accuracy: 0.9385\n",
      "Epoch 44/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1446 - accuracy: 0.9395 - val_loss: 0.1164 - val_accuracy: 0.9560\n",
      "Epoch 45/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1444 - accuracy: 0.9395 - val_loss: 0.1206 - val_accuracy: 0.9492\n",
      "Epoch 46/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1456 - accuracy: 0.9389 - val_loss: 0.1446 - val_accuracy: 0.9392\n",
      "Epoch 47/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1471 - accuracy: 0.9397 - val_loss: 0.1181 - val_accuracy: 0.9535\n",
      "Epoch 48/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1377 - accuracy: 0.9423 - val_loss: 0.1212 - val_accuracy: 0.9550\n",
      "Epoch 49/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1329 - accuracy: 0.9451 - val_loss: 0.1051 - val_accuracy: 0.9593\n",
      "Epoch 50/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1260 - accuracy: 0.9489 - val_loss: 0.1151 - val_accuracy: 0.9571\n",
      "Epoch 51/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1622 - accuracy: 0.9322 - val_loss: 0.2855 - val_accuracy: 0.8863\n",
      "Epoch 52/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1392 - accuracy: 0.9440 - val_loss: 0.1068 - val_accuracy: 0.9600\n",
      "Epoch 53/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1301 - accuracy: 0.9478 - val_loss: 0.2327 - val_accuracy: 0.8989\n",
      "Epoch 54/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1324 - accuracy: 0.9453 - val_loss: 0.1852 - val_accuracy: 0.9249\n",
      "Epoch 55/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1221 - accuracy: 0.9504 - val_loss: 0.1135 - val_accuracy: 0.9589\n",
      "Epoch 56/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1329 - accuracy: 0.9460 - val_loss: 0.1025 - val_accuracy: 0.9596\n",
      "Epoch 57/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1209 - accuracy: 0.9512 - val_loss: 0.1163 - val_accuracy: 0.9532\n",
      "Epoch 58/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1232 - accuracy: 0.9498 - val_loss: 0.0975 - val_accuracy: 0.9628\n",
      "Epoch 59/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1368 - accuracy: 0.9435 - val_loss: 0.0966 - val_accuracy: 0.9632\n",
      "Epoch 60/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1261 - accuracy: 0.9483 - val_loss: 0.1495 - val_accuracy: 0.9410\n",
      "Epoch 61/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1199 - accuracy: 0.9522 - val_loss: 0.2481 - val_accuracy: 0.9139\n",
      "Epoch 62/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2695 - accuracy: 0.8756 - val_loss: 0.1704 - val_accuracy: 0.9292\n",
      "Epoch 63/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1895 - accuracy: 0.9175 - val_loss: 0.1550 - val_accuracy: 0.9314\n",
      "Epoch 64/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1668 - accuracy: 0.9299 - val_loss: 0.1417 - val_accuracy: 0.9460\n",
      "Epoch 65/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1605 - accuracy: 0.9316 - val_loss: 0.1261 - val_accuracy: 0.9550\n",
      "Epoch 66/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1416 - accuracy: 0.9421 - val_loss: 0.1621 - val_accuracy: 0.9410\n",
      "Epoch 67/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1505 - accuracy: 0.9391 - val_loss: 0.1409 - val_accuracy: 0.9442\n",
      "Epoch 68/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1363 - accuracy: 0.9443 - val_loss: 0.1221 - val_accuracy: 0.9535\n",
      "Epoch 69/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1306 - accuracy: 0.9473 - val_loss: 0.1472 - val_accuracy: 0.9439\n",
      "Epoch 70/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1252 - accuracy: 0.9504 - val_loss: 0.1147 - val_accuracy: 0.9532\n",
      "Epoch 71/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1212 - accuracy: 0.9511 - val_loss: 0.1220 - val_accuracy: 0.9543\n",
      "Epoch 72/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1182 - accuracy: 0.9529 - val_loss: 0.0980 - val_accuracy: 0.9618\n",
      "Epoch 73/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1169 - accuracy: 0.9558 - val_loss: 0.0940 - val_accuracy: 0.9657\n",
      "Epoch 74/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1093 - accuracy: 0.9583 - val_loss: 0.0959 - val_accuracy: 0.9632\n",
      "Epoch 75/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1436 - accuracy: 0.9410 - val_loss: 0.1952 - val_accuracy: 0.9199\n",
      "Epoch 76/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1339 - accuracy: 0.9468 - val_loss: 0.1288 - val_accuracy: 0.9475\n",
      "Epoch 77/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1018 - accuracy: 0.9616 - val_loss: 0.0841 - val_accuracy: 0.9664\n",
      "Epoch 78/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1071 - accuracy: 0.9581 - val_loss: 0.1403 - val_accuracy: 0.9442\n",
      "Epoch 79/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1012 - accuracy: 0.9612 - val_loss: 0.1040 - val_accuracy: 0.9614\n",
      "Epoch 80/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0983 - accuracy: 0.9634 - val_loss: 0.1219 - val_accuracy: 0.9535\n",
      "Epoch 81/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0889 - accuracy: 0.9666 - val_loss: 0.1294 - val_accuracy: 0.9557\n",
      "Epoch 82/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1167 - accuracy: 0.9557 - val_loss: 0.1788 - val_accuracy: 0.9189\n",
      "Epoch 83/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1021 - accuracy: 0.9605 - val_loss: 0.1329 - val_accuracy: 0.9417\n",
      "Epoch 84/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1141 - accuracy: 0.9555 - val_loss: 0.1015 - val_accuracy: 0.9621\n",
      "Epoch 85/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0957 - accuracy: 0.9646 - val_loss: 0.2176 - val_accuracy: 0.9114\n",
      "Epoch 86/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0921 - accuracy: 0.9648 - val_loss: 0.0744 - val_accuracy: 0.9721\n",
      "Epoch 87/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0839 - accuracy: 0.9689 - val_loss: 0.0770 - val_accuracy: 0.9746\n",
      "Epoch 88/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0998 - accuracy: 0.9634 - val_loss: 0.1272 - val_accuracy: 0.9500\n",
      "Epoch 89/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0741 - accuracy: 0.9731 - val_loss: 0.1056 - val_accuracy: 0.9560\n",
      "Epoch 90/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0771 - accuracy: 0.9720 - val_loss: 0.0863 - val_accuracy: 0.9671\n",
      "Epoch 91/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0914 - accuracy: 0.9650 - val_loss: 0.1288 - val_accuracy: 0.9539\n",
      "Epoch 92/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0713 - accuracy: 0.9737 - val_loss: 0.1284 - val_accuracy: 0.9593\n",
      "Epoch 93/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0702 - accuracy: 0.9735 - val_loss: 0.0697 - val_accuracy: 0.9786\n",
      "Epoch 94/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0796 - accuracy: 0.9715 - val_loss: 0.0860 - val_accuracy: 0.9660\n",
      "Epoch 95/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0873 - accuracy: 0.9671 - val_loss: 0.0800 - val_accuracy: 0.9736\n",
      "Epoch 96/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0776 - accuracy: 0.9720 - val_loss: 0.0698 - val_accuracy: 0.9778\n",
      "Epoch 97/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0691 - accuracy: 0.9748 - val_loss: 0.0717 - val_accuracy: 0.9757\n",
      "Epoch 98/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0766 - accuracy: 0.9706 - val_loss: 0.0744 - val_accuracy: 0.9764\n",
      "Epoch 99/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0775 - accuracy: 0.9715 - val_loss: 0.0677 - val_accuracy: 0.9771\n",
      "Epoch 100/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0783 - accuracy: 0.9706 - val_loss: 0.0825 - val_accuracy: 0.9689\n",
      "Epoch 101/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0671 - accuracy: 0.9752 - val_loss: 0.0717 - val_accuracy: 0.9750\n",
      "Epoch 102/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0715 - accuracy: 0.9743 - val_loss: 0.1078 - val_accuracy: 0.9550\n",
      "Epoch 103/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0778 - accuracy: 0.9713 - val_loss: 0.2161 - val_accuracy: 0.9114\n",
      "Epoch 104/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0734 - accuracy: 0.9729 - val_loss: 0.2406 - val_accuracy: 0.9092\n",
      "Epoch 105/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0758 - accuracy: 0.9720 - val_loss: 0.0647 - val_accuracy: 0.9761\n",
      "Epoch 106/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0663 - accuracy: 0.9764 - val_loss: 0.0611 - val_accuracy: 0.9796\n",
      "Epoch 107/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0601 - accuracy: 0.9778 - val_loss: 0.0586 - val_accuracy: 0.9803\n",
      "Epoch 108/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0661 - accuracy: 0.9769 - val_loss: 0.0847 - val_accuracy: 0.9678\n",
      "Epoch 109/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0578 - accuracy: 0.9785 - val_loss: 0.0794 - val_accuracy: 0.9732\n",
      "Epoch 110/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0737 - accuracy: 0.9735 - val_loss: 0.0786 - val_accuracy: 0.9700\n",
      "Epoch 111/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0621 - accuracy: 0.9767 - val_loss: 0.0865 - val_accuracy: 0.9703\n",
      "Epoch 112/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1053 - accuracy: 0.9587 - val_loss: 0.0855 - val_accuracy: 0.9675\n",
      "Epoch 113/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0568 - accuracy: 0.9791 - val_loss: 0.0647 - val_accuracy: 0.9778\n",
      "Epoch 114/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0662 - accuracy: 0.9762 - val_loss: 0.0791 - val_accuracy: 0.9664\n",
      "Epoch 115/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0595 - accuracy: 0.9786 - val_loss: 0.0822 - val_accuracy: 0.9685\n",
      "Epoch 116/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0628 - accuracy: 0.9769 - val_loss: 0.0682 - val_accuracy: 0.9775\n",
      "Epoch 117/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0700 - accuracy: 0.9751 - val_loss: 0.0590 - val_accuracy: 0.9800\n",
      "Epoch 118/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0762 - accuracy: 0.9720 - val_loss: 0.1405 - val_accuracy: 0.9425\n",
      "Epoch 119/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0540 - accuracy: 0.9804 - val_loss: 0.0893 - val_accuracy: 0.9650\n",
      "Epoch 120/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0490 - accuracy: 0.9824 - val_loss: 0.0740 - val_accuracy: 0.9764\n",
      "Epoch 121/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0879 - accuracy: 0.9659 - val_loss: 0.0630 - val_accuracy: 0.9786\n",
      "Epoch 122/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0453 - accuracy: 0.9836 - val_loss: 0.0493 - val_accuracy: 0.9846\n",
      "Epoch 123/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0496 - accuracy: 0.9815 - val_loss: 0.0674 - val_accuracy: 0.9768\n",
      "Epoch 124/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0465 - accuracy: 0.9826 - val_loss: 0.0669 - val_accuracy: 0.9757\n",
      "Epoch 125/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0602 - accuracy: 0.9780 - val_loss: 0.0862 - val_accuracy: 0.9682\n",
      "Epoch 126/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0561 - accuracy: 0.9785 - val_loss: 0.0496 - val_accuracy: 0.9807\n",
      "Epoch 127/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0574 - accuracy: 0.9789 - val_loss: 0.0591 - val_accuracy: 0.9796\n",
      "Epoch 128/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0498 - accuracy: 0.9819 - val_loss: 0.0827 - val_accuracy: 0.9703\n",
      "Epoch 129/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0615 - accuracy: 0.9770 - val_loss: 0.4111 - val_accuracy: 0.8914\n",
      "Epoch 130/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1941 - accuracy: 0.9217 - val_loss: 0.1040 - val_accuracy: 0.9585\n",
      "Epoch 131/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0560 - accuracy: 0.9799 - val_loss: 0.0544 - val_accuracy: 0.9811\n",
      "Epoch 132/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0505 - accuracy: 0.9817 - val_loss: 0.0619 - val_accuracy: 0.9786\n",
      "Epoch 133/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0694 - accuracy: 0.9748 - val_loss: 0.2045 - val_accuracy: 0.9132\n",
      "Epoch 134/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0525 - accuracy: 0.9803 - val_loss: 0.0563 - val_accuracy: 0.9821\n",
      "Epoch 135/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0459 - accuracy: 0.9836 - val_loss: 0.0930 - val_accuracy: 0.9678\n",
      "Epoch 136/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0513 - accuracy: 0.9813 - val_loss: 0.0580 - val_accuracy: 0.9818\n",
      "Epoch 137/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0546 - accuracy: 0.9808 - val_loss: 0.0510 - val_accuracy: 0.9839\n",
      "Epoch 138/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0438 - accuracy: 0.9841 - val_loss: 0.0725 - val_accuracy: 0.9771\n",
      "Epoch 139/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0443 - accuracy: 0.9847 - val_loss: 0.0722 - val_accuracy: 0.9764\n",
      "Epoch 140/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0562 - accuracy: 0.9791 - val_loss: 0.0788 - val_accuracy: 0.9736\n",
      "Epoch 141/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0425 - accuracy: 0.9846 - val_loss: 0.0734 - val_accuracy: 0.9789\n",
      "Epoch 142/500\n",
      "329/333 [============================>.] - ETA: 0s - loss: 0.0454 - accuracy: 0.9839Restoring model weights from the end of the best epoch: 122.\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0454 - accuracy: 0.9839 - val_loss: 0.1467 - val_accuracy: 0.9450\n",
      "Epoch 142: early stopping\n",
      "Number of iterations 2\n",
      "F1-scores:  [0.794888178913738, 0.9737324373854611]\n",
      "Average F1-Score 0.8843103081495995\n",
      "Std Dev F1-Score 0.08942212923586157\n",
      "Error bar F1-Score 0.06323099397081754\n",
      "Epoch 1/500\n",
      "333/333 [==============================] - 11s 16ms/step - loss: 0.5599 - accuracy: 0.7108 - val_loss: 0.5279 - val_accuracy: 0.7127\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5291 - accuracy: 0.7066 - val_loss: 0.5025 - val_accuracy: 0.7127\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5169 - accuracy: 0.7115 - val_loss: 0.5011 - val_accuracy: 0.7127\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5127 - accuracy: 0.7178 - val_loss: 0.5052 - val_accuracy: 0.7234\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5106 - accuracy: 0.7228 - val_loss: 0.5121 - val_accuracy: 0.7130\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5090 - accuracy: 0.7269 - val_loss: 0.4908 - val_accuracy: 0.7327\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5055 - accuracy: 0.7284 - val_loss: 0.5036 - val_accuracy: 0.7184\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5001 - accuracy: 0.7295 - val_loss: 0.4807 - val_accuracy: 0.7480\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.4949 - accuracy: 0.7318 - val_loss: 0.4936 - val_accuracy: 0.7252\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5006 - accuracy: 0.7298 - val_loss: 0.4812 - val_accuracy: 0.7402\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.4790 - accuracy: 0.7354 - val_loss: 0.4759 - val_accuracy: 0.7452\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5021 - accuracy: 0.7254 - val_loss: 0.4840 - val_accuracy: 0.7470\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.4931 - accuracy: 0.7329 - val_loss: 0.4848 - val_accuracy: 0.7380\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.4920 - accuracy: 0.7335 - val_loss: 0.4822 - val_accuracy: 0.7298\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.4924 - accuracy: 0.7339 - val_loss: 0.4911 - val_accuracy: 0.7287\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.4749 - accuracy: 0.7435 - val_loss: 0.4683 - val_accuracy: 0.7316\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.3979 - accuracy: 0.7961 - val_loss: 0.4594 - val_accuracy: 0.7838\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.3859 - accuracy: 0.7981 - val_loss: 0.3078 - val_accuracy: 0.8513\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.3329 - accuracy: 0.8379 - val_loss: 0.2920 - val_accuracy: 0.8488\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.3219 - accuracy: 0.8476 - val_loss: 0.2770 - val_accuracy: 0.8692\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2863 - accuracy: 0.8628 - val_loss: 0.2714 - val_accuracy: 0.8599\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2826 - accuracy: 0.8646 - val_loss: 0.2497 - val_accuracy: 0.8713\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2777 - accuracy: 0.8664 - val_loss: 0.3304 - val_accuracy: 0.8524\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2739 - accuracy: 0.8679 - val_loss: 0.2385 - val_accuracy: 0.8781\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2787 - accuracy: 0.8662 - val_loss: 0.2453 - val_accuracy: 0.8753\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2743 - accuracy: 0.8695 - val_loss: 0.4245 - val_accuracy: 0.8256\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2722 - accuracy: 0.8683 - val_loss: 0.2874 - val_accuracy: 0.8606\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2759 - accuracy: 0.8646 - val_loss: 0.2812 - val_accuracy: 0.8803\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2745 - accuracy: 0.8657 - val_loss: 0.2380 - val_accuracy: 0.8771\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2659 - accuracy: 0.8702 - val_loss: 0.2434 - val_accuracy: 0.8778\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2812 - accuracy: 0.8630 - val_loss: 0.3802 - val_accuracy: 0.8642\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2710 - accuracy: 0.8660 - val_loss: 0.2354 - val_accuracy: 0.8821\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2660 - accuracy: 0.8717 - val_loss: 0.2522 - val_accuracy: 0.8731\n",
      "Epoch 34/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2719 - accuracy: 0.8671 - val_loss: 0.2637 - val_accuracy: 0.8713\n",
      "Epoch 35/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2690 - accuracy: 0.8685 - val_loss: 0.2559 - val_accuracy: 0.8746\n",
      "Epoch 36/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2729 - accuracy: 0.8663 - val_loss: 0.2458 - val_accuracy: 0.8713\n",
      "Epoch 37/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2688 - accuracy: 0.8671 - val_loss: 0.2350 - val_accuracy: 0.8760\n",
      "Epoch 38/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2645 - accuracy: 0.8679 - val_loss: 0.2328 - val_accuracy: 0.8778\n",
      "Epoch 39/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2663 - accuracy: 0.8668 - val_loss: 0.2591 - val_accuracy: 0.8606\n",
      "Epoch 40/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2655 - accuracy: 0.8677 - val_loss: 0.2431 - val_accuracy: 0.8821\n",
      "Epoch 41/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2676 - accuracy: 0.8681 - val_loss: 0.2631 - val_accuracy: 0.8767\n",
      "Epoch 42/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2678 - accuracy: 0.8698 - val_loss: 0.2402 - val_accuracy: 0.8724\n",
      "Epoch 43/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2628 - accuracy: 0.8703 - val_loss: 0.2353 - val_accuracy: 0.8735\n",
      "Epoch 44/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2641 - accuracy: 0.8698 - val_loss: 0.2538 - val_accuracy: 0.8799\n",
      "Epoch 45/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2632 - accuracy: 0.8685 - val_loss: 0.4522 - val_accuracy: 0.8181\n",
      "Epoch 46/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.3324 - accuracy: 0.8298 - val_loss: 0.2369 - val_accuracy: 0.8810\n",
      "Epoch 47/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2711 - accuracy: 0.8653 - val_loss: 0.2441 - val_accuracy: 0.8831\n",
      "Epoch 48/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2680 - accuracy: 0.8664 - val_loss: 0.2333 - val_accuracy: 0.8731\n",
      "Epoch 49/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2664 - accuracy: 0.8683 - val_loss: 0.2455 - val_accuracy: 0.8849\n",
      "Epoch 50/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2664 - accuracy: 0.8692 - val_loss: 0.2489 - val_accuracy: 0.8767\n",
      "Epoch 51/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2654 - accuracy: 0.8696 - val_loss: 0.2321 - val_accuracy: 0.8785\n",
      "Epoch 52/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2659 - accuracy: 0.8673 - val_loss: 0.2631 - val_accuracy: 0.8660\n",
      "Epoch 53/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2692 - accuracy: 0.8667 - val_loss: 0.2487 - val_accuracy: 0.8699\n",
      "Epoch 54/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2635 - accuracy: 0.8693 - val_loss: 0.2313 - val_accuracy: 0.8824\n",
      "Epoch 55/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2656 - accuracy: 0.8675 - val_loss: 0.2325 - val_accuracy: 0.8828\n",
      "Epoch 56/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2585 - accuracy: 0.8704 - val_loss: 0.2400 - val_accuracy: 0.8746\n",
      "Epoch 57/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2584 - accuracy: 0.8703 - val_loss: 0.2565 - val_accuracy: 0.8756\n",
      "Epoch 58/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2605 - accuracy: 0.8696 - val_loss: 0.2289 - val_accuracy: 0.8849\n",
      "Epoch 59/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2602 - accuracy: 0.8719 - val_loss: 0.2658 - val_accuracy: 0.8792\n",
      "Epoch 60/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2617 - accuracy: 0.8695 - val_loss: 0.3066 - val_accuracy: 0.8438\n",
      "Epoch 61/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2719 - accuracy: 0.8665 - val_loss: 0.2341 - val_accuracy: 0.8735\n",
      "Epoch 62/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2683 - accuracy: 0.8687 - val_loss: 0.2361 - val_accuracy: 0.8810\n",
      "Epoch 63/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2586 - accuracy: 0.8710 - val_loss: 0.2458 - val_accuracy: 0.8706\n",
      "Epoch 64/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2654 - accuracy: 0.8679 - val_loss: 0.2318 - val_accuracy: 0.8767\n",
      "Epoch 65/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2703 - accuracy: 0.8675 - val_loss: 0.3383 - val_accuracy: 0.8463\n",
      "Epoch 66/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2566 - accuracy: 0.8717 - val_loss: 0.2306 - val_accuracy: 0.8813\n",
      "Epoch 67/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2618 - accuracy: 0.8699 - val_loss: 0.2285 - val_accuracy: 0.8796\n",
      "Epoch 68/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2606 - accuracy: 0.8697 - val_loss: 0.2302 - val_accuracy: 0.8760\n",
      "Epoch 69/500\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.2543 - accuracy: 0.8726Restoring model weights from the end of the best epoch: 49.\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2543 - accuracy: 0.8726 - val_loss: 0.2677 - val_accuracy: 0.8763\n",
      "Epoch 69: early stopping\n",
      "Number of iterations 3\n",
      "F1-scores:  [0.794888178913738, 0.9737324373854611, 0.8083333333333333]\n",
      "Average F1-Score 0.8589846498775108\n",
      "Std Dev F1-Score 0.08132438788710711\n",
      "Error bar F1-Score 0.04695265723830283\n",
      "Epoch 1/500\n",
      "333/333 [==============================] - 11s 17ms/step - loss: 0.5513 - accuracy: 0.7126 - val_loss: 0.5259 - val_accuracy: 0.7127\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5157 - accuracy: 0.7201 - val_loss: 0.5026 - val_accuracy: 0.7055\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5150 - accuracy: 0.7190 - val_loss: 0.5028 - val_accuracy: 0.7137\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5053 - accuracy: 0.7270 - val_loss: 0.4924 - val_accuracy: 0.7380\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.4950 - accuracy: 0.7304 - val_loss: 0.5036 - val_accuracy: 0.6994\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.4650 - accuracy: 0.7465 - val_loss: 0.4320 - val_accuracy: 0.7673\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.4353 - accuracy: 0.7723 - val_loss: 0.4108 - val_accuracy: 0.7945\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.4108 - accuracy: 0.7948 - val_loss: 0.3698 - val_accuracy: 0.8306\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.3357 - accuracy: 0.8441 - val_loss: 0.4117 - val_accuracy: 0.8006\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3081 - accuracy: 0.8579 - val_loss: 0.2622 - val_accuracy: 0.8831\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2564 - accuracy: 0.8841 - val_loss: 0.2160 - val_accuracy: 0.9081\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2462 - accuracy: 0.8885 - val_loss: 0.3080 - val_accuracy: 0.8520\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2201 - accuracy: 0.9043 - val_loss: 0.1914 - val_accuracy: 0.9164\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2169 - accuracy: 0.9033 - val_loss: 0.1838 - val_accuracy: 0.9228\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2175 - accuracy: 0.9031 - val_loss: 0.1723 - val_accuracy: 0.9267\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2042 - accuracy: 0.9112 - val_loss: 0.1952 - val_accuracy: 0.9149\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2040 - accuracy: 0.9072 - val_loss: 0.2009 - val_accuracy: 0.9142\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1970 - accuracy: 0.9136 - val_loss: 0.1803 - val_accuracy: 0.9142\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1901 - accuracy: 0.9141 - val_loss: 0.1997 - val_accuracy: 0.9081\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2058 - accuracy: 0.9059 - val_loss: 0.2220 - val_accuracy: 0.8960\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1947 - accuracy: 0.9133 - val_loss: 0.2231 - val_accuracy: 0.8974\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1977 - accuracy: 0.9124 - val_loss: 0.1767 - val_accuracy: 0.9257\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1892 - accuracy: 0.9156 - val_loss: 0.1643 - val_accuracy: 0.9360\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1886 - accuracy: 0.9156 - val_loss: 0.1746 - val_accuracy: 0.9207\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1799 - accuracy: 0.9204 - val_loss: 0.1652 - val_accuracy: 0.9282\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1841 - accuracy: 0.9188 - val_loss: 0.1579 - val_accuracy: 0.9346\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1923 - accuracy: 0.9158 - val_loss: 0.1593 - val_accuracy: 0.9353\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1768 - accuracy: 0.9242 - val_loss: 0.1569 - val_accuracy: 0.9317\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1770 - accuracy: 0.9226 - val_loss: 0.2131 - val_accuracy: 0.9157\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1817 - accuracy: 0.9209 - val_loss: 0.1745 - val_accuracy: 0.9217\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1716 - accuracy: 0.9255 - val_loss: 0.1660 - val_accuracy: 0.9207\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1716 - accuracy: 0.9257 - val_loss: 0.1753 - val_accuracy: 0.9146\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1719 - accuracy: 0.9260 - val_loss: 0.1395 - val_accuracy: 0.9467\n",
      "Epoch 34/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1810 - accuracy: 0.9214 - val_loss: 0.1457 - val_accuracy: 0.9378\n",
      "Epoch 35/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1569 - accuracy: 0.9310 - val_loss: 0.1315 - val_accuracy: 0.9471\n",
      "Epoch 36/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1568 - accuracy: 0.9334 - val_loss: 0.1258 - val_accuracy: 0.9518\n",
      "Epoch 37/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1631 - accuracy: 0.9306 - val_loss: 0.1417 - val_accuracy: 0.9425\n",
      "Epoch 38/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1547 - accuracy: 0.9343 - val_loss: 0.1339 - val_accuracy: 0.9421\n",
      "Epoch 39/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1493 - accuracy: 0.9364 - val_loss: 0.1547 - val_accuracy: 0.9310\n",
      "Epoch 40/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1556 - accuracy: 0.9337 - val_loss: 0.1626 - val_accuracy: 0.9282\n",
      "Epoch 41/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1575 - accuracy: 0.9319 - val_loss: 0.1534 - val_accuracy: 0.9317\n",
      "Epoch 42/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1491 - accuracy: 0.9347 - val_loss: 0.1326 - val_accuracy: 0.9475\n",
      "Epoch 43/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1507 - accuracy: 0.9361 - val_loss: 0.1243 - val_accuracy: 0.9510\n",
      "Epoch 44/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1559 - accuracy: 0.9341 - val_loss: 0.1534 - val_accuracy: 0.9321\n",
      "Epoch 45/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1407 - accuracy: 0.9407 - val_loss: 0.1918 - val_accuracy: 0.9203\n",
      "Epoch 46/500\n",
      "333/333 [==============================] - 4s 14ms/step - loss: 0.1461 - accuracy: 0.9380 - val_loss: 0.1188 - val_accuracy: 0.9532\n",
      "Epoch 47/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1623 - accuracy: 0.9317 - val_loss: 0.1302 - val_accuracy: 0.9500\n",
      "Epoch 48/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1355 - accuracy: 0.9447 - val_loss: 0.1401 - val_accuracy: 0.9371\n",
      "Epoch 49/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1394 - accuracy: 0.9412 - val_loss: 0.1199 - val_accuracy: 0.9532\n",
      "Epoch 50/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1278 - accuracy: 0.9481 - val_loss: 0.1214 - val_accuracy: 0.9478\n",
      "Epoch 51/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1286 - accuracy: 0.9479 - val_loss: 0.1133 - val_accuracy: 0.9532\n",
      "Epoch 52/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1298 - accuracy: 0.9466 - val_loss: 0.1240 - val_accuracy: 0.9521\n",
      "Epoch 53/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1254 - accuracy: 0.9475 - val_loss: 0.1103 - val_accuracy: 0.9557\n",
      "Epoch 54/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1239 - accuracy: 0.9501 - val_loss: 0.1323 - val_accuracy: 0.9446\n",
      "Epoch 55/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1232 - accuracy: 0.9513 - val_loss: 0.1360 - val_accuracy: 0.9471\n",
      "Epoch 56/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1185 - accuracy: 0.9519 - val_loss: 0.1154 - val_accuracy: 0.9539\n",
      "Epoch 57/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1257 - accuracy: 0.9494 - val_loss: 0.1112 - val_accuracy: 0.9532\n",
      "Epoch 58/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1107 - accuracy: 0.9563 - val_loss: 0.1869 - val_accuracy: 0.9185\n",
      "Epoch 59/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1107 - accuracy: 0.9559 - val_loss: 0.1663 - val_accuracy: 0.9292\n",
      "Epoch 60/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1240 - accuracy: 0.9504 - val_loss: 0.1160 - val_accuracy: 0.9600\n",
      "Epoch 61/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1213 - accuracy: 0.9498 - val_loss: 0.1140 - val_accuracy: 0.9557\n",
      "Epoch 62/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1112 - accuracy: 0.9567 - val_loss: 0.1074 - val_accuracy: 0.9603\n",
      "Epoch 63/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1191 - accuracy: 0.9540 - val_loss: 0.1025 - val_accuracy: 0.9593\n",
      "Epoch 64/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1008 - accuracy: 0.9609 - val_loss: 0.0933 - val_accuracy: 0.9657\n",
      "Epoch 65/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1144 - accuracy: 0.9547 - val_loss: 0.1644 - val_accuracy: 0.9328\n",
      "Epoch 66/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3593 - accuracy: 0.8327 - val_loss: 0.2659 - val_accuracy: 0.8710\n",
      "Epoch 67/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2444 - accuracy: 0.8903 - val_loss: 0.2075 - val_accuracy: 0.9121\n",
      "Epoch 68/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2036 - accuracy: 0.9112 - val_loss: 0.1935 - val_accuracy: 0.9081\n",
      "Epoch 69/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1905 - accuracy: 0.9179 - val_loss: 0.1653 - val_accuracy: 0.9346\n",
      "Epoch 70/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1820 - accuracy: 0.9221 - val_loss: 0.1372 - val_accuracy: 0.9450\n",
      "Epoch 71/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1563 - accuracy: 0.9361 - val_loss: 0.1431 - val_accuracy: 0.9407\n",
      "Epoch 72/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1478 - accuracy: 0.9397 - val_loss: 0.2000 - val_accuracy: 0.9157\n",
      "Epoch 73/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1536 - accuracy: 0.9375 - val_loss: 0.1776 - val_accuracy: 0.9242\n",
      "Epoch 74/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1539 - accuracy: 0.9372 - val_loss: 0.1053 - val_accuracy: 0.9571\n",
      "Epoch 75/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1337 - accuracy: 0.9477 - val_loss: 0.1261 - val_accuracy: 0.9485\n",
      "Epoch 76/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1573 - accuracy: 0.9393 - val_loss: 0.1215 - val_accuracy: 0.9550\n",
      "Epoch 77/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1486 - accuracy: 0.9409 - val_loss: 0.1272 - val_accuracy: 0.9446\n",
      "Epoch 78/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1323 - accuracy: 0.9484 - val_loss: 0.1159 - val_accuracy: 0.9568\n",
      "Epoch 79/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1256 - accuracy: 0.9510 - val_loss: 0.1321 - val_accuracy: 0.9510\n",
      "Epoch 80/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1237 - accuracy: 0.9507 - val_loss: 0.1229 - val_accuracy: 0.9521\n",
      "Epoch 81/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1121 - accuracy: 0.9566 - val_loss: 0.1129 - val_accuracy: 0.9553\n",
      "Epoch 82/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1114 - accuracy: 0.9565 - val_loss: 0.0946 - val_accuracy: 0.9635\n",
      "Epoch 83/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1385 - accuracy: 0.9446 - val_loss: 0.1021 - val_accuracy: 0.9614\n",
      "Epoch 84/500\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.1165 - accuracy: 0.9547Restoring model weights from the end of the best epoch: 64.\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1164 - accuracy: 0.9547 - val_loss: 0.0972 - val_accuracy: 0.9653\n",
      "Epoch 84: early stopping\n",
      "Number of iterations 4\n",
      "F1-scores:  [0.794888178913738, 0.9737324373854611, 0.8083333333333333, 0.9412484700122399]\n",
      "Average F1-Score 0.879550604911193\n",
      "Std Dev F1-Score 0.07892475890524983\n",
      "Error bar F1-Score 0.039462379452624916\n",
      "Epoch 1/500\n",
      "333/333 [==============================] - 11s 18ms/step - loss: 0.5527 - accuracy: 0.7112 - val_loss: 0.5017 - val_accuracy: 0.7084\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5146 - accuracy: 0.7250 - val_loss: 0.4596 - val_accuracy: 0.7480\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.4328 - accuracy: 0.7744 - val_loss: 0.3227 - val_accuracy: 0.8538\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3299 - accuracy: 0.8449 - val_loss: 0.2873 - val_accuracy: 0.8667\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.3041 - accuracy: 0.8589 - val_loss: 0.2978 - val_accuracy: 0.8635\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2971 - accuracy: 0.8623 - val_loss: 0.4366 - val_accuracy: 0.7934\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2865 - accuracy: 0.8681 - val_loss: 0.2793 - val_accuracy: 0.8785\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2733 - accuracy: 0.8776 - val_loss: 0.2594 - val_accuracy: 0.8810\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2706 - accuracy: 0.8797 - val_loss: 0.3283 - val_accuracy: 0.8381\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3641 - accuracy: 0.8113 - val_loss: 0.2477 - val_accuracy: 0.8967\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3018 - accuracy: 0.8612 - val_loss: 0.2302 - val_accuracy: 0.9078\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2571 - accuracy: 0.8888 - val_loss: 0.2554 - val_accuracy: 0.8860\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2609 - accuracy: 0.8859 - val_loss: 0.2403 - val_accuracy: 0.8928\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2469 - accuracy: 0.8929 - val_loss: 0.2486 - val_accuracy: 0.8867\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2508 - accuracy: 0.8898 - val_loss: 0.2145 - val_accuracy: 0.9107\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2451 - accuracy: 0.8950 - val_loss: 0.2364 - val_accuracy: 0.8974\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2363 - accuracy: 0.8958 - val_loss: 0.1933 - val_accuracy: 0.9242\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2379 - accuracy: 0.8979 - val_loss: 0.3374 - val_accuracy: 0.8806\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2417 - accuracy: 0.8916 - val_loss: 0.2097 - val_accuracy: 0.9078\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2329 - accuracy: 0.8941 - val_loss: 0.1961 - val_accuracy: 0.9107\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2347 - accuracy: 0.8930 - val_loss: 0.2493 - val_accuracy: 0.8956\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2245 - accuracy: 0.8995 - val_loss: 0.2803 - val_accuracy: 0.8767\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2272 - accuracy: 0.8965 - val_loss: 0.2090 - val_accuracy: 0.9064\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2215 - accuracy: 0.9011 - val_loss: 0.1860 - val_accuracy: 0.9199\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2156 - accuracy: 0.9003 - val_loss: 0.1843 - val_accuracy: 0.9228\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2174 - accuracy: 0.9013 - val_loss: 0.1735 - val_accuracy: 0.9239\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2106 - accuracy: 0.9078 - val_loss: 0.2364 - val_accuracy: 0.8914\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2059 - accuracy: 0.9086 - val_loss: 0.1681 - val_accuracy: 0.9278\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2240 - accuracy: 0.9008 - val_loss: 0.2388 - val_accuracy: 0.8914\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2159 - accuracy: 0.9035 - val_loss: 0.1769 - val_accuracy: 0.9246\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1987 - accuracy: 0.9144 - val_loss: 0.1509 - val_accuracy: 0.9360\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1987 - accuracy: 0.9115 - val_loss: 0.1582 - val_accuracy: 0.9346\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1963 - accuracy: 0.9156 - val_loss: 0.2290 - val_accuracy: 0.9031\n",
      "Epoch 34/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1905 - accuracy: 0.9162 - val_loss: 0.1519 - val_accuracy: 0.9339\n",
      "Epoch 35/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1840 - accuracy: 0.9211 - val_loss: 0.2103 - val_accuracy: 0.8960\n",
      "Epoch 36/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2686 - accuracy: 0.8835 - val_loss: 0.2296 - val_accuracy: 0.8960\n",
      "Epoch 37/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2273 - accuracy: 0.9009 - val_loss: 0.1980 - val_accuracy: 0.9217\n",
      "Epoch 38/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1950 - accuracy: 0.9167 - val_loss: 0.1538 - val_accuracy: 0.9332\n",
      "Epoch 39/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1910 - accuracy: 0.9187 - val_loss: 0.1641 - val_accuracy: 0.9321\n",
      "Epoch 40/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1917 - accuracy: 0.9164 - val_loss: 0.1527 - val_accuracy: 0.9360\n",
      "Epoch 41/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1776 - accuracy: 0.9240 - val_loss: 0.1413 - val_accuracy: 0.9464\n",
      "Epoch 42/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1662 - accuracy: 0.9308 - val_loss: 0.1768 - val_accuracy: 0.9228\n",
      "Epoch 43/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1714 - accuracy: 0.9266 - val_loss: 0.2154 - val_accuracy: 0.9053\n",
      "Epoch 44/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1662 - accuracy: 0.9318 - val_loss: 0.1993 - val_accuracy: 0.9135\n",
      "Epoch 45/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1617 - accuracy: 0.9328 - val_loss: 0.1948 - val_accuracy: 0.9135\n",
      "Epoch 46/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1553 - accuracy: 0.9353 - val_loss: 0.1857 - val_accuracy: 0.9203\n",
      "Epoch 47/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1525 - accuracy: 0.9383 - val_loss: 0.1586 - val_accuracy: 0.9325\n",
      "Epoch 48/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1482 - accuracy: 0.9390 - val_loss: 0.1182 - val_accuracy: 0.9467\n",
      "Epoch 49/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1446 - accuracy: 0.9421 - val_loss: 0.1482 - val_accuracy: 0.9346\n",
      "Epoch 50/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1439 - accuracy: 0.9423 - val_loss: 0.1175 - val_accuracy: 0.9496\n",
      "Epoch 51/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1364 - accuracy: 0.9443 - val_loss: 0.1545 - val_accuracy: 0.9328\n",
      "Epoch 52/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1479 - accuracy: 0.9386 - val_loss: 0.1338 - val_accuracy: 0.9442\n",
      "Epoch 53/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1420 - accuracy: 0.9433 - val_loss: 0.1862 - val_accuracy: 0.9224\n",
      "Epoch 54/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1316 - accuracy: 0.9477 - val_loss: 0.1198 - val_accuracy: 0.9514\n",
      "Epoch 55/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1303 - accuracy: 0.9471 - val_loss: 0.1096 - val_accuracy: 0.9596\n",
      "Epoch 56/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1330 - accuracy: 0.9469 - val_loss: 0.1054 - val_accuracy: 0.9575\n",
      "Epoch 57/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1266 - accuracy: 0.9499 - val_loss: 0.1897 - val_accuracy: 0.9146\n",
      "Epoch 58/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1303 - accuracy: 0.9481 - val_loss: 0.1084 - val_accuracy: 0.9571\n",
      "Epoch 59/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1197 - accuracy: 0.9541 - val_loss: 0.1143 - val_accuracy: 0.9535\n",
      "Epoch 60/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1253 - accuracy: 0.9500 - val_loss: 0.1063 - val_accuracy: 0.9564\n",
      "Epoch 61/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1220 - accuracy: 0.9520 - val_loss: 0.1156 - val_accuracy: 0.9560\n",
      "Epoch 62/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1217 - accuracy: 0.9528 - val_loss: 0.0942 - val_accuracy: 0.9646\n",
      "Epoch 63/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1169 - accuracy: 0.9536 - val_loss: 0.1081 - val_accuracy: 0.9607\n",
      "Epoch 64/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1111 - accuracy: 0.9574 - val_loss: 0.0952 - val_accuracy: 0.9675\n",
      "Epoch 65/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1096 - accuracy: 0.9564 - val_loss: 0.0901 - val_accuracy: 0.9668\n",
      "Epoch 66/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1248 - accuracy: 0.9515 - val_loss: 0.1244 - val_accuracy: 0.9518\n",
      "Epoch 67/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1040 - accuracy: 0.9590 - val_loss: 0.2434 - val_accuracy: 0.9171\n",
      "Epoch 68/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1151 - accuracy: 0.9558 - val_loss: 0.1217 - val_accuracy: 0.9525\n",
      "Epoch 69/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1048 - accuracy: 0.9601 - val_loss: 0.1160 - val_accuracy: 0.9535\n",
      "Epoch 70/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1052 - accuracy: 0.9599 - val_loss: 0.1532 - val_accuracy: 0.9453\n",
      "Epoch 71/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1017 - accuracy: 0.9607 - val_loss: 0.1061 - val_accuracy: 0.9632\n",
      "Epoch 72/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1101 - accuracy: 0.9592 - val_loss: 0.0932 - val_accuracy: 0.9653\n",
      "Epoch 73/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0919 - accuracy: 0.9649 - val_loss: 0.3468 - val_accuracy: 0.8956\n",
      "Epoch 74/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1054 - accuracy: 0.9603 - val_loss: 0.0841 - val_accuracy: 0.9678\n",
      "Epoch 75/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0927 - accuracy: 0.9650 - val_loss: 0.6729 - val_accuracy: 0.7916\n",
      "Epoch 76/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3732 - accuracy: 0.8169 - val_loss: 0.3512 - val_accuracy: 0.8267\n",
      "Epoch 77/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2491 - accuracy: 0.8872 - val_loss: 0.2121 - val_accuracy: 0.9146\n",
      "Epoch 78/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2021 - accuracy: 0.9145 - val_loss: 0.2049 - val_accuracy: 0.9146\n",
      "Epoch 79/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1687 - accuracy: 0.9276 - val_loss: 0.3049 - val_accuracy: 0.8721\n",
      "Epoch 80/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1898 - accuracy: 0.9204 - val_loss: 0.1650 - val_accuracy: 0.9357\n",
      "Epoch 81/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1473 - accuracy: 0.9397 - val_loss: 0.1181 - val_accuracy: 0.9525\n",
      "Epoch 82/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1428 - accuracy: 0.9416 - val_loss: 0.1322 - val_accuracy: 0.9485\n",
      "Epoch 83/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1568 - accuracy: 0.9338 - val_loss: 0.1193 - val_accuracy: 0.9500\n",
      "Epoch 84/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1349 - accuracy: 0.9454 - val_loss: 0.2100 - val_accuracy: 0.9042\n",
      "Epoch 85/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1371 - accuracy: 0.9418 - val_loss: 0.1013 - val_accuracy: 0.9596\n",
      "Epoch 86/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1249 - accuracy: 0.9487 - val_loss: 0.0960 - val_accuracy: 0.9607\n",
      "Epoch 87/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1335 - accuracy: 0.9455 - val_loss: 0.1084 - val_accuracy: 0.9607\n",
      "Epoch 88/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1334 - accuracy: 0.9468 - val_loss: 0.1171 - val_accuracy: 0.9510\n",
      "Epoch 89/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1654 - accuracy: 0.9361 - val_loss: 0.1606 - val_accuracy: 0.9346\n",
      "Epoch 90/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1481 - accuracy: 0.9422 - val_loss: 0.1257 - val_accuracy: 0.9500\n",
      "Epoch 91/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1246 - accuracy: 0.9509 - val_loss: 0.1027 - val_accuracy: 0.9607\n",
      "Epoch 92/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1204 - accuracy: 0.9528 - val_loss: 0.1031 - val_accuracy: 0.9600\n",
      "Epoch 93/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1126 - accuracy: 0.9537 - val_loss: 0.1587 - val_accuracy: 0.9346\n",
      "Epoch 94/500\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.1203 - accuracy: 0.9500Restoring model weights from the end of the best epoch: 74.\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1203 - accuracy: 0.9500 - val_loss: 0.1699 - val_accuracy: 0.9292\n",
      "Epoch 94: early stopping\n",
      "Number of iterations 5\n",
      "F1-scores:  [0.794888178913738, 0.9737324373854611, 0.8083333333333333, 0.9412484700122399, 0.9457177322074789]\n",
      "Average F1-Score 0.8927840303704502\n",
      "Std Dev F1-Score 0.07539090298003011\n",
      "Error bar F1-Score 0.03371583678968776\n",
      "Epoch 1/500\n",
      "333/333 [==============================] - 11s 18ms/step - loss: 0.5555 - accuracy: 0.7111 - val_loss: 0.5256 - val_accuracy: 0.7127\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5225 - accuracy: 0.7133 - val_loss: 0.5216 - val_accuracy: 0.7127\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5180 - accuracy: 0.7142 - val_loss: 0.5035 - val_accuracy: 0.7362\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5158 - accuracy: 0.7211 - val_loss: 0.5032 - val_accuracy: 0.7205\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5072 - accuracy: 0.7251 - val_loss: 0.4961 - val_accuracy: 0.7166\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4556 - accuracy: 0.7609 - val_loss: 0.3997 - val_accuracy: 0.8134\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3885 - accuracy: 0.8092 - val_loss: 0.3095 - val_accuracy: 0.8528\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3152 - accuracy: 0.8579 - val_loss: 0.2575 - val_accuracy: 0.8838\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2867 - accuracy: 0.8738 - val_loss: 0.2592 - val_accuracy: 0.8903\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2853 - accuracy: 0.8733 - val_loss: 0.2402 - val_accuracy: 0.8999\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2688 - accuracy: 0.8778 - val_loss: 0.2246 - val_accuracy: 0.9071\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2547 - accuracy: 0.8880 - val_loss: 0.2839 - val_accuracy: 0.8756\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2413 - accuracy: 0.8952 - val_loss: 0.2303 - val_accuracy: 0.8967\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2343 - accuracy: 0.8975 - val_loss: 0.2006 - val_accuracy: 0.9210\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2347 - accuracy: 0.8968 - val_loss: 0.2242 - val_accuracy: 0.9031\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2390 - accuracy: 0.8901 - val_loss: 0.2296 - val_accuracy: 0.8992\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2348 - accuracy: 0.8947 - val_loss: 0.2023 - val_accuracy: 0.9107\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2102 - accuracy: 0.9082 - val_loss: 0.2053 - val_accuracy: 0.9078\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2159 - accuracy: 0.9051 - val_loss: 0.1895 - val_accuracy: 0.9185\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2032 - accuracy: 0.9115 - val_loss: 0.1960 - val_accuracy: 0.9081\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1964 - accuracy: 0.9159 - val_loss: 0.2547 - val_accuracy: 0.8910\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4906 - accuracy: 0.7404 - val_loss: 0.3900 - val_accuracy: 0.7970\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3258 - accuracy: 0.8475 - val_loss: 0.2621 - val_accuracy: 0.8763\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2900 - accuracy: 0.8589 - val_loss: 0.2942 - val_accuracy: 0.8706\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2847 - accuracy: 0.8620 - val_loss: 0.2503 - val_accuracy: 0.8760\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3300 - accuracy: 0.8461 - val_loss: 0.4271 - val_accuracy: 0.7977\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3982 - accuracy: 0.7596 - val_loss: 0.3999 - val_accuracy: 0.7294\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3808 - accuracy: 0.8003 - val_loss: 0.2812 - val_accuracy: 0.8756\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2988 - accuracy: 0.8599 - val_loss: 0.2663 - val_accuracy: 0.8742\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2780 - accuracy: 0.8653 - val_loss: 0.2485 - val_accuracy: 0.8749\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2913 - accuracy: 0.8595 - val_loss: 0.2580 - val_accuracy: 0.8738\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2741 - accuracy: 0.8676 - val_loss: 0.2871 - val_accuracy: 0.8688\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2680 - accuracy: 0.8676 - val_loss: 0.2461 - val_accuracy: 0.8785\n",
      "Epoch 34/500\n",
      "330/333 [============================>.] - ETA: 0s - loss: 0.2775 - accuracy: 0.8654Restoring model weights from the end of the best epoch: 14.\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2774 - accuracy: 0.8655 - val_loss: 0.2692 - val_accuracy: 0.8681\n",
      "Epoch 34: early stopping\n",
      "Number of iterations 6\n",
      "F1-scores:  [0.794888178913738, 0.9737324373854611, 0.8083333333333333, 0.9412484700122399, 0.9457177322074789, 0.863664404688464]\n",
      "Average F1-Score 0.8879307594234525\n",
      "Std Dev F1-Score 0.06967252976995396\n",
      "Error bar F1-Score 0.02844369117087631\n",
      "Epoch 1/500\n",
      "333/333 [==============================] - 11s 19ms/step - loss: 0.5491 - accuracy: 0.7138 - val_loss: 0.5062 - val_accuracy: 0.7395\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5122 - accuracy: 0.7181 - val_loss: 0.4921 - val_accuracy: 0.7323\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5061 - accuracy: 0.7270 - val_loss: 0.4384 - val_accuracy: 0.7630\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4540 - accuracy: 0.7448 - val_loss: 0.4715 - val_accuracy: 0.7309\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4216 - accuracy: 0.7618 - val_loss: 0.3652 - val_accuracy: 0.8052\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3604 - accuracy: 0.8197 - val_loss: 0.3357 - val_accuracy: 0.8331\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3315 - accuracy: 0.8387 - val_loss: 0.2849 - val_accuracy: 0.8592\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3226 - accuracy: 0.8466 - val_loss: 0.3325 - val_accuracy: 0.8345\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3079 - accuracy: 0.8535 - val_loss: 0.2760 - val_accuracy: 0.8620\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2884 - accuracy: 0.8638 - val_loss: 0.2563 - val_accuracy: 0.8735\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3013 - accuracy: 0.8555 - val_loss: 0.2652 - val_accuracy: 0.8670\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2809 - accuracy: 0.8667 - val_loss: 0.3534 - val_accuracy: 0.8263\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2791 - accuracy: 0.8669 - val_loss: 0.2453 - val_accuracy: 0.8788\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2785 - accuracy: 0.8650 - val_loss: 0.2438 - val_accuracy: 0.8753\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3283 - accuracy: 0.8424 - val_loss: 0.2726 - val_accuracy: 0.8796\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2827 - accuracy: 0.8645 - val_loss: 0.2623 - val_accuracy: 0.8756\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2806 - accuracy: 0.8638 - val_loss: 0.2542 - val_accuracy: 0.8753\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2724 - accuracy: 0.8678 - val_loss: 0.2560 - val_accuracy: 0.8703\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2842 - accuracy: 0.8646 - val_loss: 0.2958 - val_accuracy: 0.8778\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2901 - accuracy: 0.8618 - val_loss: 0.2497 - val_accuracy: 0.8778\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2735 - accuracy: 0.8681 - val_loss: 0.2408 - val_accuracy: 0.8849\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2765 - accuracy: 0.8668 - val_loss: 0.7073 - val_accuracy: 0.7827\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2850 - accuracy: 0.8645 - val_loss: 0.2387 - val_accuracy: 0.8817\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2721 - accuracy: 0.8697 - val_loss: 0.2369 - val_accuracy: 0.8846\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2726 - accuracy: 0.8681 - val_loss: 0.2658 - val_accuracy: 0.8785\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2725 - accuracy: 0.8678 - val_loss: 0.2361 - val_accuracy: 0.8813\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2773 - accuracy: 0.8662 - val_loss: 0.2685 - val_accuracy: 0.8756\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2779 - accuracy: 0.8669 - val_loss: 0.2694 - val_accuracy: 0.8685\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2703 - accuracy: 0.8690 - val_loss: 0.2365 - val_accuracy: 0.8767\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2686 - accuracy: 0.8694 - val_loss: 0.2372 - val_accuracy: 0.8810\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2666 - accuracy: 0.8700 - val_loss: 0.2439 - val_accuracy: 0.8821\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2701 - accuracy: 0.8678 - val_loss: 0.2392 - val_accuracy: 0.8746\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2632 - accuracy: 0.8725 - val_loss: 0.2426 - val_accuracy: 0.8778\n",
      "Epoch 34/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2758 - accuracy: 0.8676 - val_loss: 0.2464 - val_accuracy: 0.8860\n",
      "Epoch 35/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4765 - accuracy: 0.7720 - val_loss: 0.6011 - val_accuracy: 0.7127\n",
      "Epoch 36/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5247 - accuracy: 0.7254 - val_loss: 0.3730 - val_accuracy: 0.8706\n",
      "Epoch 37/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5007 - accuracy: 0.7286 - val_loss: 0.4921 - val_accuracy: 0.7391\n",
      "Epoch 38/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5083 - accuracy: 0.7287 - val_loss: 0.4909 - val_accuracy: 0.7416\n",
      "Epoch 39/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5149 - accuracy: 0.7210 - val_loss: 0.4920 - val_accuracy: 0.7316\n",
      "Epoch 40/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4989 - accuracy: 0.7306 - val_loss: 0.5156 - val_accuracy: 0.7205\n",
      "Epoch 41/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4940 - accuracy: 0.7325 - val_loss: 0.4868 - val_accuracy: 0.7341\n",
      "Epoch 42/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4901 - accuracy: 0.7381 - val_loss: 0.4885 - val_accuracy: 0.7380\n",
      "Epoch 43/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4927 - accuracy: 0.7325 - val_loss: 0.4900 - val_accuracy: 0.7355\n",
      "Epoch 44/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4934 - accuracy: 0.7298 - val_loss: 0.4825 - val_accuracy: 0.7409\n",
      "Epoch 45/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4881 - accuracy: 0.7371 - val_loss: 0.4775 - val_accuracy: 0.7412\n",
      "Epoch 46/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4842 - accuracy: 0.7420 - val_loss: 0.4756 - val_accuracy: 0.7409\n",
      "Epoch 47/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4831 - accuracy: 0.7401 - val_loss: 0.4827 - val_accuracy: 0.7373\n",
      "Epoch 48/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4774 - accuracy: 0.7460 - val_loss: 0.4106 - val_accuracy: 0.7763\n",
      "Epoch 49/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3986 - accuracy: 0.7764 - val_loss: 0.3574 - val_accuracy: 0.7949\n",
      "Epoch 50/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4300 - accuracy: 0.7623 - val_loss: 0.3546 - val_accuracy: 0.7949\n",
      "Epoch 51/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3840 - accuracy: 0.7798 - val_loss: 0.3547 - val_accuracy: 0.7966\n",
      "Epoch 52/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3918 - accuracy: 0.7613 - val_loss: 0.4372 - val_accuracy: 0.7259\n",
      "Epoch 53/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3548 - accuracy: 0.8055 - val_loss: 0.2687 - val_accuracy: 0.8728\n",
      "Epoch 54/500\n",
      "330/333 [============================>.] - ETA: 0s - loss: 0.2898 - accuracy: 0.8616Restoring model weights from the end of the best epoch: 34.\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2897 - accuracy: 0.8618 - val_loss: 0.2487 - val_accuracy: 0.8781\n",
      "Epoch 54: early stopping\n",
      "Number of iterations 7\n",
      "F1-scores:  [0.794888178913738, 0.9737324373854611, 0.8083333333333333, 0.9412484700122399, 0.9457177322074789, 0.863664404688464, 0.8053691275167786]\n",
      "Average F1-Score 0.8761362405796419\n",
      "Std Dev F1-Score 0.07067856491293607\n",
      "Error bar F1-Score 0.02671398654036634\n",
      "Epoch 1/500\n",
      "333/333 [==============================] - 11s 18ms/step - loss: 0.5867 - accuracy: 0.7105 - val_loss: 0.4997 - val_accuracy: 0.6780\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4994 - accuracy: 0.7175 - val_loss: 0.3955 - val_accuracy: 0.7445\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3759 - accuracy: 0.8153 - val_loss: 0.3374 - val_accuracy: 0.8613\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3425 - accuracy: 0.8367 - val_loss: 0.4324 - val_accuracy: 0.7813\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3115 - accuracy: 0.8550 - val_loss: 0.2676 - val_accuracy: 0.8735\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3079 - accuracy: 0.8558 - val_loss: 0.2725 - val_accuracy: 0.8756\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2949 - accuracy: 0.8602 - val_loss: 0.3228 - val_accuracy: 0.8663\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3018 - accuracy: 0.8593 - val_loss: 0.2915 - val_accuracy: 0.8470\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2988 - accuracy: 0.8570 - val_loss: 0.2903 - val_accuracy: 0.8749\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2856 - accuracy: 0.8641 - val_loss: 0.2460 - val_accuracy: 0.8738\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2893 - accuracy: 0.8616 - val_loss: 0.2692 - val_accuracy: 0.8670\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2909 - accuracy: 0.8622 - val_loss: 0.2596 - val_accuracy: 0.8706\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2762 - accuracy: 0.8645 - val_loss: 0.5974 - val_accuracy: 0.7323\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4836 - accuracy: 0.7690 - val_loss: 0.3443 - val_accuracy: 0.8427\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3103 - accuracy: 0.8549 - val_loss: 0.2965 - val_accuracy: 0.8685\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3024 - accuracy: 0.8554 - val_loss: 0.2959 - val_accuracy: 0.8585\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3486 - accuracy: 0.8225 - val_loss: 0.2763 - val_accuracy: 0.8771\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3032 - accuracy: 0.8572 - val_loss: 0.2547 - val_accuracy: 0.8717\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2894 - accuracy: 0.8623 - val_loss: 0.2701 - val_accuracy: 0.8713\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2958 - accuracy: 0.8607 - val_loss: 0.2576 - val_accuracy: 0.8792\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2873 - accuracy: 0.8626 - val_loss: 0.2529 - val_accuracy: 0.8767\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2828 - accuracy: 0.8628 - val_loss: 0.2609 - val_accuracy: 0.8713\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2949 - accuracy: 0.8574 - val_loss: 0.3742 - val_accuracy: 0.8134\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2840 - accuracy: 0.8645 - val_loss: 0.3799 - val_accuracy: 0.8313\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3026 - accuracy: 0.8577 - val_loss: 0.2658 - val_accuracy: 0.8624\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2885 - accuracy: 0.8622 - val_loss: 0.2485 - val_accuracy: 0.8760\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2746 - accuracy: 0.8637 - val_loss: 0.2513 - val_accuracy: 0.8735\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2806 - accuracy: 0.8656 - val_loss: 0.2423 - val_accuracy: 0.8717\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2780 - accuracy: 0.8659 - val_loss: 0.2741 - val_accuracy: 0.8635\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2791 - accuracy: 0.8632 - val_loss: 0.2452 - val_accuracy: 0.8803\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2743 - accuracy: 0.8649 - val_loss: 0.2513 - val_accuracy: 0.8781\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2781 - accuracy: 0.8669 - val_loss: 0.2580 - val_accuracy: 0.8767\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2681 - accuracy: 0.8702 - val_loss: 0.2617 - val_accuracy: 0.8742\n",
      "Epoch 34/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3042 - accuracy: 0.8582 - val_loss: 0.2472 - val_accuracy: 0.8771\n",
      "Epoch 35/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2791 - accuracy: 0.8631 - val_loss: 0.2439 - val_accuracy: 0.8871\n",
      "Epoch 36/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3261 - accuracy: 0.8347 - val_loss: 0.2650 - val_accuracy: 0.8767\n",
      "Epoch 37/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3009 - accuracy: 0.8542 - val_loss: 0.3506 - val_accuracy: 0.8710\n",
      "Epoch 38/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2743 - accuracy: 0.8681 - val_loss: 0.2805 - val_accuracy: 0.8799\n",
      "Epoch 39/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2817 - accuracy: 0.8645 - val_loss: 0.2423 - val_accuracy: 0.8756\n",
      "Epoch 40/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2776 - accuracy: 0.8643 - val_loss: 0.2471 - val_accuracy: 0.8817\n",
      "Epoch 41/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2787 - accuracy: 0.8640 - val_loss: 0.2428 - val_accuracy: 0.8792\n",
      "Epoch 42/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2800 - accuracy: 0.8652 - val_loss: 0.2357 - val_accuracy: 0.8831\n",
      "Epoch 43/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2716 - accuracy: 0.8686 - val_loss: 0.2478 - val_accuracy: 0.8728\n",
      "Epoch 44/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2665 - accuracy: 0.8689 - val_loss: 0.2335 - val_accuracy: 0.8792\n",
      "Epoch 45/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2665 - accuracy: 0.8689 - val_loss: 0.4003 - val_accuracy: 0.8127\n",
      "Epoch 46/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2718 - accuracy: 0.8690 - val_loss: 0.2633 - val_accuracy: 0.8717\n",
      "Epoch 47/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2700 - accuracy: 0.8665 - val_loss: 0.2350 - val_accuracy: 0.8763\n",
      "Epoch 48/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3057 - accuracy: 0.8539 - val_loss: 0.2420 - val_accuracy: 0.8810\n",
      "Epoch 49/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2767 - accuracy: 0.8694 - val_loss: 0.2357 - val_accuracy: 0.8796\n",
      "Epoch 50/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2746 - accuracy: 0.8678 - val_loss: 0.2412 - val_accuracy: 0.8774\n",
      "Epoch 51/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2837 - accuracy: 0.8655 - val_loss: 0.2396 - val_accuracy: 0.8792\n",
      "Epoch 52/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2763 - accuracy: 0.8645 - val_loss: 0.2383 - val_accuracy: 0.8817\n",
      "Epoch 53/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2685 - accuracy: 0.8698 - val_loss: 0.2368 - val_accuracy: 0.8831\n",
      "Epoch 54/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2739 - accuracy: 0.8663 - val_loss: 0.2507 - val_accuracy: 0.8692\n",
      "Epoch 55/500\n",
      "333/333 [==============================] - ETA: 0s - loss: 0.2641 - accuracy: 0.8701Restoring model weights from the end of the best epoch: 35.\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2641 - accuracy: 0.8701 - val_loss: 0.2467 - val_accuracy: 0.8781\n",
      "Epoch 55: early stopping\n",
      "Number of iterations 8\n",
      "F1-scores:  [0.794888178913738, 0.9737324373854611, 0.8083333333333333, 0.9412484700122399, 0.9457177322074789, 0.863664404688464, 0.8053691275167786, 0.8134592680047226]\n",
      "Average F1-Score 0.868301619007777\n",
      "Std Dev F1-Score 0.06928705623782426\n",
      "Error bar F1-Score 0.024496673657109603\n",
      "Epoch 1/500\n",
      "333/333 [==============================] - 11s 18ms/step - loss: 0.5626 - accuracy: 0.7074 - val_loss: 0.5250 - val_accuracy: 0.7127\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5156 - accuracy: 0.7192 - val_loss: 0.5061 - val_accuracy: 0.7116\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5122 - accuracy: 0.7241 - val_loss: 0.5057 - val_accuracy: 0.7437\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5044 - accuracy: 0.7287 - val_loss: 0.4833 - val_accuracy: 0.7412\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5019 - accuracy: 0.7279 - val_loss: 0.5200 - val_accuracy: 0.7073\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4889 - accuracy: 0.7330 - val_loss: 0.4699 - val_accuracy: 0.7527\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4699 - accuracy: 0.7415 - val_loss: 0.4548 - val_accuracy: 0.7470\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4468 - accuracy: 0.7559 - val_loss: 0.4223 - val_accuracy: 0.7848\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4264 - accuracy: 0.7805 - val_loss: 0.3640 - val_accuracy: 0.8335\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3347 - accuracy: 0.8444 - val_loss: 0.2670 - val_accuracy: 0.8824\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2733 - accuracy: 0.8771 - val_loss: 0.2599 - val_accuracy: 0.8849\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2597 - accuracy: 0.8844 - val_loss: 0.2455 - val_accuracy: 0.8906\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2413 - accuracy: 0.8928 - val_loss: 0.3605 - val_accuracy: 0.8385\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2328 - accuracy: 0.8933 - val_loss: 0.1953 - val_accuracy: 0.9089\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2175 - accuracy: 0.9043 - val_loss: 0.1943 - val_accuracy: 0.9078\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2027 - accuracy: 0.9116 - val_loss: 0.2081 - val_accuracy: 0.9171\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2063 - accuracy: 0.9099 - val_loss: 0.1758 - val_accuracy: 0.9253\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2104 - accuracy: 0.9061 - val_loss: 0.1762 - val_accuracy: 0.9289\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2006 - accuracy: 0.9127 - val_loss: 0.1845 - val_accuracy: 0.9171\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1891 - accuracy: 0.9177 - val_loss: 0.1865 - val_accuracy: 0.9153\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1882 - accuracy: 0.9177 - val_loss: 0.1698 - val_accuracy: 0.9299\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1865 - accuracy: 0.9170 - val_loss: 0.1612 - val_accuracy: 0.9325\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1828 - accuracy: 0.9175 - val_loss: 0.1603 - val_accuracy: 0.9346\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1833 - accuracy: 0.9218 - val_loss: 0.1621 - val_accuracy: 0.9335\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1768 - accuracy: 0.9238 - val_loss: 0.1715 - val_accuracy: 0.9264\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2068 - accuracy: 0.9078 - val_loss: 0.1517 - val_accuracy: 0.9364\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1735 - accuracy: 0.9237 - val_loss: 0.1460 - val_accuracy: 0.9421\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1708 - accuracy: 0.9264 - val_loss: 0.1535 - val_accuracy: 0.9371\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1920 - accuracy: 0.9163 - val_loss: 0.1828 - val_accuracy: 0.9235\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1635 - accuracy: 0.9284 - val_loss: 0.1408 - val_accuracy: 0.9371\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1565 - accuracy: 0.9327 - val_loss: 0.1428 - val_accuracy: 0.9392\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1598 - accuracy: 0.9323 - val_loss: 0.1588 - val_accuracy: 0.9367\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1646 - accuracy: 0.9311 - val_loss: 0.1352 - val_accuracy: 0.9467\n",
      "Epoch 34/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1617 - accuracy: 0.9307 - val_loss: 0.1407 - val_accuracy: 0.9428\n",
      "Epoch 35/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1664 - accuracy: 0.9303 - val_loss: 0.1873 - val_accuracy: 0.9192\n",
      "Epoch 36/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1503 - accuracy: 0.9371 - val_loss: 0.2698 - val_accuracy: 0.8767\n",
      "Epoch 37/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1506 - accuracy: 0.9359 - val_loss: 0.4106 - val_accuracy: 0.8066\n",
      "Epoch 38/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1508 - accuracy: 0.9372 - val_loss: 0.1550 - val_accuracy: 0.9364\n",
      "Epoch 39/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1497 - accuracy: 0.9386 - val_loss: 0.1196 - val_accuracy: 0.9532\n",
      "Epoch 40/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1338 - accuracy: 0.9457 - val_loss: 0.1784 - val_accuracy: 0.9339\n",
      "Epoch 41/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1435 - accuracy: 0.9409 - val_loss: 0.1504 - val_accuracy: 0.9378\n",
      "Epoch 42/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1393 - accuracy: 0.9423 - val_loss: 0.1218 - val_accuracy: 0.9521\n",
      "Epoch 43/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1297 - accuracy: 0.9475 - val_loss: 0.1153 - val_accuracy: 0.9553\n",
      "Epoch 44/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1389 - accuracy: 0.9435 - val_loss: 0.1202 - val_accuracy: 0.9546\n",
      "Epoch 45/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1211 - accuracy: 0.9511 - val_loss: 0.1287 - val_accuracy: 0.9478\n",
      "Epoch 46/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1285 - accuracy: 0.9498 - val_loss: 0.1306 - val_accuracy: 0.9446\n",
      "Epoch 47/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1279 - accuracy: 0.9496 - val_loss: 0.1072 - val_accuracy: 0.9582\n",
      "Epoch 48/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1187 - accuracy: 0.9519 - val_loss: 0.1491 - val_accuracy: 0.9335\n",
      "Epoch 49/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1176 - accuracy: 0.9549 - val_loss: 0.1050 - val_accuracy: 0.9625\n",
      "Epoch 50/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1157 - accuracy: 0.9542 - val_loss: 0.1212 - val_accuracy: 0.9514\n",
      "Epoch 51/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1118 - accuracy: 0.9562 - val_loss: 0.1122 - val_accuracy: 0.9557\n",
      "Epoch 52/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1144 - accuracy: 0.9546 - val_loss: 0.1152 - val_accuracy: 0.9503\n",
      "Epoch 53/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1072 - accuracy: 0.9577 - val_loss: 0.1247 - val_accuracy: 0.9510\n",
      "Epoch 54/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1101 - accuracy: 0.9572 - val_loss: 0.1475 - val_accuracy: 0.9478\n",
      "Epoch 55/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1138 - accuracy: 0.9550 - val_loss: 0.1304 - val_accuracy: 0.9439\n",
      "Epoch 56/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0991 - accuracy: 0.9619 - val_loss: 0.0998 - val_accuracy: 0.9610\n",
      "Epoch 57/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1102 - accuracy: 0.9575 - val_loss: 0.1109 - val_accuracy: 0.9525\n",
      "Epoch 58/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1024 - accuracy: 0.9581 - val_loss: 0.1050 - val_accuracy: 0.9575\n",
      "Epoch 59/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1102 - accuracy: 0.9556 - val_loss: 0.1609 - val_accuracy: 0.9257\n",
      "Epoch 60/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1052 - accuracy: 0.9577 - val_loss: 0.1608 - val_accuracy: 0.9360\n",
      "Epoch 61/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1236 - accuracy: 0.9499 - val_loss: 0.1338 - val_accuracy: 0.9453\n",
      "Epoch 62/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1125 - accuracy: 0.9550 - val_loss: 0.1385 - val_accuracy: 0.9414\n",
      "Epoch 63/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1000 - accuracy: 0.9615 - val_loss: 0.1362 - val_accuracy: 0.9464\n",
      "Epoch 64/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0932 - accuracy: 0.9637 - val_loss: 0.0983 - val_accuracy: 0.9618\n",
      "Epoch 65/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0989 - accuracy: 0.9612 - val_loss: 0.0957 - val_accuracy: 0.9650\n",
      "Epoch 66/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1351 - accuracy: 0.9462 - val_loss: 0.1039 - val_accuracy: 0.9543\n",
      "Epoch 67/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0994 - accuracy: 0.9617 - val_loss: 0.1070 - val_accuracy: 0.9546\n",
      "Epoch 68/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0924 - accuracy: 0.9645 - val_loss: 0.1145 - val_accuracy: 0.9571\n",
      "Epoch 69/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0883 - accuracy: 0.9657 - val_loss: 0.1108 - val_accuracy: 0.9564\n",
      "Epoch 70/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0877 - accuracy: 0.9663 - val_loss: 0.0896 - val_accuracy: 0.9696\n",
      "Epoch 71/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0851 - accuracy: 0.9674 - val_loss: 0.0912 - val_accuracy: 0.9653\n",
      "Epoch 72/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0959 - accuracy: 0.9637 - val_loss: 0.1171 - val_accuracy: 0.9546\n",
      "Epoch 73/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0818 - accuracy: 0.9693 - val_loss: 0.1336 - val_accuracy: 0.9510\n",
      "Epoch 74/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0904 - accuracy: 0.9657 - val_loss: 0.1004 - val_accuracy: 0.9618\n",
      "Epoch 75/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0822 - accuracy: 0.9692 - val_loss: 0.1066 - val_accuracy: 0.9575\n",
      "Epoch 76/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0817 - accuracy: 0.9693 - val_loss: 0.0866 - val_accuracy: 0.9671\n",
      "Epoch 77/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0841 - accuracy: 0.9669 - val_loss: 0.0897 - val_accuracy: 0.9646\n",
      "Epoch 78/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0867 - accuracy: 0.9677 - val_loss: 0.1077 - val_accuracy: 0.9578\n",
      "Epoch 79/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0811 - accuracy: 0.9694 - val_loss: 0.1741 - val_accuracy: 0.9339\n",
      "Epoch 80/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0886 - accuracy: 0.9654 - val_loss: 0.1144 - val_accuracy: 0.9543\n",
      "Epoch 81/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0907 - accuracy: 0.9623 - val_loss: 0.0953 - val_accuracy: 0.9635\n",
      "Epoch 82/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0821 - accuracy: 0.9673 - val_loss: 0.1095 - val_accuracy: 0.9564\n",
      "Epoch 83/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0779 - accuracy: 0.9701 - val_loss: 0.0849 - val_accuracy: 0.9664\n",
      "Epoch 84/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0848 - accuracy: 0.9668 - val_loss: 0.0865 - val_accuracy: 0.9668\n",
      "Epoch 85/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0764 - accuracy: 0.9709 - val_loss: 0.0898 - val_accuracy: 0.9700\n",
      "Epoch 86/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0821 - accuracy: 0.9694 - val_loss: 0.0913 - val_accuracy: 0.9675\n",
      "Epoch 87/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0713 - accuracy: 0.9733 - val_loss: 0.1013 - val_accuracy: 0.9635\n",
      "Epoch 88/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0790 - accuracy: 0.9704 - val_loss: 0.0847 - val_accuracy: 0.9703\n",
      "Epoch 89/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0737 - accuracy: 0.9724 - val_loss: 0.0902 - val_accuracy: 0.9660\n",
      "Epoch 90/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0674 - accuracy: 0.9755 - val_loss: 0.0947 - val_accuracy: 0.9653\n",
      "Epoch 91/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0690 - accuracy: 0.9732 - val_loss: 0.1271 - val_accuracy: 0.9503\n",
      "Epoch 92/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0642 - accuracy: 0.9757 - val_loss: 0.1464 - val_accuracy: 0.9464\n",
      "Epoch 93/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0665 - accuracy: 0.9752 - val_loss: 0.0910 - val_accuracy: 0.9650\n",
      "Epoch 94/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0680 - accuracy: 0.9737 - val_loss: 0.0765 - val_accuracy: 0.9714\n",
      "Epoch 95/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0634 - accuracy: 0.9763 - val_loss: 0.0903 - val_accuracy: 0.9664\n",
      "Epoch 96/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0740 - accuracy: 0.9726 - val_loss: 0.1025 - val_accuracy: 0.9610\n",
      "Epoch 97/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0788 - accuracy: 0.9692 - val_loss: 0.1123 - val_accuracy: 0.9568\n",
      "Epoch 98/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0755 - accuracy: 0.9726 - val_loss: 0.0728 - val_accuracy: 0.9778\n",
      "Epoch 99/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0620 - accuracy: 0.9767 - val_loss: 0.0942 - val_accuracy: 0.9660\n",
      "Epoch 100/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0651 - accuracy: 0.9752 - val_loss: 0.0984 - val_accuracy: 0.9646\n",
      "Epoch 101/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0631 - accuracy: 0.9757 - val_loss: 0.0859 - val_accuracy: 0.9678\n",
      "Epoch 102/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0607 - accuracy: 0.9777 - val_loss: 0.0759 - val_accuracy: 0.9728\n",
      "Epoch 103/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0646 - accuracy: 0.9751 - val_loss: 0.1750 - val_accuracy: 0.9335\n",
      "Epoch 104/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0734 - accuracy: 0.9725 - val_loss: 0.1060 - val_accuracy: 0.9635\n",
      "Epoch 105/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0815 - accuracy: 0.9683 - val_loss: 0.0971 - val_accuracy: 0.9621\n",
      "Epoch 106/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0625 - accuracy: 0.9761 - val_loss: 0.0740 - val_accuracy: 0.9746\n",
      "Epoch 107/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0692 - accuracy: 0.9756 - val_loss: 0.0877 - val_accuracy: 0.9675\n",
      "Epoch 108/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0608 - accuracy: 0.9780 - val_loss: 0.0743 - val_accuracy: 0.9771\n",
      "Epoch 109/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0651 - accuracy: 0.9747 - val_loss: 0.0730 - val_accuracy: 0.9736\n",
      "Epoch 110/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0529 - accuracy: 0.9796 - val_loss: 0.0806 - val_accuracy: 0.9707\n",
      "Epoch 111/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0585 - accuracy: 0.9790 - val_loss: 0.0809 - val_accuracy: 0.9721\n",
      "Epoch 112/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0590 - accuracy: 0.9770 - val_loss: 0.1043 - val_accuracy: 0.9657\n",
      "Epoch 113/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0518 - accuracy: 0.9809 - val_loss: 0.0904 - val_accuracy: 0.9653\n",
      "Epoch 114/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0771 - accuracy: 0.9713 - val_loss: 0.0846 - val_accuracy: 0.9696\n",
      "Epoch 115/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0616 - accuracy: 0.9769 - val_loss: 0.0743 - val_accuracy: 0.9753\n",
      "Epoch 116/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0495 - accuracy: 0.9818 - val_loss: 0.0817 - val_accuracy: 0.9746\n",
      "Epoch 117/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0513 - accuracy: 0.9798 - val_loss: 0.0857 - val_accuracy: 0.9703\n",
      "Epoch 118/500\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.0451 - accuracy: 0.9831Restoring model weights from the end of the best epoch: 98.\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0451 - accuracy: 0.9831 - val_loss: 0.0735 - val_accuracy: 0.9761\n",
      "Epoch 118: early stopping\n",
      "Number of iterations 9\n",
      "F1-scores:  [0.794888178913738, 0.9737324373854611, 0.8083333333333333, 0.9412484700122399, 0.9457177322074789, 0.863664404688464, 0.8053691275167786, 0.8134592680047226, 0.961346633416459]\n",
      "Average F1-Score 0.878639953942075\n",
      "Std Dev F1-Score 0.07157048854894785\n",
      "Error bar F1-Score 0.023856829516315948\n",
      "Epoch 1/500\n",
      "333/333 [==============================] - 12s 18ms/step - loss: 0.5747 - accuracy: 0.7107 - val_loss: 0.5728 - val_accuracy: 0.7127\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5725 - accuracy: 0.7077 - val_loss: 0.5443 - val_accuracy: 0.7098\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4748 - accuracy: 0.7507 - val_loss: 0.3772 - val_accuracy: 0.8295\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3900 - accuracy: 0.8041 - val_loss: 0.3464 - val_accuracy: 0.8506\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3236 - accuracy: 0.8481 - val_loss: 0.2716 - val_accuracy: 0.8685\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3103 - accuracy: 0.8553 - val_loss: 0.2763 - val_accuracy: 0.8710\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3030 - accuracy: 0.8573 - val_loss: 0.3893 - val_accuracy: 0.8642\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2970 - accuracy: 0.8588 - val_loss: 0.3799 - val_accuracy: 0.8156\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2944 - accuracy: 0.8623 - val_loss: 0.2548 - val_accuracy: 0.8756\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2794 - accuracy: 0.8644 - val_loss: 0.2476 - val_accuracy: 0.8813\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2808 - accuracy: 0.8646 - val_loss: 0.2489 - val_accuracy: 0.8742\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2697 - accuracy: 0.8702 - val_loss: 0.2700 - val_accuracy: 0.8792\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2722 - accuracy: 0.8686 - val_loss: 0.2284 - val_accuracy: 0.8867\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2802 - accuracy: 0.8644 - val_loss: 0.3070 - val_accuracy: 0.8506\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2682 - accuracy: 0.8686 - val_loss: 0.2363 - val_accuracy: 0.8974\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2589 - accuracy: 0.8755 - val_loss: 0.2392 - val_accuracy: 0.8753\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2429 - accuracy: 0.8829 - val_loss: 0.1945 - val_accuracy: 0.9149\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2373 - accuracy: 0.8853 - val_loss: 0.1847 - val_accuracy: 0.9210\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2290 - accuracy: 0.8944 - val_loss: 0.2248 - val_accuracy: 0.8874\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2244 - accuracy: 0.8936 - val_loss: 0.2061 - val_accuracy: 0.9035\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2270 - accuracy: 0.8940 - val_loss: 0.2066 - val_accuracy: 0.9185\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2180 - accuracy: 0.9005 - val_loss: 0.2098 - val_accuracy: 0.9017\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2067 - accuracy: 0.9027 - val_loss: 0.2195 - val_accuracy: 0.8974\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2162 - accuracy: 0.9006 - val_loss: 0.1838 - val_accuracy: 0.9203\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2185 - accuracy: 0.8995 - val_loss: 0.1807 - val_accuracy: 0.9232\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2043 - accuracy: 0.9067 - val_loss: 0.1888 - val_accuracy: 0.9132\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1997 - accuracy: 0.9094 - val_loss: 0.1682 - val_accuracy: 0.9260\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1975 - accuracy: 0.9124 - val_loss: 0.2121 - val_accuracy: 0.9014\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1996 - accuracy: 0.9095 - val_loss: 0.1583 - val_accuracy: 0.9328\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1931 - accuracy: 0.9135 - val_loss: 0.1739 - val_accuracy: 0.9235\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1914 - accuracy: 0.9146 - val_loss: 0.2468 - val_accuracy: 0.8831\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1910 - accuracy: 0.9148 - val_loss: 0.1717 - val_accuracy: 0.9228\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1927 - accuracy: 0.9143 - val_loss: 0.3003 - val_accuracy: 0.8785\n",
      "Epoch 34/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1841 - accuracy: 0.9168 - val_loss: 0.1444 - val_accuracy: 0.9392\n",
      "Epoch 35/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1921 - accuracy: 0.9142 - val_loss: 0.1835 - val_accuracy: 0.9142\n",
      "Epoch 36/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1831 - accuracy: 0.9179 - val_loss: 0.1655 - val_accuracy: 0.9257\n",
      "Epoch 37/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1811 - accuracy: 0.9196 - val_loss: 0.1590 - val_accuracy: 0.9285\n",
      "Epoch 38/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1763 - accuracy: 0.9225 - val_loss: 0.2978 - val_accuracy: 0.8828\n",
      "Epoch 39/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1915 - accuracy: 0.9141 - val_loss: 0.1433 - val_accuracy: 0.9392\n",
      "Epoch 40/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1778 - accuracy: 0.9207 - val_loss: 0.1523 - val_accuracy: 0.9339\n",
      "Epoch 41/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1705 - accuracy: 0.9246 - val_loss: 0.2747 - val_accuracy: 0.8713\n",
      "Epoch 42/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1672 - accuracy: 0.9278 - val_loss: 0.1613 - val_accuracy: 0.9260\n",
      "Epoch 43/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1737 - accuracy: 0.9247 - val_loss: 0.1618 - val_accuracy: 0.9271\n",
      "Epoch 44/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1689 - accuracy: 0.9258 - val_loss: 0.1565 - val_accuracy: 0.9360\n",
      "Epoch 45/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1648 - accuracy: 0.9289 - val_loss: 0.1867 - val_accuracy: 0.9135\n",
      "Epoch 46/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1600 - accuracy: 0.9296 - val_loss: 0.1612 - val_accuracy: 0.9321\n",
      "Epoch 47/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1692 - accuracy: 0.9270 - val_loss: 0.1429 - val_accuracy: 0.9375\n",
      "Epoch 48/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1689 - accuracy: 0.9261 - val_loss: 0.1565 - val_accuracy: 0.9353\n",
      "Epoch 49/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1557 - accuracy: 0.9329 - val_loss: 0.1263 - val_accuracy: 0.9503\n",
      "Epoch 50/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1745 - accuracy: 0.9253 - val_loss: 0.1586 - val_accuracy: 0.9274\n",
      "Epoch 51/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1579 - accuracy: 0.9331 - val_loss: 0.1399 - val_accuracy: 0.9407\n",
      "Epoch 52/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1550 - accuracy: 0.9355 - val_loss: 0.1493 - val_accuracy: 0.9339\n",
      "Epoch 53/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1614 - accuracy: 0.9317 - val_loss: 0.1261 - val_accuracy: 0.9482\n",
      "Epoch 54/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1548 - accuracy: 0.9339 - val_loss: 0.1281 - val_accuracy: 0.9471\n",
      "Epoch 55/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1454 - accuracy: 0.9385 - val_loss: 0.1093 - val_accuracy: 0.9553\n",
      "Epoch 56/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1502 - accuracy: 0.9379 - val_loss: 0.1184 - val_accuracy: 0.9500\n",
      "Epoch 57/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1433 - accuracy: 0.9409 - val_loss: 0.1549 - val_accuracy: 0.9321\n",
      "Epoch 58/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1435 - accuracy: 0.9379 - val_loss: 0.1323 - val_accuracy: 0.9400\n",
      "Epoch 59/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1416 - accuracy: 0.9411 - val_loss: 0.1130 - val_accuracy: 0.9535\n",
      "Epoch 60/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1361 - accuracy: 0.9447 - val_loss: 0.1303 - val_accuracy: 0.9457\n",
      "Epoch 61/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1497 - accuracy: 0.9368 - val_loss: 0.2050 - val_accuracy: 0.9110\n",
      "Epoch 62/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1347 - accuracy: 0.9453 - val_loss: 0.1163 - val_accuracy: 0.9564\n",
      "Epoch 63/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1320 - accuracy: 0.9468 - val_loss: 0.1297 - val_accuracy: 0.9432\n",
      "Epoch 64/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1288 - accuracy: 0.9473 - val_loss: 0.1341 - val_accuracy: 0.9410\n",
      "Epoch 65/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1669 - accuracy: 0.9308 - val_loss: 0.1675 - val_accuracy: 0.9228\n",
      "Epoch 66/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1310 - accuracy: 0.9456 - val_loss: 0.1178 - val_accuracy: 0.9571\n",
      "Epoch 67/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1239 - accuracy: 0.9501 - val_loss: 0.1236 - val_accuracy: 0.9457\n",
      "Epoch 68/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1322 - accuracy: 0.9456 - val_loss: 0.1015 - val_accuracy: 0.9578\n",
      "Epoch 69/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1233 - accuracy: 0.9493 - val_loss: 0.1248 - val_accuracy: 0.9503\n",
      "Epoch 70/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1187 - accuracy: 0.9524 - val_loss: 0.1049 - val_accuracy: 0.9607\n",
      "Epoch 71/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1385 - accuracy: 0.9435 - val_loss: 0.1299 - val_accuracy: 0.9425\n",
      "Epoch 72/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1186 - accuracy: 0.9530 - val_loss: 0.1857 - val_accuracy: 0.9260\n",
      "Epoch 73/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1637 - accuracy: 0.9310 - val_loss: 0.2658 - val_accuracy: 0.8774\n",
      "Epoch 74/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1515 - accuracy: 0.9371 - val_loss: 0.1114 - val_accuracy: 0.9564\n",
      "Epoch 75/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1269 - accuracy: 0.9490 - val_loss: 0.1063 - val_accuracy: 0.9539\n",
      "Epoch 76/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1256 - accuracy: 0.9475 - val_loss: 0.1526 - val_accuracy: 0.9328\n",
      "Epoch 77/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1126 - accuracy: 0.9545 - val_loss: 0.1184 - val_accuracy: 0.9496\n",
      "Epoch 78/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1202 - accuracy: 0.9518 - val_loss: 0.0952 - val_accuracy: 0.9621\n",
      "Epoch 79/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1116 - accuracy: 0.9554 - val_loss: 0.0852 - val_accuracy: 0.9675\n",
      "Epoch 80/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1065 - accuracy: 0.9577 - val_loss: 0.0988 - val_accuracy: 0.9628\n",
      "Epoch 81/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1029 - accuracy: 0.9598 - val_loss: 0.1003 - val_accuracy: 0.9628\n",
      "Epoch 82/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1118 - accuracy: 0.9548 - val_loss: 0.1263 - val_accuracy: 0.9482\n",
      "Epoch 83/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1102 - accuracy: 0.9571 - val_loss: 0.2258 - val_accuracy: 0.8985\n",
      "Epoch 84/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1068 - accuracy: 0.9578 - val_loss: 0.0841 - val_accuracy: 0.9660\n",
      "Epoch 85/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1041 - accuracy: 0.9598 - val_loss: 0.1150 - val_accuracy: 0.9560\n",
      "Epoch 86/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0989 - accuracy: 0.9613 - val_loss: 0.1458 - val_accuracy: 0.9485\n",
      "Epoch 87/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0981 - accuracy: 0.9612 - val_loss: 0.0959 - val_accuracy: 0.9621\n",
      "Epoch 88/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1015 - accuracy: 0.9597 - val_loss: 0.1189 - val_accuracy: 0.9492\n",
      "Epoch 89/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0949 - accuracy: 0.9634 - val_loss: 0.0804 - val_accuracy: 0.9682\n",
      "Epoch 90/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1027 - accuracy: 0.9605 - val_loss: 0.0788 - val_accuracy: 0.9703\n",
      "Epoch 91/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0910 - accuracy: 0.9649 - val_loss: 0.1547 - val_accuracy: 0.9321\n",
      "Epoch 92/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0961 - accuracy: 0.9634 - val_loss: 0.0761 - val_accuracy: 0.9696\n",
      "Epoch 93/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0940 - accuracy: 0.9633 - val_loss: 0.0862 - val_accuracy: 0.9653\n",
      "Epoch 94/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0792 - accuracy: 0.9698 - val_loss: 0.1049 - val_accuracy: 0.9589\n",
      "Epoch 95/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0857 - accuracy: 0.9677 - val_loss: 0.0769 - val_accuracy: 0.9711\n",
      "Epoch 96/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0827 - accuracy: 0.9678 - val_loss: 0.1471 - val_accuracy: 0.9442\n",
      "Epoch 97/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1736 - accuracy: 0.9286 - val_loss: 0.0979 - val_accuracy: 0.9639\n",
      "Epoch 98/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0955 - accuracy: 0.9634 - val_loss: 0.0989 - val_accuracy: 0.9621\n",
      "Epoch 99/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0822 - accuracy: 0.9692 - val_loss: 0.0866 - val_accuracy: 0.9678\n",
      "Epoch 100/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0821 - accuracy: 0.9693 - val_loss: 0.0701 - val_accuracy: 0.9736\n",
      "Epoch 101/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0841 - accuracy: 0.9680 - val_loss: 0.0919 - val_accuracy: 0.9646\n",
      "Epoch 102/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0878 - accuracy: 0.9673 - val_loss: 0.1253 - val_accuracy: 0.9496\n",
      "Epoch 103/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1567 - accuracy: 0.9327 - val_loss: 0.1090 - val_accuracy: 0.9560\n",
      "Epoch 104/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0763 - accuracy: 0.9712 - val_loss: 0.0937 - val_accuracy: 0.9646\n",
      "Epoch 105/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0868 - accuracy: 0.9657 - val_loss: 0.0812 - val_accuracy: 0.9682\n",
      "Epoch 106/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0863 - accuracy: 0.9664 - val_loss: 0.0731 - val_accuracy: 0.9739\n",
      "Epoch 107/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0783 - accuracy: 0.9695 - val_loss: 0.0891 - val_accuracy: 0.9653\n",
      "Epoch 108/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0820 - accuracy: 0.9689 - val_loss: 0.0847 - val_accuracy: 0.9700\n",
      "Epoch 109/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0778 - accuracy: 0.9703 - val_loss: 0.0791 - val_accuracy: 0.9728\n",
      "Epoch 110/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0756 - accuracy: 0.9712 - val_loss: 0.0755 - val_accuracy: 0.9725\n",
      "Epoch 111/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0930 - accuracy: 0.9642 - val_loss: 0.0787 - val_accuracy: 0.9711\n",
      "Epoch 112/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0777 - accuracy: 0.9691 - val_loss: 0.1344 - val_accuracy: 0.9428\n",
      "Epoch 113/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0760 - accuracy: 0.9711 - val_loss: 0.0745 - val_accuracy: 0.9714\n",
      "Epoch 114/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0700 - accuracy: 0.9737 - val_loss: 0.0743 - val_accuracy: 0.9728\n",
      "Epoch 115/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0665 - accuracy: 0.9749 - val_loss: 0.0954 - val_accuracy: 0.9675\n",
      "Epoch 116/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0763 - accuracy: 0.9722 - val_loss: 0.2270 - val_accuracy: 0.9121\n",
      "Epoch 117/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0857 - accuracy: 0.9681 - val_loss: 0.0929 - val_accuracy: 0.9668\n",
      "Epoch 118/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0765 - accuracy: 0.9701 - val_loss: 0.0783 - val_accuracy: 0.9696\n",
      "Epoch 119/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0655 - accuracy: 0.9749 - val_loss: 0.0944 - val_accuracy: 0.9671\n",
      "Epoch 120/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0816 - accuracy: 0.9684 - val_loss: 0.0823 - val_accuracy: 0.9718\n",
      "Epoch 121/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0682 - accuracy: 0.9734 - val_loss: 0.0742 - val_accuracy: 0.9707\n",
      "Epoch 122/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0697 - accuracy: 0.9740 - val_loss: 0.1057 - val_accuracy: 0.9564\n",
      "Epoch 123/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0705 - accuracy: 0.9738 - val_loss: 0.0749 - val_accuracy: 0.9718\n",
      "Epoch 124/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0673 - accuracy: 0.9735 - val_loss: 0.0724 - val_accuracy: 0.9739\n",
      "Epoch 125/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0630 - accuracy: 0.9756 - val_loss: 0.0824 - val_accuracy: 0.9714\n",
      "Epoch 126/500\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.0665 - accuracy: 0.9751Restoring model weights from the end of the best epoch: 106.\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0666 - accuracy: 0.9750 - val_loss: 0.0793 - val_accuracy: 0.9721\n",
      "Epoch 126: early stopping\n",
      "Number of iterations 10\n",
      "F1-scores:  [0.794888178913738, 0.9737324373854611, 0.8083333333333333, 0.9412484700122399, 0.9457177322074789, 0.863664404688464, 0.8053691275167786, 0.8134592680047226, 0.961346633416459, 0.95551492992078]\n",
      "Average F1-Score 0.8863274515399455\n",
      "Std Dev F1-Score 0.07170760016816174\n",
      "Error bar F1-Score 0.02267593420760642\n"
     ]
    }
   ],
   "source": [
    "###Collect F-Score 10 times\n",
    "import sklearn\n",
    "from tqdm.notebook import tqdm\n",
    "def calc_f1_score(X_train_scaled,X_test_scaled,X_train_scaled_f,X_test_scaled_f,y_train,y_test,earlystop):\n",
    "  input_1 = Input((X_train_scaled.shape[1], X_train_scaled.shape[2]))\n",
    "  input_2 = Input((X_train_scaled_f.shape[1], X_train_scaled_f.shape[2]))\n",
    "  x1=LSTM(units = 100, return_sequences = True)(input_1)\n",
    "  x1=LSTM(units = 50)(x1)\n",
    "  x2=LSTM(units = 100, return_sequences = True)(input_2)\n",
    "  x2=LSTM(units = 50)(x2)\n",
    "  x = layers.concatenate([x1, x2])\n",
    "  output_layer = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "  classifier=keras.Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "  # Compiling the RNN\n",
    "  classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  classifier.fit([X_train_scaled,X_train_scaled_f], y_train[:,0], epochs = 500, batch_size = 64,validation_data=([X_test_scaled,X_test_scaled_f],y_test[:,0]),callbacks=[earlystop])\n",
    "  y_pred = classifier.predict([X_test_scaled,X_test_scaled_f])\n",
    "  y_pred= (y_pred>=0.5).astype(int)\n",
    "  return(sklearn.metrics.f1_score(y_test[:,0],y_pred))\n",
    "\n",
    "f1_score_list=[]\n",
    "for i in tqdm(range(10)):\n",
    "  f1_score_list=f1_score_list+[calc_f1_score(X_train_scaled,X_test_scaled,X_train_scaled_f,X_test_scaled_f,y_train,y_test,earlystop)]\n",
    "  print(\"Number of iterations\",len(f1_score_list))\n",
    "  print(\"F1-scores: \",f1_score_list)\n",
    "  print(\"Average F1-Score\",np.mean(f1_score_list))\n",
    "  print(\"Std Dev F1-Score\",np.std(f1_score_list))\n",
    "  print(\"Error bar F1-Score\",np.std(f1_score_list)/np.sqrt(len(f1_score_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e3df61a1bd4042eca563b664859036b9",
      "0d54dfa25e25478ca3e095782bcd59e2",
      "d5118db5b6be4447b07197da86aa2c2a",
      "f64483d04e964450960d63930746bd16",
      "727c2d7d9a4a42729ffc556e82f7728b",
      "d4e3afd520af4bd5ba8c1cffc61b9f55",
      "a80d7158d6f14bffaa4395a1a3e9de2f",
      "7869e2a0f0ba49cd8588e7c4419ffd97",
      "a62d714d2f8b4100987988e2fa35f9a2",
      "b113b2edd10c4a4688001055ea4e5921",
      "bc388221e1ef4b2481adce78b617c38a"
     ]
    },
    "id": "0KtTep2IsGf7",
    "outputId": "9af86239-9559-442c-d026-ca97f302b790"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.019330501556396484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3df61a1bd4042eca563b664859036b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "333/333 [==============================] - 10s 16ms/step - loss: 0.5842 - accuracy: 0.7102 - val_loss: 0.5641 - val_accuracy: 0.7127\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.5515 - accuracy: 0.7072 - val_loss: 0.5631 - val_accuracy: 0.7127\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4055 - accuracy: 0.7892 - val_loss: 0.4345 - val_accuracy: 0.7795\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.3476 - accuracy: 0.8315 - val_loss: 0.3061 - val_accuracy: 0.8642\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.3116 - accuracy: 0.8496 - val_loss: 0.2697 - val_accuracy: 0.8778\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.3041 - accuracy: 0.8537 - val_loss: 0.2911 - val_accuracy: 0.8545\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2996 - accuracy: 0.8554 - val_loss: 0.2477 - val_accuracy: 0.8792\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2777 - accuracy: 0.8648 - val_loss: 0.2367 - val_accuracy: 0.8810\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2901 - accuracy: 0.8613 - val_loss: 0.2600 - val_accuracy: 0.8753\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2978 - accuracy: 0.8570 - val_loss: 0.3110 - val_accuracy: 0.8410\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.3007 - accuracy: 0.8523 - val_loss: 0.5340 - val_accuracy: 0.8034\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2889 - accuracy: 0.8607 - val_loss: 0.2448 - val_accuracy: 0.8749\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2762 - accuracy: 0.8652 - val_loss: 0.2657 - val_accuracy: 0.8656\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2811 - accuracy: 0.8634 - val_loss: 0.2490 - val_accuracy: 0.8738\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2828 - accuracy: 0.8630 - val_loss: 0.2949 - val_accuracy: 0.8685\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2828 - accuracy: 0.8622 - val_loss: 0.3220 - val_accuracy: 0.8756\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2742 - accuracy: 0.8667 - val_loss: 0.2326 - val_accuracy: 0.8810\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2728 - accuracy: 0.8675 - val_loss: 0.2465 - val_accuracy: 0.8771\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2726 - accuracy: 0.8660 - val_loss: 0.2391 - val_accuracy: 0.8763\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2678 - accuracy: 0.8678 - val_loss: 0.2351 - val_accuracy: 0.8824\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2864 - accuracy: 0.8645 - val_loss: 0.2435 - val_accuracy: 0.8763\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2773 - accuracy: 0.8654 - val_loss: 0.2351 - val_accuracy: 0.8856\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2645 - accuracy: 0.8699 - val_loss: 0.2411 - val_accuracy: 0.8799\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2631 - accuracy: 0.8697 - val_loss: 0.2325 - val_accuracy: 0.8792\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2705 - accuracy: 0.8664 - val_loss: 0.2492 - val_accuracy: 0.8788\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2774 - accuracy: 0.8646 - val_loss: 0.2613 - val_accuracy: 0.8717\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2767 - accuracy: 0.8636 - val_loss: 0.2392 - val_accuracy: 0.8803\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2618 - accuracy: 0.8697 - val_loss: 0.2367 - val_accuracy: 0.8763\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2812 - accuracy: 0.8624 - val_loss: 0.2324 - val_accuracy: 0.8803\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2638 - accuracy: 0.8676 - val_loss: 0.2326 - val_accuracy: 0.8835\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2759 - accuracy: 0.8634 - val_loss: 0.2881 - val_accuracy: 0.8788\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2652 - accuracy: 0.8663 - val_loss: 0.2666 - val_accuracy: 0.8703\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2710 - accuracy: 0.8668 - val_loss: 0.6163 - val_accuracy: 0.7127\n",
      "Epoch 34/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.6004 - accuracy: 0.7136 - val_loss: 0.5997 - val_accuracy: 0.7127\n",
      "Epoch 35/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5994 - accuracy: 0.7136 - val_loss: 0.5999 - val_accuracy: 0.7127\n",
      "Epoch 36/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5994 - accuracy: 0.7136 - val_loss: 0.5998 - val_accuracy: 0.7127\n",
      "Epoch 37/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5993 - accuracy: 0.7136 - val_loss: 0.5998 - val_accuracy: 0.7127\n",
      "Epoch 38/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5994 - accuracy: 0.7136 - val_loss: 0.6025 - val_accuracy: 0.7127\n",
      "Epoch 39/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5995 - accuracy: 0.7136 - val_loss: 0.5998 - val_accuracy: 0.7127\n",
      "Epoch 40/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5996 - accuracy: 0.7136 - val_loss: 0.6004 - val_accuracy: 0.7127\n",
      "Epoch 41/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5993 - accuracy: 0.7136 - val_loss: 0.5997 - val_accuracy: 0.7127\n",
      "Epoch 42/500\n",
      "333/333 [==============================] - ETA: 0s - loss: 0.5993 - accuracy: 0.7136Restoring model weights from the end of the best epoch: 22.\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5993 - accuracy: 0.7136 - val_loss: 0.5998 - val_accuracy: 0.7127\n",
      "Epoch 42: early stopping\n",
      "Number of iterations 1\n",
      "F1-scores:  [0.7948717948717948]\n",
      "Average F1-Score 0.7948717948717948\n",
      "Std Dev F1-Score 0.0\n",
      "Error bar F1-Score 0.0\n",
      "Epoch 1/500\n",
      "333/333 [==============================] - 10s 16ms/step - loss: 0.5466 - accuracy: 0.7125 - val_loss: 0.5091 - val_accuracy: 0.7119\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5172 - accuracy: 0.7167 - val_loss: 0.4946 - val_accuracy: 0.7434\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5164 - accuracy: 0.7187 - val_loss: 0.4965 - val_accuracy: 0.7405\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5129 - accuracy: 0.7237 - val_loss: 0.5169 - val_accuracy: 0.7345\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5109 - accuracy: 0.7236 - val_loss: 0.5064 - val_accuracy: 0.7202\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5093 - accuracy: 0.7228 - val_loss: 0.5053 - val_accuracy: 0.7452\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5048 - accuracy: 0.7289 - val_loss: 0.4903 - val_accuracy: 0.7366\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5033 - accuracy: 0.7279 - val_loss: 0.4923 - val_accuracy: 0.7241\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4992 - accuracy: 0.7291 - val_loss: 0.4983 - val_accuracy: 0.7152\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4989 - accuracy: 0.7334 - val_loss: 0.5128 - val_accuracy: 0.7398\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4942 - accuracy: 0.7340 - val_loss: 0.4794 - val_accuracy: 0.7402\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4928 - accuracy: 0.7299 - val_loss: 0.4784 - val_accuracy: 0.7455\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4820 - accuracy: 0.7367 - val_loss: 0.4624 - val_accuracy: 0.7402\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4632 - accuracy: 0.7443 - val_loss: 0.4542 - val_accuracy: 0.7577\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4429 - accuracy: 0.7610 - val_loss: 0.4314 - val_accuracy: 0.7834\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4042 - accuracy: 0.7969 - val_loss: 0.3524 - val_accuracy: 0.8335\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.3283 - accuracy: 0.8460 - val_loss: 0.2589 - val_accuracy: 0.8713\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2824 - accuracy: 0.8714 - val_loss: 0.2908 - val_accuracy: 0.8738\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2528 - accuracy: 0.8874 - val_loss: 0.2090 - val_accuracy: 0.9003\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2424 - accuracy: 0.8908 - val_loss: 0.2445 - val_accuracy: 0.8924\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2354 - accuracy: 0.8941 - val_loss: 0.1964 - val_accuracy: 0.9039\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2204 - accuracy: 0.9008 - val_loss: 0.1897 - val_accuracy: 0.9185\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2098 - accuracy: 0.9071 - val_loss: 0.2189 - val_accuracy: 0.8967\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2091 - accuracy: 0.9047 - val_loss: 0.1910 - val_accuracy: 0.9157\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2055 - accuracy: 0.9072 - val_loss: 0.1965 - val_accuracy: 0.9067\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2062 - accuracy: 0.9082 - val_loss: 0.1988 - val_accuracy: 0.9121\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2116 - accuracy: 0.9052 - val_loss: 0.2234 - val_accuracy: 0.8946\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2000 - accuracy: 0.9090 - val_loss: 0.1630 - val_accuracy: 0.9307\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1952 - accuracy: 0.9114 - val_loss: 0.1641 - val_accuracy: 0.9267\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1917 - accuracy: 0.9155 - val_loss: 0.2254 - val_accuracy: 0.8914\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1906 - accuracy: 0.9152 - val_loss: 0.1671 - val_accuracy: 0.9278\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1825 - accuracy: 0.9186 - val_loss: 0.2199 - val_accuracy: 0.9135\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1940 - accuracy: 0.9151 - val_loss: 0.1554 - val_accuracy: 0.9321\n",
      "Epoch 34/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1772 - accuracy: 0.9215 - val_loss: 0.1498 - val_accuracy: 0.9392\n",
      "Epoch 35/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1910 - accuracy: 0.9158 - val_loss: 0.1805 - val_accuracy: 0.9189\n",
      "Epoch 36/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1778 - accuracy: 0.9217 - val_loss: 0.2250 - val_accuracy: 0.9146\n",
      "Epoch 37/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1837 - accuracy: 0.9176 - val_loss: 0.1470 - val_accuracy: 0.9403\n",
      "Epoch 38/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1829 - accuracy: 0.9193 - val_loss: 0.1761 - val_accuracy: 0.9192\n",
      "Epoch 39/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1766 - accuracy: 0.9229 - val_loss: 0.1565 - val_accuracy: 0.9339\n",
      "Epoch 40/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1716 - accuracy: 0.9256 - val_loss: 0.1425 - val_accuracy: 0.9410\n",
      "Epoch 41/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1774 - accuracy: 0.9235 - val_loss: 0.1693 - val_accuracy: 0.9160\n",
      "Epoch 42/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1738 - accuracy: 0.9218 - val_loss: 0.1579 - val_accuracy: 0.9264\n",
      "Epoch 43/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1759 - accuracy: 0.9219 - val_loss: 0.1456 - val_accuracy: 0.9360\n",
      "Epoch 44/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1664 - accuracy: 0.9267 - val_loss: 0.1601 - val_accuracy: 0.9289\n",
      "Epoch 45/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1732 - accuracy: 0.9231 - val_loss: 0.1365 - val_accuracy: 0.9421\n",
      "Epoch 46/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1588 - accuracy: 0.9308 - val_loss: 0.1557 - val_accuracy: 0.9350\n",
      "Epoch 47/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1580 - accuracy: 0.9333 - val_loss: 0.1574 - val_accuracy: 0.9325\n",
      "Epoch 48/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1616 - accuracy: 0.9317 - val_loss: 0.1683 - val_accuracy: 0.9321\n",
      "Epoch 49/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1638 - accuracy: 0.9291 - val_loss: 0.1421 - val_accuracy: 0.9392\n",
      "Epoch 50/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1577 - accuracy: 0.9315 - val_loss: 0.1629 - val_accuracy: 0.9303\n",
      "Epoch 51/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1502 - accuracy: 0.9350 - val_loss: 0.1546 - val_accuracy: 0.9350\n",
      "Epoch 52/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1421 - accuracy: 0.9390 - val_loss: 0.1327 - val_accuracy: 0.9478\n",
      "Epoch 53/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2497 - accuracy: 0.8747 - val_loss: 0.4019 - val_accuracy: 0.8077\n",
      "Epoch 54/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.3087 - accuracy: 0.8617 - val_loss: 0.2303 - val_accuracy: 0.8985\n",
      "Epoch 55/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1916 - accuracy: 0.9194 - val_loss: 0.1515 - val_accuracy: 0.9357\n",
      "Epoch 56/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1531 - accuracy: 0.9351 - val_loss: 0.1738 - val_accuracy: 0.9235\n",
      "Epoch 57/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1463 - accuracy: 0.9367 - val_loss: 0.1247 - val_accuracy: 0.9543\n",
      "Epoch 58/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1596 - accuracy: 0.9323 - val_loss: 0.1225 - val_accuracy: 0.9518\n",
      "Epoch 59/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1395 - accuracy: 0.9404 - val_loss: 0.1248 - val_accuracy: 0.9539\n",
      "Epoch 60/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1397 - accuracy: 0.9422 - val_loss: 0.1498 - val_accuracy: 0.9403\n",
      "Epoch 61/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1325 - accuracy: 0.9453 - val_loss: 0.1186 - val_accuracy: 0.9500\n",
      "Epoch 62/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1392 - accuracy: 0.9418 - val_loss: 0.1367 - val_accuracy: 0.9464\n",
      "Epoch 63/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1295 - accuracy: 0.9467 - val_loss: 0.1179 - val_accuracy: 0.9507\n",
      "Epoch 64/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1366 - accuracy: 0.9426 - val_loss: 0.1244 - val_accuracy: 0.9492\n",
      "Epoch 65/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1264 - accuracy: 0.9477 - val_loss: 0.1147 - val_accuracy: 0.9582\n",
      "Epoch 66/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1289 - accuracy: 0.9475 - val_loss: 0.1807 - val_accuracy: 0.9221\n",
      "Epoch 67/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1335 - accuracy: 0.9441 - val_loss: 0.0991 - val_accuracy: 0.9628\n",
      "Epoch 68/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1282 - accuracy: 0.9472 - val_loss: 0.1085 - val_accuracy: 0.9575\n",
      "Epoch 69/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1272 - accuracy: 0.9469 - val_loss: 0.1564 - val_accuracy: 0.9332\n",
      "Epoch 70/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1303 - accuracy: 0.9461 - val_loss: 0.1105 - val_accuracy: 0.9528\n",
      "Epoch 71/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1188 - accuracy: 0.9514 - val_loss: 0.1152 - val_accuracy: 0.9593\n",
      "Epoch 72/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1210 - accuracy: 0.9506 - val_loss: 0.1199 - val_accuracy: 0.9492\n",
      "Epoch 73/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1513 - accuracy: 0.9365 - val_loss: 0.1269 - val_accuracy: 0.9510\n",
      "Epoch 74/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1150 - accuracy: 0.9530 - val_loss: 0.1058 - val_accuracy: 0.9571\n",
      "Epoch 75/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1187 - accuracy: 0.9531 - val_loss: 0.1059 - val_accuracy: 0.9610\n",
      "Epoch 76/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1110 - accuracy: 0.9569 - val_loss: 0.1231 - val_accuracy: 0.9503\n",
      "Epoch 77/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1228 - accuracy: 0.9492 - val_loss: 0.1131 - val_accuracy: 0.9600\n",
      "Epoch 78/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1157 - accuracy: 0.9535 - val_loss: 0.0991 - val_accuracy: 0.9646\n",
      "Epoch 79/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1213 - accuracy: 0.9505 - val_loss: 0.0971 - val_accuracy: 0.9646\n",
      "Epoch 80/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1130 - accuracy: 0.9538 - val_loss: 0.1039 - val_accuracy: 0.9618\n",
      "Epoch 81/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1196 - accuracy: 0.9514 - val_loss: 0.1049 - val_accuracy: 0.9625\n",
      "Epoch 82/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1029 - accuracy: 0.9597 - val_loss: 0.0935 - val_accuracy: 0.9693\n",
      "Epoch 83/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1042 - accuracy: 0.9599 - val_loss: 0.1042 - val_accuracy: 0.9596\n",
      "Epoch 84/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1032 - accuracy: 0.9603 - val_loss: 0.1054 - val_accuracy: 0.9596\n",
      "Epoch 85/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1550 - accuracy: 0.9407 - val_loss: 0.1063 - val_accuracy: 0.9575\n",
      "Epoch 86/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1271 - accuracy: 0.9472 - val_loss: 0.0976 - val_accuracy: 0.9628\n",
      "Epoch 87/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1070 - accuracy: 0.9582 - val_loss: 0.1047 - val_accuracy: 0.9568\n",
      "Epoch 88/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1020 - accuracy: 0.9605 - val_loss: 0.1357 - val_accuracy: 0.9507\n",
      "Epoch 89/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.0981 - accuracy: 0.9618 - val_loss: 0.0949 - val_accuracy: 0.9650\n",
      "Epoch 90/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1007 - accuracy: 0.9601 - val_loss: 0.0948 - val_accuracy: 0.9671\n",
      "Epoch 91/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.0966 - accuracy: 0.9629 - val_loss: 0.1080 - val_accuracy: 0.9593\n",
      "Epoch 92/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.0919 - accuracy: 0.9648 - val_loss: 0.1075 - val_accuracy: 0.9603\n",
      "Epoch 93/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1276 - accuracy: 0.9490 - val_loss: 0.1220 - val_accuracy: 0.9571\n",
      "Epoch 94/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1122 - accuracy: 0.9555 - val_loss: 0.0944 - val_accuracy: 0.9646\n",
      "Epoch 95/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.0926 - accuracy: 0.9643 - val_loss: 0.0905 - val_accuracy: 0.9664\n",
      "Epoch 96/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.0873 - accuracy: 0.9668 - val_loss: 0.0926 - val_accuracy: 0.9653\n",
      "Epoch 97/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.0867 - accuracy: 0.9656 - val_loss: 0.1072 - val_accuracy: 0.9557\n",
      "Epoch 98/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.0955 - accuracy: 0.9627 - val_loss: 0.1479 - val_accuracy: 0.9382\n",
      "Epoch 99/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.0874 - accuracy: 0.9650 - val_loss: 0.1201 - val_accuracy: 0.9543\n",
      "Epoch 100/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.0846 - accuracy: 0.9667 - val_loss: 0.1326 - val_accuracy: 0.9496\n",
      "Epoch 101/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.0860 - accuracy: 0.9671 - val_loss: 0.0968 - val_accuracy: 0.9646\n",
      "Epoch 102/500\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.0835 - accuracy: 0.9690Restoring model weights from the end of the best epoch: 82.\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.0836 - accuracy: 0.9690 - val_loss: 0.0940 - val_accuracy: 0.9639\n",
      "Epoch 102: early stopping\n",
      "Number of iterations 2\n",
      "F1-scores:  [0.7948717948717948, 0.9470443349753696]\n",
      "Average F1-Score 0.8709580649235822\n",
      "Std Dev F1-Score 0.07608627005178736\n",
      "Error bar F1-Score 0.05380111750880977\n",
      "Epoch 1/500\n",
      "333/333 [==============================] - 11s 16ms/step - loss: 0.5466 - accuracy: 0.7091 - val_loss: 0.5081 - val_accuracy: 0.7127\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5173 - accuracy: 0.7174 - val_loss: 0.4975 - val_accuracy: 0.7455\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5110 - accuracy: 0.7227 - val_loss: 0.4974 - val_accuracy: 0.7373\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.5015 - accuracy: 0.7271 - val_loss: 0.4591 - val_accuracy: 0.7548\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.4447 - accuracy: 0.7715 - val_loss: 0.3707 - val_accuracy: 0.8220\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.3635 - accuracy: 0.8281 - val_loss: 0.3100 - val_accuracy: 0.8599\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.3606 - accuracy: 0.8251 - val_loss: 0.2952 - val_accuracy: 0.8710\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.3125 - accuracy: 0.8598 - val_loss: 0.3305 - val_accuracy: 0.8431\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.3065 - accuracy: 0.8625 - val_loss: 0.2561 - val_accuracy: 0.8903\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2831 - accuracy: 0.8757 - val_loss: 0.2568 - val_accuracy: 0.8888\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2737 - accuracy: 0.8798 - val_loss: 0.2382 - val_accuracy: 0.8989\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2591 - accuracy: 0.8861 - val_loss: 0.2300 - val_accuracy: 0.9024\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2569 - accuracy: 0.8891 - val_loss: 0.2182 - val_accuracy: 0.9056\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2539 - accuracy: 0.8899 - val_loss: 0.2144 - val_accuracy: 0.9099\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2437 - accuracy: 0.8944 - val_loss: 0.2410 - val_accuracy: 0.8906\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2501 - accuracy: 0.8881 - val_loss: 0.2314 - val_accuracy: 0.9024\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2343 - accuracy: 0.8965 - val_loss: 0.2646 - val_accuracy: 0.8874\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2319 - accuracy: 0.8980 - val_loss: 0.2026 - val_accuracy: 0.9103\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2279 - accuracy: 0.8988 - val_loss: 0.2082 - val_accuracy: 0.9074\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.2239 - accuracy: 0.9002 - val_loss: 0.2370 - val_accuracy: 0.8924\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2126 - accuracy: 0.9054 - val_loss: 0.1831 - val_accuracy: 0.9217\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2107 - accuracy: 0.9076 - val_loss: 0.1763 - val_accuracy: 0.9228\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2111 - accuracy: 0.9072 - val_loss: 0.1723 - val_accuracy: 0.9267\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1988 - accuracy: 0.9131 - val_loss: 0.1922 - val_accuracy: 0.9149\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1894 - accuracy: 0.9187 - val_loss: 0.1807 - val_accuracy: 0.9228\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1856 - accuracy: 0.9214 - val_loss: 0.1560 - val_accuracy: 0.9375\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1847 - accuracy: 0.9213 - val_loss: 0.1699 - val_accuracy: 0.9257\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1844 - accuracy: 0.9212 - val_loss: 0.1970 - val_accuracy: 0.9124\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1789 - accuracy: 0.9255 - val_loss: 0.1723 - val_accuracy: 0.9278\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1750 - accuracy: 0.9267 - val_loss: 0.1531 - val_accuracy: 0.9332\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1854 - accuracy: 0.9227 - val_loss: 0.1655 - val_accuracy: 0.9310\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1628 - accuracy: 0.9326 - val_loss: 0.1425 - val_accuracy: 0.9417\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1577 - accuracy: 0.9363 - val_loss: 0.1498 - val_accuracy: 0.9382\n",
      "Epoch 34/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1637 - accuracy: 0.9339 - val_loss: 0.1387 - val_accuracy: 0.9400\n",
      "Epoch 35/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1501 - accuracy: 0.9390 - val_loss: 0.1389 - val_accuracy: 0.9475\n",
      "Epoch 36/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1523 - accuracy: 0.9381 - val_loss: 0.1546 - val_accuracy: 0.9332\n",
      "Epoch 37/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1484 - accuracy: 0.9393 - val_loss: 0.1735 - val_accuracy: 0.9249\n",
      "Epoch 38/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1502 - accuracy: 0.9391 - val_loss: 0.1296 - val_accuracy: 0.9446\n",
      "Epoch 39/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1498 - accuracy: 0.9392 - val_loss: 0.1457 - val_accuracy: 0.9389\n",
      "Epoch 40/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1453 - accuracy: 0.9405 - val_loss: 0.1643 - val_accuracy: 0.9253\n",
      "Epoch 41/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1361 - accuracy: 0.9468 - val_loss: 0.1606 - val_accuracy: 0.9285\n",
      "Epoch 42/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1376 - accuracy: 0.9450 - val_loss: 0.1224 - val_accuracy: 0.9475\n",
      "Epoch 43/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1261 - accuracy: 0.9503 - val_loss: 0.1231 - val_accuracy: 0.9496\n",
      "Epoch 44/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1291 - accuracy: 0.9490 - val_loss: 0.1178 - val_accuracy: 0.9539\n",
      "Epoch 45/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1282 - accuracy: 0.9488 - val_loss: 0.1134 - val_accuracy: 0.9593\n",
      "Epoch 46/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1242 - accuracy: 0.9517 - val_loss: 0.1590 - val_accuracy: 0.9332\n",
      "Epoch 47/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1229 - accuracy: 0.9501 - val_loss: 0.1218 - val_accuracy: 0.9496\n",
      "Epoch 48/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1213 - accuracy: 0.9517 - val_loss: 0.1454 - val_accuracy: 0.9378\n",
      "Epoch 49/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1211 - accuracy: 0.9522 - val_loss: 0.1130 - val_accuracy: 0.9603\n",
      "Epoch 50/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1184 - accuracy: 0.9532 - val_loss: 0.1054 - val_accuracy: 0.9603\n",
      "Epoch 51/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1151 - accuracy: 0.9550 - val_loss: 0.1678 - val_accuracy: 0.9325\n",
      "Epoch 52/500\n",
      "333/333 [==============================] - 4s 12ms/step - loss: 0.1361 - accuracy: 0.9449 - val_loss: 0.1021 - val_accuracy: 0.9585\n",
      "Epoch 53/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1118 - accuracy: 0.9569 - val_loss: 0.1393 - val_accuracy: 0.9396\n",
      "Epoch 54/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1117 - accuracy: 0.9569 - val_loss: 0.1104 - val_accuracy: 0.9560\n",
      "Epoch 55/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1138 - accuracy: 0.9555 - val_loss: 0.1222 - val_accuracy: 0.9525\n",
      "Epoch 56/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1088 - accuracy: 0.9559 - val_loss: 0.0942 - val_accuracy: 0.9639\n",
      "Epoch 57/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1177 - accuracy: 0.9538 - val_loss: 0.1045 - val_accuracy: 0.9585\n",
      "Epoch 58/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1047 - accuracy: 0.9610 - val_loss: 0.1050 - val_accuracy: 0.9585\n",
      "Epoch 59/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0993 - accuracy: 0.9614 - val_loss: 0.1029 - val_accuracy: 0.9568\n",
      "Epoch 60/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1050 - accuracy: 0.9609 - val_loss: 0.0940 - val_accuracy: 0.9653\n",
      "Epoch 61/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1018 - accuracy: 0.9605 - val_loss: 0.1155 - val_accuracy: 0.9528\n",
      "Epoch 62/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1010 - accuracy: 0.9621 - val_loss: 0.0931 - val_accuracy: 0.9653\n",
      "Epoch 63/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0937 - accuracy: 0.9636 - val_loss: 0.1065 - val_accuracy: 0.9600\n",
      "Epoch 64/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0980 - accuracy: 0.9632 - val_loss: 0.2274 - val_accuracy: 0.9157\n",
      "Epoch 65/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1306 - accuracy: 0.9507 - val_loss: 0.1024 - val_accuracy: 0.9600\n",
      "Epoch 66/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0868 - accuracy: 0.9679 - val_loss: 0.0952 - val_accuracy: 0.9635\n",
      "Epoch 67/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0984 - accuracy: 0.9610 - val_loss: 0.1284 - val_accuracy: 0.9503\n",
      "Epoch 68/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0874 - accuracy: 0.9667 - val_loss: 0.1773 - val_accuracy: 0.9314\n",
      "Epoch 69/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0950 - accuracy: 0.9634 - val_loss: 0.0769 - val_accuracy: 0.9753\n",
      "Epoch 70/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0824 - accuracy: 0.9689 - val_loss: 0.1306 - val_accuracy: 0.9489\n",
      "Epoch 71/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0910 - accuracy: 0.9653 - val_loss: 0.0950 - val_accuracy: 0.9628\n",
      "Epoch 72/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0880 - accuracy: 0.9667 - val_loss: 0.0724 - val_accuracy: 0.9732\n",
      "Epoch 73/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0768 - accuracy: 0.9721 - val_loss: 0.0705 - val_accuracy: 0.9753\n",
      "Epoch 74/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0807 - accuracy: 0.9692 - val_loss: 0.0967 - val_accuracy: 0.9650\n",
      "Epoch 75/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1003 - accuracy: 0.9618 - val_loss: 0.0853 - val_accuracy: 0.9685\n",
      "Epoch 76/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0786 - accuracy: 0.9713 - val_loss: 0.0936 - val_accuracy: 0.9657\n",
      "Epoch 77/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0835 - accuracy: 0.9697 - val_loss: 0.0820 - val_accuracy: 0.9678\n",
      "Epoch 78/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0706 - accuracy: 0.9742 - val_loss: 0.1110 - val_accuracy: 0.9589\n",
      "Epoch 79/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0764 - accuracy: 0.9717 - val_loss: 0.0645 - val_accuracy: 0.9778\n",
      "Epoch 80/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0734 - accuracy: 0.9726 - val_loss: 0.1327 - val_accuracy: 0.9485\n",
      "Epoch 81/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0902 - accuracy: 0.9647 - val_loss: 0.0763 - val_accuracy: 0.9714\n",
      "Epoch 82/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0713 - accuracy: 0.9740 - val_loss: 0.1012 - val_accuracy: 0.9625\n",
      "Epoch 83/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0848 - accuracy: 0.9691 - val_loss: 0.0674 - val_accuracy: 0.9782\n",
      "Epoch 84/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0775 - accuracy: 0.9723 - val_loss: 0.0759 - val_accuracy: 0.9736\n",
      "Epoch 85/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0638 - accuracy: 0.9761 - val_loss: 0.0981 - val_accuracy: 0.9650\n",
      "Epoch 86/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0749 - accuracy: 0.9717 - val_loss: 0.0919 - val_accuracy: 0.9643\n",
      "Epoch 87/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0881 - accuracy: 0.9683 - val_loss: 0.0887 - val_accuracy: 0.9678\n",
      "Epoch 88/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0641 - accuracy: 0.9767 - val_loss: 0.0996 - val_accuracy: 0.9628\n",
      "Epoch 89/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0715 - accuracy: 0.9736 - val_loss: 0.1035 - val_accuracy: 0.9589\n",
      "Epoch 90/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0860 - accuracy: 0.9676 - val_loss: 0.1000 - val_accuracy: 0.9671\n",
      "Epoch 91/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0569 - accuracy: 0.9801 - val_loss: 0.0696 - val_accuracy: 0.9771\n",
      "Epoch 92/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0880 - accuracy: 0.9678 - val_loss: 0.0756 - val_accuracy: 0.9732\n",
      "Epoch 93/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0619 - accuracy: 0.9776 - val_loss: 0.0610 - val_accuracy: 0.9811\n",
      "Epoch 94/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0643 - accuracy: 0.9770 - val_loss: 0.0649 - val_accuracy: 0.9757\n",
      "Epoch 95/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.0720 - accuracy: 0.9730 - val_loss: 0.0643 - val_accuracy: 0.9814\n",
      "Epoch 96/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1950 - accuracy: 0.9095 - val_loss: 0.3710 - val_accuracy: 0.8177\n",
      "Epoch 97/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.3103 - accuracy: 0.8494 - val_loss: 0.3724 - val_accuracy: 0.8184\n",
      "Epoch 98/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2554 - accuracy: 0.8817 - val_loss: 0.2125 - val_accuracy: 0.8967\n",
      "Epoch 99/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2407 - accuracy: 0.8902 - val_loss: 0.1913 - val_accuracy: 0.9178\n",
      "Epoch 100/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.2221 - accuracy: 0.8988 - val_loss: 0.1741 - val_accuracy: 0.9257\n",
      "Epoch 101/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2147 - accuracy: 0.9050 - val_loss: 0.2011 - val_accuracy: 0.9114\n",
      "Epoch 102/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2031 - accuracy: 0.9107 - val_loss: 0.1881 - val_accuracy: 0.9189\n",
      "Epoch 103/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1935 - accuracy: 0.9161 - val_loss: 0.1419 - val_accuracy: 0.9364\n",
      "Epoch 104/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1788 - accuracy: 0.9232 - val_loss: 0.1747 - val_accuracy: 0.9167\n",
      "Epoch 105/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1677 - accuracy: 0.9292 - val_loss: 0.1236 - val_accuracy: 0.9503\n",
      "Epoch 106/500\n",
      "333/333 [==============================] - 4s 13ms/step - loss: 0.1629 - accuracy: 0.9326 - val_loss: 0.1549 - val_accuracy: 0.9346\n",
      "Epoch 107/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1678 - accuracy: 0.9286 - val_loss: 0.2039 - val_accuracy: 0.9064\n",
      "Epoch 108/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1488 - accuracy: 0.9379 - val_loss: 0.1269 - val_accuracy: 0.9467\n",
      "Epoch 109/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1455 - accuracy: 0.9399 - val_loss: 0.1139 - val_accuracy: 0.9525\n",
      "Epoch 110/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1521 - accuracy: 0.9386 - val_loss: 0.1428 - val_accuracy: 0.9371\n",
      "Epoch 111/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1595 - accuracy: 0.9324 - val_loss: 0.1240 - val_accuracy: 0.9482\n",
      "Epoch 112/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1427 - accuracy: 0.9419 - val_loss: 0.1405 - val_accuracy: 0.9417\n",
      "Epoch 113/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1274 - accuracy: 0.9491 - val_loss: 0.1213 - val_accuracy: 0.9492\n",
      "Epoch 114/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1202 - accuracy: 0.9525 - val_loss: 0.0973 - val_accuracy: 0.9632\n",
      "Epoch 115/500\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 0.9432Restoring model weights from the end of the best epoch: 95.\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1407 - accuracy: 0.9432 - val_loss: 0.1041 - val_accuracy: 0.9578\n",
      "Epoch 115: early stopping\n",
      "Number of iterations 3\n",
      "F1-scores:  [0.7948717948717948, 0.9470443349753696, 0.9683313032886723]\n",
      "Average F1-Score 0.9034158110452789\n",
      "Std Dev F1-Score 0.07724263218497529\n",
      "Error bar F1-Score 0.04459605448491074\n",
      "Epoch 1/500\n",
      "333/333 [==============================] - 11s 18ms/step - loss: 0.5433 - accuracy: 0.7126 - val_loss: 0.5139 - val_accuracy: 0.7127\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5483 - accuracy: 0.7090 - val_loss: 0.5732 - val_accuracy: 0.7127\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5608 - accuracy: 0.7104 - val_loss: 0.5507 - val_accuracy: 0.6548\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5245 - accuracy: 0.7179 - val_loss: 0.4598 - val_accuracy: 0.7445\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4817 - accuracy: 0.7285 - val_loss: 0.4759 - val_accuracy: 0.7076\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4861 - accuracy: 0.7193 - val_loss: 0.4721 - val_accuracy: 0.7009\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4051 - accuracy: 0.7866 - val_loss: 0.3362 - val_accuracy: 0.8381\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3479 - accuracy: 0.8297 - val_loss: 0.3158 - val_accuracy: 0.8520\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3084 - accuracy: 0.8568 - val_loss: 0.3141 - val_accuracy: 0.8653\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2874 - accuracy: 0.8680 - val_loss: 0.2493 - val_accuracy: 0.8849\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2803 - accuracy: 0.8747 - val_loss: 0.2933 - val_accuracy: 0.8724\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2793 - accuracy: 0.8770 - val_loss: 0.2319 - val_accuracy: 0.8985\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2744 - accuracy: 0.8760 - val_loss: 0.3348 - val_accuracy: 0.8467\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2652 - accuracy: 0.8813 - val_loss: 0.2323 - val_accuracy: 0.9064\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2548 - accuracy: 0.8872 - val_loss: 0.2421 - val_accuracy: 0.8906\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2534 - accuracy: 0.8885 - val_loss: 0.2096 - val_accuracy: 0.9067\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2449 - accuracy: 0.8939 - val_loss: 0.2076 - val_accuracy: 0.9128\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4722 - accuracy: 0.7563 - val_loss: 0.4082 - val_accuracy: 0.7591\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3336 - accuracy: 0.8443 - val_loss: 0.2634 - val_accuracy: 0.8885\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2724 - accuracy: 0.8804 - val_loss: 0.2700 - val_accuracy: 0.8813\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2665 - accuracy: 0.8813 - val_loss: 0.2426 - val_accuracy: 0.8935\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2638 - accuracy: 0.8833 - val_loss: 0.2485 - val_accuracy: 0.8881\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2627 - accuracy: 0.8853 - val_loss: 0.2833 - val_accuracy: 0.8685\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2467 - accuracy: 0.8935 - val_loss: 0.2315 - val_accuracy: 0.8989\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2678 - accuracy: 0.8837 - val_loss: 0.2524 - val_accuracy: 0.8960\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2465 - accuracy: 0.8949 - val_loss: 0.3125 - val_accuracy: 0.8399\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2460 - accuracy: 0.8916 - val_loss: 0.2040 - val_accuracy: 0.9128\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2243 - accuracy: 0.8993 - val_loss: 0.1868 - val_accuracy: 0.9242\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2203 - accuracy: 0.9017 - val_loss: 0.1787 - val_accuracy: 0.9232\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2416 - accuracy: 0.8912 - val_loss: 0.1935 - val_accuracy: 0.9124\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2160 - accuracy: 0.9014 - val_loss: 0.1799 - val_accuracy: 0.9214\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2249 - accuracy: 0.8994 - val_loss: 0.1735 - val_accuracy: 0.9164\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1977 - accuracy: 0.9120 - val_loss: 0.1805 - val_accuracy: 0.9164\n",
      "Epoch 34/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2001 - accuracy: 0.9122 - val_loss: 0.1610 - val_accuracy: 0.9328\n",
      "Epoch 35/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1979 - accuracy: 0.9126 - val_loss: 0.1694 - val_accuracy: 0.9235\n",
      "Epoch 36/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2128 - accuracy: 0.9041 - val_loss: 0.1574 - val_accuracy: 0.9271\n",
      "Epoch 37/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2010 - accuracy: 0.9115 - val_loss: 0.1998 - val_accuracy: 0.9067\n",
      "Epoch 38/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1903 - accuracy: 0.9159 - val_loss: 0.1745 - val_accuracy: 0.9274\n",
      "Epoch 39/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2042 - accuracy: 0.9106 - val_loss: 0.1696 - val_accuracy: 0.9182\n",
      "Epoch 40/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1879 - accuracy: 0.9166 - val_loss: 0.1852 - val_accuracy: 0.9239\n",
      "Epoch 41/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1934 - accuracy: 0.9141 - val_loss: 0.1507 - val_accuracy: 0.9325\n",
      "Epoch 42/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1964 - accuracy: 0.9125 - val_loss: 0.1610 - val_accuracy: 0.9332\n",
      "Epoch 43/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1842 - accuracy: 0.9201 - val_loss: 0.1554 - val_accuracy: 0.9296\n",
      "Epoch 44/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1812 - accuracy: 0.9201 - val_loss: 0.1680 - val_accuracy: 0.9214\n",
      "Epoch 45/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1789 - accuracy: 0.9229 - val_loss: 0.1504 - val_accuracy: 0.9350\n",
      "Epoch 46/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1803 - accuracy: 0.9210 - val_loss: 0.2197 - val_accuracy: 0.9042\n",
      "Epoch 47/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1827 - accuracy: 0.9192 - val_loss: 0.1483 - val_accuracy: 0.9317\n",
      "Epoch 48/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1886 - accuracy: 0.9188 - val_loss: 0.1893 - val_accuracy: 0.9171\n",
      "Epoch 49/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1768 - accuracy: 0.9218 - val_loss: 0.1468 - val_accuracy: 0.9428\n",
      "Epoch 50/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1757 - accuracy: 0.9243 - val_loss: 0.1550 - val_accuracy: 0.9339\n",
      "Epoch 51/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1744 - accuracy: 0.9257 - val_loss: 0.1619 - val_accuracy: 0.9335\n",
      "Epoch 52/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1693 - accuracy: 0.9255 - val_loss: 0.1546 - val_accuracy: 0.9307\n",
      "Epoch 53/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1761 - accuracy: 0.9224 - val_loss: 0.1609 - val_accuracy: 0.9314\n",
      "Epoch 54/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1628 - accuracy: 0.9303 - val_loss: 0.1689 - val_accuracy: 0.9239\n",
      "Epoch 55/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1711 - accuracy: 0.9258 - val_loss: 0.1554 - val_accuracy: 0.9339\n",
      "Epoch 56/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1578 - accuracy: 0.9324 - val_loss: 0.1815 - val_accuracy: 0.9235\n",
      "Epoch 57/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1622 - accuracy: 0.9306 - val_loss: 0.1328 - val_accuracy: 0.9464\n",
      "Epoch 58/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1509 - accuracy: 0.9355 - val_loss: 0.1406 - val_accuracy: 0.9425\n",
      "Epoch 59/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1502 - accuracy: 0.9352 - val_loss: 0.1557 - val_accuracy: 0.9339\n",
      "Epoch 60/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1510 - accuracy: 0.9352 - val_loss: 0.1331 - val_accuracy: 0.9450\n",
      "Epoch 61/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1586 - accuracy: 0.9330 - val_loss: 0.1232 - val_accuracy: 0.9439\n",
      "Epoch 62/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1554 - accuracy: 0.9347 - val_loss: 0.1776 - val_accuracy: 0.9253\n",
      "Epoch 63/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1510 - accuracy: 0.9356 - val_loss: 0.1443 - val_accuracy: 0.9385\n",
      "Epoch 64/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1421 - accuracy: 0.9398 - val_loss: 0.1243 - val_accuracy: 0.9439\n",
      "Epoch 65/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1475 - accuracy: 0.9381 - val_loss: 0.1289 - val_accuracy: 0.9489\n",
      "Epoch 66/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1391 - accuracy: 0.9410 - val_loss: 0.1324 - val_accuracy: 0.9442\n",
      "Epoch 67/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1414 - accuracy: 0.9409 - val_loss: 0.1195 - val_accuracy: 0.9525\n",
      "Epoch 68/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1413 - accuracy: 0.9412 - val_loss: 0.1631 - val_accuracy: 0.9242\n",
      "Epoch 69/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1410 - accuracy: 0.9397 - val_loss: 0.1198 - val_accuracy: 0.9503\n",
      "Epoch 70/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1323 - accuracy: 0.9444 - val_loss: 0.1412 - val_accuracy: 0.9414\n",
      "Epoch 71/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1258 - accuracy: 0.9485 - val_loss: 0.1214 - val_accuracy: 0.9478\n",
      "Epoch 72/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1339 - accuracy: 0.9442 - val_loss: 0.1154 - val_accuracy: 0.9503\n",
      "Epoch 73/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1364 - accuracy: 0.9422 - val_loss: 0.1392 - val_accuracy: 0.9421\n",
      "Epoch 74/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1312 - accuracy: 0.9475 - val_loss: 0.1189 - val_accuracy: 0.9521\n",
      "Epoch 75/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1459 - accuracy: 0.9398 - val_loss: 0.1345 - val_accuracy: 0.9435\n",
      "Epoch 76/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1236 - accuracy: 0.9488 - val_loss: 0.1046 - val_accuracy: 0.9603\n",
      "Epoch 77/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1270 - accuracy: 0.9473 - val_loss: 0.1447 - val_accuracy: 0.9425\n",
      "Epoch 78/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1210 - accuracy: 0.9508 - val_loss: 0.1129 - val_accuracy: 0.9528\n",
      "Epoch 79/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1146 - accuracy: 0.9536 - val_loss: 0.1074 - val_accuracy: 0.9571\n",
      "Epoch 80/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1171 - accuracy: 0.9521 - val_loss: 0.1186 - val_accuracy: 0.9535\n",
      "Epoch 81/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1220 - accuracy: 0.9528 - val_loss: 0.1057 - val_accuracy: 0.9593\n",
      "Epoch 82/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1140 - accuracy: 0.9552 - val_loss: 0.1121 - val_accuracy: 0.9575\n",
      "Epoch 83/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1084 - accuracy: 0.9563 - val_loss: 0.0992 - val_accuracy: 0.9621\n",
      "Epoch 84/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1141 - accuracy: 0.9538 - val_loss: 0.1084 - val_accuracy: 0.9585\n",
      "Epoch 85/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1203 - accuracy: 0.9513 - val_loss: 0.0915 - val_accuracy: 0.9632\n",
      "Epoch 86/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1085 - accuracy: 0.9561 - val_loss: 0.1243 - val_accuracy: 0.9514\n",
      "Epoch 87/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1054 - accuracy: 0.9569 - val_loss: 0.1044 - val_accuracy: 0.9589\n",
      "Epoch 88/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1018 - accuracy: 0.9587 - val_loss: 0.1417 - val_accuracy: 0.9464\n",
      "Epoch 89/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1029 - accuracy: 0.9588 - val_loss: 0.0969 - val_accuracy: 0.9614\n",
      "Epoch 90/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1225 - accuracy: 0.9520 - val_loss: 0.1075 - val_accuracy: 0.9603\n",
      "Epoch 91/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1018 - accuracy: 0.9591 - val_loss: 0.1028 - val_accuracy: 0.9621\n",
      "Epoch 92/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1122 - accuracy: 0.9558 - val_loss: 0.2495 - val_accuracy: 0.8903\n",
      "Epoch 93/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1049 - accuracy: 0.9580 - val_loss: 0.1066 - val_accuracy: 0.9593\n",
      "Epoch 94/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0995 - accuracy: 0.9610 - val_loss: 0.0917 - val_accuracy: 0.9675\n",
      "Epoch 95/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0952 - accuracy: 0.9602 - val_loss: 0.0882 - val_accuracy: 0.9657\n",
      "Epoch 96/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0955 - accuracy: 0.9619 - val_loss: 0.0978 - val_accuracy: 0.9639\n",
      "Epoch 97/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0935 - accuracy: 0.9630 - val_loss: 0.0934 - val_accuracy: 0.9693\n",
      "Epoch 98/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0901 - accuracy: 0.9644 - val_loss: 0.1002 - val_accuracy: 0.9607\n",
      "Epoch 99/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0902 - accuracy: 0.9650 - val_loss: 0.0822 - val_accuracy: 0.9660\n",
      "Epoch 100/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0878 - accuracy: 0.9636 - val_loss: 0.1044 - val_accuracy: 0.9546\n",
      "Epoch 101/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0837 - accuracy: 0.9676 - val_loss: 0.0737 - val_accuracy: 0.9693\n",
      "Epoch 102/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0868 - accuracy: 0.9652 - val_loss: 0.1255 - val_accuracy: 0.9503\n",
      "Epoch 103/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0831 - accuracy: 0.9682 - val_loss: 0.0807 - val_accuracy: 0.9718\n",
      "Epoch 104/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0754 - accuracy: 0.9697 - val_loss: 0.0850 - val_accuracy: 0.9657\n",
      "Epoch 105/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0816 - accuracy: 0.9677 - val_loss: 0.1831 - val_accuracy: 0.9296\n",
      "Epoch 106/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0819 - accuracy: 0.9689 - val_loss: 0.1887 - val_accuracy: 0.9249\n",
      "Epoch 107/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0829 - accuracy: 0.9669 - val_loss: 0.0745 - val_accuracy: 0.9736\n",
      "Epoch 108/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0773 - accuracy: 0.9704 - val_loss: 0.1336 - val_accuracy: 0.9500\n",
      "Epoch 109/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0727 - accuracy: 0.9707 - val_loss: 0.0947 - val_accuracy: 0.9689\n",
      "Epoch 110/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0751 - accuracy: 0.9706 - val_loss: 0.0996 - val_accuracy: 0.9621\n",
      "Epoch 111/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0714 - accuracy: 0.9723 - val_loss: 0.0952 - val_accuracy: 0.9650\n",
      "Epoch 112/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0670 - accuracy: 0.9745 - val_loss: 0.0757 - val_accuracy: 0.9711\n",
      "Epoch 113/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0979 - accuracy: 0.9623 - val_loss: 0.0842 - val_accuracy: 0.9725\n",
      "Epoch 114/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0670 - accuracy: 0.9743 - val_loss: 0.1315 - val_accuracy: 0.9532\n",
      "Epoch 115/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0732 - accuracy: 0.9719 - val_loss: 0.0657 - val_accuracy: 0.9768\n",
      "Epoch 116/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0630 - accuracy: 0.9759 - val_loss: 0.1426 - val_accuracy: 0.9410\n",
      "Epoch 117/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0688 - accuracy: 0.9733 - val_loss: 0.0890 - val_accuracy: 0.9664\n",
      "Epoch 118/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0670 - accuracy: 0.9749 - val_loss: 0.0677 - val_accuracy: 0.9732\n",
      "Epoch 119/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0852 - accuracy: 0.9678 - val_loss: 0.1216 - val_accuracy: 0.9553\n",
      "Epoch 120/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0807 - accuracy: 0.9692 - val_loss: 0.0992 - val_accuracy: 0.9643\n",
      "Epoch 121/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0563 - accuracy: 0.9778 - val_loss: 0.0667 - val_accuracy: 0.9768\n",
      "Epoch 122/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0678 - accuracy: 0.9739 - val_loss: 0.0710 - val_accuracy: 0.9771\n",
      "Epoch 123/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0579 - accuracy: 0.9779 - val_loss: 0.0720 - val_accuracy: 0.9757\n",
      "Epoch 124/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0608 - accuracy: 0.9768 - val_loss: 0.0769 - val_accuracy: 0.9711\n",
      "Epoch 125/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0653 - accuracy: 0.9759 - val_loss: 0.0652 - val_accuracy: 0.9746\n",
      "Epoch 126/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0623 - accuracy: 0.9765 - val_loss: 0.1545 - val_accuracy: 0.9439\n",
      "Epoch 127/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0588 - accuracy: 0.9773 - val_loss: 0.0684 - val_accuracy: 0.9768\n",
      "Epoch 128/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0733 - accuracy: 0.9711 - val_loss: 0.0770 - val_accuracy: 0.9746\n",
      "Epoch 129/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0553 - accuracy: 0.9790 - val_loss: 0.0593 - val_accuracy: 0.9821\n",
      "Epoch 130/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0506 - accuracy: 0.9801 - val_loss: 0.0735 - val_accuracy: 0.9753\n",
      "Epoch 131/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0729 - accuracy: 0.9716 - val_loss: 0.0752 - val_accuracy: 0.9721\n",
      "Epoch 132/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0498 - accuracy: 0.9809 - val_loss: 0.2099 - val_accuracy: 0.9207\n",
      "Epoch 133/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0739 - accuracy: 0.9716 - val_loss: 0.0823 - val_accuracy: 0.9682\n",
      "Epoch 134/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0506 - accuracy: 0.9811 - val_loss: 0.0592 - val_accuracy: 0.9807\n",
      "Epoch 135/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0671 - accuracy: 0.9749 - val_loss: 0.0631 - val_accuracy: 0.9789\n",
      "Epoch 136/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0481 - accuracy: 0.9820 - val_loss: 0.0711 - val_accuracy: 0.9746\n",
      "Epoch 137/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0567 - accuracy: 0.9780 - val_loss: 0.0643 - val_accuracy: 0.9775\n",
      "Epoch 138/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0557 - accuracy: 0.9791 - val_loss: 0.0858 - val_accuracy: 0.9718\n",
      "Epoch 139/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0500 - accuracy: 0.9801 - val_loss: 0.0611 - val_accuracy: 0.9807\n",
      "Epoch 140/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0526 - accuracy: 0.9798 - val_loss: 0.0887 - val_accuracy: 0.9675\n",
      "Epoch 141/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0594 - accuracy: 0.9774 - val_loss: 0.0857 - val_accuracy: 0.9700\n",
      "Epoch 142/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0452 - accuracy: 0.9834 - val_loss: 0.0705 - val_accuracy: 0.9743\n",
      "Epoch 143/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0445 - accuracy: 0.9832 - val_loss: 0.0579 - val_accuracy: 0.9796\n",
      "Epoch 144/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0564 - accuracy: 0.9792 - val_loss: 0.0731 - val_accuracy: 0.9807\n",
      "Epoch 145/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0717 - accuracy: 0.9741 - val_loss: 0.0605 - val_accuracy: 0.9796\n",
      "Epoch 146/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0462 - accuracy: 0.9825 - val_loss: 0.0876 - val_accuracy: 0.9671\n",
      "Epoch 147/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0473 - accuracy: 0.9822 - val_loss: 0.0908 - val_accuracy: 0.9668\n",
      "Epoch 148/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0504 - accuracy: 0.9816 - val_loss: 0.0607 - val_accuracy: 0.9807\n",
      "Epoch 149/500\n",
      "333/333 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9801Restoring model weights from the end of the best epoch: 129.\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0545 - accuracy: 0.9801 - val_loss: 0.1198 - val_accuracy: 0.9557\n",
      "Epoch 149: early stopping\n",
      "Number of iterations 4\n",
      "F1-scores:  [0.7948717948717948, 0.9470443349753696, 0.9683313032886723, 0.969249692496925]\n",
      "Average F1-Score 0.9198742814081905\n",
      "Std Dev F1-Score 0.07271493594996867\n",
      "Error bar F1-Score 0.036357467974984334\n",
      "Epoch 1/500\n",
      "333/333 [==============================] - 11s 20ms/step - loss: 0.5545 - accuracy: 0.7130 - val_loss: 0.5088 - val_accuracy: 0.7094\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5052 - accuracy: 0.7209 - val_loss: 0.5337 - val_accuracy: 0.7127\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4358 - accuracy: 0.7685 - val_loss: 0.3791 - val_accuracy: 0.8038\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3722 - accuracy: 0.8129 - val_loss: 0.3409 - val_accuracy: 0.8385\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3483 - accuracy: 0.8281 - val_loss: 0.2971 - val_accuracy: 0.8538\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3220 - accuracy: 0.8465 - val_loss: 0.3109 - val_accuracy: 0.8635\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3043 - accuracy: 0.8556 - val_loss: 0.3417 - val_accuracy: 0.8420\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3078 - accuracy: 0.8542 - val_loss: 0.2720 - val_accuracy: 0.8778\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2955 - accuracy: 0.8590 - val_loss: 0.2580 - val_accuracy: 0.8728\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2932 - accuracy: 0.8599 - val_loss: 0.2659 - val_accuracy: 0.8710\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2829 - accuracy: 0.8647 - val_loss: 0.2876 - val_accuracy: 0.8746\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2774 - accuracy: 0.8657 - val_loss: 0.2621 - val_accuracy: 0.8699\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2877 - accuracy: 0.8628 - val_loss: 0.2560 - val_accuracy: 0.8724\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2843 - accuracy: 0.8626 - val_loss: 0.2376 - val_accuracy: 0.8796\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3169 - accuracy: 0.8456 - val_loss: 0.2796 - val_accuracy: 0.8778\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2843 - accuracy: 0.8631 - val_loss: 0.2484 - val_accuracy: 0.8760\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2730 - accuracy: 0.8671 - val_loss: 0.2415 - val_accuracy: 0.8785\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2988 - accuracy: 0.8583 - val_loss: 0.2757 - val_accuracy: 0.8792\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2707 - accuracy: 0.8678 - val_loss: 0.3344 - val_accuracy: 0.8631\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2706 - accuracy: 0.8683 - val_loss: 0.3800 - val_accuracy: 0.8360\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2714 - accuracy: 0.8676 - val_loss: 0.2387 - val_accuracy: 0.8831\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2725 - accuracy: 0.8654 - val_loss: 0.2392 - val_accuracy: 0.8763\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2705 - accuracy: 0.8690 - val_loss: 0.2465 - val_accuracy: 0.8724\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2716 - accuracy: 0.8677 - val_loss: 0.2395 - val_accuracy: 0.8838\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2637 - accuracy: 0.8687 - val_loss: 0.2452 - val_accuracy: 0.8788\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2651 - accuracy: 0.8693 - val_loss: 0.2859 - val_accuracy: 0.8781\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3014 - accuracy: 0.8568 - val_loss: 0.2452 - val_accuracy: 0.8742\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2690 - accuracy: 0.8695 - val_loss: 0.2344 - val_accuracy: 0.8831\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2806 - accuracy: 0.8639 - val_loss: 0.2550 - val_accuracy: 0.8756\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2723 - accuracy: 0.8674 - val_loss: 0.2971 - val_accuracy: 0.8599\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2745 - accuracy: 0.8659 - val_loss: 0.2413 - val_accuracy: 0.8771\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3122 - accuracy: 0.8454 - val_loss: 0.2472 - val_accuracy: 0.8863\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2803 - accuracy: 0.8661 - val_loss: 0.3534 - val_accuracy: 0.8574\n",
      "Epoch 34/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2859 - accuracy: 0.8630 - val_loss: 0.3202 - val_accuracy: 0.8578\n",
      "Epoch 35/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2650 - accuracy: 0.8707 - val_loss: 0.2357 - val_accuracy: 0.8828\n",
      "Epoch 36/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2806 - accuracy: 0.8654 - val_loss: 0.2427 - val_accuracy: 0.8771\n",
      "Epoch 37/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2606 - accuracy: 0.8722 - val_loss: 0.3237 - val_accuracy: 0.8395\n",
      "Epoch 38/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2750 - accuracy: 0.8659 - val_loss: 0.2534 - val_accuracy: 0.8778\n",
      "Epoch 39/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2744 - accuracy: 0.8695 - val_loss: 0.2548 - val_accuracy: 0.8806\n",
      "Epoch 40/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2613 - accuracy: 0.8729 - val_loss: 0.2366 - val_accuracy: 0.8821\n",
      "Epoch 41/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2566 - accuracy: 0.8748 - val_loss: 0.2491 - val_accuracy: 0.8824\n",
      "Epoch 42/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2700 - accuracy: 0.8711 - val_loss: 0.2311 - val_accuracy: 0.8935\n",
      "Epoch 43/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2646 - accuracy: 0.8756 - val_loss: 0.3219 - val_accuracy: 0.8599\n",
      "Epoch 44/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2687 - accuracy: 0.8733 - val_loss: 0.2293 - val_accuracy: 0.8863\n",
      "Epoch 45/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2666 - accuracy: 0.8758 - val_loss: 0.2482 - val_accuracy: 0.8731\n",
      "Epoch 46/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2596 - accuracy: 0.8774 - val_loss: 0.2423 - val_accuracy: 0.8960\n",
      "Epoch 47/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2353 - accuracy: 0.8952 - val_loss: 0.1815 - val_accuracy: 0.9282\n",
      "Epoch 48/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2150 - accuracy: 0.9091 - val_loss: 0.2028 - val_accuracy: 0.9189\n",
      "Epoch 49/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2087 - accuracy: 0.9137 - val_loss: 0.1703 - val_accuracy: 0.9289\n",
      "Epoch 50/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2024 - accuracy: 0.9168 - val_loss: 0.1511 - val_accuracy: 0.9464\n",
      "Epoch 51/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2004 - accuracy: 0.9173 - val_loss: 0.1444 - val_accuracy: 0.9482\n",
      "Epoch 52/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2051 - accuracy: 0.9130 - val_loss: 0.2769 - val_accuracy: 0.9010\n",
      "Epoch 53/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2061 - accuracy: 0.9170 - val_loss: 0.6479 - val_accuracy: 0.7402\n",
      "Epoch 54/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3210 - accuracy: 0.8429 - val_loss: 0.2409 - val_accuracy: 0.8860\n",
      "Epoch 55/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2693 - accuracy: 0.8691 - val_loss: 0.2380 - val_accuracy: 0.8817\n",
      "Epoch 56/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2704 - accuracy: 0.8691 - val_loss: 0.2360 - val_accuracy: 0.8788\n",
      "Epoch 57/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2684 - accuracy: 0.8710 - val_loss: 0.6952 - val_accuracy: 0.7198\n",
      "Epoch 58/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4052 - accuracy: 0.7985 - val_loss: 0.2856 - val_accuracy: 0.8810\n",
      "Epoch 59/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2920 - accuracy: 0.8637 - val_loss: 0.2463 - val_accuracy: 0.8824\n",
      "Epoch 60/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2769 - accuracy: 0.8637 - val_loss: 0.2454 - val_accuracy: 0.8853\n",
      "Epoch 61/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2720 - accuracy: 0.8679 - val_loss: 0.2234 - val_accuracy: 0.9042\n",
      "Epoch 62/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2662 - accuracy: 0.8815 - val_loss: 0.2490 - val_accuracy: 0.8817\n",
      "Epoch 63/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2685 - accuracy: 0.8673 - val_loss: 0.2956 - val_accuracy: 0.8578\n",
      "Epoch 64/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2621 - accuracy: 0.8693 - val_loss: 0.2618 - val_accuracy: 0.8881\n",
      "Epoch 65/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2692 - accuracy: 0.8662 - val_loss: 0.2457 - val_accuracy: 0.8763\n",
      "Epoch 66/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2924 - accuracy: 0.8584 - val_loss: 0.2348 - val_accuracy: 0.8831\n",
      "Epoch 67/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2653 - accuracy: 0.8713 - val_loss: 0.2589 - val_accuracy: 0.8803\n",
      "Epoch 68/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2669 - accuracy: 0.8692 - val_loss: 0.2358 - val_accuracy: 0.8774\n",
      "Epoch 69/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2624 - accuracy: 0.8736 - val_loss: 0.2333 - val_accuracy: 0.8853\n",
      "Epoch 70/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2616 - accuracy: 0.8798 - val_loss: 0.2167 - val_accuracy: 0.9056\n",
      "Epoch 71/500\n",
      "330/333 [============================>.] - ETA: 0s - loss: 0.2894 - accuracy: 0.8623Restoring model weights from the end of the best epoch: 51.\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2893 - accuracy: 0.8623 - val_loss: 0.2408 - val_accuracy: 0.8856\n",
      "Epoch 71: early stopping\n",
      "Number of iterations 5\n",
      "F1-scores:  [0.7948717948717948, 0.9470443349753696, 0.9683313032886723, 0.969249692496925, 0.9086326402016384]\n",
      "Average F1-Score 0.9176259531668801\n",
      "Std Dev F1-Score 0.0651934770332825\n",
      "Error bar F1-Score 0.029155409267198198\n",
      "Epoch 1/500\n",
      "333/333 [==============================] - 11s 18ms/step - loss: 0.5576 - accuracy: 0.7139 - val_loss: 0.5395 - val_accuracy: 0.7277\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5183 - accuracy: 0.7166 - val_loss: 0.5008 - val_accuracy: 0.7398\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5081 - accuracy: 0.7232 - val_loss: 0.4970 - val_accuracy: 0.7112\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5013 - accuracy: 0.7276 - val_loss: 0.4941 - val_accuracy: 0.7352\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5086 - accuracy: 0.7218 - val_loss: 0.4886 - val_accuracy: 0.7416\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.5078 - accuracy: 0.7221 - val_loss: 0.4937 - val_accuracy: 0.7234\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4804 - accuracy: 0.7322 - val_loss: 0.4682 - val_accuracy: 0.7355\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4664 - accuracy: 0.7346 - val_loss: 0.4424 - val_accuracy: 0.7548\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.4133 - accuracy: 0.7862 - val_loss: 0.3607 - val_accuracy: 0.8295\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.3430 - accuracy: 0.8369 - val_loss: 0.2871 - val_accuracy: 0.8656\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2880 - accuracy: 0.8654 - val_loss: 0.2893 - val_accuracy: 0.8760\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2701 - accuracy: 0.8738 - val_loss: 0.2695 - val_accuracy: 0.8692\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2441 - accuracy: 0.8882 - val_loss: 0.2640 - val_accuracy: 0.8792\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2305 - accuracy: 0.8949 - val_loss: 0.2066 - val_accuracy: 0.9017\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2266 - accuracy: 0.8956 - val_loss: 0.3186 - val_accuracy: 0.8656\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2233 - accuracy: 0.8982 - val_loss: 0.2250 - val_accuracy: 0.9010\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2239 - accuracy: 0.8977 - val_loss: 0.1943 - val_accuracy: 0.9099\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2115 - accuracy: 0.9047 - val_loss: 0.1762 - val_accuracy: 0.9267\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2207 - accuracy: 0.8996 - val_loss: 0.2415 - val_accuracy: 0.8778\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2071 - accuracy: 0.9058 - val_loss: 0.1902 - val_accuracy: 0.9182\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2092 - accuracy: 0.9051 - val_loss: 0.1671 - val_accuracy: 0.9257\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.2018 - accuracy: 0.9100 - val_loss: 0.1777 - val_accuracy: 0.9235\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1986 - accuracy: 0.9108 - val_loss: 0.1731 - val_accuracy: 0.9214\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1968 - accuracy: 0.9110 - val_loss: 0.1683 - val_accuracy: 0.9274\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1910 - accuracy: 0.9159 - val_loss: 0.2048 - val_accuracy: 0.9046\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1969 - accuracy: 0.9123 - val_loss: 0.1593 - val_accuracy: 0.9278\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1919 - accuracy: 0.9149 - val_loss: 0.2084 - val_accuracy: 0.9031\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1832 - accuracy: 0.9173 - val_loss: 0.1678 - val_accuracy: 0.9199\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1762 - accuracy: 0.9233 - val_loss: 0.1727 - val_accuracy: 0.9264\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1857 - accuracy: 0.9211 - val_loss: 0.1556 - val_accuracy: 0.9278\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1740 - accuracy: 0.9237 - val_loss: 0.1511 - val_accuracy: 0.9375\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1903 - accuracy: 0.9164 - val_loss: 0.1538 - val_accuracy: 0.9314\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1686 - accuracy: 0.9291 - val_loss: 0.1547 - val_accuracy: 0.9339\n",
      "Epoch 34/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1766 - accuracy: 0.9236 - val_loss: 0.1438 - val_accuracy: 0.9435\n",
      "Epoch 35/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1594 - accuracy: 0.9321 - val_loss: 0.1546 - val_accuracy: 0.9367\n",
      "Epoch 36/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1674 - accuracy: 0.9276 - val_loss: 0.1954 - val_accuracy: 0.9128\n",
      "Epoch 37/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1676 - accuracy: 0.9283 - val_loss: 0.1915 - val_accuracy: 0.9228\n",
      "Epoch 38/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1589 - accuracy: 0.9330 - val_loss: 0.1435 - val_accuracy: 0.9403\n",
      "Epoch 39/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1463 - accuracy: 0.9382 - val_loss: 0.1525 - val_accuracy: 0.9357\n",
      "Epoch 40/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1525 - accuracy: 0.9345 - val_loss: 0.1442 - val_accuracy: 0.9389\n",
      "Epoch 41/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1504 - accuracy: 0.9355 - val_loss: 0.1202 - val_accuracy: 0.9525\n",
      "Epoch 42/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1407 - accuracy: 0.9420 - val_loss: 0.1315 - val_accuracy: 0.9464\n",
      "Epoch 43/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1496 - accuracy: 0.9395 - val_loss: 0.1475 - val_accuracy: 0.9492\n",
      "Epoch 44/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1423 - accuracy: 0.9403 - val_loss: 0.1728 - val_accuracy: 0.9357\n",
      "Epoch 45/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1411 - accuracy: 0.9429 - val_loss: 0.2836 - val_accuracy: 0.9107\n",
      "Epoch 46/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1513 - accuracy: 0.9363 - val_loss: 0.3012 - val_accuracy: 0.8610\n",
      "Epoch 47/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1428 - accuracy: 0.9404 - val_loss: 0.1207 - val_accuracy: 0.9489\n",
      "Epoch 48/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1345 - accuracy: 0.9447 - val_loss: 0.1275 - val_accuracy: 0.9503\n",
      "Epoch 49/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1288 - accuracy: 0.9478 - val_loss: 0.1151 - val_accuracy: 0.9507\n",
      "Epoch 50/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1272 - accuracy: 0.9465 - val_loss: 0.1055 - val_accuracy: 0.9575\n",
      "Epoch 51/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1338 - accuracy: 0.9473 - val_loss: 0.1102 - val_accuracy: 0.9546\n",
      "Epoch 52/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1267 - accuracy: 0.9465 - val_loss: 0.1441 - val_accuracy: 0.9364\n",
      "Epoch 53/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1230 - accuracy: 0.9499 - val_loss: 0.1563 - val_accuracy: 0.9346\n",
      "Epoch 54/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1212 - accuracy: 0.9498 - val_loss: 0.1318 - val_accuracy: 0.9460\n",
      "Epoch 55/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1144 - accuracy: 0.9546 - val_loss: 0.1470 - val_accuracy: 0.9364\n",
      "Epoch 56/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1260 - accuracy: 0.9492 - val_loss: 0.1136 - val_accuracy: 0.9557\n",
      "Epoch 57/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1328 - accuracy: 0.9466 - val_loss: 0.1610 - val_accuracy: 0.9335\n",
      "Epoch 58/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1141 - accuracy: 0.9530 - val_loss: 0.1156 - val_accuracy: 0.9546\n",
      "Epoch 59/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1411 - accuracy: 0.9431 - val_loss: 0.1441 - val_accuracy: 0.9425\n",
      "Epoch 60/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1205 - accuracy: 0.9528 - val_loss: 0.0955 - val_accuracy: 0.9639\n",
      "Epoch 61/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1064 - accuracy: 0.9585 - val_loss: 0.1454 - val_accuracy: 0.9400\n",
      "Epoch 62/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1180 - accuracy: 0.9531 - val_loss: 0.1240 - val_accuracy: 0.9518\n",
      "Epoch 63/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1116 - accuracy: 0.9565 - val_loss: 0.0986 - val_accuracy: 0.9596\n",
      "Epoch 64/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0989 - accuracy: 0.9608 - val_loss: 0.0972 - val_accuracy: 0.9607\n",
      "Epoch 65/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1096 - accuracy: 0.9564 - val_loss: 0.1688 - val_accuracy: 0.9249\n",
      "Epoch 66/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1171 - accuracy: 0.9545 - val_loss: 0.0993 - val_accuracy: 0.9603\n",
      "Epoch 67/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1064 - accuracy: 0.9577 - val_loss: 0.0925 - val_accuracy: 0.9668\n",
      "Epoch 68/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0935 - accuracy: 0.9627 - val_loss: 0.1172 - val_accuracy: 0.9500\n",
      "Epoch 69/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1028 - accuracy: 0.9596 - val_loss: 0.0895 - val_accuracy: 0.9660\n",
      "Epoch 70/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0871 - accuracy: 0.9663 - val_loss: 0.0980 - val_accuracy: 0.9614\n",
      "Epoch 71/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1046 - accuracy: 0.9586 - val_loss: 0.1094 - val_accuracy: 0.9571\n",
      "Epoch 72/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0868 - accuracy: 0.9670 - val_loss: 0.0892 - val_accuracy: 0.9643\n",
      "Epoch 73/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0883 - accuracy: 0.9657 - val_loss: 0.0881 - val_accuracy: 0.9682\n",
      "Epoch 74/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0890 - accuracy: 0.9646 - val_loss: 0.0893 - val_accuracy: 0.9646\n",
      "Epoch 75/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0882 - accuracy: 0.9661 - val_loss: 0.1014 - val_accuracy: 0.9568\n",
      "Epoch 76/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0874 - accuracy: 0.9665 - val_loss: 0.0745 - val_accuracy: 0.9693\n",
      "Epoch 77/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0828 - accuracy: 0.9679 - val_loss: 0.0901 - val_accuracy: 0.9639\n",
      "Epoch 78/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0810 - accuracy: 0.9679 - val_loss: 0.1025 - val_accuracy: 0.9600\n",
      "Epoch 79/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0988 - accuracy: 0.9607 - val_loss: 0.1268 - val_accuracy: 0.9460\n",
      "Epoch 80/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0872 - accuracy: 0.9661 - val_loss: 0.0975 - val_accuracy: 0.9625\n",
      "Epoch 81/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0763 - accuracy: 0.9704 - val_loss: 0.0880 - val_accuracy: 0.9650\n",
      "Epoch 82/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0762 - accuracy: 0.9707 - val_loss: 0.1806 - val_accuracy: 0.9317\n",
      "Epoch 83/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0819 - accuracy: 0.9686 - val_loss: 0.1050 - val_accuracy: 0.9618\n",
      "Epoch 84/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0909 - accuracy: 0.9650 - val_loss: 0.0868 - val_accuracy: 0.9693\n",
      "Epoch 85/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0812 - accuracy: 0.9684 - val_loss: 0.1094 - val_accuracy: 0.9571\n",
      "Epoch 86/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0728 - accuracy: 0.9733 - val_loss: 0.1521 - val_accuracy: 0.9335\n",
      "Epoch 87/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0828 - accuracy: 0.9667 - val_loss: 0.1044 - val_accuracy: 0.9628\n",
      "Epoch 88/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0992 - accuracy: 0.9619 - val_loss: 0.0921 - val_accuracy: 0.9646\n",
      "Epoch 89/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0830 - accuracy: 0.9685 - val_loss: 0.1262 - val_accuracy: 0.9568\n",
      "Epoch 90/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0771 - accuracy: 0.9719 - val_loss: 0.0998 - val_accuracy: 0.9675\n",
      "Epoch 91/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0805 - accuracy: 0.9686 - val_loss: 0.1097 - val_accuracy: 0.9557\n",
      "Epoch 92/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0773 - accuracy: 0.9701 - val_loss: 0.0991 - val_accuracy: 0.9610\n",
      "Epoch 93/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0749 - accuracy: 0.9708 - val_loss: 0.1316 - val_accuracy: 0.9514\n",
      "Epoch 94/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0695 - accuracy: 0.9731 - val_loss: 0.0983 - val_accuracy: 0.9635\n",
      "Epoch 95/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0664 - accuracy: 0.9751 - val_loss: 0.0828 - val_accuracy: 0.9703\n",
      "Epoch 96/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1656 - accuracy: 0.9359 - val_loss: 0.1262 - val_accuracy: 0.9496\n",
      "Epoch 97/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0748 - accuracy: 0.9715 - val_loss: 0.1105 - val_accuracy: 0.9553\n",
      "Epoch 98/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0650 - accuracy: 0.9754 - val_loss: 0.0887 - val_accuracy: 0.9678\n",
      "Epoch 99/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0763 - accuracy: 0.9713 - val_loss: 0.1399 - val_accuracy: 0.9417\n",
      "Epoch 100/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0730 - accuracy: 0.9722 - val_loss: 0.0926 - val_accuracy: 0.9653\n",
      "Epoch 101/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0642 - accuracy: 0.9749 - val_loss: 0.1075 - val_accuracy: 0.9603\n",
      "Epoch 102/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0676 - accuracy: 0.9753 - val_loss: 0.0937 - val_accuracy: 0.9668\n",
      "Epoch 103/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0655 - accuracy: 0.9753 - val_loss: 0.1483 - val_accuracy: 0.9485\n",
      "Epoch 104/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0677 - accuracy: 0.9739 - val_loss: 0.0906 - val_accuracy: 0.9628\n",
      "Epoch 105/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0851 - accuracy: 0.9671 - val_loss: 0.1161 - val_accuracy: 0.9528\n",
      "Epoch 106/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0541 - accuracy: 0.9800 - val_loss: 0.0976 - val_accuracy: 0.9693\n",
      "Epoch 107/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0703 - accuracy: 0.9745 - val_loss: 0.0984 - val_accuracy: 0.9621\n",
      "Epoch 108/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0624 - accuracy: 0.9766 - val_loss: 0.0967 - val_accuracy: 0.9639\n",
      "Epoch 109/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0886 - accuracy: 0.9663 - val_loss: 0.0979 - val_accuracy: 0.9625\n",
      "Epoch 110/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0583 - accuracy: 0.9789 - val_loss: 0.0888 - val_accuracy: 0.9693\n",
      "Epoch 111/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0763 - accuracy: 0.9711 - val_loss: 0.0819 - val_accuracy: 0.9739\n",
      "Epoch 112/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0611 - accuracy: 0.9775 - val_loss: 0.0911 - val_accuracy: 0.9682\n",
      "Epoch 113/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0575 - accuracy: 0.9780 - val_loss: 0.1011 - val_accuracy: 0.9657\n",
      "Epoch 114/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0583 - accuracy: 0.9783 - val_loss: 0.1299 - val_accuracy: 0.9535\n",
      "Epoch 115/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1131 - accuracy: 0.9575 - val_loss: 0.1008 - val_accuracy: 0.9568\n",
      "Epoch 116/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0694 - accuracy: 0.9745 - val_loss: 0.0869 - val_accuracy: 0.9693\n",
      "Epoch 117/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0570 - accuracy: 0.9793 - val_loss: 0.0928 - val_accuracy: 0.9660\n",
      "Epoch 118/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0641 - accuracy: 0.9767 - val_loss: 0.1282 - val_accuracy: 0.9471\n",
      "Epoch 119/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1079 - accuracy: 0.9604 - val_loss: 0.0869 - val_accuracy: 0.9700\n",
      "Epoch 120/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0551 - accuracy: 0.9801 - val_loss: 0.0814 - val_accuracy: 0.9671\n",
      "Epoch 121/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0544 - accuracy: 0.9793 - val_loss: 0.0867 - val_accuracy: 0.9711\n",
      "Epoch 122/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0604 - accuracy: 0.9777 - val_loss: 0.0744 - val_accuracy: 0.9711\n",
      "Epoch 123/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0635 - accuracy: 0.9748 - val_loss: 0.0865 - val_accuracy: 0.9696\n",
      "Epoch 124/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0583 - accuracy: 0.9778 - val_loss: 0.0849 - val_accuracy: 0.9711\n",
      "Epoch 125/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0523 - accuracy: 0.9809 - val_loss: 0.1012 - val_accuracy: 0.9646\n",
      "Epoch 126/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0721 - accuracy: 0.9727 - val_loss: 0.2341 - val_accuracy: 0.9192\n",
      "Epoch 127/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0600 - accuracy: 0.9785 - val_loss: 0.0845 - val_accuracy: 0.9707\n",
      "Epoch 128/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0430 - accuracy: 0.9841 - val_loss: 0.0966 - val_accuracy: 0.9685\n",
      "Epoch 129/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0686 - accuracy: 0.9748 - val_loss: 0.0751 - val_accuracy: 0.9743\n",
      "Epoch 130/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0556 - accuracy: 0.9788 - val_loss: 0.0945 - val_accuracy: 0.9668\n",
      "Epoch 131/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0485 - accuracy: 0.9832 - val_loss: 0.1623 - val_accuracy: 0.9471\n",
      "Epoch 132/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0501 - accuracy: 0.9809 - val_loss: 0.0974 - val_accuracy: 0.9664\n",
      "Epoch 133/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0617 - accuracy: 0.9762 - val_loss: 0.1162 - val_accuracy: 0.9575\n",
      "Epoch 134/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0430 - accuracy: 0.9845 - val_loss: 0.1022 - val_accuracy: 0.9650\n",
      "Epoch 135/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0652 - accuracy: 0.9745 - val_loss: 0.0867 - val_accuracy: 0.9678\n",
      "Epoch 136/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.1094 - accuracy: 0.9566 - val_loss: 0.0827 - val_accuracy: 0.9718\n",
      "Epoch 137/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0556 - accuracy: 0.9799 - val_loss: 0.1356 - val_accuracy: 0.9492\n",
      "Epoch 138/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1391 - accuracy: 0.9451 - val_loss: 0.1739 - val_accuracy: 0.9282\n",
      "Epoch 139/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1179 - accuracy: 0.9499 - val_loss: 0.1425 - val_accuracy: 0.9475\n",
      "Epoch 140/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0521 - accuracy: 0.9806 - val_loss: 0.0853 - val_accuracy: 0.9696\n",
      "Epoch 141/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0586 - accuracy: 0.9780 - val_loss: 0.0860 - val_accuracy: 0.9700\n",
      "Epoch 142/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0530 - accuracy: 0.9804 - val_loss: 0.0838 - val_accuracy: 0.9728\n",
      "Epoch 143/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0423 - accuracy: 0.9847 - val_loss: 0.0801 - val_accuracy: 0.9721\n",
      "Epoch 144/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0612 - accuracy: 0.9774 - val_loss: 0.1274 - val_accuracy: 0.9521\n",
      "Epoch 145/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0445 - accuracy: 0.9840 - val_loss: 0.0874 - val_accuracy: 0.9696\n",
      "Epoch 146/500\n",
      "333/333 [==============================] - 5s 14ms/step - loss: 0.0363 - accuracy: 0.9861 - val_loss: 0.0923 - val_accuracy: 0.9671\n",
      "Epoch 147/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0772 - accuracy: 0.9723 - val_loss: 0.0800 - val_accuracy: 0.9707\n",
      "Epoch 148/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0364 - accuracy: 0.9864 - val_loss: 0.1236 - val_accuracy: 0.9585\n",
      "Epoch 149/500\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.0912 - accuracy: 0.9681Restoring model weights from the end of the best epoch: 129.\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0912 - accuracy: 0.9681 - val_loss: 0.1192 - val_accuracy: 0.9568\n",
      "Epoch 149: early stopping\n",
      "Number of iterations 6\n",
      "F1-scores:  [0.7948717948717948, 0.9470443349753696, 0.9683313032886723, 0.969249692496925, 0.9086326402016384, 0.9556650246305418]\n",
      "Average F1-Score 0.9239657984108237\n",
      "Std Dev F1-Score 0.06117836814043603\n",
      "Error bar F1-Score 0.024975964206701874\n",
      "Epoch 1/500\n",
      "333/333 [==============================] - 11s 18ms/step - loss: 0.5516 - accuracy: 0.7113 - val_loss: 0.5058 - val_accuracy: 0.7127\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5244 - accuracy: 0.7143 - val_loss: 0.4963 - val_accuracy: 0.7452\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5156 - accuracy: 0.7167 - val_loss: 0.4987 - val_accuracy: 0.7127\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5101 - accuracy: 0.7251 - val_loss: 0.4863 - val_accuracy: 0.7395\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5041 - accuracy: 0.7250 - val_loss: 0.5104 - val_accuracy: 0.7337\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4987 - accuracy: 0.7286 - val_loss: 0.5022 - val_accuracy: 0.7148\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4885 - accuracy: 0.7334 - val_loss: 0.4593 - val_accuracy: 0.7491\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4597 - accuracy: 0.7443 - val_loss: 0.4235 - val_accuracy: 0.7763\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4265 - accuracy: 0.7803 - val_loss: 0.4003 - val_accuracy: 0.8049\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4089 - accuracy: 0.7944 - val_loss: 0.3729 - val_accuracy: 0.8209\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3972 - accuracy: 0.8040 - val_loss: 0.3516 - val_accuracy: 0.8581\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3345 - accuracy: 0.8472 - val_loss: 0.3033 - val_accuracy: 0.8549\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2837 - accuracy: 0.8668 - val_loss: 0.2700 - val_accuracy: 0.8921\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2638 - accuracy: 0.8797 - val_loss: 0.2454 - val_accuracy: 0.9021\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2623 - accuracy: 0.8805 - val_loss: 0.4279 - val_accuracy: 0.7698\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3729 - accuracy: 0.8205 - val_loss: 0.2512 - val_accuracy: 0.8917\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2496 - accuracy: 0.8874 - val_loss: 0.2106 - val_accuracy: 0.9028\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2263 - accuracy: 0.8950 - val_loss: 0.3066 - val_accuracy: 0.8524\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3353 - accuracy: 0.8417 - val_loss: 0.3700 - val_accuracy: 0.8252\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3258 - accuracy: 0.8449 - val_loss: 0.2936 - val_accuracy: 0.8556\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2488 - accuracy: 0.8838 - val_loss: 0.3108 - val_accuracy: 0.8617\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2320 - accuracy: 0.8941 - val_loss: 0.1994 - val_accuracy: 0.9089\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2154 - accuracy: 0.9031 - val_loss: 0.1977 - val_accuracy: 0.9128\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2040 - accuracy: 0.9093 - val_loss: 0.1997 - val_accuracy: 0.9121\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2012 - accuracy: 0.9102 - val_loss: 0.2177 - val_accuracy: 0.9046\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2015 - accuracy: 0.9102 - val_loss: 0.1779 - val_accuracy: 0.9210\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1996 - accuracy: 0.9104 - val_loss: 0.1992 - val_accuracy: 0.9089\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1951 - accuracy: 0.9119 - val_loss: 0.1666 - val_accuracy: 0.9299\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1861 - accuracy: 0.9190 - val_loss: 0.1613 - val_accuracy: 0.9299\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2061 - accuracy: 0.9066 - val_loss: 0.1853 - val_accuracy: 0.9146\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1857 - accuracy: 0.9192 - val_loss: 0.2399 - val_accuracy: 0.8806\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1856 - accuracy: 0.9175 - val_loss: 0.1573 - val_accuracy: 0.9332\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1745 - accuracy: 0.9228 - val_loss: 0.1861 - val_accuracy: 0.9235\n",
      "Epoch 34/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1769 - accuracy: 0.9205 - val_loss: 0.1614 - val_accuracy: 0.9271\n",
      "Epoch 35/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1877 - accuracy: 0.9185 - val_loss: 0.1526 - val_accuracy: 0.9346\n",
      "Epoch 36/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1757 - accuracy: 0.9223 - val_loss: 0.1547 - val_accuracy: 0.9339\n",
      "Epoch 37/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1691 - accuracy: 0.9270 - val_loss: 0.1599 - val_accuracy: 0.9332\n",
      "Epoch 38/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1649 - accuracy: 0.9291 - val_loss: 0.1419 - val_accuracy: 0.9403\n",
      "Epoch 39/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1683 - accuracy: 0.9284 - val_loss: 0.1969 - val_accuracy: 0.9096\n",
      "Epoch 40/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1639 - accuracy: 0.9299 - val_loss: 0.1608 - val_accuracy: 0.9296\n",
      "Epoch 41/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1584 - accuracy: 0.9323 - val_loss: 0.1549 - val_accuracy: 0.9303\n",
      "Epoch 42/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1587 - accuracy: 0.9312 - val_loss: 0.1563 - val_accuracy: 0.9310\n",
      "Epoch 43/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1543 - accuracy: 0.9339 - val_loss: 0.1550 - val_accuracy: 0.9353\n",
      "Epoch 44/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2047 - accuracy: 0.9078 - val_loss: 0.1525 - val_accuracy: 0.9353\n",
      "Epoch 45/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1590 - accuracy: 0.9325 - val_loss: 0.1397 - val_accuracy: 0.9435\n",
      "Epoch 46/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1491 - accuracy: 0.9355 - val_loss: 0.1307 - val_accuracy: 0.9471\n",
      "Epoch 47/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1441 - accuracy: 0.9383 - val_loss: 0.1772 - val_accuracy: 0.9246\n",
      "Epoch 48/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1455 - accuracy: 0.9375 - val_loss: 0.1295 - val_accuracy: 0.9450\n",
      "Epoch 49/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1429 - accuracy: 0.9394 - val_loss: 0.1274 - val_accuracy: 0.9518\n",
      "Epoch 50/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1467 - accuracy: 0.9372 - val_loss: 0.1384 - val_accuracy: 0.9367\n",
      "Epoch 51/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1397 - accuracy: 0.9411 - val_loss: 0.1278 - val_accuracy: 0.9492\n",
      "Epoch 52/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3020 - accuracy: 0.8604 - val_loss: 0.3479 - val_accuracy: 0.8449\n",
      "Epoch 53/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2801 - accuracy: 0.8707 - val_loss: 0.2297 - val_accuracy: 0.8949\n",
      "Epoch 54/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2319 - accuracy: 0.8948 - val_loss: 0.2061 - val_accuracy: 0.9128\n",
      "Epoch 55/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2060 - accuracy: 0.9108 - val_loss: 0.3190 - val_accuracy: 0.8785\n",
      "Epoch 56/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1971 - accuracy: 0.9156 - val_loss: 0.1829 - val_accuracy: 0.9235\n",
      "Epoch 57/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1838 - accuracy: 0.9218 - val_loss: 0.1811 - val_accuracy: 0.9235\n",
      "Epoch 58/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1705 - accuracy: 0.9282 - val_loss: 0.2036 - val_accuracy: 0.9114\n",
      "Epoch 59/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1641 - accuracy: 0.9310 - val_loss: 0.1762 - val_accuracy: 0.9196\n",
      "Epoch 60/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1598 - accuracy: 0.9337 - val_loss: 0.2287 - val_accuracy: 0.8949\n",
      "Epoch 61/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1652 - accuracy: 0.9300 - val_loss: 0.1474 - val_accuracy: 0.9371\n",
      "Epoch 62/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1490 - accuracy: 0.9393 - val_loss: 0.1337 - val_accuracy: 0.9457\n",
      "Epoch 63/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1521 - accuracy: 0.9348 - val_loss: 0.1646 - val_accuracy: 0.9274\n",
      "Epoch 64/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1477 - accuracy: 0.9401 - val_loss: 0.1938 - val_accuracy: 0.9207\n",
      "Epoch 65/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1465 - accuracy: 0.9403 - val_loss: 0.1479 - val_accuracy: 0.9332\n",
      "Epoch 66/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1417 - accuracy: 0.9433 - val_loss: 0.1435 - val_accuracy: 0.9382\n",
      "Epoch 67/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1388 - accuracy: 0.9433 - val_loss: 0.1228 - val_accuracy: 0.9507\n",
      "Epoch 68/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1324 - accuracy: 0.9466 - val_loss: 0.1286 - val_accuracy: 0.9489\n",
      "Epoch 69/500\n",
      "333/333 [==============================] - ETA: 0s - loss: 0.1310 - accuracy: 0.9474Restoring model weights from the end of the best epoch: 49.\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1310 - accuracy: 0.9474 - val_loss: 0.1408 - val_accuracy: 0.9435\n",
      "Epoch 69: early stopping\n",
      "Number of iterations 7\n",
      "F1-scores:  [0.7948717948717948, 0.9470443349753696, 0.9683313032886723, 0.969249692496925, 0.9086326402016384, 0.9556650246305418, 0.9181322013341419]\n",
      "Average F1-Score 0.9231324273998692\n",
      "Std Dev F1-Score 0.05667693619368349\n",
      "Error bar F1-Score 0.021421868320223175\n",
      "Epoch 1/500\n",
      "333/333 [==============================] - 12s 18ms/step - loss: 0.5583 - accuracy: 0.7103 - val_loss: 0.5100 - val_accuracy: 0.7127\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5215 - accuracy: 0.7132 - val_loss: 0.5345 - val_accuracy: 0.7127\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5203 - accuracy: 0.7154 - val_loss: 0.5122 - val_accuracy: 0.7127\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5179 - accuracy: 0.7170 - val_loss: 0.4974 - val_accuracy: 0.7402\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5181 - accuracy: 0.7178 - val_loss: 0.5358 - val_accuracy: 0.6737\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5121 - accuracy: 0.7248 - val_loss: 0.4946 - val_accuracy: 0.7309\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5077 - accuracy: 0.7233 - val_loss: 0.5187 - val_accuracy: 0.7155\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4948 - accuracy: 0.7313 - val_loss: 0.4399 - val_accuracy: 0.7620\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4658 - accuracy: 0.7443 - val_loss: 0.4426 - val_accuracy: 0.7784\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3893 - accuracy: 0.8052 - val_loss: 0.3890 - val_accuracy: 0.8295\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3376 - accuracy: 0.8462 - val_loss: 0.5465 - val_accuracy: 0.7048\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4890 - accuracy: 0.7331 - val_loss: 0.4404 - val_accuracy: 0.7673\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4022 - accuracy: 0.7984 - val_loss: 0.3755 - val_accuracy: 0.8331\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3293 - accuracy: 0.8457 - val_loss: 0.3971 - val_accuracy: 0.8184\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3033 - accuracy: 0.8596 - val_loss: 0.2575 - val_accuracy: 0.8763\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2659 - accuracy: 0.8776 - val_loss: 0.2799 - val_accuracy: 0.8756\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2679 - accuracy: 0.8765 - val_loss: 0.2525 - val_accuracy: 0.8835\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2344 - accuracy: 0.8944 - val_loss: 0.2108 - val_accuracy: 0.9060\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2323 - accuracy: 0.8949 - val_loss: 0.2115 - val_accuracy: 0.9081\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2175 - accuracy: 0.9041 - val_loss: 0.1884 - val_accuracy: 0.9214\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2169 - accuracy: 0.9025 - val_loss: 0.2597 - val_accuracy: 0.8746\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2135 - accuracy: 0.9046 - val_loss: 0.2016 - val_accuracy: 0.9121\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2153 - accuracy: 0.9051 - val_loss: 0.1670 - val_accuracy: 0.9282\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2006 - accuracy: 0.9111 - val_loss: 0.2335 - val_accuracy: 0.8835\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1999 - accuracy: 0.9106 - val_loss: 0.1678 - val_accuracy: 0.9278\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1999 - accuracy: 0.9113 - val_loss: 0.2191 - val_accuracy: 0.9042\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1979 - accuracy: 0.9117 - val_loss: 0.1676 - val_accuracy: 0.9232\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1903 - accuracy: 0.9160 - val_loss: 0.1637 - val_accuracy: 0.9264\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1898 - accuracy: 0.9163 - val_loss: 0.1680 - val_accuracy: 0.9235\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1914 - accuracy: 0.9145 - val_loss: 0.1924 - val_accuracy: 0.9060\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1845 - accuracy: 0.9196 - val_loss: 0.1556 - val_accuracy: 0.9289\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1859 - accuracy: 0.9191 - val_loss: 0.2557 - val_accuracy: 0.9017\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1859 - accuracy: 0.9195 - val_loss: 0.1600 - val_accuracy: 0.9242\n",
      "Epoch 34/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1808 - accuracy: 0.9206 - val_loss: 0.2527 - val_accuracy: 0.8942\n",
      "Epoch 35/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1798 - accuracy: 0.9211 - val_loss: 0.1521 - val_accuracy: 0.9339\n",
      "Epoch 36/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1914 - accuracy: 0.9156 - val_loss: 0.1590 - val_accuracy: 0.9228\n",
      "Epoch 37/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1748 - accuracy: 0.9247 - val_loss: 0.1597 - val_accuracy: 0.9292\n",
      "Epoch 38/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1710 - accuracy: 0.9260 - val_loss: 0.1427 - val_accuracy: 0.9346\n",
      "Epoch 39/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1716 - accuracy: 0.9258 - val_loss: 0.1887 - val_accuracy: 0.9182\n",
      "Epoch 40/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1719 - accuracy: 0.9254 - val_loss: 0.1408 - val_accuracy: 0.9425\n",
      "Epoch 41/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1661 - accuracy: 0.9290 - val_loss: 0.1550 - val_accuracy: 0.9321\n",
      "Epoch 42/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1700 - accuracy: 0.9252 - val_loss: 0.1712 - val_accuracy: 0.9239\n",
      "Epoch 43/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1609 - accuracy: 0.9301 - val_loss: 0.2139 - val_accuracy: 0.8931\n",
      "Epoch 44/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1600 - accuracy: 0.9323 - val_loss: 0.1595 - val_accuracy: 0.9325\n",
      "Epoch 45/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1706 - accuracy: 0.9255 - val_loss: 0.1414 - val_accuracy: 0.9439\n",
      "Epoch 46/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1698 - accuracy: 0.9260 - val_loss: 0.1451 - val_accuracy: 0.9357\n",
      "Epoch 47/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1563 - accuracy: 0.9347 - val_loss: 0.1667 - val_accuracy: 0.9317\n",
      "Epoch 48/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1545 - accuracy: 0.9341 - val_loss: 0.1417 - val_accuracy: 0.9364\n",
      "Epoch 49/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1460 - accuracy: 0.9373 - val_loss: 0.1564 - val_accuracy: 0.9299\n",
      "Epoch 50/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1578 - accuracy: 0.9321 - val_loss: 0.1230 - val_accuracy: 0.9460\n",
      "Epoch 51/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1481 - accuracy: 0.9365 - val_loss: 0.1249 - val_accuracy: 0.9492\n",
      "Epoch 52/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1583 - accuracy: 0.9314 - val_loss: 0.1372 - val_accuracy: 0.9382\n",
      "Epoch 53/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1422 - accuracy: 0.9416 - val_loss: 0.1313 - val_accuracy: 0.9500\n",
      "Epoch 54/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1467 - accuracy: 0.9381 - val_loss: 0.2159 - val_accuracy: 0.9192\n",
      "Epoch 55/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1394 - accuracy: 0.9416 - val_loss: 0.1228 - val_accuracy: 0.9485\n",
      "Epoch 56/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1459 - accuracy: 0.9383 - val_loss: 0.1418 - val_accuracy: 0.9403\n",
      "Epoch 57/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1382 - accuracy: 0.9404 - val_loss: 0.1447 - val_accuracy: 0.9417\n",
      "Epoch 58/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1330 - accuracy: 0.9449 - val_loss: 0.1322 - val_accuracy: 0.9471\n",
      "Epoch 59/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1382 - accuracy: 0.9425 - val_loss: 0.1223 - val_accuracy: 0.9510\n",
      "Epoch 60/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1302 - accuracy: 0.9470 - val_loss: 0.1123 - val_accuracy: 0.9535\n",
      "Epoch 61/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1238 - accuracy: 0.9497 - val_loss: 0.1204 - val_accuracy: 0.9489\n",
      "Epoch 62/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1278 - accuracy: 0.9473 - val_loss: 0.2330 - val_accuracy: 0.9071\n",
      "Epoch 63/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1296 - accuracy: 0.9470 - val_loss: 0.1283 - val_accuracy: 0.9482\n",
      "Epoch 64/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1294 - accuracy: 0.9465 - val_loss: 0.2201 - val_accuracy: 0.8967\n",
      "Epoch 65/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1330 - accuracy: 0.9453 - val_loss: 0.1146 - val_accuracy: 0.9521\n",
      "Epoch 66/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1275 - accuracy: 0.9467 - val_loss: 0.1147 - val_accuracy: 0.9532\n",
      "Epoch 67/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1236 - accuracy: 0.9496 - val_loss: 0.1049 - val_accuracy: 0.9568\n",
      "Epoch 68/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1282 - accuracy: 0.9478 - val_loss: 0.1034 - val_accuracy: 0.9546\n",
      "Epoch 69/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1134 - accuracy: 0.9537 - val_loss: 0.1112 - val_accuracy: 0.9521\n",
      "Epoch 70/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1154 - accuracy: 0.9529 - val_loss: 0.1373 - val_accuracy: 0.9478\n",
      "Epoch 71/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1222 - accuracy: 0.9510 - val_loss: 0.0999 - val_accuracy: 0.9585\n",
      "Epoch 72/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1159 - accuracy: 0.9534 - val_loss: 0.1018 - val_accuracy: 0.9600\n",
      "Epoch 73/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1038 - accuracy: 0.9593 - val_loss: 0.1786 - val_accuracy: 0.9271\n",
      "Epoch 74/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1131 - accuracy: 0.9559 - val_loss: 0.1030 - val_accuracy: 0.9585\n",
      "Epoch 75/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1181 - accuracy: 0.9511 - val_loss: 0.1082 - val_accuracy: 0.9525\n",
      "Epoch 76/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1067 - accuracy: 0.9577 - val_loss: 0.1214 - val_accuracy: 0.9503\n",
      "Epoch 77/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1092 - accuracy: 0.9567 - val_loss: 0.1947 - val_accuracy: 0.9135\n",
      "Epoch 78/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1155 - accuracy: 0.9538 - val_loss: 0.1054 - val_accuracy: 0.9553\n",
      "Epoch 79/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1001 - accuracy: 0.9611 - val_loss: 0.2092 - val_accuracy: 0.9342\n",
      "Epoch 80/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1106 - accuracy: 0.9551 - val_loss: 0.1059 - val_accuracy: 0.9557\n",
      "Epoch 81/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1053 - accuracy: 0.9586 - val_loss: 0.1238 - val_accuracy: 0.9528\n",
      "Epoch 82/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1076 - accuracy: 0.9574 - val_loss: 0.1114 - val_accuracy: 0.9560\n",
      "Epoch 83/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0959 - accuracy: 0.9634 - val_loss: 0.0856 - val_accuracy: 0.9682\n",
      "Epoch 84/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0950 - accuracy: 0.9619 - val_loss: 0.1330 - val_accuracy: 0.9428\n",
      "Epoch 85/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0867 - accuracy: 0.9663 - val_loss: 0.1027 - val_accuracy: 0.9582\n",
      "Epoch 86/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0979 - accuracy: 0.9629 - val_loss: 0.0929 - val_accuracy: 0.9671\n",
      "Epoch 87/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1019 - accuracy: 0.9612 - val_loss: 0.1267 - val_accuracy: 0.9475\n",
      "Epoch 88/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0847 - accuracy: 0.9669 - val_loss: 0.0834 - val_accuracy: 0.9653\n",
      "Epoch 89/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0929 - accuracy: 0.9642 - val_loss: 0.0878 - val_accuracy: 0.9664\n",
      "Epoch 90/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0983 - accuracy: 0.9614 - val_loss: 0.1074 - val_accuracy: 0.9589\n",
      "Epoch 91/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0844 - accuracy: 0.9664 - val_loss: 0.0838 - val_accuracy: 0.9700\n",
      "Epoch 92/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0920 - accuracy: 0.9654 - val_loss: 0.1437 - val_accuracy: 0.9375\n",
      "Epoch 93/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0844 - accuracy: 0.9673 - val_loss: 0.1172 - val_accuracy: 0.9518\n",
      "Epoch 94/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0868 - accuracy: 0.9660 - val_loss: 0.1054 - val_accuracy: 0.9621\n",
      "Epoch 95/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0931 - accuracy: 0.9634 - val_loss: 0.0951 - val_accuracy: 0.9657\n",
      "Epoch 96/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0812 - accuracy: 0.9679 - val_loss: 0.1074 - val_accuracy: 0.9560\n",
      "Epoch 97/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0780 - accuracy: 0.9698 - val_loss: 0.0868 - val_accuracy: 0.9696\n",
      "Epoch 98/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0815 - accuracy: 0.9688 - val_loss: 0.0823 - val_accuracy: 0.9689\n",
      "Epoch 99/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0818 - accuracy: 0.9674 - val_loss: 0.0795 - val_accuracy: 0.9736\n",
      "Epoch 100/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0813 - accuracy: 0.9690 - val_loss: 0.0947 - val_accuracy: 0.9643\n",
      "Epoch 101/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0743 - accuracy: 0.9715 - val_loss: 0.0851 - val_accuracy: 0.9689\n",
      "Epoch 102/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0746 - accuracy: 0.9707 - val_loss: 0.1058 - val_accuracy: 0.9557\n",
      "Epoch 103/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0658 - accuracy: 0.9751 - val_loss: 0.1182 - val_accuracy: 0.9546\n",
      "Epoch 104/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0888 - accuracy: 0.9644 - val_loss: 0.0872 - val_accuracy: 0.9660\n",
      "Epoch 105/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0634 - accuracy: 0.9766 - val_loss: 0.1470 - val_accuracy: 0.9553\n",
      "Epoch 106/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0611 - accuracy: 0.9766 - val_loss: 0.0803 - val_accuracy: 0.9696\n",
      "Epoch 107/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0626 - accuracy: 0.9761 - val_loss: 0.0830 - val_accuracy: 0.9718\n",
      "Epoch 108/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0665 - accuracy: 0.9753 - val_loss: 0.0808 - val_accuracy: 0.9703\n",
      "Epoch 109/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0680 - accuracy: 0.9742 - val_loss: 0.0880 - val_accuracy: 0.9685\n",
      "Epoch 110/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0590 - accuracy: 0.9780 - val_loss: 0.0838 - val_accuracy: 0.9718\n",
      "Epoch 111/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0646 - accuracy: 0.9756 - val_loss: 0.0785 - val_accuracy: 0.9714\n",
      "Epoch 112/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0723 - accuracy: 0.9733 - val_loss: 0.0676 - val_accuracy: 0.9778\n",
      "Epoch 113/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0693 - accuracy: 0.9751 - val_loss: 0.0864 - val_accuracy: 0.9685\n",
      "Epoch 114/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0601 - accuracy: 0.9772 - val_loss: 0.1169 - val_accuracy: 0.9585\n",
      "Epoch 115/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0580 - accuracy: 0.9773 - val_loss: 0.0987 - val_accuracy: 0.9646\n",
      "Epoch 116/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0619 - accuracy: 0.9772 - val_loss: 0.0902 - val_accuracy: 0.9685\n",
      "Epoch 117/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0626 - accuracy: 0.9763 - val_loss: 0.0872 - val_accuracy: 0.9671\n",
      "Epoch 118/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0741 - accuracy: 0.9724 - val_loss: 0.1075 - val_accuracy: 0.9607\n",
      "Epoch 119/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0581 - accuracy: 0.9777 - val_loss: 0.0662 - val_accuracy: 0.9753\n",
      "Epoch 120/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0599 - accuracy: 0.9774 - val_loss: 0.0941 - val_accuracy: 0.9632\n",
      "Epoch 121/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0537 - accuracy: 0.9812 - val_loss: 0.0849 - val_accuracy: 0.9685\n",
      "Epoch 122/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0536 - accuracy: 0.9800 - val_loss: 0.0717 - val_accuracy: 0.9764\n",
      "Epoch 123/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0442 - accuracy: 0.9835 - val_loss: 0.1215 - val_accuracy: 0.9564\n",
      "Epoch 124/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0838 - accuracy: 0.9695 - val_loss: 0.1042 - val_accuracy: 0.9618\n",
      "Epoch 125/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0450 - accuracy: 0.9843 - val_loss: 0.0655 - val_accuracy: 0.9786\n",
      "Epoch 126/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0622 - accuracy: 0.9764 - val_loss: 0.0791 - val_accuracy: 0.9725\n",
      "Epoch 127/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0465 - accuracy: 0.9827 - val_loss: 0.0679 - val_accuracy: 0.9757\n",
      "Epoch 128/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0464 - accuracy: 0.9832 - val_loss: 0.0675 - val_accuracy: 0.9778\n",
      "Epoch 129/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0524 - accuracy: 0.9805 - val_loss: 0.0732 - val_accuracy: 0.9753\n",
      "Epoch 130/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0397 - accuracy: 0.9862 - val_loss: 0.0795 - val_accuracy: 0.9736\n",
      "Epoch 131/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0544 - accuracy: 0.9798 - val_loss: 0.1298 - val_accuracy: 0.9575\n",
      "Epoch 132/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0544 - accuracy: 0.9800 - val_loss: 0.0596 - val_accuracy: 0.9800\n",
      "Epoch 133/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0411 - accuracy: 0.9841 - val_loss: 0.0694 - val_accuracy: 0.9768\n",
      "Epoch 134/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0450 - accuracy: 0.9831 - val_loss: 0.0631 - val_accuracy: 0.9775\n",
      "Epoch 135/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0419 - accuracy: 0.9833 - val_loss: 0.0911 - val_accuracy: 0.9678\n",
      "Epoch 136/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0643 - accuracy: 0.9766 - val_loss: 0.1150 - val_accuracy: 0.9578\n",
      "Epoch 137/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0577 - accuracy: 0.9769 - val_loss: 0.0665 - val_accuracy: 0.9778\n",
      "Epoch 138/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0473 - accuracy: 0.9824 - val_loss: 0.0626 - val_accuracy: 0.9793\n",
      "Epoch 139/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0537 - accuracy: 0.9804 - val_loss: 0.0746 - val_accuracy: 0.9739\n",
      "Epoch 140/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0400 - accuracy: 0.9852 - val_loss: 0.0984 - val_accuracy: 0.9621\n",
      "Epoch 141/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0432 - accuracy: 0.9847 - val_loss: 0.1080 - val_accuracy: 0.9653\n",
      "Epoch 142/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0536 - accuracy: 0.9799 - val_loss: 0.0595 - val_accuracy: 0.9800\n",
      "Epoch 143/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0361 - accuracy: 0.9870 - val_loss: 0.0549 - val_accuracy: 0.9828\n",
      "Epoch 144/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0457 - accuracy: 0.9841 - val_loss: 0.0657 - val_accuracy: 0.9764\n",
      "Epoch 145/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0388 - accuracy: 0.9856 - val_loss: 0.0741 - val_accuracy: 0.9768\n",
      "Epoch 146/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0366 - accuracy: 0.9860 - val_loss: 0.0595 - val_accuracy: 0.9814\n",
      "Epoch 147/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0396 - accuracy: 0.9854 - val_loss: 0.0604 - val_accuracy: 0.9803\n",
      "Epoch 148/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0564 - accuracy: 0.9785 - val_loss: 0.0706 - val_accuracy: 0.9743\n",
      "Epoch 149/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0440 - accuracy: 0.9830 - val_loss: 0.0808 - val_accuracy: 0.9707\n",
      "Epoch 150/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0386 - accuracy: 0.9862 - val_loss: 0.0593 - val_accuracy: 0.9796\n",
      "Epoch 151/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0360 - accuracy: 0.9870 - val_loss: 0.0718 - val_accuracy: 0.9768\n",
      "Epoch 152/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0342 - accuracy: 0.9870 - val_loss: 0.0595 - val_accuracy: 0.9789\n",
      "Epoch 153/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0584 - accuracy: 0.9788 - val_loss: 0.0590 - val_accuracy: 0.9818\n",
      "Epoch 154/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0375 - accuracy: 0.9864 - val_loss: 0.0701 - val_accuracy: 0.9803\n",
      "Epoch 155/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0281 - accuracy: 0.9907 - val_loss: 0.0857 - val_accuracy: 0.9696\n",
      "Epoch 156/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0697 - accuracy: 0.9745 - val_loss: 0.0772 - val_accuracy: 0.9739\n",
      "Epoch 157/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0324 - accuracy: 0.9882 - val_loss: 0.0585 - val_accuracy: 0.9807\n",
      "Epoch 158/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0383 - accuracy: 0.9858 - val_loss: 0.0641 - val_accuracy: 0.9789\n",
      "Epoch 159/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0287 - accuracy: 0.9897 - val_loss: 0.0553 - val_accuracy: 0.9807\n",
      "Epoch 160/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0370 - accuracy: 0.9860 - val_loss: 0.0764 - val_accuracy: 0.9743\n",
      "Epoch 161/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0330 - accuracy: 0.9874 - val_loss: 0.0695 - val_accuracy: 0.9764\n",
      "Epoch 162/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0416 - accuracy: 0.9850 - val_loss: 0.0679 - val_accuracy: 0.9796\n",
      "Epoch 163/500\n",
      "332/333 [============================>.] - ETA: 0s - loss: 0.0686 - accuracy: 0.9768Restoring model weights from the end of the best epoch: 143.\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.0685 - accuracy: 0.9769 - val_loss: 0.0601 - val_accuracy: 0.9782\n",
      "Epoch 163: early stopping\n",
      "Number of iterations 8\n",
      "F1-scores:  [0.7948717948717948, 0.9470443349753696, 0.9683313032886723, 0.969249692496925, 0.9086326402016384, 0.9556650246305418, 0.9181322013341419, 0.9705882352941176]\n",
      "Average F1-Score 0.9290644033866502\n",
      "Std Dev F1-Score 0.05529067808427783\n",
      "Error bar F1-Score 0.01954820670489764\n",
      "Epoch 1/500\n",
      "333/333 [==============================] - 12s 19ms/step - loss: 0.5509 - accuracy: 0.7095 - val_loss: 0.5012 - val_accuracy: 0.7084\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5238 - accuracy: 0.7126 - val_loss: 0.4999 - val_accuracy: 0.7298\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5142 - accuracy: 0.7189 - val_loss: 0.4978 - val_accuracy: 0.7230\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5150 - accuracy: 0.7205 - val_loss: 0.4996 - val_accuracy: 0.7398\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5121 - accuracy: 0.7268 - val_loss: 0.5024 - val_accuracy: 0.7423\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5028 - accuracy: 0.7308 - val_loss: 0.4892 - val_accuracy: 0.7434\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4972 - accuracy: 0.7301 - val_loss: 0.4720 - val_accuracy: 0.7359\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4763 - accuracy: 0.7371 - val_loss: 0.4665 - val_accuracy: 0.7402\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 6s 17ms/step - loss: 0.4502 - accuracy: 0.7626 - val_loss: 0.4238 - val_accuracy: 0.7791\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4469 - accuracy: 0.7582 - val_loss: 0.3915 - val_accuracy: 0.8127\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3975 - accuracy: 0.7962 - val_loss: 0.4224 - val_accuracy: 0.7652\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3957 - accuracy: 0.7933 - val_loss: 0.4481 - val_accuracy: 0.7584\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4460 - accuracy: 0.7541 - val_loss: 0.4355 - val_accuracy: 0.7523\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3925 - accuracy: 0.8006 - val_loss: 0.3099 - val_accuracy: 0.8653\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4355 - accuracy: 0.7784 - val_loss: 0.5140 - val_accuracy: 0.7073\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5002 - accuracy: 0.7262 - val_loss: 0.4915 - val_accuracy: 0.7327\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4908 - accuracy: 0.7307 - val_loss: 0.4832 - val_accuracy: 0.7287\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4816 - accuracy: 0.7343 - val_loss: 0.4700 - val_accuracy: 0.7259\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4701 - accuracy: 0.7355 - val_loss: 0.4673 - val_accuracy: 0.7466\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4583 - accuracy: 0.7433 - val_loss: 0.4384 - val_accuracy: 0.7623\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4332 - accuracy: 0.7632 - val_loss: 0.4431 - val_accuracy: 0.7487\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4324 - accuracy: 0.7654 - val_loss: 0.4248 - val_accuracy: 0.7859\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4221 - accuracy: 0.7797 - val_loss: 0.4262 - val_accuracy: 0.7873\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3949 - accuracy: 0.8002 - val_loss: 0.3754 - val_accuracy: 0.8109\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3609 - accuracy: 0.8261 - val_loss: 0.3875 - val_accuracy: 0.8242\n",
      "Epoch 26/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3342 - accuracy: 0.8408 - val_loss: 0.3284 - val_accuracy: 0.8460\n",
      "Epoch 27/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3296 - accuracy: 0.8473 - val_loss: 0.2796 - val_accuracy: 0.8721\n",
      "Epoch 28/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3019 - accuracy: 0.8616 - val_loss: 0.2754 - val_accuracy: 0.8735\n",
      "Epoch 29/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2769 - accuracy: 0.8706 - val_loss: 0.2444 - val_accuracy: 0.8849\n",
      "Epoch 30/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2827 - accuracy: 0.8705 - val_loss: 0.2295 - val_accuracy: 0.8892\n",
      "Epoch 31/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2595 - accuracy: 0.8783 - val_loss: 0.2452 - val_accuracy: 0.8828\n",
      "Epoch 32/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2660 - accuracy: 0.8736 - val_loss: 0.2570 - val_accuracy: 0.8799\n",
      "Epoch 33/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2510 - accuracy: 0.8808 - val_loss: 0.2222 - val_accuracy: 0.8871\n",
      "Epoch 34/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2443 - accuracy: 0.8853 - val_loss: 0.2944 - val_accuracy: 0.8692\n",
      "Epoch 35/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2413 - accuracy: 0.8883 - val_loss: 0.1849 - val_accuracy: 0.9149\n",
      "Epoch 36/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2357 - accuracy: 0.8888 - val_loss: 0.1931 - val_accuracy: 0.9071\n",
      "Epoch 37/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2199 - accuracy: 0.8981 - val_loss: 0.2414 - val_accuracy: 0.8967\n",
      "Epoch 38/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2384 - accuracy: 0.8903 - val_loss: 0.1897 - val_accuracy: 0.9149\n",
      "Epoch 39/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2132 - accuracy: 0.9019 - val_loss: 0.1901 - val_accuracy: 0.9164\n",
      "Epoch 40/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2202 - accuracy: 0.9004 - val_loss: 0.2243 - val_accuracy: 0.8942\n",
      "Epoch 41/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2145 - accuracy: 0.8996 - val_loss: 0.2770 - val_accuracy: 0.8746\n",
      "Epoch 42/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2060 - accuracy: 0.9048 - val_loss: 0.1673 - val_accuracy: 0.9253\n",
      "Epoch 43/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2078 - accuracy: 0.9037 - val_loss: 0.1995 - val_accuracy: 0.9028\n",
      "Epoch 44/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2164 - accuracy: 0.8992 - val_loss: 0.2276 - val_accuracy: 0.8921\n",
      "Epoch 45/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2099 - accuracy: 0.9031 - val_loss: 0.1878 - val_accuracy: 0.9139\n",
      "Epoch 46/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2001 - accuracy: 0.9092 - val_loss: 0.1859 - val_accuracy: 0.9164\n",
      "Epoch 47/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2089 - accuracy: 0.9026 - val_loss: 0.1762 - val_accuracy: 0.9196\n",
      "Epoch 48/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2064 - accuracy: 0.9069 - val_loss: 0.2278 - val_accuracy: 0.8931\n",
      "Epoch 49/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1969 - accuracy: 0.9093 - val_loss: 0.2006 - val_accuracy: 0.9117\n",
      "Epoch 50/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1895 - accuracy: 0.9152 - val_loss: 0.1672 - val_accuracy: 0.9232\n",
      "Epoch 51/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2067 - accuracy: 0.9101 - val_loss: 0.1646 - val_accuracy: 0.9282\n",
      "Epoch 52/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2779 - accuracy: 0.8725 - val_loss: 0.2851 - val_accuracy: 0.8678\n",
      "Epoch 53/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2860 - accuracy: 0.8637 - val_loss: 0.2310 - val_accuracy: 0.8781\n",
      "Epoch 54/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2623 - accuracy: 0.8715 - val_loss: 0.2370 - val_accuracy: 0.8771\n",
      "Epoch 55/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2476 - accuracy: 0.8781 - val_loss: 0.2291 - val_accuracy: 0.8885\n",
      "Epoch 56/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2455 - accuracy: 0.8823 - val_loss: 0.2464 - val_accuracy: 0.8771\n",
      "Epoch 57/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2371 - accuracy: 0.8831 - val_loss: 0.2055 - val_accuracy: 0.8914\n",
      "Epoch 58/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2361 - accuracy: 0.8856 - val_loss: 0.2105 - val_accuracy: 0.8896\n",
      "Epoch 59/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2270 - accuracy: 0.8884 - val_loss: 0.1996 - val_accuracy: 0.8949\n",
      "Epoch 60/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2296 - accuracy: 0.8879 - val_loss: 0.2051 - val_accuracy: 0.8881\n",
      "Epoch 61/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2234 - accuracy: 0.8890 - val_loss: 0.1994 - val_accuracy: 0.9110\n",
      "Epoch 62/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2202 - accuracy: 0.8963 - val_loss: 0.2733 - val_accuracy: 0.8713\n",
      "Epoch 63/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2130 - accuracy: 0.8995 - val_loss: 0.1851 - val_accuracy: 0.9146\n",
      "Epoch 64/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2108 - accuracy: 0.8997 - val_loss: 0.1859 - val_accuracy: 0.9103\n",
      "Epoch 65/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.2074 - accuracy: 0.9032 - val_loss: 0.1702 - val_accuracy: 0.9224\n",
      "Epoch 66/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1976 - accuracy: 0.9092 - val_loss: 0.2179 - val_accuracy: 0.8914\n",
      "Epoch 67/500\n",
      "333/333 [==============================] - 5s 16ms/step - loss: 0.1974 - accuracy: 0.9101 - val_loss: 0.1823 - val_accuracy: 0.9207\n",
      "Epoch 68/500\n",
      "333/333 [==============================] - 5s 16ms/step - loss: 0.2050 - accuracy: 0.9049 - val_loss: 0.1784 - val_accuracy: 0.9224\n",
      "Epoch 69/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1944 - accuracy: 0.9105 - val_loss: 0.1636 - val_accuracy: 0.9224\n",
      "Epoch 70/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1914 - accuracy: 0.9127 - val_loss: 0.1665 - val_accuracy: 0.9221\n",
      "Epoch 71/500\n",
      "331/333 [============================>.] - ETA: 0s - loss: 0.1958 - accuracy: 0.9102Restoring model weights from the end of the best epoch: 51.\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.1960 - accuracy: 0.9101 - val_loss: 0.1720 - val_accuracy: 0.9217\n",
      "Epoch 71: early stopping\n",
      "Number of iterations 9\n",
      "F1-scores:  [0.7948717948717948, 0.9470443349753696, 0.9683313032886723, 0.969249692496925, 0.9086326402016384, 0.9556650246305418, 0.9181322013341419, 0.9705882352941176, 0.8801431127012522]\n",
      "Average F1-Score 0.9236287044216058\n",
      "Std Dev F1-Score 0.054348509064015\n",
      "Error bar F1-Score 0.018116169688004998\n",
      "Epoch 1/500\n",
      "333/333 [==============================] - 11s 18ms/step - loss: 0.5559 - accuracy: 0.7096 - val_loss: 0.5163 - val_accuracy: 0.7127\n",
      "Epoch 2/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5182 - accuracy: 0.7159 - val_loss: 0.4936 - val_accuracy: 0.7462\n",
      "Epoch 3/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5078 - accuracy: 0.7231 - val_loss: 0.4873 - val_accuracy: 0.7026\n",
      "Epoch 4/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4773 - accuracy: 0.7372 - val_loss: 0.4268 - val_accuracy: 0.7959\n",
      "Epoch 5/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.3943 - accuracy: 0.8014 - val_loss: 0.4008 - val_accuracy: 0.8149\n",
      "Epoch 6/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5287 - accuracy: 0.7339 - val_loss: 0.5070 - val_accuracy: 0.7127\n",
      "Epoch 7/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5186 - accuracy: 0.7126 - val_loss: 0.4948 - val_accuracy: 0.7287\n",
      "Epoch 8/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5147 - accuracy: 0.7189 - val_loss: 0.5044 - val_accuracy: 0.7241\n",
      "Epoch 9/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5113 - accuracy: 0.7185 - val_loss: 0.5014 - val_accuracy: 0.7144\n",
      "Epoch 10/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5087 - accuracy: 0.7241 - val_loss: 0.4891 - val_accuracy: 0.7470\n",
      "Epoch 11/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5001 - accuracy: 0.7308 - val_loss: 0.4936 - val_accuracy: 0.7398\n",
      "Epoch 12/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5042 - accuracy: 0.7227 - val_loss: 0.4946 - val_accuracy: 0.7377\n",
      "Epoch 13/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.5000 - accuracy: 0.7251 - val_loss: 0.4820 - val_accuracy: 0.7441\n",
      "Epoch 14/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4994 - accuracy: 0.7305 - val_loss: 0.4861 - val_accuracy: 0.7498\n",
      "Epoch 15/500\n",
      "333/333 [==============================] - 5s 16ms/step - loss: 0.4955 - accuracy: 0.7351 - val_loss: 0.4864 - val_accuracy: 0.7480\n",
      "Epoch 16/500\n",
      "333/333 [==============================] - 5s 16ms/step - loss: 0.4925 - accuracy: 0.7347 - val_loss: 0.4846 - val_accuracy: 0.7441\n",
      "Epoch 17/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4930 - accuracy: 0.7352 - val_loss: 0.4795 - val_accuracy: 0.7452\n",
      "Epoch 18/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4926 - accuracy: 0.7379 - val_loss: 0.4792 - val_accuracy: 0.7434\n",
      "Epoch 19/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4952 - accuracy: 0.7356 - val_loss: 0.4826 - val_accuracy: 0.7434\n",
      "Epoch 20/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4898 - accuracy: 0.7402 - val_loss: 0.4931 - val_accuracy: 0.7345\n",
      "Epoch 21/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4908 - accuracy: 0.7398 - val_loss: 0.4818 - val_accuracy: 0.7441\n",
      "Epoch 22/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4897 - accuracy: 0.7377 - val_loss: 0.4926 - val_accuracy: 0.7480\n",
      "Epoch 23/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4878 - accuracy: 0.7373 - val_loss: 0.4868 - val_accuracy: 0.7366\n",
      "Epoch 24/500\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4883 - accuracy: 0.7384 - val_loss: 0.4774 - val_accuracy: 0.7409\n",
      "Epoch 25/500\n",
      "333/333 [==============================] - ETA: 0s - loss: 0.4871 - accuracy: 0.7406Restoring model weights from the end of the best epoch: 5.\n",
      "333/333 [==============================] - 5s 15ms/step - loss: 0.4871 - accuracy: 0.7406 - val_loss: 0.4944 - val_accuracy: 0.7255\n",
      "Epoch 25: early stopping\n",
      "Number of iterations 10\n",
      "F1-scores:  [0.7948717948717948, 0.9470443349753696, 0.9683313032886723, 0.969249692496925, 0.9086326402016384, 0.9556650246305418, 0.9181322013341419, 0.9705882352941176, 0.8801431127012522, 0.6495263870094722]\n",
      "Average F1-Score 0.8962184726803925\n",
      "Std Dev F1-Score 0.09705808379880772\n",
      "Error bar F1-Score 0.030692461013572012\n"
     ]
    }
   ],
   "source": [
    "###Collect F-Score 10 times\n",
    "import sklearn\n",
    "from tqdm.notebook import tqdm\n",
    "def calc_f1_score(X_train_scaled,X_test_scaled,X_train_scaled_f,X_test_scaled_f,y_train,y_test,earlystop):\n",
    "  input_1 = Input((X_train_scaled.shape[1], X_train_scaled.shape[2]))\n",
    "  input_2 = Input((X_train_scaled_f.shape[1], X_train_scaled_f.shape[2]))\n",
    "  x1=LSTM(units = 100, return_sequences = True)(input_1)\n",
    "  x1=LSTM(units = 50)(x1)\n",
    "  x2=LSTM(units = 100, return_sequences = True)(input_2)\n",
    "  x2=LSTM(units = 50)(x2)\n",
    "  x = layers.concatenate([x1, x2])\n",
    "  output_layer = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "  classifier=keras.Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "  # Compiling the RNN\n",
    "  classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  classifier.fit([X_train_scaled,X_train_scaled_f], y_train[:,0], epochs = 500, batch_size = 64,validation_data=([X_test_scaled,X_test_scaled_f],y_test[:,0]),callbacks=[earlystop])\n",
    "  y_pred = classifier.predict([X_test_scaled,X_test_scaled_f])\n",
    "  y_pred= (y_pred>=0.5).astype(int)\n",
    "  return(sklearn.metrics.f1_score(y_test[:,0],y_pred))\n",
    "\n",
    "f1_score_list=[]\n",
    "for i in tqdm(range(10)):\n",
    "  f1_score_list=f1_score_list+[calc_f1_score(X_train_scaled,X_test_scaled,X_train_scaled_f,X_test_scaled_f,y_train,y_test,earlystop)]\n",
    "  print(\"Number of iterations\",len(f1_score_list))\n",
    "  print(\"F1-scores: \",f1_score_list)\n",
    "  print(\"Average F1-Score\",np.mean(f1_score_list))\n",
    "  print(\"Std Dev F1-Score\",np.std(f1_score_list))\n",
    "  print(\"Error bar F1-Score\",np.std(f1_score_list)/np.sqrt(len(f1_score_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average F1-Score 0.8962184726803925\n",
    "# Std Dev F1-Score 0.09705808379880772\n",
    "# Error bar F1-Score 0.030692461013572012"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_1d_freq_exp1_v2.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0cfb27c8ba5f4ddcb12d1bcefa9fed26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0d54dfa25e25478ca3e095782bcd59e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_d4e3afd520af4bd5ba8c1cffc61b9f55",
      "placeholder": "​",
      "style": "IPY_MODEL_a80d7158d6f14bffaa4395a1a3e9de2f",
      "tabbable": null,
      "tooltip": null,
      "value": "100%"
     }
    },
    "1b321eb832624af9b61a7c36958f353f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "26e310b233ba45e7941c14a34a69fcbe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35f2a4db4d974ea39230bb12543b0b1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_39a01d56f9594c539ee84a08b265300e",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0cfb27c8ba5f4ddcb12d1bcefa9fed26",
      "tabbable": null,
      "tooltip": null,
      "value": 10
     }
    },
    "39a01d56f9594c539ee84a08b265300e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6fccd6ca93114ae482cc12c6bc8427e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_c3950c775a6e4a52acf6753c64e4e54d",
      "placeholder": "​",
      "style": "IPY_MODEL_fed147ef48db480c9d3f35d0e77323c1",
      "tabbable": null,
      "tooltip": null,
      "value": "100%"
     }
    },
    "727c2d7d9a4a42729ffc556e82f7728b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7869e2a0f0ba49cd8588e7c4419ffd97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81cacd2f5c56425c8619138a24f6cb5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93a328fbdc954390b26f6dd0386bc1a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_26e310b233ba45e7941c14a34a69fcbe",
      "placeholder": "​",
      "style": "IPY_MODEL_1b321eb832624af9b61a7c36958f353f",
      "tabbable": null,
      "tooltip": null,
      "value": " 10/10 [1:06:54&lt;00:00, 463.08s/it]"
     }
    },
    "a62d714d2f8b4100987988e2fa35f9a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a80d7158d6f14bffaa4395a1a3e9de2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "b113b2edd10c4a4688001055ea4e5921": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc388221e1ef4b2481adce78b617c38a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "c3950c775a6e4a52acf6753c64e4e54d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cec7ba07af6041609cc62a20e1a21909": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6fccd6ca93114ae482cc12c6bc8427e6",
       "IPY_MODEL_35f2a4db4d974ea39230bb12543b0b1c",
       "IPY_MODEL_93a328fbdc954390b26f6dd0386bc1a1"
      ],
      "layout": "IPY_MODEL_81cacd2f5c56425c8619138a24f6cb5e",
      "tabbable": null,
      "tooltip": null
     }
    },
    "d4e3afd520af4bd5ba8c1cffc61b9f55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5118db5b6be4447b07197da86aa2c2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_7869e2a0f0ba49cd8588e7c4419ffd97",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a62d714d2f8b4100987988e2fa35f9a2",
      "tabbable": null,
      "tooltip": null,
      "value": 10
     }
    },
    "e3df61a1bd4042eca563b664859036b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0d54dfa25e25478ca3e095782bcd59e2",
       "IPY_MODEL_d5118db5b6be4447b07197da86aa2c2a",
       "IPY_MODEL_f64483d04e964450960d63930746bd16"
      ],
      "layout": "IPY_MODEL_727c2d7d9a4a42729ffc556e82f7728b",
      "tabbable": null,
      "tooltip": null
     }
    },
    "f64483d04e964450960d63930746bd16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_b113b2edd10c4a4688001055ea4e5921",
      "placeholder": "​",
      "style": "IPY_MODEL_bc388221e1ef4b2481adce78b617c38a",
      "tabbable": null,
      "tooltip": null,
      "value": " 10/10 [1:18:59&lt;00:00, 420.20s/it]"
     }
    },
    "fed147ef48db480c9d3f35d0e77323c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
