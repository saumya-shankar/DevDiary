{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiple_Object_Transformer_1d_freq_exp2_exp5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "621085b9eda2407aad15039c01c35a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1cd55fabff9409aad30ae6d6b2bab36",
              "IPY_MODEL_02327f02993e4ca6a4aae9e1bd16a417",
              "IPY_MODEL_eab0519b3397484ca0f00a053f13b052"
            ],
            "layout": "IPY_MODEL_08c38625eddc4a96abc47bb8ffbf2ce6"
          }
        },
        "a1cd55fabff9409aad30ae6d6b2bab36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ac360c8889e4d4caa0af5c162773be8",
            "placeholder": "​",
            "style": "IPY_MODEL_492bbe5a04c2442d8630d8d3fb9a5ae2",
            "value": "100%"
          }
        },
        "02327f02993e4ca6a4aae9e1bd16a417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2dc7aa3d74348dfba7e7347e9ce08dc",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c220fa6d116b4feab44d733b9d11631b",
            "value": 125
          }
        },
        "eab0519b3397484ca0f00a053f13b052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f84a243561144540861d17a7a1288de0",
            "placeholder": "​",
            "style": "IPY_MODEL_1ccdbffc83064b3d8133dda7da783bb5",
            "value": " 125/125 [00:40&lt;00:00,  3.03it/s]"
          }
        },
        "08c38625eddc4a96abc47bb8ffbf2ce6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ac360c8889e4d4caa0af5c162773be8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "492bbe5a04c2442d8630d8d3fb9a5ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2dc7aa3d74348dfba7e7347e9ce08dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c220fa6d116b4feab44d733b9d11631b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f84a243561144540861d17a7a1288de0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ccdbffc83064b3d8133dda7da783bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "140e933e97a248f6bcb414f04357154a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a018283c86024f2a990e296a8896e50f",
              "IPY_MODEL_4f699bf975c544f095dfaacb1e941d62",
              "IPY_MODEL_15f0490020df4c51ae29319eeeca92a9"
            ],
            "layout": "IPY_MODEL_256403fffd104fee81f01f25accfc619"
          }
        },
        "a018283c86024f2a990e296a8896e50f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc0bf4d5454444cd892f86fee7cbc28e",
            "placeholder": "​",
            "style": "IPY_MODEL_4863db38a17e4fec8d0be69d5e65d42b",
            "value": "100%"
          }
        },
        "4f699bf975c544f095dfaacb1e941d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fa6d0b7192446c7a67db1753fc4b2c2",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2babad089d484e58b58c6abd07589fcf",
            "value": 125
          }
        },
        "15f0490020df4c51ae29319eeeca92a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_394d5c417f6044c5b9137780a0ff757d",
            "placeholder": "​",
            "style": "IPY_MODEL_459052057df34515b83b66043d428e3f",
            "value": " 125/125 [00:40&lt;00:00,  3.12it/s]"
          }
        },
        "256403fffd104fee81f01f25accfc619": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc0bf4d5454444cd892f86fee7cbc28e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4863db38a17e4fec8d0be69d5e65d42b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fa6d0b7192446c7a67db1753fc4b2c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2babad089d484e58b58c6abd07589fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "394d5c417f6044c5b9137780a0ff757d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "459052057df34515b83b66043d428e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JYsWwiwnPzi",
        "outputId": "8631d64a-c5a9-4d11-97ed-fb7e9cc8b2dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Aug 15 17:52:57 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mounting google drive on colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IdNIB899nhlq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92754386-fde5-42ef-a408-f0b72a038ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import copy\n",
        "from scipy import signal"
      ],
      "metadata": {
        "id": "GfSazzTdnmaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/GraphWise_X_trainv7_multiobject_exp2_exp5_v2.npy\")\n",
        "X_train_f=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/GraphWise_X_f_trainv7_multiobject_exp2_exp5_v2.npy\")\n",
        "y_train=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/GraphWise_y_trainv7_multiobject_exp2_exp5_v2.npy\").astype(int)\n",
        "\n",
        "X_test=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/GraphWise_X_testv7_multiobject_exp2_exp5_v2.npy\")\n",
        "X_test_f=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/GraphWise_X_f_testv7_multiobject_exp2_exp5_v2.npy\")\n",
        "y_test=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/GraphWise_y_testv7_multiobject_exp2_exp5_v2.npy\").astype(int)\n"
      ],
      "metadata": {
        "id": "bXN_d9Evntel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_train_f.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(X_test.shape)\n",
        "print(X_test_f.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynZ-H4OtsGrl",
        "outputId": "66718d67-27e5-4a76-9e29-f2f35d146482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(875, 30, 50, 4)\n",
            "(875, 30, 26, 2)\n",
            "(875, 30, 30)\n",
            "(125, 30, 50, 4)\n",
            "(125, 30, 26, 2)\n",
            "(125, 30, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train1=y_train.reshape(y_train.shape[0],-1)\n",
        "y_test1=y_test.reshape(y_test.shape[0],-1)\n",
        "\n",
        "y_train1=np.expand_dims(y_train1,-1)\n",
        "y_test1=np.expand_dims(y_test1,-1)\n",
        "\n",
        "print(y_train1.shape)\n",
        "print(y_test1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMPEt3tEPl6x",
        "outputId": "f5a12e3a-621a-4174-ee9b-5749032a5c56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(875, 900, 1)\n",
            "(125, 900, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WUhqnDj8Pl-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Input\n",
        "from tensorflow.keras import layers\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "padding_dim=30\n",
        "padding_val=1e6"
      ],
      "metadata": {
        "id": "WvpdxcB6kS22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras keras_nlp\n",
        "import keras_nlp"
      ],
      "metadata": {
        "id": "20tXUebI-PWL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94edb7f9-2deb-4035-8610-dd4f1bfb2da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Collecting keras_nlp\n",
            "  Downloading keras_nlp-0.3.0-py3-none-any.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from keras_nlp) (1.2.0)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 43.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras_nlp) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras_nlp) (21.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras_nlp) (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras_nlp) (3.0.9)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (4.1.1)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (0.26.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (1.47.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (1.6.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (14.0.6)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->keras_nlp) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->keras_nlp) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (3.2.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->keras_nlp) (0.12.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 5.0 kB/s \n",
            "\u001b[?25hCollecting flatbuffers>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting gast>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 3.7 kB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-text to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 70.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: tensorflow-text, keras-nlp\n",
            "Successfully installed keras-nlp-0.3.0 tensorflow-text-2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padding_val=1e6\n",
        "\n",
        "class out_adj_mat(keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(out_adj_mat, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        out1=tf.matmul(inputs,tf.transpose(inputs,[0,2,1]))#Loss\n",
        "        out2=tf.keras.layers.Activation('sigmoid')(out1)#Actual output\n",
        "        out1=tf.reshape(out1,(-1,padding_dim*padding_dim))\n",
        "        out1=tf.expand_dims(out1,-1)\n",
        "        return out1\n",
        "    \n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        mask=tf.expand_dims(mask,axis=-1)\n",
        "        mask=tf.cast(mask,tf.dtypes.int64)\n",
        "        mask2=tf.matmul(mask,tf.transpose(mask,[0,2,1]))#Actual Output\n",
        "        mask1=tf.experimental.numpy.triu(mask2,1)#Loss\n",
        "        mask1=tf.cast(mask1,bool)\n",
        "        mask1=tf.reshape(mask1,(-1,padding_dim*padding_dim))\n",
        "        return mask1\n",
        "\n",
        "\n",
        "# Part 2 - Building the RNN\n",
        "\n",
        "# Importing the Keras libraries and packages\n",
        "\n",
        "input_1 = Input((X_train.shape[1], X_train.shape[2], X_train.shape[3]),name=\"time\") #20,50,4\n",
        "input_2 = Input((X_train_f.shape[1], X_train_f.shape[2], X_train_f.shape[3]),name=\"freq\") #20,26,2\n",
        "\n",
        "x1=layers.Masking(mask_value=padding_val)(input_1)\n",
        "x1=layers.TimeDistributed(LSTM(units = 100, return_sequences = True))(x1)\n",
        "x1=layers.TimeDistributed(LSTM(units = 50))(x1)\n",
        "\n",
        "x2=layers.Masking(mask_value=padding_val)(input_2)\n",
        "x2=layers.TimeDistributed(LSTM(units = 100, return_sequences = True))(x2)\n",
        "x2=layers.TimeDistributed(LSTM(units = 50))(x2)\n",
        "\n",
        "merge_layer=layers.concatenate([x1,x2]) #B,20,100\n",
        "x=keras_nlp.layers.TransformerEncoder(intermediate_dim=64, num_heads=4,dropout=0.1)(merge_layer)\n",
        "x=keras_nlp.layers.TransformerEncoder(intermediate_dim=64, num_heads=4,dropout=0.1)(x)\n",
        "x=keras_nlp.layers.TransformerEncoder(intermediate_dim=64, num_heads=4,dropout=0.1)(x)\n",
        "\n",
        "out=out_adj_mat()(x)\n",
        "\n",
        "classifier=keras.Model(inputs=[input_1, input_2], outputs=[out])\n",
        "\n",
        "# # Compiling the RNN\n",
        "classifier.compile(optimizer = 'adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics = 'accuracy')\n"
      ],
      "metadata": {
        "id": "u8CMIO_ToBr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x1._keras_mask)\n",
        "print(x2._keras_mask)\n",
        "print(merge_layer._keras_mask)\n",
        "print(x._keras_mask)\n",
        "print(out._keras_mask)\n",
        "# print(A_rec._keras_mask)\n",
        "\n",
        "print(out)\n",
        "# print(A_rec)\n",
        "\n",
        "print(x)\n",
        "print(tf.transpose(x,[0,2,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21ATfgO4x3PB",
        "outputId": "6cdf35b2-935d-4d80-a9a1-3f701b9d5036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.bool, name=None), name='Any:0')\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.bool, name=None), name='Any:0')\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.bool, name=None), name='All:0')\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 30), dtype=tf.bool, name=None), name='Placeholder_1:0')\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 900), dtype=tf.bool, name=None), name='Reshape:0')\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 900, 1), dtype=tf.float32, name=None), name='out_adj_mat/ExpandDims:0', description=\"created by layer 'out_adj_mat'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 30, 100), dtype=tf.float32, name=None), name='transformer_encoder_2/layer_normalization_1/batchnorm/add_1:0', description=\"created by layer 'transformer_encoder_2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 100, 30), dtype=tf.float32, name=None), name='tf.compat.v1.transpose/transpose:0', description=\"created by layer 'tf.compat.v1.transpose'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\",\n",
        "                             monitor=\"val_accuracy\",\n",
        "                             mode=\"max\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)\n",
        "\n",
        "\n",
        "earlystop = EarlyStopping(monitor = 'val_accuracy', # value being monitored for improvement\n",
        "                          min_delta = 0, #Abs value and is the min change required before we stop\n",
        "                          patience = 50, #Number of epochs we wait before stopping \n",
        "                          verbose = 1,\n",
        "                          restore_best_weights = True) #keeps the best weigths once stopped\n",
        "\n",
        "# we put our call backs into a callback list\n",
        "callbacks = [earlystop,checkpoint]\n"
      ],
      "metadata": {
        "id": "uf-jNI2KZJUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtZ5szc114Hu",
        "outputId": "1ba3c0d6-58b2-470c-94e4-22c417d33b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " time (InputLayer)              [(None, 30, 50, 4)]  0           []                               \n",
            "                                                                                                  \n",
            " freq (InputLayer)              [(None, 30, 26, 2)]  0           []                               \n",
            "                                                                                                  \n",
            " masking (Masking)              (None, 30, 50, 4)    0           ['time[0][0]']                   \n",
            "                                                                                                  \n",
            " masking_1 (Masking)            (None, 30, 26, 2)    0           ['freq[0][0]']                   \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, 30, 50, 100)  42000      ['masking[0][0]']                \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            " time_distributed_2 (TimeDistri  (None, 30, 26, 100)  41200      ['masking_1[0][0]']              \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " time_distributed_1 (TimeDistri  (None, 30, 50)      30200       ['time_distributed[0][0]']       \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " time_distributed_3 (TimeDistri  (None, 30, 50)      30200       ['time_distributed_2[0][0]']     \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 30, 100)      0           ['time_distributed_1[0][0]',     \n",
            "                                                                  'time_distributed_3[0][0]']     \n",
            "                                                                                                  \n",
            " transformer_encoder (Transform  (None, 30, 100)     53764       ['concatenate[0][0]']            \n",
            " erEncoder)                                                                                       \n",
            "                                                                                                  \n",
            " transformer_encoder_1 (Transfo  (None, 30, 100)     53764       ['transformer_encoder[0][0]']    \n",
            " rmerEncoder)                                                                                     \n",
            "                                                                                                  \n",
            " transformer_encoder_2 (Transfo  (None, 30, 100)     53764       ['transformer_encoder_1[0][0]']  \n",
            " rmerEncoder)                                                                                     \n",
            "                                                                                                  \n",
            " out_adj_mat (out_adj_mat)      (None, 900, 1)       0           ['transformer_encoder_2[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 304,892\n",
            "Trainable params: 304,892\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "dvZf3AAQ6hdZ",
        "outputId": "f1658354-fbcb-4317-c25f-0e8c2e39a79e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the RNN to the Training set\n",
        "history=classifier.fit([X_train,X_train_f], y_train1, epochs = 500, batch_size = 64,validation_data=([X_test,X_test_f],y_test1),callbacks=callbacks)\n"
      ],
      "metadata": {
        "id": "jcUvZBOYoFNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1bb6bbc-16a1-45b1-c356-80ad5bbce86b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 3.3523 - accuracy: 0.4992\n",
            "Epoch 1: val_accuracy improved from -inf to 0.62183, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 34s 755ms/step - loss: 3.3523 - accuracy: 0.4992 - val_loss: 6.9641 - val_accuracy: 0.6218\n",
            "Epoch 2/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - ETA: 0s - loss: 1.0600 - accuracy: 0.5538\n",
            "Epoch 2: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 1.0600 - accuracy: 0.5538 - val_loss: 7.4179 - val_accuracy: 0.5593\n",
            "Epoch 3/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.5858 - accuracy: 0.5101\n",
            "Epoch 3: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.5858 - accuracy: 0.5101 - val_loss: 7.4979 - val_accuracy: 0.5589\n",
            "Epoch 4/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.5192 - accuracy: 0.5492\n",
            "Epoch 4: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.5192 - accuracy: 0.5492 - val_loss: 7.4967 - val_accuracy: 0.5530\n",
            "Epoch 5/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.4799 - accuracy: 0.5596\n",
            "Epoch 5: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.4799 - accuracy: 0.5596 - val_loss: 7.3372 - val_accuracy: 0.5551\n",
            "Epoch 6/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.4489 - accuracy: 0.5727\n",
            "Epoch 6: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.4489 - accuracy: 0.5727 - val_loss: 7.2276 - val_accuracy: 0.5607\n",
            "Epoch 7/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.4340 - accuracy: 0.5739\n",
            "Epoch 7: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.4340 - accuracy: 0.5739 - val_loss: 6.9942 - val_accuracy: 0.5742\n",
            "Epoch 8/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.4097 - accuracy: 0.5820\n",
            "Epoch 8: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.4097 - accuracy: 0.5820 - val_loss: 6.8263 - val_accuracy: 0.5862\n",
            "Epoch 9/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.3947 - accuracy: 0.5828\n",
            "Epoch 9: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.3947 - accuracy: 0.5828 - val_loss: 6.7486 - val_accuracy: 0.5830\n",
            "Epoch 10/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.5893\n",
            "Epoch 10: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.3779 - accuracy: 0.5893 - val_loss: 6.4961 - val_accuracy: 0.5982\n",
            "Epoch 11/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.3683 - accuracy: 0.5910\n",
            "Epoch 11: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 312ms/step - loss: 0.3683 - accuracy: 0.5910 - val_loss: 6.3078 - val_accuracy: 0.6099\n",
            "Epoch 12/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.3520 - accuracy: 0.5991\n",
            "Epoch 12: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.3520 - accuracy: 0.5991 - val_loss: 6.1896 - val_accuracy: 0.6091\n",
            "Epoch 13/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.3458 - accuracy: 0.5989\n",
            "Epoch 13: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.3458 - accuracy: 0.5989 - val_loss: 6.1101 - val_accuracy: 0.6124\n",
            "Epoch 14/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.3321 - accuracy: 0.6040\n",
            "Epoch 14: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.3321 - accuracy: 0.6040 - val_loss: 6.0334 - val_accuracy: 0.6082\n",
            "Epoch 15/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.3231 - accuracy: 0.6074\n",
            "Epoch 15: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.3231 - accuracy: 0.6074 - val_loss: 5.8992 - val_accuracy: 0.6102\n",
            "Epoch 16/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.3125 - accuracy: 0.6084\n",
            "Epoch 16: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 5s 372ms/step - loss: 0.3125 - accuracy: 0.6084 - val_loss: 5.8181 - val_accuracy: 0.6083\n",
            "Epoch 17/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.3057 - accuracy: 0.6109\n",
            "Epoch 17: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.3057 - accuracy: 0.6109 - val_loss: 5.6630 - val_accuracy: 0.6113\n",
            "Epoch 18/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2972 - accuracy: 0.6126\n",
            "Epoch 18: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 311ms/step - loss: 0.2972 - accuracy: 0.6126 - val_loss: 5.6051 - val_accuracy: 0.6006\n",
            "Epoch 19/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2868 - accuracy: 0.6188\n",
            "Epoch 19: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.2868 - accuracy: 0.6188 - val_loss: 5.3719 - val_accuracy: 0.6134\n",
            "Epoch 20/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2820 - accuracy: 0.6204\n",
            "Epoch 20: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.2820 - accuracy: 0.6204 - val_loss: 5.2726 - val_accuracy: 0.6034\n",
            "Epoch 21/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2737 - accuracy: 0.6235\n",
            "Epoch 21: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 311ms/step - loss: 0.2737 - accuracy: 0.6235 - val_loss: 5.0833 - val_accuracy: 0.6027\n",
            "Epoch 22/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2642 - accuracy: 0.6295\n",
            "Epoch 22: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 312ms/step - loss: 0.2642 - accuracy: 0.6295 - val_loss: 4.9318 - val_accuracy: 0.6049\n",
            "Epoch 23/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2610 - accuracy: 0.6283\n",
            "Epoch 23: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.2610 - accuracy: 0.6283 - val_loss: 4.7409 - val_accuracy: 0.6040\n",
            "Epoch 24/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2536 - accuracy: 0.6307\n",
            "Epoch 24: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.2536 - accuracy: 0.6307 - val_loss: 4.6136 - val_accuracy: 0.5993\n",
            "Epoch 25/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2469 - accuracy: 0.6325\n",
            "Epoch 25: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.2469 - accuracy: 0.6325 - val_loss: 4.3433 - val_accuracy: 0.6049\n",
            "Epoch 26/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2360 - accuracy: 0.6395\n",
            "Epoch 26: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.2360 - accuracy: 0.6395 - val_loss: 4.0670 - val_accuracy: 0.5916\n",
            "Epoch 27/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2323 - accuracy: 0.6425\n",
            "Epoch 27: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.2323 - accuracy: 0.6425 - val_loss: 3.6681 - val_accuracy: 0.6129\n",
            "Epoch 28/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2247 - accuracy: 0.6455\n",
            "Epoch 28: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.2247 - accuracy: 0.6455 - val_loss: 3.2337 - val_accuracy: 0.6050\n",
            "Epoch 29/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.6478\n",
            "Epoch 29: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 312ms/step - loss: 0.2180 - accuracy: 0.6478 - val_loss: 2.4138 - val_accuracy: 0.5999\n",
            "Epoch 30/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2044 - accuracy: 0.6586\n",
            "Epoch 30: val_accuracy did not improve from 0.62183\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.2044 - accuracy: 0.6586 - val_loss: 1.8491 - val_accuracy: 0.6195\n",
            "Epoch 31/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.1902 - accuracy: 0.6693\n",
            "Epoch 31: val_accuracy improved from 0.62183 to 0.63482, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 341ms/step - loss: 0.1902 - accuracy: 0.6693 - val_loss: 1.4867 - val_accuracy: 0.6348\n",
            "Epoch 32/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.1752 - accuracy: 0.6796\n",
            "Epoch 32: val_accuracy improved from 0.63482 to 0.66036, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 324ms/step - loss: 0.1752 - accuracy: 0.6796 - val_loss: 1.1437 - val_accuracy: 0.6604\n",
            "Epoch 33/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.1554 - accuracy: 0.6940\n",
            "Epoch 33: val_accuracy improved from 0.66036 to 0.68898, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.1554 - accuracy: 0.6940 - val_loss: 0.8527 - val_accuracy: 0.6890\n",
            "Epoch 34/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.1370 - accuracy: 0.7072\n",
            "Epoch 34: val_accuracy improved from 0.68898 to 0.71469, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.1370 - accuracy: 0.7072 - val_loss: 0.6115 - val_accuracy: 0.7147\n",
            "Epoch 35/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.7267\n",
            "Epoch 35: val_accuracy improved from 0.71469 to 0.73146, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.1189 - accuracy: 0.7267 - val_loss: 0.4577 - val_accuracy: 0.7315\n",
            "Epoch 36/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.7408\n",
            "Epoch 36: val_accuracy improved from 0.73146 to 0.73340, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.1003 - accuracy: 0.7408 - val_loss: 0.3339 - val_accuracy: 0.7334\n",
            "Epoch 37/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.7546\n",
            "Epoch 37: val_accuracy improved from 0.73340 to 0.73771, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0846 - accuracy: 0.7546 - val_loss: 0.2495 - val_accuracy: 0.7377\n",
            "Epoch 38/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.7645\n",
            "Epoch 38: val_accuracy improved from 0.73771 to 0.74614, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 327ms/step - loss: 0.0731 - accuracy: 0.7645 - val_loss: 0.1984 - val_accuracy: 0.7461\n",
            "Epoch 39/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.7781\n",
            "Epoch 39: val_accuracy improved from 0.74614 to 0.76152, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0645 - accuracy: 0.7781 - val_loss: 0.1673 - val_accuracy: 0.7615\n",
            "Epoch 40/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 0.7880\n",
            "Epoch 40: val_accuracy improved from 0.76152 to 0.77473, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 327ms/step - loss: 0.0606 - accuracy: 0.7880 - val_loss: 0.1488 - val_accuracy: 0.7747\n",
            "Epoch 41/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.7957\n",
            "Epoch 41: val_accuracy improved from 0.77473 to 0.78756, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0577 - accuracy: 0.7957 - val_loss: 0.1410 - val_accuracy: 0.7876\n",
            "Epoch 42/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.8037\n",
            "Epoch 42: val_accuracy improved from 0.78756 to 0.79479, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0561 - accuracy: 0.8037 - val_loss: 0.1370 - val_accuracy: 0.7948\n",
            "Epoch 43/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.8104\n",
            "Epoch 43: val_accuracy improved from 0.79479 to 0.81281, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0548 - accuracy: 0.8104 - val_loss: 0.1307 - val_accuracy: 0.8128\n",
            "Epoch 44/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.8125\n",
            "Epoch 44: val_accuracy improved from 0.81281 to 0.82654, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0547 - accuracy: 0.8125 - val_loss: 0.1277 - val_accuracy: 0.8265\n",
            "Epoch 45/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.8175\n",
            "Epoch 45: val_accuracy did not improve from 0.82654\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0538 - accuracy: 0.8175 - val_loss: 0.1308 - val_accuracy: 0.8120\n",
            "Epoch 46/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 0.8222\n",
            "Epoch 46: val_accuracy improved from 0.82654 to 0.83069, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 341ms/step - loss: 0.0532 - accuracy: 0.8222 - val_loss: 0.1237 - val_accuracy: 0.8307\n",
            "Epoch 47/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 0.8253\n",
            "Epoch 47: val_accuracy improved from 0.83069 to 0.83230, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0520 - accuracy: 0.8253 - val_loss: 0.1236 - val_accuracy: 0.8323\n",
            "Epoch 48/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.8258\n",
            "Epoch 48: val_accuracy improved from 0.83230 to 0.83452, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0516 - accuracy: 0.8258 - val_loss: 0.1221 - val_accuracy: 0.8345\n",
            "Epoch 49/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.8272\n",
            "Epoch 49: val_accuracy improved from 0.83452 to 0.83707, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0511 - accuracy: 0.8272 - val_loss: 0.1225 - val_accuracy: 0.8371\n",
            "Epoch 50/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.8275\n",
            "Epoch 50: val_accuracy did not improve from 0.83707\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0513 - accuracy: 0.8275 - val_loss: 0.1249 - val_accuracy: 0.8316\n",
            "Epoch 51/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.8321\n",
            "Epoch 51: val_accuracy improved from 0.83707 to 0.83991, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 339ms/step - loss: 0.0508 - accuracy: 0.8321 - val_loss: 0.1210 - val_accuracy: 0.8399\n",
            "Epoch 52/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.8328\n",
            "Epoch 52: val_accuracy improved from 0.83991 to 0.84464, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 328ms/step - loss: 0.0500 - accuracy: 0.8328 - val_loss: 0.1196 - val_accuracy: 0.8446\n",
            "Epoch 53/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 0.8312\n",
            "Epoch 53: val_accuracy did not improve from 0.84464\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0497 - accuracy: 0.8312 - val_loss: 0.1223 - val_accuracy: 0.8365\n",
            "Epoch 54/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.8346\n",
            "Epoch 54: val_accuracy did not improve from 0.84464\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0494 - accuracy: 0.8346 - val_loss: 0.1198 - val_accuracy: 0.8444\n",
            "Epoch 55/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.8326\n",
            "Epoch 55: val_accuracy improved from 0.84464 to 0.84558, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 346ms/step - loss: 0.0492 - accuracy: 0.8326 - val_loss: 0.1179 - val_accuracy: 0.8456\n",
            "Epoch 56/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.8356\n",
            "Epoch 56: val_accuracy did not improve from 0.84558\n",
            "14/14 [==============================] - 4s 312ms/step - loss: 0.0489 - accuracy: 0.8356 - val_loss: 0.1168 - val_accuracy: 0.8445\n",
            "Epoch 57/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.8376\n",
            "Epoch 57: val_accuracy improved from 0.84558 to 0.84632, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0482 - accuracy: 0.8376 - val_loss: 0.1163 - val_accuracy: 0.8463\n",
            "Epoch 58/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.8365\n",
            "Epoch 58: val_accuracy did not improve from 0.84632\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0488 - accuracy: 0.8365 - val_loss: 0.1312 - val_accuracy: 0.8325\n",
            "Epoch 59/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.8350\n",
            "Epoch 59: val_accuracy improved from 0.84632 to 0.84821, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 341ms/step - loss: 0.0503 - accuracy: 0.8350 - val_loss: 0.1200 - val_accuracy: 0.8482\n",
            "Epoch 60/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.8387\n",
            "Epoch 60: val_accuracy improved from 0.84821 to 0.85134, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0483 - accuracy: 0.8387 - val_loss: 0.1152 - val_accuracy: 0.8513\n",
            "Epoch 61/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.8400\n",
            "Epoch 61: val_accuracy improved from 0.85134 to 0.85191, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0477 - accuracy: 0.8400 - val_loss: 0.1154 - val_accuracy: 0.8519\n",
            "Epoch 62/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.8404\n",
            "Epoch 62: val_accuracy did not improve from 0.85191\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0476 - accuracy: 0.8404 - val_loss: 0.1159 - val_accuracy: 0.8480\n",
            "Epoch 63/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.8416\n",
            "Epoch 63: val_accuracy did not improve from 0.85191\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0472 - accuracy: 0.8416 - val_loss: 0.1138 - val_accuracy: 0.8503\n",
            "Epoch 64/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.8408\n",
            "Epoch 64: val_accuracy improved from 0.85191 to 0.85216, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 341ms/step - loss: 0.0472 - accuracy: 0.8408 - val_loss: 0.1126 - val_accuracy: 0.8522\n",
            "Epoch 65/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.8422\n",
            "Epoch 65: val_accuracy improved from 0.85216 to 0.85397, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 330ms/step - loss: 0.0472 - accuracy: 0.8422 - val_loss: 0.1165 - val_accuracy: 0.8540\n",
            "Epoch 66/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.8423\n",
            "Epoch 66: val_accuracy did not improve from 0.85397\n",
            "14/14 [==============================] - 4s 312ms/step - loss: 0.0469 - accuracy: 0.8423 - val_loss: 0.1126 - val_accuracy: 0.8529\n",
            "Epoch 67/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.8419\n",
            "Epoch 67: val_accuracy did not improve from 0.85397\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0468 - accuracy: 0.8419 - val_loss: 0.1130 - val_accuracy: 0.8529\n",
            "Epoch 68/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.8425\n",
            "Epoch 68: val_accuracy did not improve from 0.85397\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0468 - accuracy: 0.8425 - val_loss: 0.1159 - val_accuracy: 0.8499\n",
            "Epoch 69/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.8424\n",
            "Epoch 69: val_accuracy did not improve from 0.85397\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0470 - accuracy: 0.8424 - val_loss: 0.1118 - val_accuracy: 0.8530\n",
            "Epoch 70/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 0.8434\n",
            "Epoch 70: val_accuracy improved from 0.85397 to 0.85578, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 343ms/step - loss: 0.0466 - accuracy: 0.8434 - val_loss: 0.1124 - val_accuracy: 0.8558\n",
            "Epoch 71/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.8438\n",
            "Epoch 71: val_accuracy did not improve from 0.85578\n",
            "14/14 [==============================] - 4s 312ms/step - loss: 0.0461 - accuracy: 0.8438 - val_loss: 0.1114 - val_accuracy: 0.8548\n",
            "Epoch 72/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.8448\n",
            "Epoch 72: val_accuracy did not improve from 0.85578\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0462 - accuracy: 0.8448 - val_loss: 0.1146 - val_accuracy: 0.8520\n",
            "Epoch 73/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.8448\n",
            "Epoch 73: val_accuracy improved from 0.85578 to 0.85582, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 341ms/step - loss: 0.0459 - accuracy: 0.8448 - val_loss: 0.1126 - val_accuracy: 0.8558\n",
            "Epoch 74/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.8459\n",
            "Epoch 74: val_accuracy did not improve from 0.85582\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0458 - accuracy: 0.8459 - val_loss: 0.1125 - val_accuracy: 0.8470\n",
            "Epoch 75/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.8446\n",
            "Epoch 75: val_accuracy did not improve from 0.85582\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0461 - accuracy: 0.8446 - val_loss: 0.1097 - val_accuracy: 0.8523\n",
            "Epoch 76/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.8441\n",
            "Epoch 76: val_accuracy improved from 0.85582 to 0.86030, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 341ms/step - loss: 0.0460 - accuracy: 0.8441 - val_loss: 0.1185 - val_accuracy: 0.8603\n",
            "Epoch 77/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.8446\n",
            "Epoch 77: val_accuracy did not improve from 0.86030\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0467 - accuracy: 0.8446 - val_loss: 0.1146 - val_accuracy: 0.8539\n",
            "Epoch 78/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.8469\n",
            "Epoch 78: val_accuracy did not improve from 0.86030\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0461 - accuracy: 0.8469 - val_loss: 0.1145 - val_accuracy: 0.8579\n",
            "Epoch 79/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.8456\n",
            "Epoch 79: val_accuracy did not improve from 0.86030\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0455 - accuracy: 0.8456 - val_loss: 0.1105 - val_accuracy: 0.8541\n",
            "Epoch 80/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.8473\n",
            "Epoch 80: val_accuracy did not improve from 0.86030\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0452 - accuracy: 0.8473 - val_loss: 0.1121 - val_accuracy: 0.8571\n",
            "Epoch 81/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.8487\n",
            "Epoch 81: val_accuracy did not improve from 0.86030\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0451 - accuracy: 0.8487 - val_loss: 0.1091 - val_accuracy: 0.8520\n",
            "Epoch 82/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.8476\n",
            "Epoch 82: val_accuracy did not improve from 0.86030\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0449 - accuracy: 0.8476 - val_loss: 0.1109 - val_accuracy: 0.8585\n",
            "Epoch 83/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.8494\n",
            "Epoch 83: val_accuracy did not improve from 0.86030\n",
            "14/14 [==============================] - 4s 312ms/step - loss: 0.0447 - accuracy: 0.8494 - val_loss: 0.1138 - val_accuracy: 0.8542\n",
            "Epoch 84/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0445 - accuracy: 0.8496\n",
            "Epoch 84: val_accuracy did not improve from 0.86030\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0445 - accuracy: 0.8496 - val_loss: 0.1077 - val_accuracy: 0.8533\n",
            "Epoch 85/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.8495\n",
            "Epoch 85: val_accuracy did not improve from 0.86030\n",
            "14/14 [==============================] - 4s 312ms/step - loss: 0.0446 - accuracy: 0.8495 - val_loss: 0.1079 - val_accuracy: 0.8563\n",
            "Epoch 86/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.8459\n",
            "Epoch 86: val_accuracy did not improve from 0.86030\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0480 - accuracy: 0.8459 - val_loss: 0.1105 - val_accuracy: 0.8527\n",
            "Epoch 87/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 0.8490\n",
            "Epoch 87: val_accuracy did not improve from 0.86030\n",
            "14/14 [==============================] - 4s 312ms/step - loss: 0.0452 - accuracy: 0.8490 - val_loss: 0.1121 - val_accuracy: 0.8557\n",
            "Epoch 88/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.8504\n",
            "Epoch 88: val_accuracy did not improve from 0.86030\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0446 - accuracy: 0.8504 - val_loss: 0.1081 - val_accuracy: 0.8580\n",
            "Epoch 89/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.8526\n",
            "Epoch 89: val_accuracy did not improve from 0.86030\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0440 - accuracy: 0.8526 - val_loss: 0.1064 - val_accuracy: 0.8559\n",
            "Epoch 90/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 0.8511\n",
            "Epoch 90: val_accuracy improved from 0.86030 to 0.86298, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 341ms/step - loss: 0.0441 - accuracy: 0.8511 - val_loss: 0.1111 - val_accuracy: 0.8630\n",
            "Epoch 91/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.8534\n",
            "Epoch 91: val_accuracy did not improve from 0.86298\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0438 - accuracy: 0.8534 - val_loss: 0.1061 - val_accuracy: 0.8571\n",
            "Epoch 92/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.8528\n",
            "Epoch 92: val_accuracy did not improve from 0.86298\n",
            "14/14 [==============================] - 4s 311ms/step - loss: 0.0435 - accuracy: 0.8528 - val_loss: 0.1072 - val_accuracy: 0.8571\n",
            "Epoch 93/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.8548\n",
            "Epoch 93: val_accuracy did not improve from 0.86298\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0433 - accuracy: 0.8548 - val_loss: 0.1084 - val_accuracy: 0.8593\n",
            "Epoch 94/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.8529\n",
            "Epoch 94: val_accuracy did not improve from 0.86298\n",
            "14/14 [==============================] - 4s 311ms/step - loss: 0.0437 - accuracy: 0.8529 - val_loss: 0.1089 - val_accuracy: 0.8594\n",
            "Epoch 95/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.8474\n",
            "Epoch 95: val_accuracy did not improve from 0.86298\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0488 - accuracy: 0.8474 - val_loss: 0.1105 - val_accuracy: 0.8581\n",
            "Epoch 96/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.8514\n",
            "Epoch 96: val_accuracy did not improve from 0.86298\n",
            "14/14 [==============================] - 4s 311ms/step - loss: 0.0454 - accuracy: 0.8514 - val_loss: 0.1073 - val_accuracy: 0.8574\n",
            "Epoch 97/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 0.8539\n",
            "Epoch 97: val_accuracy did not improve from 0.86298\n",
            "14/14 [==============================] - 4s 311ms/step - loss: 0.0438 - accuracy: 0.8539 - val_loss: 0.1074 - val_accuracy: 0.8586\n",
            "Epoch 98/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.8555\n",
            "Epoch 98: val_accuracy improved from 0.86298 to 0.86483, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 343ms/step - loss: 0.0432 - accuracy: 0.8555 - val_loss: 0.1101 - val_accuracy: 0.8648\n",
            "Epoch 99/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.8567\n",
            "Epoch 99: val_accuracy did not improve from 0.86483\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0428 - accuracy: 0.8567 - val_loss: 0.1044 - val_accuracy: 0.8596\n",
            "Epoch 100/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.8565\n",
            "Epoch 100: val_accuracy did not improve from 0.86483\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0427 - accuracy: 0.8565 - val_loss: 0.1063 - val_accuracy: 0.8607\n",
            "Epoch 101/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.8557\n",
            "Epoch 101: val_accuracy improved from 0.86483 to 0.86989, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 342ms/step - loss: 0.0427 - accuracy: 0.8557 - val_loss: 0.1083 - val_accuracy: 0.8699\n",
            "Epoch 102/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.8582\n",
            "Epoch 102: val_accuracy did not improve from 0.86989\n",
            "14/14 [==============================] - 4s 312ms/step - loss: 0.0425 - accuracy: 0.8582 - val_loss: 0.1047 - val_accuracy: 0.8652\n",
            "Epoch 103/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.8588\n",
            "Epoch 103: val_accuracy did not improve from 0.86989\n",
            "14/14 [==============================] - 4s 312ms/step - loss: 0.0422 - accuracy: 0.8588 - val_loss: 0.1056 - val_accuracy: 0.8639\n",
            "Epoch 104/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.8593\n",
            "Epoch 104: val_accuracy improved from 0.86989 to 0.87013, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 342ms/step - loss: 0.0420 - accuracy: 0.8593 - val_loss: 0.1054 - val_accuracy: 0.8701\n",
            "Epoch 105/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.8616\n",
            "Epoch 105: val_accuracy did not improve from 0.87013\n",
            "14/14 [==============================] - 4s 312ms/step - loss: 0.0420 - accuracy: 0.8616 - val_loss: 0.1028 - val_accuracy: 0.8679\n",
            "Epoch 106/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.8624\n",
            "Epoch 106: val_accuracy did not improve from 0.87013\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0420 - accuracy: 0.8624 - val_loss: 0.1060 - val_accuracy: 0.8609\n",
            "Epoch 107/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0468 - accuracy: 0.8543\n",
            "Epoch 107: val_accuracy did not improve from 0.87013\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0468 - accuracy: 0.8543 - val_loss: 0.1319 - val_accuracy: 0.8653\n",
            "Epoch 108/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.8230\n",
            "Epoch 108: val_accuracy did not improve from 0.87013\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0570 - accuracy: 0.8230 - val_loss: 0.1222 - val_accuracy: 0.8677\n",
            "Epoch 109/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.8387\n",
            "Epoch 109: val_accuracy did not improve from 0.87013\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0536 - accuracy: 0.8387 - val_loss: 0.1199 - val_accuracy: 0.8671\n",
            "Epoch 110/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.8443\n",
            "Epoch 110: val_accuracy did not improve from 0.87013\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0514 - accuracy: 0.8443 - val_loss: 0.1163 - val_accuracy: 0.8675\n",
            "Epoch 111/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.8502\n",
            "Epoch 111: val_accuracy improved from 0.87013 to 0.87457, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 345ms/step - loss: 0.0499 - accuracy: 0.8502 - val_loss: 0.1181 - val_accuracy: 0.8746\n",
            "Epoch 112/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.8511\n",
            "Epoch 112: val_accuracy improved from 0.87457 to 0.87474, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0487 - accuracy: 0.8511 - val_loss: 0.1153 - val_accuracy: 0.8747\n",
            "Epoch 113/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.8582\n",
            "Epoch 113: val_accuracy did not improve from 0.87474\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0458 - accuracy: 0.8582 - val_loss: 0.1108 - val_accuracy: 0.8728\n",
            "Epoch 114/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 0.8648\n",
            "Epoch 114: val_accuracy did not improve from 0.87474\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0424 - accuracy: 0.8648 - val_loss: 0.1075 - val_accuracy: 0.8729\n",
            "Epoch 115/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.8692\n",
            "Epoch 115: val_accuracy did not improve from 0.87474\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0407 - accuracy: 0.8692 - val_loss: 0.1016 - val_accuracy: 0.8703\n",
            "Epoch 116/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 0.8688\n",
            "Epoch 116: val_accuracy improved from 0.87474 to 0.88058, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 341ms/step - loss: 0.0406 - accuracy: 0.8688 - val_loss: 0.1029 - val_accuracy: 0.8806\n",
            "Epoch 117/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.8729\n",
            "Epoch 117: val_accuracy did not improve from 0.88058\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0401 - accuracy: 0.8729 - val_loss: 0.1008 - val_accuracy: 0.8782\n",
            "Epoch 118/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.8760\n",
            "Epoch 118: val_accuracy improved from 0.88058 to 0.88132, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 344ms/step - loss: 0.0395 - accuracy: 0.8760 - val_loss: 0.1011 - val_accuracy: 0.8813\n",
            "Epoch 119/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.8782\n",
            "Epoch 119: val_accuracy improved from 0.88132 to 0.88457, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 329ms/step - loss: 0.0392 - accuracy: 0.8782 - val_loss: 0.1010 - val_accuracy: 0.8846\n",
            "Epoch 120/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.8651\n",
            "Epoch 120: val_accuracy did not improve from 0.88457\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0450 - accuracy: 0.8651 - val_loss: 0.1195 - val_accuracy: 0.8698\n",
            "Epoch 121/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0542 - accuracy: 0.8355\n",
            "Epoch 121: val_accuracy did not improve from 0.88457\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0542 - accuracy: 0.8355 - val_loss: 0.1210 - val_accuracy: 0.8784\n",
            "Epoch 122/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.8435\n",
            "Epoch 122: val_accuracy did not improve from 0.88457\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0518 - accuracy: 0.8435 - val_loss: 0.1216 - val_accuracy: 0.8632\n",
            "Epoch 123/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0491 - accuracy: 0.8562\n",
            "Epoch 123: val_accuracy did not improve from 0.88457\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0491 - accuracy: 0.8562 - val_loss: 0.1162 - val_accuracy: 0.8742\n",
            "Epoch 124/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 0.8620\n",
            "Epoch 124: val_accuracy did not improve from 0.88457\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0466 - accuracy: 0.8620 - val_loss: 0.1145 - val_accuracy: 0.8801\n",
            "Epoch 125/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.8679\n",
            "Epoch 125: val_accuracy did not improve from 0.88457\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0456 - accuracy: 0.8679 - val_loss: 0.1202 - val_accuracy: 0.8707\n",
            "Epoch 126/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.8717\n",
            "Epoch 126: val_accuracy improved from 0.88457 to 0.88765, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 343ms/step - loss: 0.0451 - accuracy: 0.8717 - val_loss: 0.1221 - val_accuracy: 0.8877\n",
            "Epoch 127/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.8728\n",
            "Epoch 127: val_accuracy did not improve from 0.88765\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0450 - accuracy: 0.8728 - val_loss: 0.1210 - val_accuracy: 0.8723\n",
            "Epoch 128/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0436 - accuracy: 0.8754\n",
            "Epoch 128: val_accuracy did not improve from 0.88765\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0436 - accuracy: 0.8754 - val_loss: 0.1157 - val_accuracy: 0.8865\n",
            "Epoch 129/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.8801\n",
            "Epoch 129: val_accuracy improved from 0.88765 to 0.89485, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 345ms/step - loss: 0.0422 - accuracy: 0.8801 - val_loss: 0.1179 - val_accuracy: 0.8948\n",
            "Epoch 130/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.8823\n",
            "Epoch 130: val_accuracy did not improve from 0.89485\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0414 - accuracy: 0.8823 - val_loss: 0.1126 - val_accuracy: 0.8916\n",
            "Epoch 131/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.8823\n",
            "Epoch 131: val_accuracy did not improve from 0.89485\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0411 - accuracy: 0.8823 - val_loss: 0.1156 - val_accuracy: 0.8713\n",
            "Epoch 132/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.8773\n",
            "Epoch 132: val_accuracy improved from 0.89485 to 0.89727, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 343ms/step - loss: 0.0428 - accuracy: 0.8773 - val_loss: 0.1121 - val_accuracy: 0.8973\n",
            "Epoch 133/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.8843\n",
            "Epoch 133: val_accuracy did not improve from 0.89727\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0408 - accuracy: 0.8843 - val_loss: 0.1080 - val_accuracy: 0.8887\n",
            "Epoch 134/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.8840\n",
            "Epoch 134: val_accuracy did not improve from 0.89727\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0404 - accuracy: 0.8840 - val_loss: 0.1104 - val_accuracy: 0.8910\n",
            "Epoch 135/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.8859\n",
            "Epoch 135: val_accuracy did not improve from 0.89727\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0396 - accuracy: 0.8859 - val_loss: 0.1122 - val_accuracy: 0.8863\n",
            "Epoch 136/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.8859\n",
            "Epoch 136: val_accuracy improved from 0.89727 to 0.90982, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 343ms/step - loss: 0.0404 - accuracy: 0.8859 - val_loss: 0.1201 - val_accuracy: 0.9098\n",
            "Epoch 137/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.8855\n",
            "Epoch 137: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 312ms/step - loss: 0.0403 - accuracy: 0.8855 - val_loss: 0.1146 - val_accuracy: 0.8940\n",
            "Epoch 138/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.8862\n",
            "Epoch 138: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0394 - accuracy: 0.8862 - val_loss: 0.1087 - val_accuracy: 0.9024\n",
            "Epoch 139/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.8896\n",
            "Epoch 139: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0386 - accuracy: 0.8896 - val_loss: 0.1061 - val_accuracy: 0.8954\n",
            "Epoch 140/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.8914\n",
            "Epoch 140: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0378 - accuracy: 0.8914 - val_loss: 0.1165 - val_accuracy: 0.8969\n",
            "Epoch 141/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.8895\n",
            "Epoch 141: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0390 - accuracy: 0.8895 - val_loss: 0.1091 - val_accuracy: 0.8791\n",
            "Epoch 142/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.8895\n",
            "Epoch 142: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0389 - accuracy: 0.8895 - val_loss: 0.1105 - val_accuracy: 0.8909\n",
            "Epoch 143/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.8906\n",
            "Epoch 143: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0378 - accuracy: 0.8906 - val_loss: 0.1074 - val_accuracy: 0.8944\n",
            "Epoch 144/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.8918\n",
            "Epoch 144: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0378 - accuracy: 0.8918 - val_loss: 0.1065 - val_accuracy: 0.8931\n",
            "Epoch 145/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.8824\n",
            "Epoch 145: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 319ms/step - loss: 0.0409 - accuracy: 0.8824 - val_loss: 0.1112 - val_accuracy: 0.9039\n",
            "Epoch 146/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.8797\n",
            "Epoch 146: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0420 - accuracy: 0.8797 - val_loss: 0.1070 - val_accuracy: 0.8934\n",
            "Epoch 147/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.8881\n",
            "Epoch 147: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0392 - accuracy: 0.8881 - val_loss: 0.1084 - val_accuracy: 0.8857\n",
            "Epoch 148/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 0.8907\n",
            "Epoch 148: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0380 - accuracy: 0.8907 - val_loss: 0.1027 - val_accuracy: 0.8939\n",
            "Epoch 149/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.8936\n",
            "Epoch 149: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0374 - accuracy: 0.8936 - val_loss: 0.1084 - val_accuracy: 0.9047\n",
            "Epoch 150/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.8960\n",
            "Epoch 150: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0364 - accuracy: 0.8960 - val_loss: 0.1055 - val_accuracy: 0.9079\n",
            "Epoch 151/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.8964\n",
            "Epoch 151: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0358 - accuracy: 0.8964 - val_loss: 0.1027 - val_accuracy: 0.9048\n",
            "Epoch 152/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.8968\n",
            "Epoch 152: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 312ms/step - loss: 0.0361 - accuracy: 0.8968 - val_loss: 0.1011 - val_accuracy: 0.9085\n",
            "Epoch 153/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.8970\n",
            "Epoch 153: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0358 - accuracy: 0.8970 - val_loss: 0.0994 - val_accuracy: 0.9050\n",
            "Epoch 154/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.8981\n",
            "Epoch 154: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0358 - accuracy: 0.8981 - val_loss: 0.0980 - val_accuracy: 0.9078\n",
            "Epoch 155/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.8963\n",
            "Epoch 155: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0358 - accuracy: 0.8963 - val_loss: 0.1005 - val_accuracy: 0.8961\n",
            "Epoch 156/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.8818\n",
            "Epoch 156: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0416 - accuracy: 0.8818 - val_loss: 0.1063 - val_accuracy: 0.8975\n",
            "Epoch 157/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.8846\n",
            "Epoch 157: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0395 - accuracy: 0.8846 - val_loss: 0.1111 - val_accuracy: 0.8981\n",
            "Epoch 158/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.8916\n",
            "Epoch 158: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0370 - accuracy: 0.8916 - val_loss: 0.1075 - val_accuracy: 0.9065\n",
            "Epoch 159/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.8948\n",
            "Epoch 159: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0358 - accuracy: 0.8948 - val_loss: 0.1057 - val_accuracy: 0.9094\n",
            "Epoch 160/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.8976\n",
            "Epoch 160: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0348 - accuracy: 0.8976 - val_loss: 0.1038 - val_accuracy: 0.9065\n",
            "Epoch 161/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.8969\n",
            "Epoch 161: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0348 - accuracy: 0.8969 - val_loss: 0.1038 - val_accuracy: 0.9031\n",
            "Epoch 162/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.8989\n",
            "Epoch 162: val_accuracy did not improve from 0.90982\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0350 - accuracy: 0.8989 - val_loss: 0.1064 - val_accuracy: 0.9017\n",
            "Epoch 163/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 0.8985\n",
            "Epoch 163: val_accuracy improved from 0.90982 to 0.91134, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 342ms/step - loss: 0.0347 - accuracy: 0.8985 - val_loss: 0.1098 - val_accuracy: 0.9113\n",
            "Epoch 164/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.8991\n",
            "Epoch 164: val_accuracy did not improve from 0.91134\n",
            "14/14 [==============================] - 4s 312ms/step - loss: 0.0343 - accuracy: 0.8991 - val_loss: 0.1069 - val_accuracy: 0.9047\n",
            "Epoch 165/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.8986\n",
            "Epoch 165: val_accuracy did not improve from 0.91134\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0345 - accuracy: 0.8986 - val_loss: 0.1016 - val_accuracy: 0.9106\n",
            "Epoch 166/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9000\n",
            "Epoch 166: val_accuracy did not improve from 0.91134\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0341 - accuracy: 0.9000 - val_loss: 0.1113 - val_accuracy: 0.9081\n",
            "Epoch 167/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.8987\n",
            "Epoch 167: val_accuracy did not improve from 0.91134\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0344 - accuracy: 0.8987 - val_loss: 0.1028 - val_accuracy: 0.9057\n",
            "Epoch 168/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 0.8981\n",
            "Epoch 168: val_accuracy improved from 0.91134 to 0.91269, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 346ms/step - loss: 0.0347 - accuracy: 0.8981 - val_loss: 0.1004 - val_accuracy: 0.9127\n",
            "Epoch 169/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.8990\n",
            "Epoch 169: val_accuracy did not improve from 0.91269\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0344 - accuracy: 0.8990 - val_loss: 0.0918 - val_accuracy: 0.9108\n",
            "Epoch 170/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 0.9000\n",
            "Epoch 170: val_accuracy did not improve from 0.91269\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0335 - accuracy: 0.9000 - val_loss: 0.0959 - val_accuracy: 0.9125\n",
            "Epoch 171/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9009\n",
            "Epoch 171: val_accuracy improved from 0.91269 to 0.91315, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 345ms/step - loss: 0.0336 - accuracy: 0.9009 - val_loss: 0.0934 - val_accuracy: 0.9131\n",
            "Epoch 172/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.8985\n",
            "Epoch 172: val_accuracy did not improve from 0.91315\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0342 - accuracy: 0.8985 - val_loss: 0.1020 - val_accuracy: 0.9030\n",
            "Epoch 173/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.8997\n",
            "Epoch 173: val_accuracy did not improve from 0.91315\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0344 - accuracy: 0.8997 - val_loss: 0.1062 - val_accuracy: 0.9120\n",
            "Epoch 174/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.8993\n",
            "Epoch 174: val_accuracy improved from 0.91315 to 0.91335, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 342ms/step - loss: 0.0342 - accuracy: 0.8993 - val_loss: 0.0997 - val_accuracy: 0.9134\n",
            "Epoch 175/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9009\n",
            "Epoch 175: val_accuracy improved from 0.91335 to 0.91779, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0340 - accuracy: 0.9009 - val_loss: 0.0981 - val_accuracy: 0.9178\n",
            "Epoch 176/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9014\n",
            "Epoch 176: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0338 - accuracy: 0.9014 - val_loss: 0.1069 - val_accuracy: 0.9155\n",
            "Epoch 177/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9035\n",
            "Epoch 177: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0330 - accuracy: 0.9035 - val_loss: 0.0960 - val_accuracy: 0.9122\n",
            "Epoch 178/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9028\n",
            "Epoch 178: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0332 - accuracy: 0.9028 - val_loss: 0.1064 - val_accuracy: 0.9098\n",
            "Epoch 179/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9018\n",
            "Epoch 179: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0331 - accuracy: 0.9018 - val_loss: 0.0989 - val_accuracy: 0.9176\n",
            "Epoch 180/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9036\n",
            "Epoch 180: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0327 - accuracy: 0.9036 - val_loss: 0.0976 - val_accuracy: 0.9175\n",
            "Epoch 181/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9026\n",
            "Epoch 181: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0330 - accuracy: 0.9026 - val_loss: 0.1077 - val_accuracy: 0.9158\n",
            "Epoch 182/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9011\n",
            "Epoch 182: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0330 - accuracy: 0.9011 - val_loss: 0.0941 - val_accuracy: 0.9140\n",
            "Epoch 183/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9031\n",
            "Epoch 183: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0331 - accuracy: 0.9031 - val_loss: 0.0904 - val_accuracy: 0.9086\n",
            "Epoch 184/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9031\n",
            "Epoch 184: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0332 - accuracy: 0.9031 - val_loss: 0.1108 - val_accuracy: 0.9132\n",
            "Epoch 185/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9029\n",
            "Epoch 185: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0325 - accuracy: 0.9029 - val_loss: 0.0927 - val_accuracy: 0.9147\n",
            "Epoch 186/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9026\n",
            "Epoch 186: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0328 - accuracy: 0.9026 - val_loss: 0.0903 - val_accuracy: 0.9141\n",
            "Epoch 187/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9036\n",
            "Epoch 187: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0328 - accuracy: 0.9036 - val_loss: 0.0946 - val_accuracy: 0.9056\n",
            "Epoch 188/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9026\n",
            "Epoch 188: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0331 - accuracy: 0.9026 - val_loss: 0.0995 - val_accuracy: 0.9086\n",
            "Epoch 189/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9052\n",
            "Epoch 189: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0318 - accuracy: 0.9052 - val_loss: 0.0980 - val_accuracy: 0.9135\n",
            "Epoch 190/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9057\n",
            "Epoch 190: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0319 - accuracy: 0.9057 - val_loss: 0.1079 - val_accuracy: 0.9114\n",
            "Epoch 191/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9024\n",
            "Epoch 191: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0327 - accuracy: 0.9024 - val_loss: 0.1049 - val_accuracy: 0.9083\n",
            "Epoch 192/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9045\n",
            "Epoch 192: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0324 - accuracy: 0.9045 - val_loss: 0.1073 - val_accuracy: 0.9175\n",
            "Epoch 193/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9040\n",
            "Epoch 193: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0321 - accuracy: 0.9040 - val_loss: 0.0972 - val_accuracy: 0.9177\n",
            "Epoch 194/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9035\n",
            "Epoch 194: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 312ms/step - loss: 0.0328 - accuracy: 0.9035 - val_loss: 0.1037 - val_accuracy: 0.9146\n",
            "Epoch 195/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9034\n",
            "Epoch 195: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0337 - accuracy: 0.9034 - val_loss: 0.0946 - val_accuracy: 0.9160\n",
            "Epoch 196/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9032\n",
            "Epoch 196: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0325 - accuracy: 0.9032 - val_loss: 0.0947 - val_accuracy: 0.9141\n",
            "Epoch 197/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9040\n",
            "Epoch 197: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0323 - accuracy: 0.9040 - val_loss: 0.0949 - val_accuracy: 0.9140\n",
            "Epoch 198/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9047\n",
            "Epoch 198: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0323 - accuracy: 0.9047 - val_loss: 0.0928 - val_accuracy: 0.9158\n",
            "Epoch 199/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9040\n",
            "Epoch 199: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0316 - accuracy: 0.9040 - val_loss: 0.0921 - val_accuracy: 0.9135\n",
            "Epoch 200/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9059\n",
            "Epoch 200: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0312 - accuracy: 0.9059 - val_loss: 0.1026 - val_accuracy: 0.9103\n",
            "Epoch 201/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9056\n",
            "Epoch 201: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0311 - accuracy: 0.9056 - val_loss: 0.0969 - val_accuracy: 0.9062\n",
            "Epoch 202/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9050\n",
            "Epoch 202: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0314 - accuracy: 0.9050 - val_loss: 0.0983 - val_accuracy: 0.9149\n",
            "Epoch 203/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9051\n",
            "Epoch 203: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0316 - accuracy: 0.9051 - val_loss: 0.1002 - val_accuracy: 0.9133\n",
            "Epoch 204/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9044\n",
            "Epoch 204: val_accuracy did not improve from 0.91779\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0318 - accuracy: 0.9044 - val_loss: 0.1084 - val_accuracy: 0.9095\n",
            "Epoch 205/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9052\n",
            "Epoch 205: val_accuracy improved from 0.91779 to 0.91969, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 347ms/step - loss: 0.0312 - accuracy: 0.9052 - val_loss: 0.1047 - val_accuracy: 0.9197\n",
            "Epoch 206/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9062\n",
            "Epoch 206: val_accuracy did not improve from 0.91969\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0310 - accuracy: 0.9062 - val_loss: 0.1035 - val_accuracy: 0.9145\n",
            "Epoch 207/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9052\n",
            "Epoch 207: val_accuracy did not improve from 0.91969\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0314 - accuracy: 0.9052 - val_loss: 0.1022 - val_accuracy: 0.9155\n",
            "Epoch 208/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9062\n",
            "Epoch 208: val_accuracy did not improve from 0.91969\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0313 - accuracy: 0.9062 - val_loss: 0.1039 - val_accuracy: 0.9131\n",
            "Epoch 209/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9034\n",
            "Epoch 209: val_accuracy did not improve from 0.91969\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0321 - accuracy: 0.9034 - val_loss: 0.0923 - val_accuracy: 0.9162\n",
            "Epoch 210/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9071\n",
            "Epoch 210: val_accuracy improved from 0.91969 to 0.91993, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 346ms/step - loss: 0.0311 - accuracy: 0.9071 - val_loss: 0.0939 - val_accuracy: 0.9199\n",
            "Epoch 211/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9048\n",
            "Epoch 211: val_accuracy did not improve from 0.91993\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0319 - accuracy: 0.9048 - val_loss: 0.0999 - val_accuracy: 0.9145\n",
            "Epoch 212/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9057\n",
            "Epoch 212: val_accuracy did not improve from 0.91993\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0324 - accuracy: 0.9057 - val_loss: 0.0961 - val_accuracy: 0.9159\n",
            "Epoch 213/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9041\n",
            "Epoch 213: val_accuracy did not improve from 0.91993\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0322 - accuracy: 0.9041 - val_loss: 0.0923 - val_accuracy: 0.9152\n",
            "Epoch 214/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9057\n",
            "Epoch 214: val_accuracy improved from 0.91993 to 0.92071, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 345ms/step - loss: 0.0312 - accuracy: 0.9057 - val_loss: 0.1063 - val_accuracy: 0.9207\n",
            "Epoch 215/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9063\n",
            "Epoch 215: val_accuracy did not improve from 0.92071\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0309 - accuracy: 0.9063 - val_loss: 0.0928 - val_accuracy: 0.9162\n",
            "Epoch 216/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9065\n",
            "Epoch 216: val_accuracy did not improve from 0.92071\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0310 - accuracy: 0.9065 - val_loss: 0.0919 - val_accuracy: 0.9092\n",
            "Epoch 217/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9057\n",
            "Epoch 217: val_accuracy did not improve from 0.92071\n",
            "14/14 [==============================] - 4s 319ms/step - loss: 0.0319 - accuracy: 0.9057 - val_loss: 0.0978 - val_accuracy: 0.9096\n",
            "Epoch 218/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9066\n",
            "Epoch 218: val_accuracy did not improve from 0.92071\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0313 - accuracy: 0.9066 - val_loss: 0.0930 - val_accuracy: 0.9067\n",
            "Epoch 219/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9070\n",
            "Epoch 219: val_accuracy improved from 0.92071 to 0.92248, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 346ms/step - loss: 0.0306 - accuracy: 0.9070 - val_loss: 0.0993 - val_accuracy: 0.9225\n",
            "Epoch 220/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9080\n",
            "Epoch 220: val_accuracy improved from 0.92248 to 0.92380, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 332ms/step - loss: 0.0299 - accuracy: 0.9080 - val_loss: 0.0942 - val_accuracy: 0.9238\n",
            "Epoch 221/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9090\n",
            "Epoch 221: val_accuracy did not improve from 0.92380\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0303 - accuracy: 0.9090 - val_loss: 0.0940 - val_accuracy: 0.9170\n",
            "Epoch 222/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9079\n",
            "Epoch 222: val_accuracy did not improve from 0.92380\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0299 - accuracy: 0.9079 - val_loss: 0.0996 - val_accuracy: 0.9167\n",
            "Epoch 223/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9084\n",
            "Epoch 223: val_accuracy did not improve from 0.92380\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0299 - accuracy: 0.9084 - val_loss: 0.0963 - val_accuracy: 0.9198\n",
            "Epoch 224/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9087\n",
            "Epoch 224: val_accuracy did not improve from 0.92380\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0304 - accuracy: 0.9087 - val_loss: 0.0920 - val_accuracy: 0.9211\n",
            "Epoch 225/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9085\n",
            "Epoch 225: val_accuracy did not improve from 0.92380\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0299 - accuracy: 0.9085 - val_loss: 0.1030 - val_accuracy: 0.9224\n",
            "Epoch 226/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9087\n",
            "Epoch 226: val_accuracy did not improve from 0.92380\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0305 - accuracy: 0.9087 - val_loss: 0.0898 - val_accuracy: 0.9168\n",
            "Epoch 227/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9089\n",
            "Epoch 227: val_accuracy did not improve from 0.92380\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0307 - accuracy: 0.9089 - val_loss: 0.0972 - val_accuracy: 0.9226\n",
            "Epoch 228/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9098\n",
            "Epoch 228: val_accuracy did not improve from 0.92380\n",
            "14/14 [==============================] - 4s 311ms/step - loss: 0.0302 - accuracy: 0.9098 - val_loss: 0.0900 - val_accuracy: 0.9208\n",
            "Epoch 229/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9070\n",
            "Epoch 229: val_accuracy did not improve from 0.92380\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0302 - accuracy: 0.9070 - val_loss: 0.0897 - val_accuracy: 0.9218\n",
            "Epoch 230/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9101\n",
            "Epoch 230: val_accuracy did not improve from 0.92380\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0292 - accuracy: 0.9101 - val_loss: 0.0897 - val_accuracy: 0.9193\n",
            "Epoch 231/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9114\n",
            "Epoch 231: val_accuracy did not improve from 0.92380\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0292 - accuracy: 0.9114 - val_loss: 0.0960 - val_accuracy: 0.9178\n",
            "Epoch 232/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9113\n",
            "Epoch 232: val_accuracy did not improve from 0.92380\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0292 - accuracy: 0.9113 - val_loss: 0.1060 - val_accuracy: 0.9121\n",
            "Epoch 233/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9095\n",
            "Epoch 233: val_accuracy did not improve from 0.92380\n",
            "14/14 [==============================] - 4s 312ms/step - loss: 0.0303 - accuracy: 0.9095 - val_loss: 0.0958 - val_accuracy: 0.9222\n",
            "Epoch 234/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9103\n",
            "Epoch 234: val_accuracy did not improve from 0.92380\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0300 - accuracy: 0.9103 - val_loss: 0.0846 - val_accuracy: 0.9226\n",
            "Epoch 235/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9117\n",
            "Epoch 235: val_accuracy did not improve from 0.92380\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0293 - accuracy: 0.9117 - val_loss: 0.0914 - val_accuracy: 0.9207\n",
            "Epoch 236/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9121\n",
            "Epoch 236: val_accuracy improved from 0.92380 to 0.92696, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 342ms/step - loss: 0.0291 - accuracy: 0.9121 - val_loss: 0.0988 - val_accuracy: 0.9270\n",
            "Epoch 237/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9127\n",
            "Epoch 237: val_accuracy did not improve from 0.92696\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0292 - accuracy: 0.9127 - val_loss: 0.0841 - val_accuracy: 0.9203\n",
            "Epoch 238/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9107\n",
            "Epoch 238: val_accuracy did not improve from 0.92696\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0295 - accuracy: 0.9107 - val_loss: 0.0911 - val_accuracy: 0.9201\n",
            "Epoch 239/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9110\n",
            "Epoch 239: val_accuracy did not improve from 0.92696\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0291 - accuracy: 0.9110 - val_loss: 0.0847 - val_accuracy: 0.9234\n",
            "Epoch 240/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9126\n",
            "Epoch 240: val_accuracy improved from 0.92696 to 0.92738, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 342ms/step - loss: 0.0282 - accuracy: 0.9126 - val_loss: 0.1001 - val_accuracy: 0.9274\n",
            "Epoch 241/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9125\n",
            "Epoch 241: val_accuracy did not improve from 0.92738\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0288 - accuracy: 0.9125 - val_loss: 0.0915 - val_accuracy: 0.9217\n",
            "Epoch 242/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9114\n",
            "Epoch 242: val_accuracy did not improve from 0.92738\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0288 - accuracy: 0.9114 - val_loss: 0.0858 - val_accuracy: 0.9212\n",
            "Epoch 243/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9125\n",
            "Epoch 243: val_accuracy did not improve from 0.92738\n",
            "14/14 [==============================] - 4s 319ms/step - loss: 0.0288 - accuracy: 0.9125 - val_loss: 0.0910 - val_accuracy: 0.9216\n",
            "Epoch 244/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9142\n",
            "Epoch 244: val_accuracy did not improve from 0.92738\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0283 - accuracy: 0.9142 - val_loss: 0.0868 - val_accuracy: 0.9252\n",
            "Epoch 245/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9126\n",
            "Epoch 245: val_accuracy did not improve from 0.92738\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0283 - accuracy: 0.9126 - val_loss: 0.0948 - val_accuracy: 0.9219\n",
            "Epoch 246/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9132\n",
            "Epoch 246: val_accuracy did not improve from 0.92738\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0290 - accuracy: 0.9132 - val_loss: 0.0912 - val_accuracy: 0.9217\n",
            "Epoch 247/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.9120\n",
            "Epoch 247: val_accuracy did not improve from 0.92738\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0297 - accuracy: 0.9120 - val_loss: 0.0870 - val_accuracy: 0.9213\n",
            "Epoch 248/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9142\n",
            "Epoch 248: val_accuracy did not improve from 0.92738\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0283 - accuracy: 0.9142 - val_loss: 0.0943 - val_accuracy: 0.9259\n",
            "Epoch 249/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9148\n",
            "Epoch 249: val_accuracy did not improve from 0.92738\n",
            "14/14 [==============================] - 4s 311ms/step - loss: 0.0281 - accuracy: 0.9148 - val_loss: 0.1001 - val_accuracy: 0.9256\n",
            "Epoch 250/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9152\n",
            "Epoch 250: val_accuracy improved from 0.92738 to 0.93215, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 345ms/step - loss: 0.0284 - accuracy: 0.9152 - val_loss: 0.0933 - val_accuracy: 0.9321\n",
            "Epoch 251/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9142\n",
            "Epoch 251: val_accuracy did not improve from 0.93215\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0283 - accuracy: 0.9142 - val_loss: 0.0946 - val_accuracy: 0.9266\n",
            "Epoch 252/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9129\n",
            "Epoch 252: val_accuracy did not improve from 0.93215\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0296 - accuracy: 0.9129 - val_loss: 0.0897 - val_accuracy: 0.9192\n",
            "Epoch 253/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9131\n",
            "Epoch 253: val_accuracy did not improve from 0.93215\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0288 - accuracy: 0.9131 - val_loss: 0.0871 - val_accuracy: 0.9211\n",
            "Epoch 254/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9117\n",
            "Epoch 254: val_accuracy did not improve from 0.93215\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0295 - accuracy: 0.9117 - val_loss: 0.0992 - val_accuracy: 0.9217\n",
            "Epoch 255/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9089\n",
            "Epoch 255: val_accuracy did not improve from 0.93215\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0308 - accuracy: 0.9089 - val_loss: 0.0987 - val_accuracy: 0.9230\n",
            "Epoch 256/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9135\n",
            "Epoch 256: val_accuracy did not improve from 0.93215\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0285 - accuracy: 0.9135 - val_loss: 0.1049 - val_accuracy: 0.9254\n",
            "Epoch 257/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9151\n",
            "Epoch 257: val_accuracy did not improve from 0.93215\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0281 - accuracy: 0.9151 - val_loss: 0.0961 - val_accuracy: 0.9266\n",
            "Epoch 258/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9158\n",
            "Epoch 258: val_accuracy did not improve from 0.93215\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0276 - accuracy: 0.9158 - val_loss: 0.0892 - val_accuracy: 0.9293\n",
            "Epoch 259/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9151\n",
            "Epoch 259: val_accuracy did not improve from 0.93215\n",
            "14/14 [==============================] - 4s 319ms/step - loss: 0.0276 - accuracy: 0.9151 - val_loss: 0.0978 - val_accuracy: 0.9232\n",
            "Epoch 260/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9149\n",
            "Epoch 260: val_accuracy did not improve from 0.93215\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0277 - accuracy: 0.9149 - val_loss: 0.0847 - val_accuracy: 0.9255\n",
            "Epoch 261/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9148\n",
            "Epoch 261: val_accuracy did not improve from 0.93215\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0279 - accuracy: 0.9148 - val_loss: 0.0902 - val_accuracy: 0.9192\n",
            "Epoch 262/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.8869\n",
            "Epoch 262: val_accuracy did not improve from 0.93215\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0383 - accuracy: 0.8869 - val_loss: 0.1092 - val_accuracy: 0.8770\n",
            "Epoch 263/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 0.8934\n",
            "Epoch 263: val_accuracy did not improve from 0.93215\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0360 - accuracy: 0.8934 - val_loss: 0.0987 - val_accuracy: 0.9110\n",
            "Epoch 264/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9058\n",
            "Epoch 264: val_accuracy did not improve from 0.93215\n",
            "14/14 [==============================] - 4s 312ms/step - loss: 0.0307 - accuracy: 0.9058 - val_loss: 0.0978 - val_accuracy: 0.9247\n",
            "Epoch 265/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9107\n",
            "Epoch 265: val_accuracy did not improve from 0.93215\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0289 - accuracy: 0.9107 - val_loss: 0.1027 - val_accuracy: 0.9195\n",
            "Epoch 266/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9120\n",
            "Epoch 266: val_accuracy did not improve from 0.93215\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0283 - accuracy: 0.9120 - val_loss: 0.0911 - val_accuracy: 0.9296\n",
            "Epoch 267/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9161\n",
            "Epoch 267: val_accuracy did not improve from 0.93215\n",
            "14/14 [==============================] - 4s 311ms/step - loss: 0.0274 - accuracy: 0.9161 - val_loss: 0.0879 - val_accuracy: 0.9259\n",
            "Epoch 268/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9166\n",
            "Epoch 268: val_accuracy did not improve from 0.93215\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0274 - accuracy: 0.9166 - val_loss: 0.0854 - val_accuracy: 0.9234\n",
            "Epoch 269/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9156\n",
            "Epoch 269: val_accuracy did not improve from 0.93215\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0277 - accuracy: 0.9156 - val_loss: 0.0866 - val_accuracy: 0.9289\n",
            "Epoch 270/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9183\n",
            "Epoch 270: val_accuracy improved from 0.93215 to 0.93248, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 345ms/step - loss: 0.0267 - accuracy: 0.9183 - val_loss: 0.0873 - val_accuracy: 0.9325\n",
            "Epoch 271/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9174\n",
            "Epoch 271: val_accuracy did not improve from 0.93248\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0266 - accuracy: 0.9174 - val_loss: 0.0888 - val_accuracy: 0.9271\n",
            "Epoch 272/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9191\n",
            "Epoch 272: val_accuracy improved from 0.93248 to 0.93597, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 333ms/step - loss: 0.0269 - accuracy: 0.9191 - val_loss: 0.0908 - val_accuracy: 0.9360\n",
            "Epoch 273/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9176\n",
            "Epoch 273: val_accuracy did not improve from 0.93597\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0267 - accuracy: 0.9176 - val_loss: 0.0832 - val_accuracy: 0.9334\n",
            "Epoch 274/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9184\n",
            "Epoch 274: val_accuracy did not improve from 0.93597\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0264 - accuracy: 0.9184 - val_loss: 0.0872 - val_accuracy: 0.9257\n",
            "Epoch 275/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9184\n",
            "Epoch 275: val_accuracy did not improve from 0.93597\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0264 - accuracy: 0.9184 - val_loss: 0.0875 - val_accuracy: 0.9341\n",
            "Epoch 276/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9192\n",
            "Epoch 276: val_accuracy did not improve from 0.93597\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0264 - accuracy: 0.9192 - val_loss: 0.0910 - val_accuracy: 0.9321\n",
            "Epoch 277/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9203\n",
            "Epoch 277: val_accuracy did not improve from 0.93597\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0259 - accuracy: 0.9203 - val_loss: 0.0946 - val_accuracy: 0.9307\n",
            "Epoch 278/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9209\n",
            "Epoch 278: val_accuracy improved from 0.93597 to 0.93811, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 345ms/step - loss: 0.0258 - accuracy: 0.9209 - val_loss: 0.0884 - val_accuracy: 0.9381\n",
            "Epoch 279/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9198\n",
            "Epoch 279: val_accuracy did not improve from 0.93811\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0262 - accuracy: 0.9198 - val_loss: 0.0859 - val_accuracy: 0.9278\n",
            "Epoch 280/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9182\n",
            "Epoch 280: val_accuracy did not improve from 0.93811\n",
            "14/14 [==============================] - 4s 319ms/step - loss: 0.0268 - accuracy: 0.9182 - val_loss: 0.0843 - val_accuracy: 0.9313\n",
            "Epoch 281/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9189\n",
            "Epoch 281: val_accuracy did not improve from 0.93811\n",
            "14/14 [==============================] - 4s 319ms/step - loss: 0.0269 - accuracy: 0.9189 - val_loss: 0.0812 - val_accuracy: 0.9331\n",
            "Epoch 282/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9193\n",
            "Epoch 282: val_accuracy did not improve from 0.93811\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0264 - accuracy: 0.9193 - val_loss: 0.0819 - val_accuracy: 0.9367\n",
            "Epoch 283/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9201\n",
            "Epoch 283: val_accuracy did not improve from 0.93811\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0259 - accuracy: 0.9201 - val_loss: 0.0811 - val_accuracy: 0.9356\n",
            "Epoch 284/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9199\n",
            "Epoch 284: val_accuracy did not improve from 0.93811\n",
            "14/14 [==============================] - 4s 319ms/step - loss: 0.0260 - accuracy: 0.9199 - val_loss: 0.0942 - val_accuracy: 0.9323\n",
            "Epoch 285/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9205\n",
            "Epoch 285: val_accuracy did not improve from 0.93811\n",
            "14/14 [==============================] - 4s 321ms/step - loss: 0.0257 - accuracy: 0.9205 - val_loss: 0.0794 - val_accuracy: 0.9349\n",
            "Epoch 286/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9206\n",
            "Epoch 286: val_accuracy did not improve from 0.93811\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0259 - accuracy: 0.9206 - val_loss: 0.0846 - val_accuracy: 0.9332\n",
            "Epoch 287/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9211\n",
            "Epoch 287: val_accuracy did not improve from 0.93811\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0252 - accuracy: 0.9211 - val_loss: 0.0876 - val_accuracy: 0.9373\n",
            "Epoch 288/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9217\n",
            "Epoch 288: val_accuracy did not improve from 0.93811\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0255 - accuracy: 0.9217 - val_loss: 0.0878 - val_accuracy: 0.9289\n",
            "Epoch 289/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9218\n",
            "Epoch 289: val_accuracy did not improve from 0.93811\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0253 - accuracy: 0.9218 - val_loss: 0.0845 - val_accuracy: 0.9329\n",
            "Epoch 290/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9220\n",
            "Epoch 290: val_accuracy improved from 0.93811 to 0.93914, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 341ms/step - loss: 0.0254 - accuracy: 0.9220 - val_loss: 0.0783 - val_accuracy: 0.9391\n",
            "Epoch 291/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9201\n",
            "Epoch 291: val_accuracy did not improve from 0.93914\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0258 - accuracy: 0.9201 - val_loss: 0.0868 - val_accuracy: 0.9349\n",
            "Epoch 292/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9223\n",
            "Epoch 292: val_accuracy did not improve from 0.93914\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0256 - accuracy: 0.9223 - val_loss: 0.0871 - val_accuracy: 0.9351\n",
            "Epoch 293/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9217\n",
            "Epoch 293: val_accuracy did not improve from 0.93914\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0260 - accuracy: 0.9217 - val_loss: 0.0975 - val_accuracy: 0.9316\n",
            "Epoch 294/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9166\n",
            "Epoch 294: val_accuracy did not improve from 0.93914\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0272 - accuracy: 0.9166 - val_loss: 0.0907 - val_accuracy: 0.9324\n",
            "Epoch 295/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9214\n",
            "Epoch 295: val_accuracy did not improve from 0.93914\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0258 - accuracy: 0.9214 - val_loss: 0.0891 - val_accuracy: 0.9377\n",
            "Epoch 296/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9210\n",
            "Epoch 296: val_accuracy improved from 0.93914 to 0.93975, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 347ms/step - loss: 0.0257 - accuracy: 0.9210 - val_loss: 0.0813 - val_accuracy: 0.9398\n",
            "Epoch 297/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9240\n",
            "Epoch 297: val_accuracy did not improve from 0.93975\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0247 - accuracy: 0.9240 - val_loss: 0.0754 - val_accuracy: 0.9393\n",
            "Epoch 298/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9229\n",
            "Epoch 298: val_accuracy did not improve from 0.93975\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0254 - accuracy: 0.9229 - val_loss: 0.0919 - val_accuracy: 0.9374\n",
            "Epoch 299/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9219\n",
            "Epoch 299: val_accuracy did not improve from 0.93975\n",
            "14/14 [==============================] - 4s 319ms/step - loss: 0.0253 - accuracy: 0.9219 - val_loss: 0.0798 - val_accuracy: 0.9368\n",
            "Epoch 300/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9239\n",
            "Epoch 300: val_accuracy did not improve from 0.93975\n",
            "14/14 [==============================] - 4s 321ms/step - loss: 0.0247 - accuracy: 0.9239 - val_loss: 0.0850 - val_accuracy: 0.9358\n",
            "Epoch 301/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9218\n",
            "Epoch 301: val_accuracy did not improve from 0.93975\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0256 - accuracy: 0.9218 - val_loss: 0.0955 - val_accuracy: 0.9331\n",
            "Epoch 302/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9189\n",
            "Epoch 302: val_accuracy did not improve from 0.93975\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0266 - accuracy: 0.9189 - val_loss: 0.0725 - val_accuracy: 0.9332\n",
            "Epoch 303/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9201\n",
            "Epoch 303: val_accuracy did not improve from 0.93975\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0263 - accuracy: 0.9201 - val_loss: 0.0850 - val_accuracy: 0.9274\n",
            "Epoch 304/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9200\n",
            "Epoch 304: val_accuracy did not improve from 0.93975\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0259 - accuracy: 0.9200 - val_loss: 0.0815 - val_accuracy: 0.9353\n",
            "Epoch 305/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9215\n",
            "Epoch 305: val_accuracy did not improve from 0.93975\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0253 - accuracy: 0.9215 - val_loss: 0.0762 - val_accuracy: 0.9383\n",
            "Epoch 306/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9226\n",
            "Epoch 306: val_accuracy did not improve from 0.93975\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0251 - accuracy: 0.9226 - val_loss: 0.0878 - val_accuracy: 0.9338\n",
            "Epoch 307/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9233\n",
            "Epoch 307: val_accuracy did not improve from 0.93975\n",
            "14/14 [==============================] - 4s 321ms/step - loss: 0.0246 - accuracy: 0.9233 - val_loss: 0.0944 - val_accuracy: 0.9347\n",
            "Epoch 308/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9242\n",
            "Epoch 308: val_accuracy did not improve from 0.93975\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0245 - accuracy: 0.9242 - val_loss: 0.0870 - val_accuracy: 0.9344\n",
            "Epoch 309/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9245\n",
            "Epoch 309: val_accuracy did not improve from 0.93975\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0246 - accuracy: 0.9245 - val_loss: 0.0870 - val_accuracy: 0.9344\n",
            "Epoch 310/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9233\n",
            "Epoch 310: val_accuracy improved from 0.93975 to 0.94008, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 347ms/step - loss: 0.0246 - accuracy: 0.9233 - val_loss: 0.0849 - val_accuracy: 0.9401\n",
            "Epoch 311/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9262\n",
            "Epoch 311: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0242 - accuracy: 0.9262 - val_loss: 0.0777 - val_accuracy: 0.9363\n",
            "Epoch 312/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9251\n",
            "Epoch 312: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0241 - accuracy: 0.9251 - val_loss: 0.0775 - val_accuracy: 0.9356\n",
            "Epoch 313/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9256\n",
            "Epoch 313: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0240 - accuracy: 0.9256 - val_loss: 0.0743 - val_accuracy: 0.9382\n",
            "Epoch 314/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9275\n",
            "Epoch 314: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0233 - accuracy: 0.9275 - val_loss: 0.0831 - val_accuracy: 0.9385\n",
            "Epoch 315/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9257\n",
            "Epoch 315: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0239 - accuracy: 0.9257 - val_loss: 0.0759 - val_accuracy: 0.9367\n",
            "Epoch 316/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9270\n",
            "Epoch 316: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0239 - accuracy: 0.9270 - val_loss: 0.0857 - val_accuracy: 0.9375\n",
            "Epoch 317/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9270\n",
            "Epoch 317: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0239 - accuracy: 0.9270 - val_loss: 0.0845 - val_accuracy: 0.9362\n",
            "Epoch 318/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9275\n",
            "Epoch 318: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0241 - accuracy: 0.9275 - val_loss: 0.0798 - val_accuracy: 0.9399\n",
            "Epoch 319/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9267\n",
            "Epoch 319: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0238 - accuracy: 0.9267 - val_loss: 0.0875 - val_accuracy: 0.9368\n",
            "Epoch 320/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9266\n",
            "Epoch 320: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0238 - accuracy: 0.9266 - val_loss: 0.0984 - val_accuracy: 0.9376\n",
            "Epoch 321/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9236\n",
            "Epoch 321: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0252 - accuracy: 0.9236 - val_loss: 0.0774 - val_accuracy: 0.9343\n",
            "Epoch 322/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.8967\n",
            "Epoch 322: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0352 - accuracy: 0.8967 - val_loss: 0.1321 - val_accuracy: 0.8640\n",
            "Epoch 323/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.8689\n",
            "Epoch 323: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0442 - accuracy: 0.8689 - val_loss: 0.1215 - val_accuracy: 0.9098\n",
            "Epoch 324/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.8905\n",
            "Epoch 324: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0354 - accuracy: 0.8905 - val_loss: 0.1066 - val_accuracy: 0.9170\n",
            "Epoch 325/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9020\n",
            "Epoch 325: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0308 - accuracy: 0.9020 - val_loss: 0.1027 - val_accuracy: 0.9186\n",
            "Epoch 326/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.8971\n",
            "Epoch 326: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0353 - accuracy: 0.8971 - val_loss: 0.0997 - val_accuracy: 0.9108\n",
            "Epoch 327/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9049\n",
            "Epoch 327: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0296 - accuracy: 0.9049 - val_loss: 0.0902 - val_accuracy: 0.9291\n",
            "Epoch 328/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9113\n",
            "Epoch 328: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0277 - accuracy: 0.9113 - val_loss: 0.0918 - val_accuracy: 0.9273\n",
            "Epoch 329/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9153\n",
            "Epoch 329: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0262 - accuracy: 0.9153 - val_loss: 0.0908 - val_accuracy: 0.9355\n",
            "Epoch 330/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9187\n",
            "Epoch 330: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0256 - accuracy: 0.9187 - val_loss: 0.0791 - val_accuracy: 0.9349\n",
            "Epoch 331/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9192\n",
            "Epoch 331: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0249 - accuracy: 0.9192 - val_loss: 0.0821 - val_accuracy: 0.9354\n",
            "Epoch 332/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9208\n",
            "Epoch 332: val_accuracy did not improve from 0.94008\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0254 - accuracy: 0.9208 - val_loss: 0.0902 - val_accuracy: 0.9371\n",
            "Epoch 333/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9212\n",
            "Epoch 333: val_accuracy improved from 0.94008 to 0.94074, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 350ms/step - loss: 0.0250 - accuracy: 0.9212 - val_loss: 0.0829 - val_accuracy: 0.9407\n",
            "Epoch 334/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9234\n",
            "Epoch 334: val_accuracy did not improve from 0.94074\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0246 - accuracy: 0.9234 - val_loss: 0.0842 - val_accuracy: 0.9373\n",
            "Epoch 335/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9243\n",
            "Epoch 335: val_accuracy did not improve from 0.94074\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0241 - accuracy: 0.9243 - val_loss: 0.0828 - val_accuracy: 0.9333\n",
            "Epoch 336/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9200\n",
            "Epoch 336: val_accuracy did not improve from 0.94074\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0259 - accuracy: 0.9200 - val_loss: 0.0776 - val_accuracy: 0.9353\n",
            "Epoch 337/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9218\n",
            "Epoch 337: val_accuracy did not improve from 0.94074\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0249 - accuracy: 0.9218 - val_loss: 0.0969 - val_accuracy: 0.9363\n",
            "Epoch 338/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9222\n",
            "Epoch 338: val_accuracy did not improve from 0.94074\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0244 - accuracy: 0.9222 - val_loss: 0.0820 - val_accuracy: 0.9388\n",
            "Epoch 339/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9247\n",
            "Epoch 339: val_accuracy did not improve from 0.94074\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0238 - accuracy: 0.9247 - val_loss: 0.0799 - val_accuracy: 0.9376\n",
            "Epoch 340/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9245\n",
            "Epoch 340: val_accuracy did not improve from 0.94074\n",
            "14/14 [==============================] - 4s 319ms/step - loss: 0.0246 - accuracy: 0.9245 - val_loss: 0.1067 - val_accuracy: 0.9407\n",
            "Epoch 341/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9235\n",
            "Epoch 341: val_accuracy improved from 0.94074 to 0.94267, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 349ms/step - loss: 0.0240 - accuracy: 0.9235 - val_loss: 0.0926 - val_accuracy: 0.9427\n",
            "Epoch 342/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9250\n",
            "Epoch 342: val_accuracy did not improve from 0.94267\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0242 - accuracy: 0.9250 - val_loss: 0.0780 - val_accuracy: 0.9395\n",
            "Epoch 343/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9239\n",
            "Epoch 343: val_accuracy did not improve from 0.94267\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0244 - accuracy: 0.9239 - val_loss: 0.0781 - val_accuracy: 0.9381\n",
            "Epoch 344/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9244\n",
            "Epoch 344: val_accuracy did not improve from 0.94267\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0237 - accuracy: 0.9244 - val_loss: 0.0878 - val_accuracy: 0.9366\n",
            "Epoch 345/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9262\n",
            "Epoch 345: val_accuracy did not improve from 0.94267\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0235 - accuracy: 0.9262 - val_loss: 0.0803 - val_accuracy: 0.9394\n",
            "Epoch 346/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9266\n",
            "Epoch 346: val_accuracy did not improve from 0.94267\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0231 - accuracy: 0.9266 - val_loss: 0.1056 - val_accuracy: 0.9406\n",
            "Epoch 347/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9284\n",
            "Epoch 347: val_accuracy did not improve from 0.94267\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0235 - accuracy: 0.9284 - val_loss: 0.0864 - val_accuracy: 0.9372\n",
            "Epoch 348/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9279\n",
            "Epoch 348: val_accuracy did not improve from 0.94267\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0230 - accuracy: 0.9279 - val_loss: 0.0712 - val_accuracy: 0.9351\n",
            "Epoch 349/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9286\n",
            "Epoch 349: val_accuracy did not improve from 0.94267\n",
            "14/14 [==============================] - 4s 319ms/step - loss: 0.0228 - accuracy: 0.9286 - val_loss: 0.0824 - val_accuracy: 0.9406\n",
            "Epoch 350/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9298\n",
            "Epoch 350: val_accuracy did not improve from 0.94267\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0226 - accuracy: 0.9298 - val_loss: 0.0887 - val_accuracy: 0.9407\n",
            "Epoch 351/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9298\n",
            "Epoch 351: val_accuracy did not improve from 0.94267\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0223 - accuracy: 0.9298 - val_loss: 0.0929 - val_accuracy: 0.9419\n",
            "Epoch 352/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9305\n",
            "Epoch 352: val_accuracy did not improve from 0.94267\n",
            "14/14 [==============================] - 4s 321ms/step - loss: 0.0222 - accuracy: 0.9305 - val_loss: 0.0742 - val_accuracy: 0.9398\n",
            "Epoch 353/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9299\n",
            "Epoch 353: val_accuracy did not improve from 0.94267\n",
            "14/14 [==============================] - 4s 322ms/step - loss: 0.0225 - accuracy: 0.9299 - val_loss: 0.0794 - val_accuracy: 0.9377\n",
            "Epoch 354/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9299\n",
            "Epoch 354: val_accuracy improved from 0.94267 to 0.94317, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 349ms/step - loss: 0.0223 - accuracy: 0.9299 - val_loss: 0.0701 - val_accuracy: 0.9432\n",
            "Epoch 355/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9318\n",
            "Epoch 355: val_accuracy did not improve from 0.94317\n",
            "14/14 [==============================] - 4s 321ms/step - loss: 0.0222 - accuracy: 0.9318 - val_loss: 0.0857 - val_accuracy: 0.9381\n",
            "Epoch 356/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9313\n",
            "Epoch 356: val_accuracy did not improve from 0.94317\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0215 - accuracy: 0.9313 - val_loss: 0.0831 - val_accuracy: 0.9416\n",
            "Epoch 357/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9327\n",
            "Epoch 357: val_accuracy did not improve from 0.94317\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0216 - accuracy: 0.9327 - val_loss: 0.0765 - val_accuracy: 0.9367\n",
            "Epoch 358/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9318\n",
            "Epoch 358: val_accuracy did not improve from 0.94317\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0220 - accuracy: 0.9318 - val_loss: 0.0813 - val_accuracy: 0.9419\n",
            "Epoch 359/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9316\n",
            "Epoch 359: val_accuracy did not improve from 0.94317\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0219 - accuracy: 0.9316 - val_loss: 0.0976 - val_accuracy: 0.9330\n",
            "Epoch 360/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9094\n",
            "Epoch 360: val_accuracy did not improve from 0.94317\n",
            "14/14 [==============================] - 4s 319ms/step - loss: 0.0313 - accuracy: 0.9094 - val_loss: 0.0894 - val_accuracy: 0.9386\n",
            "Epoch 361/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9138\n",
            "Epoch 361: val_accuracy did not improve from 0.94317\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0283 - accuracy: 0.9138 - val_loss: 0.0849 - val_accuracy: 0.9318\n",
            "Epoch 362/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9210\n",
            "Epoch 362: val_accuracy did not improve from 0.94317\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0250 - accuracy: 0.9210 - val_loss: 0.0849 - val_accuracy: 0.9425\n",
            "Epoch 363/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9251\n",
            "Epoch 363: val_accuracy did not improve from 0.94317\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0238 - accuracy: 0.9251 - val_loss: 0.0742 - val_accuracy: 0.9402\n",
            "Epoch 364/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9287\n",
            "Epoch 364: val_accuracy did not improve from 0.94317\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0225 - accuracy: 0.9287 - val_loss: 0.0826 - val_accuracy: 0.9398\n",
            "Epoch 365/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9307\n",
            "Epoch 365: val_accuracy improved from 0.94317 to 0.94383, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 345ms/step - loss: 0.0218 - accuracy: 0.9307 - val_loss: 0.0741 - val_accuracy: 0.9438\n",
            "Epoch 366/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9322\n",
            "Epoch 366: val_accuracy did not improve from 0.94383\n",
            "14/14 [==============================] - 4s 313ms/step - loss: 0.0220 - accuracy: 0.9322 - val_loss: 0.0724 - val_accuracy: 0.9408\n",
            "Epoch 367/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9307\n",
            "Epoch 367: val_accuracy did not improve from 0.94383\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0219 - accuracy: 0.9307 - val_loss: 0.0811 - val_accuracy: 0.9391\n",
            "Epoch 368/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9280\n",
            "Epoch 368: val_accuracy did not improve from 0.94383\n",
            "14/14 [==============================] - 4s 319ms/step - loss: 0.0239 - accuracy: 0.9280 - val_loss: 0.0948 - val_accuracy: 0.9358\n",
            "Epoch 369/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9276\n",
            "Epoch 369: val_accuracy did not improve from 0.94383\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0237 - accuracy: 0.9276 - val_loss: 0.0754 - val_accuracy: 0.9355\n",
            "Epoch 370/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9284\n",
            "Epoch 370: val_accuracy did not improve from 0.94383\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0230 - accuracy: 0.9284 - val_loss: 0.0836 - val_accuracy: 0.9355\n",
            "Epoch 371/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9302\n",
            "Epoch 371: val_accuracy did not improve from 0.94383\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0227 - accuracy: 0.9302 - val_loss: 0.0901 - val_accuracy: 0.9366\n",
            "Epoch 372/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9305\n",
            "Epoch 372: val_accuracy did not improve from 0.94383\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0223 - accuracy: 0.9305 - val_loss: 0.0812 - val_accuracy: 0.9361\n",
            "Epoch 373/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9310\n",
            "Epoch 373: val_accuracy did not improve from 0.94383\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0222 - accuracy: 0.9310 - val_loss: 0.0814 - val_accuracy: 0.9384\n",
            "Epoch 374/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9296\n",
            "Epoch 374: val_accuracy did not improve from 0.94383\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0223 - accuracy: 0.9296 - val_loss: 0.0783 - val_accuracy: 0.9406\n",
            "Epoch 375/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9327\n",
            "Epoch 375: val_accuracy did not improve from 0.94383\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0214 - accuracy: 0.9327 - val_loss: 0.0785 - val_accuracy: 0.9410\n",
            "Epoch 376/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9332\n",
            "Epoch 376: val_accuracy did not improve from 0.94383\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0216 - accuracy: 0.9332 - val_loss: 0.0730 - val_accuracy: 0.9428\n",
            "Epoch 377/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9338\n",
            "Epoch 377: val_accuracy did not improve from 0.94383\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0210 - accuracy: 0.9338 - val_loss: 0.0893 - val_accuracy: 0.9411\n",
            "Epoch 378/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9330\n",
            "Epoch 378: val_accuracy did not improve from 0.94383\n",
            "14/14 [==============================] - 4s 319ms/step - loss: 0.0215 - accuracy: 0.9330 - val_loss: 0.0823 - val_accuracy: 0.9423\n",
            "Epoch 379/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9328\n",
            "Epoch 379: val_accuracy did not improve from 0.94383\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0213 - accuracy: 0.9328 - val_loss: 0.0765 - val_accuracy: 0.9402\n",
            "Epoch 380/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9347\n",
            "Epoch 380: val_accuracy did not improve from 0.94383\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0208 - accuracy: 0.9347 - val_loss: 0.0798 - val_accuracy: 0.9375\n",
            "Epoch 381/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9333\n",
            "Epoch 381: val_accuracy did not improve from 0.94383\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0211 - accuracy: 0.9333 - val_loss: 0.0684 - val_accuracy: 0.9399\n",
            "Epoch 382/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9324\n",
            "Epoch 382: val_accuracy did not improve from 0.94383\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0216 - accuracy: 0.9324 - val_loss: 0.0809 - val_accuracy: 0.9431\n",
            "Epoch 383/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9361\n",
            "Epoch 383: val_accuracy did not improve from 0.94383\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0209 - accuracy: 0.9361 - val_loss: 0.0785 - val_accuracy: 0.9415\n",
            "Epoch 384/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9348\n",
            "Epoch 384: val_accuracy improved from 0.94383 to 0.94395, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 345ms/step - loss: 0.0206 - accuracy: 0.9348 - val_loss: 0.0732 - val_accuracy: 0.9439\n",
            "Epoch 385/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9347\n",
            "Epoch 385: val_accuracy did not improve from 0.94395\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0207 - accuracy: 0.9347 - val_loss: 0.0908 - val_accuracy: 0.9382\n",
            "Epoch 386/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9346\n",
            "Epoch 386: val_accuracy did not improve from 0.94395\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0208 - accuracy: 0.9346 - val_loss: 0.0872 - val_accuracy: 0.9415\n",
            "Epoch 387/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9348\n",
            "Epoch 387: val_accuracy did not improve from 0.94395\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0204 - accuracy: 0.9348 - val_loss: 0.0789 - val_accuracy: 0.9439\n",
            "Epoch 388/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9358\n",
            "Epoch 388: val_accuracy did not improve from 0.94395\n",
            "14/14 [==============================] - 4s 319ms/step - loss: 0.0205 - accuracy: 0.9358 - val_loss: 0.0974 - val_accuracy: 0.9394\n",
            "Epoch 389/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9327\n",
            "Epoch 389: val_accuracy did not improve from 0.94395\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0218 - accuracy: 0.9327 - val_loss: 0.0843 - val_accuracy: 0.9412\n",
            "Epoch 390/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9328\n",
            "Epoch 390: val_accuracy did not improve from 0.94395\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0214 - accuracy: 0.9328 - val_loss: 0.0853 - val_accuracy: 0.9375\n",
            "Epoch 391/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9323\n",
            "Epoch 391: val_accuracy did not improve from 0.94395\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0215 - accuracy: 0.9323 - val_loss: 0.0876 - val_accuracy: 0.9350\n",
            "Epoch 392/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9342\n",
            "Epoch 392: val_accuracy improved from 0.94395 to 0.94481, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 346ms/step - loss: 0.0209 - accuracy: 0.9342 - val_loss: 0.1077 - val_accuracy: 0.9448\n",
            "Epoch 393/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9362\n",
            "Epoch 393: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0208 - accuracy: 0.9362 - val_loss: 0.0847 - val_accuracy: 0.9413\n",
            "Epoch 394/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 0.9325\n",
            "Epoch 394: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0224 - accuracy: 0.9325 - val_loss: 0.0878 - val_accuracy: 0.9361\n",
            "Epoch 395/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9337\n",
            "Epoch 395: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0214 - accuracy: 0.9337 - val_loss: 0.0829 - val_accuracy: 0.9345\n",
            "Epoch 396/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9351\n",
            "Epoch 396: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0208 - accuracy: 0.9351 - val_loss: 0.0681 - val_accuracy: 0.9419\n",
            "Epoch 397/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9371\n",
            "Epoch 397: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0202 - accuracy: 0.9371 - val_loss: 0.0908 - val_accuracy: 0.9428\n",
            "Epoch 398/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9375\n",
            "Epoch 398: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0200 - accuracy: 0.9375 - val_loss: 0.0691 - val_accuracy: 0.9428\n",
            "Epoch 399/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9380\n",
            "Epoch 399: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0200 - accuracy: 0.9380 - val_loss: 0.0747 - val_accuracy: 0.9411\n",
            "Epoch 400/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9361\n",
            "Epoch 400: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0210 - accuracy: 0.9361 - val_loss: 0.0770 - val_accuracy: 0.9377\n",
            "Epoch 401/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9341\n",
            "Epoch 401: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 312ms/step - loss: 0.0212 - accuracy: 0.9341 - val_loss: 0.0847 - val_accuracy: 0.9428\n",
            "Epoch 402/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9349\n",
            "Epoch 402: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0206 - accuracy: 0.9349 - val_loss: 0.0673 - val_accuracy: 0.9408\n",
            "Epoch 403/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9343\n",
            "Epoch 403: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0212 - accuracy: 0.9343 - val_loss: 0.1152 - val_accuracy: 0.9386\n",
            "Epoch 404/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9376\n",
            "Epoch 404: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0201 - accuracy: 0.9376 - val_loss: 0.0765 - val_accuracy: 0.9415\n",
            "Epoch 405/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9371\n",
            "Epoch 405: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0203 - accuracy: 0.9371 - val_loss: 0.0731 - val_accuracy: 0.9405\n",
            "Epoch 406/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9354\n",
            "Epoch 406: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0208 - accuracy: 0.9354 - val_loss: 0.0809 - val_accuracy: 0.9410\n",
            "Epoch 407/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9355\n",
            "Epoch 407: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0206 - accuracy: 0.9355 - val_loss: 0.0758 - val_accuracy: 0.9419\n",
            "Epoch 408/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9380\n",
            "Epoch 408: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0200 - accuracy: 0.9380 - val_loss: 0.0895 - val_accuracy: 0.9447\n",
            "Epoch 409/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9364\n",
            "Epoch 409: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0202 - accuracy: 0.9364 - val_loss: 0.0841 - val_accuracy: 0.9378\n",
            "Epoch 410/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9383\n",
            "Epoch 410: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0200 - accuracy: 0.9383 - val_loss: 0.0760 - val_accuracy: 0.9371\n",
            "Epoch 411/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9390\n",
            "Epoch 411: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0194 - accuracy: 0.9390 - val_loss: 0.0735 - val_accuracy: 0.9428\n",
            "Epoch 412/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9412\n",
            "Epoch 412: val_accuracy did not improve from 0.94481\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0189 - accuracy: 0.9412 - val_loss: 0.0707 - val_accuracy: 0.9426\n",
            "Epoch 413/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9415\n",
            "Epoch 413: val_accuracy improved from 0.94481 to 0.94568, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 345ms/step - loss: 0.0191 - accuracy: 0.9415 - val_loss: 0.0848 - val_accuracy: 0.9457\n",
            "Epoch 414/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9362\n",
            "Epoch 414: val_accuracy improved from 0.94568 to 0.94740, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 331ms/step - loss: 0.0202 - accuracy: 0.9362 - val_loss: 0.0758 - val_accuracy: 0.9474\n",
            "Epoch 415/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9392\n",
            "Epoch 415: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0196 - accuracy: 0.9392 - val_loss: 0.0885 - val_accuracy: 0.9419\n",
            "Epoch 416/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9372\n",
            "Epoch 416: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0205 - accuracy: 0.9372 - val_loss: 0.0744 - val_accuracy: 0.9348\n",
            "Epoch 417/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9321\n",
            "Epoch 417: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0218 - accuracy: 0.9321 - val_loss: 0.0797 - val_accuracy: 0.9439\n",
            "Epoch 418/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9358\n",
            "Epoch 418: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0205 - accuracy: 0.9358 - val_loss: 0.0797 - val_accuracy: 0.9382\n",
            "Epoch 419/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9385\n",
            "Epoch 419: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0196 - accuracy: 0.9385 - val_loss: 0.0762 - val_accuracy: 0.9440\n",
            "Epoch 420/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9391\n",
            "Epoch 420: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0197 - accuracy: 0.9391 - val_loss: 0.1003 - val_accuracy: 0.9407\n",
            "Epoch 421/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9387\n",
            "Epoch 421: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0197 - accuracy: 0.9387 - val_loss: 0.0708 - val_accuracy: 0.9433\n",
            "Epoch 422/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9406\n",
            "Epoch 422: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0187 - accuracy: 0.9406 - val_loss: 0.0776 - val_accuracy: 0.9419\n",
            "Epoch 423/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9396\n",
            "Epoch 423: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0193 - accuracy: 0.9396 - val_loss: 0.0886 - val_accuracy: 0.9439\n",
            "Epoch 424/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9396\n",
            "Epoch 424: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 322ms/step - loss: 0.0195 - accuracy: 0.9396 - val_loss: 0.0836 - val_accuracy: 0.9413\n",
            "Epoch 425/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9428\n",
            "Epoch 425: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 320ms/step - loss: 0.0184 - accuracy: 0.9428 - val_loss: 0.0928 - val_accuracy: 0.9437\n",
            "Epoch 426/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9416\n",
            "Epoch 426: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0187 - accuracy: 0.9416 - val_loss: 0.0771 - val_accuracy: 0.9407\n",
            "Epoch 427/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9427\n",
            "Epoch 427: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0181 - accuracy: 0.9427 - val_loss: 0.0864 - val_accuracy: 0.9449\n",
            "Epoch 428/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9412\n",
            "Epoch 428: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0191 - accuracy: 0.9412 - val_loss: 0.0962 - val_accuracy: 0.9417\n",
            "Epoch 429/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9422\n",
            "Epoch 429: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0187 - accuracy: 0.9422 - val_loss: 0.0863 - val_accuracy: 0.9395\n",
            "Epoch 430/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9417\n",
            "Epoch 430: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0188 - accuracy: 0.9417 - val_loss: 0.0721 - val_accuracy: 0.9410\n",
            "Epoch 431/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9420\n",
            "Epoch 431: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0189 - accuracy: 0.9420 - val_loss: 0.0855 - val_accuracy: 0.9431\n",
            "Epoch 432/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9398\n",
            "Epoch 432: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0199 - accuracy: 0.9398 - val_loss: 0.0891 - val_accuracy: 0.9432\n",
            "Epoch 433/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9382\n",
            "Epoch 433: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0204 - accuracy: 0.9382 - val_loss: 0.0777 - val_accuracy: 0.9421\n",
            "Epoch 434/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9370\n",
            "Epoch 434: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0208 - accuracy: 0.9370 - val_loss: 0.0747 - val_accuracy: 0.9412\n",
            "Epoch 435/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9238\n",
            "Epoch 435: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0256 - accuracy: 0.9238 - val_loss: 0.1035 - val_accuracy: 0.9312\n",
            "Epoch 436/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9272\n",
            "Epoch 436: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0237 - accuracy: 0.9272 - val_loss: 0.0815 - val_accuracy: 0.9385\n",
            "Epoch 437/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9291\n",
            "Epoch 437: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0228 - accuracy: 0.9291 - val_loss: 0.0734 - val_accuracy: 0.9459\n",
            "Epoch 438/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9341\n",
            "Epoch 438: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0209 - accuracy: 0.9341 - val_loss: 0.0940 - val_accuracy: 0.9409\n",
            "Epoch 439/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9404\n",
            "Epoch 439: val_accuracy did not improve from 0.94740\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0191 - accuracy: 0.9404 - val_loss: 0.0828 - val_accuracy: 0.9452\n",
            "Epoch 440/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9413\n",
            "Epoch 440: val_accuracy improved from 0.94740 to 0.94765, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 352ms/step - loss: 0.0186 - accuracy: 0.9413 - val_loss: 0.0678 - val_accuracy: 0.9476\n",
            "Epoch 441/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9421\n",
            "Epoch 441: val_accuracy did not improve from 0.94765\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0190 - accuracy: 0.9421 - val_loss: 0.0821 - val_accuracy: 0.9404\n",
            "Epoch 442/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9394\n",
            "Epoch 442: val_accuracy did not improve from 0.94765\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0192 - accuracy: 0.9394 - val_loss: 0.0889 - val_accuracy: 0.9414\n",
            "Epoch 443/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.9401\n",
            "Epoch 443: val_accuracy did not improve from 0.94765\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0192 - accuracy: 0.9401 - val_loss: 0.0880 - val_accuracy: 0.9465\n",
            "Epoch 444/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9386\n",
            "Epoch 444: val_accuracy did not improve from 0.94765\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0198 - accuracy: 0.9386 - val_loss: 0.0764 - val_accuracy: 0.9433\n",
            "Epoch 445/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9375\n",
            "Epoch 445: val_accuracy did not improve from 0.94765\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0202 - accuracy: 0.9375 - val_loss: 0.0714 - val_accuracy: 0.9342\n",
            "Epoch 446/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9381\n",
            "Epoch 446: val_accuracy did not improve from 0.94765\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0201 - accuracy: 0.9381 - val_loss: 0.1464 - val_accuracy: 0.9393\n",
            "Epoch 447/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9387\n",
            "Epoch 447: val_accuracy did not improve from 0.94765\n",
            "14/14 [==============================] - 4s 314ms/step - loss: 0.0196 - accuracy: 0.9387 - val_loss: 0.0682 - val_accuracy: 0.9453\n",
            "Epoch 448/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9438\n",
            "Epoch 448: val_accuracy did not improve from 0.94765\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0178 - accuracy: 0.9438 - val_loss: 0.0778 - val_accuracy: 0.9454\n",
            "Epoch 449/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9431\n",
            "Epoch 449: val_accuracy did not improve from 0.94765\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0183 - accuracy: 0.9431 - val_loss: 0.0741 - val_accuracy: 0.9354\n",
            "Epoch 450/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9392\n",
            "Epoch 450: val_accuracy did not improve from 0.94765\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0201 - accuracy: 0.9392 - val_loss: 0.0754 - val_accuracy: 0.9465\n",
            "Epoch 451/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9362\n",
            "Epoch 451: val_accuracy did not improve from 0.94765\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0207 - accuracy: 0.9362 - val_loss: 0.0724 - val_accuracy: 0.9450\n",
            "Epoch 452/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9422\n",
            "Epoch 452: val_accuracy did not improve from 0.94765\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0186 - accuracy: 0.9422 - val_loss: 0.0713 - val_accuracy: 0.9424\n",
            "Epoch 453/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9424\n",
            "Epoch 453: val_accuracy did not improve from 0.94765\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0187 - accuracy: 0.9424 - val_loss: 0.0790 - val_accuracy: 0.9451\n",
            "Epoch 454/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9431\n",
            "Epoch 454: val_accuracy did not improve from 0.94765\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0183 - accuracy: 0.9431 - val_loss: 0.0752 - val_accuracy: 0.9408\n",
            "Epoch 455/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9443\n",
            "Epoch 455: val_accuracy did not improve from 0.94765\n",
            "14/14 [==============================] - 4s 319ms/step - loss: 0.0177 - accuracy: 0.9443 - val_loss: 0.0888 - val_accuracy: 0.9460\n",
            "Epoch 456/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9461\n",
            "Epoch 456: val_accuracy did not improve from 0.94765\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0176 - accuracy: 0.9461 - val_loss: 0.0621 - val_accuracy: 0.9455\n",
            "Epoch 457/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9454\n",
            "Epoch 457: val_accuracy did not improve from 0.94765\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0171 - accuracy: 0.9454 - val_loss: 0.0876 - val_accuracy: 0.9419\n",
            "Epoch 458/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9477\n",
            "Epoch 458: val_accuracy improved from 0.94765 to 0.94769, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 344ms/step - loss: 0.0169 - accuracy: 0.9477 - val_loss: 0.0894 - val_accuracy: 0.9477\n",
            "Epoch 459/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9483\n",
            "Epoch 459: val_accuracy improved from 0.94769 to 0.94781, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 334ms/step - loss: 0.0168 - accuracy: 0.9483 - val_loss: 0.0955 - val_accuracy: 0.9478\n",
            "Epoch 460/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9464\n",
            "Epoch 460: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0178 - accuracy: 0.9464 - val_loss: 0.1059 - val_accuracy: 0.9466\n",
            "Epoch 461/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9438\n",
            "Epoch 461: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 319ms/step - loss: 0.0180 - accuracy: 0.9438 - val_loss: 0.0821 - val_accuracy: 0.9442\n",
            "Epoch 462/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9453\n",
            "Epoch 462: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0176 - accuracy: 0.9453 - val_loss: 0.0799 - val_accuracy: 0.9410\n",
            "Epoch 463/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9446\n",
            "Epoch 463: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0177 - accuracy: 0.9446 - val_loss: 0.0755 - val_accuracy: 0.9448\n",
            "Epoch 464/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9475\n",
            "Epoch 464: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0170 - accuracy: 0.9475 - val_loss: 0.0845 - val_accuracy: 0.9437\n",
            "Epoch 465/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9450\n",
            "Epoch 465: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0173 - accuracy: 0.9450 - val_loss: 0.0825 - val_accuracy: 0.9474\n",
            "Epoch 466/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9481\n",
            "Epoch 466: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0169 - accuracy: 0.9481 - val_loss: 0.0747 - val_accuracy: 0.9474\n",
            "Epoch 467/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9413\n",
            "Epoch 467: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0186 - accuracy: 0.9413 - val_loss: 0.0761 - val_accuracy: 0.9427\n",
            "Epoch 468/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9473\n",
            "Epoch 468: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0171 - accuracy: 0.9473 - val_loss: 0.0810 - val_accuracy: 0.9469\n",
            "Epoch 469/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9465\n",
            "Epoch 469: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 319ms/step - loss: 0.0175 - accuracy: 0.9465 - val_loss: 0.0888 - val_accuracy: 0.9430\n",
            "Epoch 470/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9292\n",
            "Epoch 470: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0249 - accuracy: 0.9292 - val_loss: 0.0805 - val_accuracy: 0.9358\n",
            "Epoch 471/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9337\n",
            "Epoch 471: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0218 - accuracy: 0.9337 - val_loss: 0.0651 - val_accuracy: 0.9431\n",
            "Epoch 472/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9398\n",
            "Epoch 472: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0196 - accuracy: 0.9398 - val_loss: 0.0894 - val_accuracy: 0.9395\n",
            "Epoch 473/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9395\n",
            "Epoch 473: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0195 - accuracy: 0.9395 - val_loss: 0.0796 - val_accuracy: 0.9407\n",
            "Epoch 474/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9413\n",
            "Epoch 474: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0188 - accuracy: 0.9413 - val_loss: 0.0996 - val_accuracy: 0.9430\n",
            "Epoch 475/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9428\n",
            "Epoch 475: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0185 - accuracy: 0.9428 - val_loss: 0.0794 - val_accuracy: 0.9384\n",
            "Epoch 476/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9446\n",
            "Epoch 476: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0171 - accuracy: 0.9446 - val_loss: 0.0723 - val_accuracy: 0.9450\n",
            "Epoch 477/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9470\n",
            "Epoch 477: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0169 - accuracy: 0.9470 - val_loss: 0.0958 - val_accuracy: 0.9424\n",
            "Epoch 478/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9443\n",
            "Epoch 478: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 320ms/step - loss: 0.0186 - accuracy: 0.9443 - val_loss: 0.0806 - val_accuracy: 0.9415\n",
            "Epoch 479/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9447\n",
            "Epoch 479: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0177 - accuracy: 0.9447 - val_loss: 0.0853 - val_accuracy: 0.9449\n",
            "Epoch 480/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9440\n",
            "Epoch 480: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0187 - accuracy: 0.9440 - val_loss: 0.0643 - val_accuracy: 0.9397\n",
            "Epoch 481/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9252\n",
            "Epoch 481: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0274 - accuracy: 0.9252 - val_loss: 0.0931 - val_accuracy: 0.9319\n",
            "Epoch 482/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9156\n",
            "Epoch 482: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0279 - accuracy: 0.9156 - val_loss: 0.0917 - val_accuracy: 0.9267\n",
            "Epoch 483/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9288\n",
            "Epoch 483: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 320ms/step - loss: 0.0230 - accuracy: 0.9288 - val_loss: 0.1104 - val_accuracy: 0.9361\n",
            "Epoch 484/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9392\n",
            "Epoch 484: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 320ms/step - loss: 0.0194 - accuracy: 0.9392 - val_loss: 0.0965 - val_accuracy: 0.9426\n",
            "Epoch 485/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9452\n",
            "Epoch 485: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0176 - accuracy: 0.9452 - val_loss: 0.0797 - val_accuracy: 0.9462\n",
            "Epoch 486/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9472\n",
            "Epoch 486: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0169 - accuracy: 0.9472 - val_loss: 0.0819 - val_accuracy: 0.9472\n",
            "Epoch 487/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9482\n",
            "Epoch 487: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0167 - accuracy: 0.9482 - val_loss: 0.0869 - val_accuracy: 0.9440\n",
            "Epoch 488/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9452\n",
            "Epoch 488: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0179 - accuracy: 0.9452 - val_loss: 0.0854 - val_accuracy: 0.9467\n",
            "Epoch 489/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9479\n",
            "Epoch 489: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0168 - accuracy: 0.9479 - val_loss: 0.0735 - val_accuracy: 0.9441\n",
            "Epoch 490/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9504\n",
            "Epoch 490: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 315ms/step - loss: 0.0160 - accuracy: 0.9504 - val_loss: 0.0812 - val_accuracy: 0.9448\n",
            "Epoch 491/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9465\n",
            "Epoch 491: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0178 - accuracy: 0.9465 - val_loss: 0.0712 - val_accuracy: 0.9432\n",
            "Epoch 492/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9477\n",
            "Epoch 492: val_accuracy did not improve from 0.94781\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0171 - accuracy: 0.9477 - val_loss: 0.0981 - val_accuracy: 0.9432\n",
            "Epoch 493/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9499\n",
            "Epoch 493: val_accuracy improved from 0.94781 to 0.94794, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 352ms/step - loss: 0.0162 - accuracy: 0.9499 - val_loss: 0.0724 - val_accuracy: 0.9479\n",
            "Epoch 494/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9473\n",
            "Epoch 494: val_accuracy did not improve from 0.94794\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0176 - accuracy: 0.9473 - val_loss: 0.0836 - val_accuracy: 0.9419\n",
            "Epoch 495/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9450\n",
            "Epoch 495: val_accuracy did not improve from 0.94794\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0176 - accuracy: 0.9450 - val_loss: 0.0740 - val_accuracy: 0.9424\n",
            "Epoch 496/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9478\n",
            "Epoch 496: val_accuracy did not improve from 0.94794\n",
            "14/14 [==============================] - 4s 319ms/step - loss: 0.0166 - accuracy: 0.9478 - val_loss: 0.0765 - val_accuracy: 0.9461\n",
            "Epoch 497/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9513\n",
            "Epoch 497: val_accuracy did not improve from 0.94794\n",
            "14/14 [==============================] - 4s 317ms/step - loss: 0.0154 - accuracy: 0.9513 - val_loss: 0.0777 - val_accuracy: 0.9453\n",
            "Epoch 498/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9529\n",
            "Epoch 498: val_accuracy did not improve from 0.94794\n",
            "14/14 [==============================] - 4s 318ms/step - loss: 0.0153 - accuracy: 0.9529 - val_loss: 0.0843 - val_accuracy: 0.9476\n",
            "Epoch 499/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9457\n",
            "Epoch 499: val_accuracy did not improve from 0.94794\n",
            "14/14 [==============================] - 4s 316ms/step - loss: 0.0171 - accuracy: 0.9457 - val_loss: 0.0747 - val_accuracy: 0.9463\n",
            "Epoch 500/500\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9511\n",
            "Epoch 500: val_accuracy improved from 0.94794 to 0.94810, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\n",
            "14/14 [==============================] - 5s 352ms/step - loss: 0.0160 - accuracy: 0.9511 - val_loss: 0.0782 - val_accuracy: 0.9481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.evaluate([X_test,X_test_f],y_test1)"
      ],
      "metadata": {
        "id": "9oZOnVixSQPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d065bb2-f074-4dab-850c-e8114d08a3a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 49ms/step - loss: 0.0782 - accuracy: 0.9481\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07820666581392288, 0.9481021761894226]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def display_learning_curves(history):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    ax1.plot(history.history[\"loss\"])\n",
        "    ax1.plot(history.history[\"val_loss\"])\n",
        "    ax1.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "\n",
        "    ax2.plot(history.history[\"accuracy\"])\n",
        "    ax2.plot(history.history[\"val_accuracy\"])\n",
        "    ax2.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
        "    ax2.set_xlabel(\"Epochs\")\n",
        "    ax2.set_ylabel(\"Accuracy\")\n",
        "    plt.show()\n",
        "\n",
        "display_learning_curves(history)"
      ],
      "metadata": {
        "id": "k7oqU_taStd_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "2ef2d6dd-4958-4506-f041-5365c3d5f1cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "temp=tf.keras.models.load_model(\"./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_multiobject_exp2_exp5_v2.h5\",\n",
        "                                custom_objects={'TransformerEncoder': keras_nlp.layers.TransformerEncoder(intermediate_dim=64, num_heads=4,dropout=0.1),\n",
        "                                                'out_adj_mat':out_adj_mat()})"
      ],
      "metadata": {
        "id": "-gaSl__OS0Yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp.evaluate([X_test,X_test_f], y_test1, 1)"
      ],
      "metadata": {
        "id": "51TR2BIrUT-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebb5a5d0-f1ff-4de7-f142-747f875887e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 9s 35ms/step - loss: 0.0782 - accuracy: 0.9481\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07820666581392288, 0.9481021761894226]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "true=[]\n",
        "pred=[]\n",
        "for i in tqdm(range(len(y_test1))):\n",
        "  result=temp([X_test[i:i+1],X_test_f[i:i+1]])\n",
        "  true=true+list(y_test1[i,:,0][result._keras_mask[0,:]])\n",
        "  temp_pred=np.array(result[result._keras_mask][:,0])\n",
        "  temp_pred[temp_pred>=0]=1\n",
        "  temp_pred[temp_pred<0]=0\n",
        "  pred=pred+list(temp_pred)"
      ],
      "metadata": {
        "id": "ZNBIwk1vZArd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "621085b9eda2407aad15039c01c35a92",
            "a1cd55fabff9409aad30ae6d6b2bab36",
            "02327f02993e4ca6a4aae9e1bd16a417",
            "eab0519b3397484ca0f00a053f13b052",
            "08c38625eddc4a96abc47bb8ffbf2ce6",
            "0ac360c8889e4d4caa0af5c162773be8",
            "492bbe5a04c2442d8630d8d3fb9a5ae2",
            "b2dc7aa3d74348dfba7e7347e9ce08dc",
            "c220fa6d116b4feab44d733b9d11631b",
            "f84a243561144540861d17a7a1288de0",
            "1ccdbffc83064b3d8133dda7da783bb5"
          ]
        },
        "outputId": "f0f45a4c-60a7-4485-f3ed-71cf22db70a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "621085b9eda2407aad15039c01c35a92"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report,confusion_matrix"
      ],
      "metadata": {
        "id": "m3sALEoJbqYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(true,pred)"
      ],
      "metadata": {
        "id": "tM1r9eFUbybo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dadd3d5a-743e-45da-8fe9-642d95ab6f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[20134,  1385],\n",
              "       [   47,  2751]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(true,pred)"
      ],
      "metadata": {
        "id": "W1Hh9Js3bz6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13940933-b2d3-472e-c23d-a48bfa68e106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.941111156803882"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(true,pred)"
      ],
      "metadata": {
        "id": "tQAefs8Nb1kF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75140cab-1a02-4c08-c369-49db30e1ff00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7934813960196135"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true,pred))"
      ],
      "metadata": {
        "id": "7uL1RGcKb3No",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5614c22d-a1f2-4485-e97f-e7d6af7950fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97     21519\n",
            "           1       0.67      0.98      0.79      2798\n",
            "\n",
            "    accuracy                           0.94     24317\n",
            "   macro avg       0.83      0.96      0.88     24317\n",
            "weighted avg       0.96      0.94      0.95     24317\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##inter structure FP vs intra structure FP rate"
      ],
      "metadata": {
        "id": "7N3_bPkZ_DkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_obj_ind(arr):\n",
        "  temp_adj_mat=copy.copy(arr)\n",
        "  index=np.where(temp_adj_mat[0,:]==1e6)[0]\n",
        "  if(len(index)==0):\n",
        "    index=temp_adj_mat.shape[0]\n",
        "  else:\n",
        "    index=index[0]\n",
        "  temp_adj_mat1=temp_adj_mat[:index,:index]\n",
        "  n1=np.where(np.sum(temp_adj_mat1,axis=0)==0)[0][1]\n",
        "  temp_adj_mat[:n1,n1:index]=-1\n",
        "  temp_adj_mat[n1:index,:n1]=-1\n",
        "  return(temp_adj_mat)"
      ],
      "metadata": {
        "id": "uz1azjtrAoQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj_ind_test=[]\n",
        "for i in range(y_test.shape[0]):\n",
        "  obj_ind_test.append(create_obj_ind(y_test[i]))\n",
        "obj_ind_test=np.stack(obj_ind_test)"
      ],
      "metadata": {
        "id": "eAF__giy-QC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj_ind_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc4D2Q9bAEVO",
        "outputId": "03a27baa-5db1-486b-b7f0-137930d60634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(125, 30, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obj_ind_test1=obj_ind_test.reshape(obj_ind_test.shape[0],-1)\n",
        "obj_ind_test1=np.expand_dims(obj_ind_test1,-1)\n",
        "obj_ind_test1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw5iVP9RDExi",
        "outputId": "b6dca275-1505-462e-ff44-7955396ca19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(125, 900, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "obj_ind_test_list=[]\n",
        "for i in tqdm(range(len(y_test1))):\n",
        "  result=temp([X_test[i:i+1],X_test_f[i:i+1]])\n",
        "  obj_ind_test_list=obj_ind_test_list+list(obj_ind_test1[i,:,0][result._keras_mask[0,:]])\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "140e933e97a248f6bcb414f04357154a",
            "a018283c86024f2a990e296a8896e50f",
            "4f699bf975c544f095dfaacb1e941d62",
            "15f0490020df4c51ae29319eeeca92a9",
            "256403fffd104fee81f01f25accfc619",
            "fc0bf4d5454444cd892f86fee7cbc28e",
            "4863db38a17e4fec8d0be69d5e65d42b",
            "5fa6d0b7192446c7a67db1753fc4b2c2",
            "2babad089d484e58b58c6abd07589fcf",
            "394d5c417f6044c5b9137780a0ff757d",
            "459052057df34515b83b66043d428e3f"
          ]
        },
        "id": "0ORjlU1TAEYl",
        "outputId": "09a1a3cf-dd85-4d12-bf57-75ad5a538a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "140e933e97a248f6bcb414f04357154a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(true))\n",
        "print(len(obj_ind_test_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0W3H7sY0WIo",
        "outputId": "b8606267-0748-4fc5-9c55-5246b5fd9841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24317\n",
            "24317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=pd.DataFrame({'true':true,'pred':np.array(pred).astype(int),'obj_ind':obj_ind_test_list})\n",
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "RrWuZrZK7ccV",
        "outputId": "afd09ac4-e14a-48e6-918f-00b74000b167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       true  pred  obj_ind\n",
              "0         1     1        1\n",
              "1         0     0        0\n",
              "2         0     0        0\n",
              "3         0     0        0\n",
              "4         0     0        0\n",
              "...     ...   ...      ...\n",
              "24312     0     1        0\n",
              "24313     0     1        0\n",
              "24314     0     1        0\n",
              "24315     0     1        0\n",
              "24316     0     1        0\n",
              "\n",
              "[24317 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8abc1604-5e90-4967-9dc0-56009d536986\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>true</th>\n",
              "      <th>pred</th>\n",
              "      <th>obj_ind</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24312</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24313</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24314</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24315</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24316</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24317 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8abc1604-5e90-4967-9dc0-56009d536986')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8abc1604-5e90-4967-9dc0-56009d536986 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8abc1604-5e90-4967-9dc0-56009d536986');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction.loc[(prediction['true']==0) & (prediction['pred']==1) & (prediction['obj_ind']==-1)]"
      ],
      "metadata": {
        "id": "tHV2ZzeY_D88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eca564bd-3e61-4a96-8197-8624159380df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       true  pred  obj_ind\n",
              "621       0     1       -1\n",
              "1097      0     1       -1\n",
              "1106      0     1       -1\n",
              "1211      0     1       -1\n",
              "1253      0     1       -1\n",
              "1254      0     1       -1\n",
              "1436      0     1       -1\n",
              "1744      0     1       -1\n",
              "1747      0     1       -1\n",
              "5396      0     1       -1\n",
              "6418      0     1       -1\n",
              "7462      0     1       -1\n",
              "7463      0     1       -1\n",
              "7903      0     1       -1\n",
              "8907      0     1       -1\n",
              "8908      0     1       -1\n",
              "9649      0     1       -1\n",
              "9650      0     1       -1\n",
              "11668     0     1       -1\n",
              "12444     0     1       -1\n",
              "12445     0     1       -1\n",
              "14306     0     1       -1\n",
              "14307     0     1       -1\n",
              "15934     0     1       -1\n",
              "21473     0     1       -1\n",
              "21628     0     1       -1\n",
              "22147     0     1       -1\n",
              "22172     0     1       -1\n",
              "22183     0     1       -1\n",
              "23237     0     1       -1\n",
              "23494     0     1       -1\n",
              "23496     0     1       -1\n",
              "23497     0     1       -1\n",
              "23890     0     1       -1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a531ce2-d8d1-43eb-a211-8493ddc69654\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>true</th>\n",
              "      <th>pred</th>\n",
              "      <th>obj_ind</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>621</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1097</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1106</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1211</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1253</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1436</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1744</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1747</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5396</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6418</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7462</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7463</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7903</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8907</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8908</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9649</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9650</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11668</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12444</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12445</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14306</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14307</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15934</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21473</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21628</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22147</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22172</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22183</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23237</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23494</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23496</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23497</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23890</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a531ce2-d8d1-43eb-a211-8493ddc69654')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5a531ce2-d8d1-43eb-a211-8493ddc69654 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5a531ce2-d8d1-43eb-a211-8493ddc69654');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inter, intra structure positive rate\n",
        "inter_structure_FP=prediction.loc[(prediction['true']==0) & (prediction['pred']==1) & (prediction['obj_ind']==-1)]\n",
        "intra_structure_FP=prediction.loc[(prediction['true']==0) & (prediction['pred']==1) & (prediction['obj_ind']!=-1)]\n",
        "FP=prediction.loc[(prediction['true']==0) & (prediction['pred']==1)]"
      ],
      "metadata": {
        "id": "rwJsQg_LD73W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inter_structure_FP.shape[0]/FP.shape[0]*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNbSYeqOD753",
        "outputId": "9ab59324-7776-4e83-b435-a51de4cef636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.454873646209386"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intra_structure_FP.shape[0]/FP.shape[0]*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BbKpK2MD78r",
        "outputId": "c8f03080-4dfc-4989-a552-85223103a53b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97.54512635379061"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NOnHZ736D7_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SycJQ_fPD8DL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}