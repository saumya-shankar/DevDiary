{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JYsWwiwnPzi",
    "outputId": "58d4ffce-26b1-48d0-f296-4f62e354c5eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug 15 06:48:36 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdNIB899nhlq",
    "outputId": "0f65697f-052b-4924-d704-78b4e42ca34d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#mounting google drive on colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfSazzTdnmaM"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXN_d9Evntel"
   },
   "outputs": [],
   "source": [
    "X_train=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_X_trainv7_exp2.npy\")\n",
    "y_train=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_y_trainv7_exp2.npy\").astype(int)\n",
    "\n",
    "X_test=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_X_testv7_exp2.npy\")\n",
    "y_test=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_y_testv7_exp2.npy\").astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NVkzHpArmQFD",
    "outputId": "ca8af14b-214f-4014-ad76-193c8081b669"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/scipy/signal/spectral.py:1966: UserWarning: nperseg = 256 is greater than input length  = 50, using nperseg = 50\n",
      "  .format(nperseg, input_length))\n"
     ]
    }
   ],
   "source": [
    "def calc_freq_signal(arr):\n",
    "    freqs, psd = signal.welch(arr, fs=10)\n",
    "    return psd\n",
    "\n",
    "X_train_f=np.apply_along_axis(calc_freq_signal, 1, X_train)\n",
    "X_test_f=np.apply_along_axis(calc_freq_signal, 1, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6MFvsoGCeuLr"
   },
   "outputs": [],
   "source": [
    "X_train_1d=np.gradient(X_train,axis=1)\n",
    "X_test_1d=np.gradient(X_test,axis=1)\n",
    "X_train=np.dstack([X_train,X_train_1d])\n",
    "X_test=np.dstack([X_test,X_test_1d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X86rj9C3fCRa",
    "outputId": "8f8c8eb4-2bef-4501-e7dd-b9a3c30d9dd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18426, 50, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yR5fAIqKH8vV"
   },
   "outputs": [],
   "source": [
    "def custom_scaler(X, range=(0, 1),min=None,max=None):\n",
    "    mi, ma = range\n",
    "    if(min==None):\n",
    "      min=X.min()\n",
    "      max=X.max()\n",
    "      print(\"\\nTrain_Scaling:- min=\",min,\" max=\",max)\n",
    "    X_std = (X - min) / (max - min)\n",
    "    X_scaled = X_std * (ma - mi) + mi\n",
    "    return min,max,X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JceKGdin-e6",
    "outputId": "f234f143-b816-409c-a479-651187713dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train_Scaling:- min= -22.01300285743306  max= 25.31370849898476\n",
      "\n",
      "Train_Scaling:- min= -23.9483772423873  max= 22.589302675577027\n",
      "\n",
      "Train_Scaling:- min= -12.057926093194933  max= 12.104502946593886\n",
      "\n",
      "Train_Scaling:- min= -17.405683792063165  max= 17.232860997377067\n",
      "Frequency signals scaling:-------------\n",
      "\n",
      "Train_Scaling:- min= 0.0  max= 294.4161865673738\n",
      "\n",
      "Train_Scaling:- min= 0.0  max= 587.9412907815806\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "#X_train contains 8 signals x1,x2,y1,y2,x1d,2d,y1d,y2d\n",
    "X_train_scaled=copy.copy(X_train)\n",
    "X_test_scaled=copy.copy(X_test)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,0:2]=custom_scaler(X_train_scaled[:,:,0:2],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,0:2]=custom_scaler(X_test_scaled[:,:,0:2],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,2:4]=custom_scaler(X_train_scaled[:,:,2:4],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,2:4]=custom_scaler(X_test_scaled[:,:,2:4],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,4:6]=custom_scaler(X_train_scaled[:,:,4:6],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,4:6]=custom_scaler(X_test_scaled[:,:,4:6],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,6:8]=custom_scaler(X_train_scaled[:,:,6:8],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,6:8]=custom_scaler(X_test_scaled[:,:,6:8],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "\n",
    "print(\"Frequency signals scaling:-------------\")\n",
    "#X_train contains 8 signals x1f,x2f,y1f,y2f\n",
    "X_train_scaled_f=copy.copy(X_train_f)\n",
    "X_test_scaled_f=copy.copy(X_test_f)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled_f[:,:,0:2]=custom_scaler(X_train_scaled_f[:,:,0:2],range=(0,1))\n",
    "_,_,X_test_scaled_f[:,:,0:2]=custom_scaler(X_test_scaled_f[:,:,0:2],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled_f[:,:,2:4]=custom_scaler(X_train_scaled_f[:,:,2:4],range=(0,1))\n",
    "_,_,X_test_scaled_f[:,:,2:4]=custom_scaler(X_test_scaled_f[:,:,2:4],range=(0,1),min=min_temp,max=max_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L7JWtkWdfSCb",
    "outputId": "f4b95001-ebab-4b91-c501-99ed061d0827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18426, 50, 8)\n",
      "(18426, 26, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(X_train_scaled_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8CMIO_ToBr9"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Part 2 - Building the RNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "\n",
    "input_1 = Input((X_train_scaled.shape[1], X_train_scaled.shape[2]))\n",
    "input_2 = Input((X_train_scaled_f.shape[1], X_train_scaled_f.shape[2]))\n",
    "\n",
    "x1=LSTM(units = 100, return_sequences = True)(input_1)\n",
    "x1=LSTM(units = 50)(x1)\n",
    "\n",
    "x2=LSTM(units = 100, return_sequences = True)(input_2)\n",
    "x2=LSTM(units = 50)(x2)\n",
    "\n",
    "x = layers.concatenate([x1, x2])\n",
    "\n",
    "output_layer = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "classifier=keras.Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "\n",
    "####################\n",
    "\"\"\"\n",
    "# Initialising the RNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "classifier.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train_scaled.shape[1], X_train_scaled.shape[2])))\n",
    "#regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "classifier.add(LSTM(units = 50))\n",
    "#regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1,activation='sigmoid'))\n",
    "\"\"\"\n",
    "\n",
    "# Compiling the RNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uf-jNI2KZJUu"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_v2.h5\",\n",
    "                             monitor=\"val_accuracy\",\n",
    "                             mode=\"max\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', # value being monitored for improvement\n",
    "                          min_delta = 0, #Abs value and is the min change required before we stop\n",
    "                          patience = 20, #Number of epochs we wait before stopping \n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True) #keeps the best weigths once stopped\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop,checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcUvZBOYoFNC",
    "outputId": "c9239b89-5ba2-4024-d8f1-c1dd2f3e7a30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.5740 - accuracy: 0.6990\n",
      "Epoch 1: val_accuracy improved from -inf to 0.78358, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_v2.h5\n",
      "288/288 [==============================] - 16s 19ms/step - loss: 0.5740 - accuracy: 0.6990 - val_loss: 0.4244 - val_accuracy: 0.7836\n",
      "Epoch 2/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.5498 - accuracy: 0.7008\n",
      "Epoch 2: val_accuracy did not improve from 0.78358\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.5495 - accuracy: 0.7009 - val_loss: 0.4366 - val_accuracy: 0.7589\n",
      "Epoch 3/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.5464 - accuracy: 0.7052\n",
      "Epoch 3: val_accuracy did not improve from 0.78358\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.5465 - accuracy: 0.7044 - val_loss: 0.4723 - val_accuracy: 0.7564\n",
      "Epoch 4/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.5395 - accuracy: 0.7056\n",
      "Epoch 4: val_accuracy did not improve from 0.78358\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.5395 - accuracy: 0.7056 - val_loss: 0.4530 - val_accuracy: 0.7830\n",
      "Epoch 5/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.5339 - accuracy: 0.7094\n",
      "Epoch 5: val_accuracy did not improve from 0.78358\n",
      "288/288 [==============================] - 8s 27ms/step - loss: 0.5338 - accuracy: 0.7097 - val_loss: 0.4271 - val_accuracy: 0.7647\n",
      "Epoch 6/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.5289 - accuracy: 0.7106\n",
      "Epoch 6: val_accuracy improved from 0.78358 to 0.79069, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_v2.h5\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.5289 - accuracy: 0.7106 - val_loss: 0.4053 - val_accuracy: 0.7907\n",
      "Epoch 7/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.4972 - accuracy: 0.7247\n",
      "Epoch 7: val_accuracy improved from 0.79069 to 0.81681, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_v2.h5\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.4969 - accuracy: 0.7246 - val_loss: 0.3583 - val_accuracy: 0.8168\n",
      "Epoch 8/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.4472 - accuracy: 0.7616\n",
      "Epoch 8: val_accuracy did not improve from 0.81681\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.4466 - accuracy: 0.7620 - val_loss: 0.4231 - val_accuracy: 0.7781\n",
      "Epoch 9/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.4310 - accuracy: 0.7796\n",
      "Epoch 9: val_accuracy improved from 0.81681 to 0.83547, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_v2.h5\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.4312 - accuracy: 0.7798 - val_loss: 0.3230 - val_accuracy: 0.8355\n",
      "Epoch 10/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8232\n",
      "Epoch 10: val_accuracy improved from 0.83547 to 0.84417, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_v2.h5\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3792 - accuracy: 0.8233 - val_loss: 0.3335 - val_accuracy: 0.8442\n",
      "Epoch 11/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.2939 - accuracy: 0.8708\n",
      "Epoch 11: val_accuracy did not improve from 0.84417\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2933 - accuracy: 0.8711 - val_loss: 0.4361 - val_accuracy: 0.7948\n",
      "Epoch 12/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.2684 - accuracy: 0.8818\n",
      "Epoch 12: val_accuracy improved from 0.84417 to 0.85252, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_v2.h5\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2688 - accuracy: 0.8817 - val_loss: 0.3039 - val_accuracy: 0.8525\n",
      "Epoch 13/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.2433 - accuracy: 0.8932\n",
      "Epoch 13: val_accuracy did not improve from 0.85252\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2438 - accuracy: 0.8929 - val_loss: 0.4550 - val_accuracy: 0.7783\n",
      "Epoch 14/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.2429 - accuracy: 0.8933\n",
      "Epoch 14: val_accuracy improved from 0.85252 to 0.87456, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_v2.h5\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2423 - accuracy: 0.8936 - val_loss: 0.2780 - val_accuracy: 0.8746\n",
      "Epoch 15/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.2401 - accuracy: 0.8927\n",
      "Epoch 15: val_accuracy did not improve from 0.87456\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2405 - accuracy: 0.8925 - val_loss: 0.2678 - val_accuracy: 0.8742\n",
      "Epoch 16/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.2272 - accuracy: 0.8986\n",
      "Epoch 16: val_accuracy improved from 0.87456 to 0.87829, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_v2.h5\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2273 - accuracy: 0.8985 - val_loss: 0.2427 - val_accuracy: 0.8783\n",
      "Epoch 17/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.9068\n",
      "Epoch 17: val_accuracy improved from 0.87829 to 0.88646, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_v2.h5\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2132 - accuracy: 0.9068 - val_loss: 0.2349 - val_accuracy: 0.8865\n",
      "Epoch 18/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.1978 - accuracy: 0.9132\n",
      "Epoch 18: val_accuracy did not improve from 0.88646\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1979 - accuracy: 0.9131 - val_loss: 0.2706 - val_accuracy: 0.8714\n",
      "Epoch 19/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.1979 - accuracy: 0.9129\n",
      "Epoch 19: val_accuracy improved from 0.88646 to 0.89161, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_v2.h5\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1990 - accuracy: 0.9124 - val_loss: 0.2381 - val_accuracy: 0.8916\n",
      "Epoch 20/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.1857 - accuracy: 0.9205\n",
      "Epoch 20: val_accuracy did not improve from 0.89161\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1859 - accuracy: 0.9205 - val_loss: 0.2695 - val_accuracy: 0.8785\n",
      "Epoch 21/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1928 - accuracy: 0.9165\n",
      "Epoch 21: val_accuracy did not improve from 0.89161\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1928 - accuracy: 0.9165 - val_loss: 0.2912 - val_accuracy: 0.8623\n",
      "Epoch 22/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1858 - accuracy: 0.9184\n",
      "Epoch 22: val_accuracy did not improve from 0.89161\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1858 - accuracy: 0.9184 - val_loss: 0.2696 - val_accuracy: 0.8731\n",
      "Epoch 23/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1779 - accuracy: 0.9226\n",
      "Epoch 23: val_accuracy did not improve from 0.89161\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1777 - accuracy: 0.9227 - val_loss: 0.2663 - val_accuracy: 0.8772\n",
      "Epoch 24/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.1799 - accuracy: 0.9232\n",
      "Epoch 24: val_accuracy did not improve from 0.89161\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1799 - accuracy: 0.9233 - val_loss: 0.2336 - val_accuracy: 0.8907\n",
      "Epoch 25/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.1746 - accuracy: 0.9250\n",
      "Epoch 25: val_accuracy did not improve from 0.89161\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1745 - accuracy: 0.9251 - val_loss: 0.3241 - val_accuracy: 0.8493\n",
      "Epoch 26/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.1789 - accuracy: 0.9214\n",
      "Epoch 26: val_accuracy did not improve from 0.89161\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1796 - accuracy: 0.9210 - val_loss: 0.3114 - val_accuracy: 0.8486\n",
      "Epoch 27/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.1753 - accuracy: 0.9249\n",
      "Epoch 27: val_accuracy did not improve from 0.89161\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1747 - accuracy: 0.9253 - val_loss: 0.2878 - val_accuracy: 0.8696\n",
      "Epoch 28/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.1742 - accuracy: 0.9246\n",
      "Epoch 28: val_accuracy did not improve from 0.89161\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.1743 - accuracy: 0.9245 - val_loss: 0.2517 - val_accuracy: 0.8849\n",
      "Epoch 29/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.1688 - accuracy: 0.9286\n",
      "Epoch 29: val_accuracy did not improve from 0.89161\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1696 - accuracy: 0.9285 - val_loss: 0.2816 - val_accuracy: 0.8781\n",
      "Epoch 30/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.1738 - accuracy: 0.9266\n",
      "Epoch 30: val_accuracy did not improve from 0.89161\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1734 - accuracy: 0.9267 - val_loss: 0.2542 - val_accuracy: 0.8891\n",
      "Epoch 31/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.1691 - accuracy: 0.9262\n",
      "Epoch 31: val_accuracy improved from 0.89161 to 0.89783, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_v2.h5\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1695 - accuracy: 0.9258 - val_loss: 0.2328 - val_accuracy: 0.8978\n",
      "Epoch 32/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.1668 - accuracy: 0.9277\n",
      "Epoch 32: val_accuracy improved from 0.89783 to 0.90121, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_v2.h5\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1668 - accuracy: 0.9278 - val_loss: 0.2135 - val_accuracy: 0.9012\n",
      "Epoch 33/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1607 - accuracy: 0.9318\n",
      "Epoch 33: val_accuracy did not improve from 0.90121\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1608 - accuracy: 0.9317 - val_loss: 0.2570 - val_accuracy: 0.8900\n",
      "Epoch 34/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1634 - accuracy: 0.9318\n",
      "Epoch 34: val_accuracy did not improve from 0.90121\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1630 - accuracy: 0.9320 - val_loss: 0.2730 - val_accuracy: 0.8829\n",
      "Epoch 35/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1693 - accuracy: 0.9304\n",
      "Epoch 35: val_accuracy improved from 0.90121 to 0.90299, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_v2.h5\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1691 - accuracy: 0.9305 - val_loss: 0.2170 - val_accuracy: 0.9030\n",
      "Epoch 36/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.1502 - accuracy: 0.9364\n",
      "Epoch 36: val_accuracy did not improve from 0.90299\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1503 - accuracy: 0.9362 - val_loss: 0.3196 - val_accuracy: 0.8664\n",
      "Epoch 37/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.1627 - accuracy: 0.9318\n",
      "Epoch 37: val_accuracy did not improve from 0.90299\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1630 - accuracy: 0.9318 - val_loss: 0.2267 - val_accuracy: 0.8975\n",
      "Epoch 38/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1521 - accuracy: 0.9352\n",
      "Epoch 38: val_accuracy did not improve from 0.90299\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1521 - accuracy: 0.9352 - val_loss: 0.2480 - val_accuracy: 0.8914\n",
      "Epoch 39/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.1477 - accuracy: 0.9387\n",
      "Epoch 39: val_accuracy did not improve from 0.90299\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1477 - accuracy: 0.9388 - val_loss: 0.2753 - val_accuracy: 0.8857\n",
      "Epoch 40/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.1459 - accuracy: 0.9405\n",
      "Epoch 40: val_accuracy did not improve from 0.90299\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1462 - accuracy: 0.9405 - val_loss: 0.2505 - val_accuracy: 0.8930\n",
      "Epoch 41/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.1448 - accuracy: 0.9378\n",
      "Epoch 41: val_accuracy did not improve from 0.90299\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1450 - accuracy: 0.9379 - val_loss: 0.2705 - val_accuracy: 0.8875\n",
      "Epoch 42/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.1392 - accuracy: 0.9433\n",
      "Epoch 42: val_accuracy did not improve from 0.90299\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1390 - accuracy: 0.9433 - val_loss: 0.2409 - val_accuracy: 0.8985\n",
      "Epoch 43/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.9439\n",
      "Epoch 43: val_accuracy did not improve from 0.90299\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1395 - accuracy: 0.9439 - val_loss: 0.2555 - val_accuracy: 0.8927\n",
      "Epoch 44/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.1445 - accuracy: 0.9397\n",
      "Epoch 44: val_accuracy did not improve from 0.90299\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1440 - accuracy: 0.9399 - val_loss: 0.2418 - val_accuracy: 0.8959\n",
      "Epoch 45/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.9401\n",
      "Epoch 45: val_accuracy did not improve from 0.90299\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1470 - accuracy: 0.9401 - val_loss: 0.2570 - val_accuracy: 0.8955\n",
      "Epoch 46/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1304 - accuracy: 0.9475\n",
      "Epoch 46: val_accuracy improved from 0.90299 to 0.90352, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_v2.h5\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1302 - accuracy: 0.9476 - val_loss: 0.2356 - val_accuracy: 0.9035\n",
      "Epoch 47/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.1371 - accuracy: 0.9445\n",
      "Epoch 47: val_accuracy did not improve from 0.90352\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1373 - accuracy: 0.9444 - val_loss: 0.2462 - val_accuracy: 0.9026\n",
      "Epoch 48/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1248 - accuracy: 0.9499\n",
      "Epoch 48: val_accuracy improved from 0.90352 to 0.90565, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_v2.h5\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1249 - accuracy: 0.9499 - val_loss: 0.2224 - val_accuracy: 0.9057\n",
      "Epoch 49/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1321 - accuracy: 0.9465\n",
      "Epoch 49: val_accuracy improved from 0.90565 to 0.91560, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_v2.h5\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1324 - accuracy: 0.9465 - val_loss: 0.1986 - val_accuracy: 0.9156\n",
      "Epoch 50/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.1258 - accuracy: 0.9500\n",
      "Epoch 50: val_accuracy did not improve from 0.91560\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1265 - accuracy: 0.9497 - val_loss: 0.2495 - val_accuracy: 0.8943\n",
      "Epoch 51/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1295 - accuracy: 0.9488\n",
      "Epoch 51: val_accuracy did not improve from 0.91560\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1295 - accuracy: 0.9488 - val_loss: 0.2506 - val_accuracy: 0.8964\n",
      "Epoch 52/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1231 - accuracy: 0.9508\n",
      "Epoch 52: val_accuracy did not improve from 0.91560\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1233 - accuracy: 0.9508 - val_loss: 0.2263 - val_accuracy: 0.9142\n",
      "Epoch 53/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.1373 - accuracy: 0.9443\n",
      "Epoch 53: val_accuracy did not improve from 0.91560\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1371 - accuracy: 0.9443 - val_loss: 0.3167 - val_accuracy: 0.8662\n",
      "Epoch 54/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1277 - accuracy: 0.9479\n",
      "Epoch 54: val_accuracy did not improve from 0.91560\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1276 - accuracy: 0.9480 - val_loss: 0.2206 - val_accuracy: 0.9092\n",
      "Epoch 55/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1181 - accuracy: 0.9532\n",
      "Epoch 55: val_accuracy did not improve from 0.91560\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1186 - accuracy: 0.9529 - val_loss: 0.2415 - val_accuracy: 0.9037\n",
      "Epoch 56/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.9480\n",
      "Epoch 56: val_accuracy did not improve from 0.91560\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1294 - accuracy: 0.9480 - val_loss: 0.2150 - val_accuracy: 0.9090\n",
      "Epoch 57/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1300 - accuracy: 0.9483\n",
      "Epoch 57: val_accuracy did not improve from 0.91560\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1298 - accuracy: 0.9484 - val_loss: 0.2546 - val_accuracy: 0.8957\n",
      "Epoch 58/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1168 - accuracy: 0.9531\n",
      "Epoch 58: val_accuracy did not improve from 0.91560\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1168 - accuracy: 0.9531 - val_loss: 0.2482 - val_accuracy: 0.9037\n",
      "Epoch 59/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.1161 - accuracy: 0.9530\n",
      "Epoch 59: val_accuracy did not improve from 0.91560\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1169 - accuracy: 0.9525 - val_loss: 0.2135 - val_accuracy: 0.9149\n",
      "Epoch 60/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1122 - accuracy: 0.9551\n",
      "Epoch 60: val_accuracy did not improve from 0.91560\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1128 - accuracy: 0.9548 - val_loss: 0.3213 - val_accuracy: 0.8829\n",
      "Epoch 61/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.9556\n",
      "Epoch 61: val_accuracy did not improve from 0.91560\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1124 - accuracy: 0.9556 - val_loss: 0.2321 - val_accuracy: 0.9112\n",
      "Epoch 62/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1077 - accuracy: 0.9582\n",
      "Epoch 62: val_accuracy did not improve from 0.91560\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1077 - accuracy: 0.9582 - val_loss: 0.2451 - val_accuracy: 0.9083\n",
      "Epoch 63/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1150 - accuracy: 0.9554\n",
      "Epoch 63: val_accuracy did not improve from 0.91560\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1152 - accuracy: 0.9552 - val_loss: 0.2353 - val_accuracy: 0.9088\n",
      "Epoch 64/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.1096 - accuracy: 0.9575\n",
      "Epoch 64: val_accuracy did not improve from 0.91560\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1095 - accuracy: 0.9576 - val_loss: 0.2400 - val_accuracy: 0.9092\n",
      "Epoch 65/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1014 - accuracy: 0.9625\n",
      "Epoch 65: val_accuracy did not improve from 0.91560\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1017 - accuracy: 0.9625 - val_loss: 0.2510 - val_accuracy: 0.9055\n",
      "Epoch 66/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9630\n",
      "Epoch 66: val_accuracy did not improve from 0.91560\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0953 - accuracy: 0.9630 - val_loss: 0.2789 - val_accuracy: 0.9035\n",
      "Epoch 67/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1026 - accuracy: 0.9605\n",
      "Epoch 67: val_accuracy improved from 0.91560 to 0.92306, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_v2.h5\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1023 - accuracy: 0.9607 - val_loss: 0.2150 - val_accuracy: 0.9231\n",
      "Epoch 68/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.0979 - accuracy: 0.9624\n",
      "Epoch 68: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0978 - accuracy: 0.9623 - val_loss: 0.2520 - val_accuracy: 0.9065\n",
      "Epoch 69/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.1084 - accuracy: 0.9582\n",
      "Epoch 69: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1090 - accuracy: 0.9581 - val_loss: 0.2567 - val_accuracy: 0.9088\n",
      "Epoch 70/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.0913 - accuracy: 0.9653\n",
      "Epoch 70: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0911 - accuracy: 0.9653 - val_loss: 0.3467 - val_accuracy: 0.8810\n",
      "Epoch 71/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.9602\n",
      "Epoch 71: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1036 - accuracy: 0.9602 - val_loss: 0.2258 - val_accuracy: 0.9154\n",
      "Epoch 72/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.0932 - accuracy: 0.9639\n",
      "Epoch 72: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0929 - accuracy: 0.9640 - val_loss: 0.2826 - val_accuracy: 0.9049\n",
      "Epoch 73/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9639\n",
      "Epoch 73: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0930 - accuracy: 0.9641 - val_loss: 0.2661 - val_accuracy: 0.9097\n",
      "Epoch 74/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.0865 - accuracy: 0.9668\n",
      "Epoch 74: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0865 - accuracy: 0.9668 - val_loss: 0.4497 - val_accuracy: 0.8643\n",
      "Epoch 75/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.0871 - accuracy: 0.9676\n",
      "Epoch 75: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0871 - accuracy: 0.9677 - val_loss: 0.2778 - val_accuracy: 0.9065\n",
      "Epoch 76/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.0837 - accuracy: 0.9687\n",
      "Epoch 76: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0839 - accuracy: 0.9686 - val_loss: 0.2204 - val_accuracy: 0.9170\n",
      "Epoch 77/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.0891 - accuracy: 0.9654\n",
      "Epoch 77: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0888 - accuracy: 0.9656 - val_loss: 0.2418 - val_accuracy: 0.9149\n",
      "Epoch 78/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.0908 - accuracy: 0.9658\n",
      "Epoch 78: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0908 - accuracy: 0.9658 - val_loss: 0.2341 - val_accuracy: 0.9209\n",
      "Epoch 79/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.0942 - accuracy: 0.9633\n",
      "Epoch 79: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0941 - accuracy: 0.9633 - val_loss: 0.2502 - val_accuracy: 0.9101\n",
      "Epoch 80/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.0717 - accuracy: 0.9733\n",
      "Epoch 80: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0717 - accuracy: 0.9733 - val_loss: 0.2475 - val_accuracy: 0.9135\n",
      "Epoch 81/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.0788 - accuracy: 0.9706\n",
      "Epoch 81: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0790 - accuracy: 0.9706 - val_loss: 0.2472 - val_accuracy: 0.9151\n",
      "Epoch 82/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.9649\n",
      "Epoch 82: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0893 - accuracy: 0.9649 - val_loss: 0.2359 - val_accuracy: 0.9170\n",
      "Epoch 83/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.0817 - accuracy: 0.9693\n",
      "Epoch 83: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0818 - accuracy: 0.9693 - val_loss: 0.2503 - val_accuracy: 0.9014\n",
      "Epoch 84/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.0806 - accuracy: 0.9701\n",
      "Epoch 84: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0809 - accuracy: 0.9698 - val_loss: 0.2252 - val_accuracy: 0.9181\n",
      "Epoch 85/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.0859 - accuracy: 0.9680\n",
      "Epoch 85: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0865 - accuracy: 0.9678 - val_loss: 0.2561 - val_accuracy: 0.9058\n",
      "Epoch 86/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.0734 - accuracy: 0.9723\n",
      "Epoch 86: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0731 - accuracy: 0.9723 - val_loss: 0.3035 - val_accuracy: 0.9065\n",
      "Epoch 87/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.0842 - accuracy: 0.9696Restoring model weights from the end of the best epoch: 67.\n",
      "\n",
      "Epoch 87: val_accuracy did not improve from 0.92306\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0835 - accuracy: 0.9699 - val_loss: 0.2917 - val_accuracy: 0.9071\n",
      "Epoch 87: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "history=classifier.fit([X_train_scaled,X_train_scaled_f], y_train[:,0], epochs = 200, batch_size = 64,validation_data=([X_test_scaled,X_test_scaled_f],y_test[:,0]),callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7puZMrQ6rZ8B",
    "outputId": "9f936082-2e10-4c5e-ceb2-096daf942c7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 1s 6ms/step - loss: 0.2150 - accuracy: 0.9231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2149837762117386, 0.9230632781982422]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate([X_test_scaled,X_test_scaled_f],y_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "pXaIqqGvsq2-",
    "outputId": "083a7967-c064-4db1-a1ab-40cbb8db86cf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def display_learning_curves(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    ax1.plot(history.history[\"loss\"])\n",
    "    ax1.plot(history.history[\"val_loss\"])\n",
    "    ax1.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "    ax2.plot(history.history[\"accuracy\"])\n",
    "    ax2.plot(history.history[\"val_accuracy\"])\n",
    "    ax2.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "display_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzJ3rz1JZlM7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0VKJswYTc4O"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "temp=tf.keras.models.load_model(\"./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9bgdUJETn0g",
    "outputId": "f3385aee-b18f-4a61-e807-9e66ef26d9a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5628/5628 [==============================] - 30s 5ms/step - loss: 0.2150 - accuracy: 0.9231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21498256921768188, 0.9230632781982422]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.evaluate([X_test_scaled,X_test_scaled_f], y_test[:,0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbTiJwqAZhcj",
    "outputId": "07951456-1847-46ed-c042-2a59681991ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 2s 6ms/step - loss: 0.2150 - accuracy: 0.9231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2149837762117386, 0.9230632781982422]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.evaluate([X_test_scaled,X_test_scaled_f], y_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RD4YF1AuT2tn"
   },
   "outputs": [],
   "source": [
    "y_pred = temp.predict([X_test_scaled,X_test_scaled_f])\n",
    "y_pred= (y_pred>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjx-DjHUWp52",
    "outputId": "cc53cc6e-0d5b-43da-d1ce-1c1b490984ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ipevqB9rXDeW"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rSeo2ltUXffg",
    "outputId": "aafd6e57-5338-42fe-85f2-c1214f39d2ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3962,  303],\n",
       "       [ 130, 1233]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eM1TBa2IXtj2",
    "outputId": "f59f1914-bd23-4d3f-8c73-b0ae5e931d28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230632551528074"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9V2DcARYNq6",
    "outputId": "1fa9c28c-902c-470d-ef93-34de7df98d96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8506381510865816"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwAjeUnMYQ1O",
    "outputId": "aef8bbc9-3c5b-4ea9-fc48-742564a54262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      4265\n",
      "           1       0.80      0.90      0.85      1363\n",
      "\n",
      "    accuracy                           0.92      5628\n",
      "   macro avg       0.89      0.92      0.90      5628\n",
      "weighted avg       0.93      0.92      0.92      5628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test[:,0],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Ip4fhGqWRGow",
    "outputId": "8e00f35e-8d00-4fe6-931c-344fd26dfd64"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c43f2b4b-e760-4e98-a934-84e1e7bd5473\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>video_id</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5623</th>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5624</th>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5625</th>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5626</th>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5627</th>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5628 rows × 6 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c43f2b4b-e760-4e98-a934-84e1e7bd5473')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c43f2b4b-e760-4e98-a934-84e1e7bd5473 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c43f2b4b-e760-4e98-a934-84e1e7bd5473');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      y_true  video_id  n1  n2  pred  pred_proba\n",
       "0          1       250   0   1     1    0.904627\n",
       "1          0       250   0   2     0    0.001371\n",
       "2          0       250   0   3     0    0.000107\n",
       "3          0       250   0   4     0    0.000026\n",
       "4          0       250   0   5     0    0.000027\n",
       "...      ...       ...  ..  ..   ...         ...\n",
       "5623       0       374   7   9     0    0.000141\n",
       "5624       0       374   7  10     0    0.000051\n",
       "5625       0       374   8   9     0    0.000640\n",
       "5626       0       374   8  10     0    0.000125\n",
       "5627       0       374   9  10     0    0.001351\n",
       "\n",
       "[5628 rows x 6 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=pd.DataFrame(y_test)\n",
    "predictions['pred']=y_pred\n",
    "predictions['pred_proba']=temp.predict([X_test_scaled,X_test_scaled_f])\n",
    "predictions.columns=['y_true','video_id','n1','n2','pred','pred_proba']\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbK_iKJMipzb"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VSDxMwl6ieEr",
    "outputId": "e7b56921-c86d-4f9b-8764-c4163b6458e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6886349510102532e-07"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(X_test_scaled_f[0,:,0],X_test_scaled_f[0,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wAnGJQnTigwv"
   },
   "outputs": [],
   "source": [
    "mse_x=[]\n",
    "mse_y=[]\n",
    "for i in range(X_test_scaled_f.shape[0]):\n",
    "  mse_x.append(mse(X_test_scaled_f[i,:,0],X_test_scaled_f[i,:,1],squared=False))\n",
    "  mse_y.append(mse(X_test_scaled_f[i,:,2],X_test_scaled_f[i,:,3],squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "SUBr_1IZig0P",
    "outputId": "2ebe8eb1-27cd-4aaf-a0d9-3df502a81065"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-036d5e65-5091-4a7f-81a5-19f6912c975d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>video_id</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>mse_x</th>\n",
       "      <th>mse_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904627</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.006378</td>\n",
       "      <td>0.004949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.011330</td>\n",
       "      <td>0.015360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.090048</td>\n",
       "      <td>0.061607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.078109</td>\n",
       "      <td>0.079370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5623</th>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.101173</td>\n",
       "      <td>0.052875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5624</th>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.060823</td>\n",
       "      <td>0.047327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5625</th>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.078838</td>\n",
       "      <td>0.056147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5626</th>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.038346</td>\n",
       "      <td>0.050486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5627</th>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.041336</td>\n",
       "      <td>0.007072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5628 rows × 8 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-036d5e65-5091-4a7f-81a5-19f6912c975d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-036d5e65-5091-4a7f-81a5-19f6912c975d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-036d5e65-5091-4a7f-81a5-19f6912c975d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      y_true  video_id  n1  n2  pred  pred_proba     mse_x     mse_y\n",
       "0          1       250   0   1     1    0.904627  0.000411  0.000247\n",
       "1          0       250   0   2     0    0.001371  0.006378  0.004949\n",
       "2          0       250   0   3     0    0.000107  0.011330  0.015360\n",
       "3          0       250   0   4     0    0.000026  0.090048  0.061607\n",
       "4          0       250   0   5     0    0.000027  0.078109  0.079370\n",
       "...      ...       ...  ..  ..   ...         ...       ...       ...\n",
       "5623       0       374   7   9     0    0.000141  0.101173  0.052875\n",
       "5624       0       374   7  10     0    0.000051  0.060823  0.047327\n",
       "5625       0       374   8   9     0    0.000640  0.078838  0.056147\n",
       "5626       0       374   8  10     0    0.000125  0.038346  0.050486\n",
       "5627       0       374   9  10     0    0.001351  0.041336  0.007072\n",
       "\n",
       "[5628 rows x 8 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['mse_x']=mse_x\n",
    "predictions['mse_y']=mse_y\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TLP6lB_1tSzk",
    "outputId": "87af736f-6fbd-452b-9ef6-0781b79dcf04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.4410854125738167, 1.1452578037379554e-266)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "a=stats.pearsonr(predictions['pred_proba'],predictions['mse_x'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "h1kv0vwmzKlE",
    "outputId": "0d752825-84eb-4491-a8f4-88c3bd8b48a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/__init__.py:1376: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.atleast_1d(X.T if isinstance(X, np.ndarray) else np.asarray(X))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1d46a3bc50>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEdCAYAAADjFntmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3SV9Z3v8feHEAiXKlBaCoJip9ZFxDNeqF1Vq7CoqNMWOdP21MROFTnlMDNQZ3TKoOlqrW3mSLWd4zBd9TJQe5GotUdlqgztaGKH5XRGVGwV7CmlgAEvU6UqEEISvueP/WR3J+4kO5Dk2e79ea21V57L7/c83/1kZ3/z+/2eiyICMzMzgGFpB2BmZsXDScHMzLKcFMzMLMtJwczMspwUzMwsy0nBzMyynBQsdZJC0vvSjiNNkmZLau5lfdkfIxsaTgqWJWmHpBZJ+yTtlfSQpGlpx9VJ0hWSNqYdR7npK2FZaXFSsO4+HhFjgcnAy8CqlOMZNJKGpx1DqfCxLB1OCpZXRBwE7gOqO5dJOlbS9yT9l6Sdkr4oaZikCZKaJX08KTdW0jZJn03m75R0q6SfSnpT0mOSTsi33172MQO4FfhQ0pL5fQ/1T5T0s2Q//yrpW5J+kKybnnTDLJK0C3g02fYXk329kuz72KT8W/5DTlpTH0mmr5d0n6R7kv09JemPc8pOkfSj5L38VtLnc9aNSo7LXklbgA8U8Gv5E0nbJf1O0k1J7CMkvSbp1Jxtv1vSAUnv6hZ7wWVz1o8B1gNTkuO+L3lfne/9B5LeAK5I3s/Xcup2OX69HQ8rHk4Klpek0cCngZ/nLF4FHAu8Fzgf+CywMCJeA64E7pD0buDvgc0R8b2cupcBXwUmApuBu3rYdU/72AosAf49IsZGxLge6q8F/hN4J3A98Gd5ypwPzAAuBK5IXnOSfY4F/rGHbedzCfBDYEKy7wckVUoaBvwz8AxwHDAX+CtJFyb1vgz8UfK6ELi8gH39d2AWcEay3ysj4hBwN/CZnHI1wCMR8V+5lftTNqfOfuBiYE9y3MdGxJ6c934fMI6ef58AFHA8rFhEhF9+EREAO4B9wO+BNmAPcGqyrgI4BFTnlP9fQFPO/Crgl8Bu4J05y+8E7s6ZHwt0ANOS+QDe19c+yHx5b+wl/uOBdmB0zrIfAD9Ipqcn+3pvzvpHgL/ImT85ee/DgdlAc55j9JFk+nrg5znrhgEvAh8GPgjs6lb3WuA7yfR24KKcdYu776tb3ehW/i/IfJnTuS9Ayfwm4H/0sJ2Cy+bUyXccrgd+1m3ZncDX8tXr63j4VTwv9wNadwsi4l8lVZD5T/AxSdVkvpQqgZ05ZXeS+a+v0+3AUuDvIuLVbtt9oXMiIvZJeg2YkrucTCuir330ZgrwWkQc6Lbf7oPlufuckmd/w4FJBe4z930dTrpLppA5XlO6dXNVAP+Ws9/cOHJj6HNfSfkpyX7/Q9IBYLakF8kk2HX5NtCfsv2Mpy8n0PvxsCLh7iPLKyI6IuL/kvmP/lzgd2T+g84dCzieTKuAJIncDnwP+Au99fTJ7BezpLFkulv2dCvT6z7IfNH25kVgQtL19Zb95r69nOk9efbXTmaQfT+Q3VbyHrv3vee+r2HA1GSbLwC/jYhxOa93RMSf5MSaG9vxfby37u/leLoev++S6Rb6M+C+yIwJ9aQ/ZaHn4959eZfjBbwnZ7qv42FFwknB8lLGJcB4YGtEdAD3AvWS3pEMFF9NpnsG4DoyXxJXAjcB30u+RDv9iaRzJY0gM7bw84jo8p9mAft4GZiabOMtImInme6Q65NB1Q8BH+/jrTYAf50MUI8F/g64JyLagf8HVEn6qKRK4IvAyG71z5T0p8qcffNXQCuZcZj/BN6U9LfJoHKFpJmSOgeU7wWulTRe0lRgWR9xAnwhKT8NuAq4J2fdD8iMOXyGTGLuTX/KQua4v7NzAL4Xm8n8nidIeg+Z49Gpr+NhRcJJwbr7Z0n7gDeAeuDyiHguWbeMzH+D24GNZAZW10g6k8yX92eTL/aVZBLEipztriUzuPoacCZdBztz5d1Hsu5R4DngJUm/66H+ZcCHgFeBr5H54mzt5f2uAb4P/Az4LXAwiYGIeJ1M3/0/kWmt7Ae6n6//IJkB+b1k/vP+04hoS47Dx4DTku3+LtlO5xfrV8h0Af0W+EkSQ18eBJ4k8+X7ELC6c0WSYJ8ic9x77ZLpT9mk/PNkkud2Sb+XNKWHot8nM5C8g8x7yiatAo6HFYnOwSazQSPpTjIDjl9MYd/3AM9HxJcHYdvXA++LiJ4S3JCStIbMWUJ9Huf+lLXy4paClRRJH5D0R8k5/BeRGSx/oIeyOyR9QdIvJO2XtFrSJEnr9YfrHMZLqkrOx381+U/5CUmdA9GVSb0XJe2W9LVu3Wb59vttST/KmV8p6RFJOor3PR34U3JaDwNR1sqPk4KVmvcATWROrf0H4M8j4uleyn8CuAB4P5nxh/VkxkfeRebv4/NkriE4lsxA7zvJXC/RktT/EJmB6fcBpwPzgP/ZR4zXAKcqc9uODwOLyHTTHVGzXdJXgWeBmyLit0dSVtJ1ORen5b7WH0lM9vbl7iMrW5J2AHURcVcy/yPglYj482R+GZmLrNaR+aJfEhG/yKk/icw5/+MioiVZVgMsjog5fez7g2QS0JvAiohoGOC3Z3ZEfJ2ClbuXc6Zb8syPJTOAOg24W9I4Mmfv1JE5lbUSeDGn52cYBZy/n1wvsB14N5kzkcyKgruPzPqQnE30lYioBs4mcxbNZ8l8+bcCE3POvT8mIk7pa5uS/pLM6a17gOWDGL5ZvzgpmPVB0hxJpyYDyG+QucDucES8SObUy29IOiYZ3P4jSef3sb33kzldtvMCsuWSThvkt2FWECcFs769h8yN394AtgKP8YfrCj4LjAC2kLlW4T4ytx3PK7nI7QfAyoh4JiJ+TWZg+/uSul8YZzbkPNBsZmZZbimYmVmWk4LZIFDmoUL5zvu/Ne3YzHrj7iMzM8tyS8HMzLKK7uK1iRMnxvTp09MOoyTt37+fMWPGpB2GWcH8mR0cTz755O8iIu9zuYsuKUyfPp1NmzalHUZJampqYvbs2WmHYVYwf2YHh6Qen/Tn7iMzM8tyUjAzsywnBTMzy3JSMDOzLCcFMzPLclIoAw0NDcycOZO5c+cyc+ZMGhr8PBczy6/oTkm1gdXQ0EBdXR2rV6+mo6ODiooKFi1aBEBNTU3K0ZlZsXFSKHH19fXU1taybNkytm7dyowZM6itraW+vt5JwczewkmhxG3ZsoUDBw68paWwY8eOtEMzsyLkMYUSN2LECJYuXcqcOXMYPnw4c+bMYenSpYwYMSLt0MysCLmlUOIOHTrEqlWrOP300+no6KCxsZFVq1Zx6NChtEMzsyLkpFDiqqurWbBgQZcxhcsuu4wHHngg7dDMrAg5KZS4urq6vGcf1dfXpx2amRUhJ4USV1NTw5133sncuXOJCCRxwQUX+MwjM8vLA80lbtmyZTz66KPcfPPNrF+/nptvvplHH32UZcuWpR2amRUhJ4USd8cdd7By5UquvvpqqqqquPrqq1m5ciV33HFH2qGZWRFyUihxra2tLFmypMuyJUuW0NramlJEZlbMPKZQ4kaOHMnixYvZvHlz9uyj0047jZEjR6YdmpkVIbcUStz555/PXXfdxXnnnceDDz7Ieeedx1133cX555+fdmhmVoTcUihxu3fvZsGCBaxZs4Zvf/vbjBw5kgULFvDrX/867dDMrAg5KZS4rVu38vTTT1NZWZl9CHpbWxtVVVVph2ZmRcjdRyVuxowZbNy4scuyjRs3MmPGjJQiMrNi5qRQ4urq6li0aBGNjY20t7fT2NjIokWLqKurSzs0MytC7j4qcTU1NTz++ONcfPHFtLa2MnLkSD73uc/5imYzy8sthRLX0NDAPffcw+TJkxk2bBiTJ0/mnnvu8SM5zSyvgpKCpIsk/UrSNkkr8qy/WtIWSb+Q9IikE3LWdUjanLzWDWTw1rfly5fT1tYGQEQA0NbWxvLly9MMy8yKVJ9JQVIF8C3gYqAaqJFU3a3Y08CsiPhvwH3A13PWtUTEaclr/gDFbQVqbm7m8OHDAEgC4PDhwzQ3N6cZlpkVqULGFM4CtkXEdgBJdwOXAFs6C0REY075nwOfGcgg7ehUVFSwZs2a7K2zP/GJT6QdkpkVqUK6j44DXsiZb06W9WQRsD5nvkrSJkk/l7TgCGI0M7MhMqBnH0n6DDALyL2HwgkRsVvSe4FHJf0yIn7Trd5iYDHApEmTaGpqGsiwyt6BAwe44IILsi2F4cMzv3YfZyt2+/bt8+d0iBWSFHYD03LmpybLupD0EaAOOD8isrfgjIjdyc/tkpqA04EuSSEibgduB5g1a1bMnj27X2/CejZhwgT27t3Lu9/9bl555RUmTpzIK6+8woQJE/BxtmLXeRW+DZ1Cuo+eAE6SdKKkEcClQJeziCSdDtwGzI+IV3KWj5c0MpmeCJxDzliEDb7Ro0dzzDHHMGrUKABGjRrFMcccw+jRo1OOzMyKUZ9JISLagaXABmArcG9EPCfpBkmdZxPdBIwFftjt1NMZwCZJzwCNwI0R4aQwhPbs2UNtbS0vvvgiEcGLL75IbW0te/bsSTs0MytCBY0pRMTDwMPdln0pZ/ojPdR7HDj1aAK0ozNlyhTuv/9+1q9fnx1TqK2tZcqUKWmHZmZFyFc0l4HO6xN6mjcz6+R7H5W4PXv2cOedd7Js2bLsk9dWrlzJFVdckXZoZlaE3FIocTNmzGDq1Kk8++yzPPLIIzz77LNMnTrVt842s7ycFEqcb51tZv3h7qMS51tnm1l/uKVQ4hoaGrjttttobc1cT9ja2sptt93mW2ebWV5OCiVu4cKFtLW1MX/+fO6//37mz59PW1sbCxcuTDs0MytCTgolrrW1lY997GM8+OCDjBs3jgcffJCPfexj2ZaDmVkuJ4UycOWVV/Y6b2bWyUmhDNTW1nY5+6i2tjbtkMysSPnsoxJ36qmn8stf/pK5c+cSEUgiIjj1VN99xMzeyi2FEnfttddSWVmZfT5zRFBZWcm1116bcmRmVoycFEpcfX09GzZsICJobGwkItiwYQP19fVph2ZmRchJocRt3bqVc889t8uyc889l61bt6YUkZkVMyeFEjdjxgw2btzYZdnGjRt97yMzy8sDzSWurq6OBQsW0NLSQltbG5WVlYwaNYpbb7017dDMrAi5pVDiHn/8cd58880uA81vvvkmjz/+eMqRmVkxclIocbfeeiujR49m6tSpDBs2jKlTpzJ69Gi3FMwsL3cflbj29nYmTpzImjVrujyOc//+/WmHZmZFyC2FMjB//nzmzJnD8OHDmTNnDvPnz087JDMrUm4plIE77riDk08+merqar75zW9yxx13pB2SmRUptxRKXOdYwjXXXMPFF1/MNddckx1bMCtWDQ0NzJw5k7lz5zJz5kw//2MIuaVQ4qqrq2lubmb8+PHs3bs3+7O6ujrt0MzyamhooK6ujtWrV2fHwRYtWgTgJwYOAbcUStxjjz3GOeecw4EDBwA4cOAA55xzDo899ljKkZnlV19fz+rVq7uMg61evdq3ZhkiTgolrrW1leeff57JkycjicmTJ/P888/7ITtWtHxrlnS5+6gMtLa28sMf/jDbFPfZR1bMOm/NMmfOnOwy35pl6BTUUpB0kaRfSdomaUWe9VdL2iLpF5IekXRCzrrLJf06eV0+kMFbYVpaWnj66adpb2/n6aefpqWlJe2QzHpUV1fHokWLujwYatGiRdTV1aUdWnmIiF5fQAXwG+C9wAjgGaC6W5k5wOhk+s+Be5LpCcD25Of4ZHp8b/s788wzwwYOEGeccUZICiAkxRlnnBGZX71ZcVq7dm2ccsopMWzYsDjllFNi7dq1aYdUUoBN0cN3cCHdR2cB2yJiO4Cku4FLgC05iaUxp/zPgc8k0xcCP42I15K6PwUuAnx+2RCZMGECzzzzDDfffDPV1dVs2bKF5cuXM2HChLRDM+tRTU0NNTU1NDU1MXv27LTDKSuFJIXjgBdy5puBD/ZSfhGwvpe6x/UnQDs6o0ePpqOjg1WrVrFr1y6OP/54xo4dy+jRo9MOzcyK0IAONEv6DDALOL+f9RYDiwEmTZpEU1PTQIZV1vbs2cNpp53GU089BcCOHTs444wz2Lx5s4+zFb19+/b5czrECkkKu4FpOfNTk2VdSPoIUAecHxGtOXVnd6vb1L1uRNwO3A4wa9ascHNx4IwbN45nnnmGb3zjG126j8aNG+dmuRU9dx8NvUKSwhPASZJOJPMlfylQm1tA0unAbcBFEfFKzqoNwN9JGp/MzwP8xPgh9MYbb1BVVdWl+6iqqoo33ngj7dDMrAj1eUpqRLQDS8l8wW8F7o2I5yTdIKnzhPebgLHADyVtlrQuqfsa8FUyieUJ4IbOQWcbGu3t7YwaNQog+6CdUaNG0d7enmZYZlakChpTiIiHgYe7LftSzvRHeqm7BlhzpAHa0ZFEVVUVO3fuJCLYuXMnxx13HJLSDs3MipBvc1HiIoLm5maqqqqyCaK5uTnbajAzy+WkUAaGDRtGS0sLEUFLSwvDhvnXbmb5+duhDBw+fLjXeTOzTk4KZWL8+PFdfpoVMz9kJz2+S2qZeP3117v8NCtWfshOutxSKBOdXUbuOrJi54fspMtJoUx0Di57kNmKnR+yky5/Q5SJzlNQfSqqFbvOh+zk8kN2ho6TQplwUrC3Cz9kJ10eaDazotI5mLxs2TK2bt3KjBkzqK+v9yDzEFGx/ec4a9as2LRpU9phlIzebmdRbL97s+58l9TBIenJiJiVb527j8zMLMtJoUyMGDGiy08zs3ycFMqEk4KZFcJJoUzs27evy08zs3ycFEqMpC6vQsuaFRPf+yg9PiW1xHQ/o+j444/nhRdeYNSoUbQcPMioqipaWlqYNm0au3btSilKs5753kfpckuhxO3atYtp06bR0tICyfMUnBCsmPneR+lyUigDu3btIiI44W9/TEQ4IVhR872P0uWkYGZFxfc+SpeTgpkVFd/7KF0eaDazouJ7H6XLScHMik5NTQ01NTW+91EK3H1kZmZZTgpmZpblpGBmZlkFJQVJF0n6laRtklbkWX+epKcktUv6ZLd1HZI2J691AxW4mZkNvD4HmiVVAN8CLgCagSckrYuILTnFdgFXAH+TZxMtEXHaAMRqZmaDrJCWwlnAtojYHhGHgLuBS3ILRMSOiPgFcHgQYjSzMuMb4qWnkFNSjwNeyJlvBj7Yj31USdoEtAM3RsQD/ahrZmXGN8RL11Bcp3BCROyW9F7gUUm/jIjf5BaQtBhYDDBp0iSampqGIKzy5GNrxe66667j85//PJI4ePAgY8eOZdmyZVx33XVMnjw57fBKnvp6eLukDwHXR8SFyfy1ABHxv/OUvRP4cUTc18O2el0PMGvWrNi0aVOh8Vs/TF/xEDtu/GjaYZj1qqKigoMHD1JZWZm9eK2trY2qqio6OjrSDq8kSHoyImblW1fImMITwEmSTpQ0ArgUKOgsIknjJY1MpicC5wBbeq9lZuXMN8RLV5/dRxHRLmkpsAGoANZExHOSbgA2RcQ6SR8A7gfGAx+X9JWIOAWYAdwm6TCZBHRjt7OWzMy6qKur49Of/jRjxoxh586dnHDCCezfv59bbrkl7dDKQkFjChHxMPBwt2Vfypl+Apiap97jwKlHGaOZlSk/Knbo+YpmMysq9fX1LF68mDFjxgAwZswYFi9e7CevDRHfJdXMisqWLVs4cODAW05J3bFjR9qhlQW3FMysqIwYMYKlS5d2eUbz0qVLGTFiRNqhlQW3FMysqBw6dIhVq1Zx+umn09HRQWNjI6tWreLQoUNph1YWnBTMrKhUV1ezYMGCLk9eu+yyy3jgAd8MYSg4KZhZUamrq8t7mwsPNA8NJwUzKyo1NTU8/vjjXHzxxbS2tjJy5Eg+97nP+b5HQ8RJwcyKSkNDAw899BDr16/v0lI4++yznRiGgJOCmRWV+vp6amtru4wp1NbWUl9f76QwBJwUzKyo+DqFdDkpmFlRGTFiBGeffXaXlsLZZ5/Nnj170g6tLDgpmFlROXToEGvXrmXSpEkAvPrqq6xduzblqMqHr2g2s6JSUVHB6NGjqaqqIiKoqqpi9OjRVFRUpB1aWXBLwcyKSnt7OxMnTmTNmjXZMYXa2lr279+fdmhlwS0FMys6CxcuZNmyZVx44YUsW7aMhQsXph1S2XBLwcyKytSpU/nOd77D2rVru7QUpk59yyNbbBA4KZhZUfn617/OVVddxZVXXpl98lpHRwff/OY30w6tLLj7yMyKSk1NDbfccgtjxoxBEmPGjOGWW27xhWtDxEnBzMyynBTMrKg0NDRw1VVXsX//fiKC/fv3c9VVV9HQ0JB2aGXBScHMisry5cuzD9SRBGQuaFu+fHmaYZUNJwUzKyrNzc3Z6YjIu9wGj88+MrOiM2zYsC4Xr33iE59IO6Sy4ZaCmZlluaVgZkXn4MGDXHjhhbS1tVFZWcnw4f6qGipuKZhZUZkwYQKtra1MmDAh77wNroKSgqSLJP1K0jZJK/KsP0/SU5LaJX2y27rLJf06eV0+UIGbWWnqvCPqyy+/DMDLL7+cvXOqDb4+k4KkCuBbwMVANVAjqbpbsV3AFcDabnUnAF8GPgicBXxZ0vijD9vMStXu3btpb2/PPk9h0qRJtLe3s3v37pQjKw+FtBTOArZFxPaIOATcDVySWyAidkTEL4DD3epeCPw0Il6LiL3AT4GLBiBuMythS5Ys4aWXXqKxsZGXXnqJJUuWpB1S2SgkKRwHvJAz35wsK8TR1DWzMhQRrF+/nsbGRtrb22lsbGT9+vVdrlmwwVMUQ/qSFgOLIdNUbGpqSjegEuZja8WusrKSsWPHdjn76OSTT6aystKf3yFQSFLYDUzLmZ+aLCvEbmB2t7pN3QtFxO3A7QCzZs2K2bNndy9iA+FfHsLH1ordnDlz+MlPfsL48ePZu3cvY8eO5dlnn2XevHn+/A6BQrqPngBOknSipBHApcC6Are/AZgnaXwywDwvWWZmlteWLVuorKxk7969AOzdu5fKykq2bNmScmTloc+kEBHtwFIyX+ZbgXsj4jlJN0iaDyDpA5KagU8Bt0l6Lqn7GvBVMonlCeCGZJmZWV7Nzc0MHz6cyspKgOzFa7730dAoaEwhIh4GHu627Es500+Q6RrKV3cNsOYoYjSzMtPa2spNN91EdXU1W7Zs4Qtf+ELaIZWNohhoNjPLJYlrrrkmO19RUZFiNOXFt7kws6LT0dHR67wNHicFMytKw4YN6/LThoaPtpkVpcOHD3f5aUPDScHMzLKcFMysKHUOLnuQeWj57KO3qT/+yk94vaWt3/Wmr3ioX+WPHVXJM1+e1+/9mB2tzsFlDzIPLSeFt6nXW9rYceNH+1Wnqamp37cJ6G8SMbO3N3cfmZlZlpOCmZllOSmYmVmWk4KZmWU5KZiZWZaTgpmZZTkpmJlZlpOCmZllOSmYmVmWk4KZmWU5KZiZWZaTgpmZZTkpmJlZlpOCmZllOSmYWVGaNGkS3/nOd5g0aVLaoZQVP0/BzIrSyy+/zMKFC9MOo+w4KZhZqiQdUdmIGIxwyp67j8wsVRHR5dUp3zOa85WzgVVQUpB0kaRfSdomaUWe9SMl3ZOs/w9J05Pl0yW1SNqcvG4d2PDNrNTMm5d5JnjnF3/nz87lNrj6TAqSKoBvARcD1UCNpOpuxRYBeyPifcDfAytz1v0mIk5LXksGKG4zK1EbNmxg3rx5XZLCvHnz2LBhQ8qRlYdCWgpnAdsiYntEHALuBi7pVuYS4LvJ9H3AXPWno9DMLMeGDRs4fPgwJ/ztjzl8+LATwhAqJCkcB7yQM9+cLMtbJiLagdeBdybrTpT0tKTHJH34KOM1M7NBNNhnH70IHB8Rr0o6E3hA0ikR8UZuIUmLgcWQOTe5qalpkMN6+3vHjBWc+t23DO/07bt9F+m6H2hqGtP//ZgNEH8fDK1CksJuYFrO/NRkWb4yzZKGA8cCr0amU7AVICKelPQb4P3AptzKEXE7cDvArFmzYvbs2f1/J2XmzRU3suPGj/arTlNTE/09ttNXPMTsy/tXx2zA/MtD/f7M2tEppPvoCeAkSSdKGgFcCqzrVmYdcHky/Ung0YgISe9KBqqR9F7gJGD7wIRuZmYDrc+WQkS0S1oKbAAqgDUR8ZykG4BNEbEOWA18X9I24DUyiQPgPOAGSW3AYWBJRLw2GG/EzMyOXkFjChHxMPBwt2Vfypk+CHwqT70fAT86yhjNzGyI+IpmMzPLclIwM7MsJwUzM8tyUjAzsywnBTMzy3JSMDOzLCcFMzPLclIwM7MsJwUzM8tyUjAzsywnBTMzyxrs5ymYmQHwx1/5Ca+3tPW73vQVD/Wr/LGjKnnmy36e85FyUngb6+8fCwD/0v8/MLOB8HpL25A9A8SOnJPC21R//7gg88dyJPXMrHx4TMHMzLKcFMzMLMtJwczMspwUzMwsy0nBzMyynBTMzCzLScHMzLJ8nYKZDYl3zFjBqd9d0f+K3+3vfgB8Pc6RclIwsyHx5tYbfUXz24C7j8zMLMtJwczMspwUzMwsq6AxBUkXAbcAFcA/RcSN3daPBL4HnAm8Cnw6InYk664FFgEdwOcjYsOARW9mbyu+s2/x6zMpSKoAvgVcADQDT0haFxFbcootAvZGxPskXQqsBD4tqRq4FDgFmAL8q6T3R0THQL8RMytuvrPv20Mh3UdnAdsiYntEHALuBi7pVuYS/nDi2H3AXElKlt8dEa0R8VtgW7I9MzMrQoUkheOAF3Lmm5NlectERDvwOvDOAuuamVmRKIrrFCQtBhYDTJo0iaampnQDehubM2dOr+u1Mv/yxsbGQYjGrG/+zBaXQpLCbmBazvzUZFm+Ms2ShgPHkhlwLqQuEXE7cDvArFmzor8Xq9gfRESP647kQiCzwebPbHEppPvoCeAkSSdKGkFm4HhdtzLrgMuT6U8Cj0bmN70OuFTSSEknAicB/zkwoZuZ2UDrs6UQERICkskAAAN+SURBVO2SlgIbyJySuiYinpN0A7ApItYBq4HvS9oGvEYmcZCUuxfYArQDf+kzj8zMildBYwoR8TDwcLdlX8qZPgh8qoe69UD9UcRoZmZDxFc0m5lZlpOCmZllOSmYmVmWk4KZmWU5KZiZWZZ6u3AkDZL+C9iZdhwlaiLwu7SDMOsHf2YHxwkR8a58K4ouKdjgkbQpImalHYdZofyZHXruPjIzsywnBTMzy3JSKC+3px2AWT/5MzvEPKZgZmZZbimYmVmWk0IZkHSRpF9J2iZpRdrxmPVF0hpJr0h6Nu1Yyo2TQomTVAF8C7gYqAZqJFWnG5VZn+4ELko7iHLkpFD6zgK2RcT2iDgE3A1cknJMZr2KiJ+ReTaLDTEnhdJ3HPBCznxzsszM7C2cFMzMLMtJofTtBqblzE9NlpmZvYWTQul7AjhJ0omSRpB5fva6lGMysyLlpFDiIqIdWApsALYC90bEc+lGZdY7SQ3AvwMnS2qWtCjtmMqFr2g2M7MstxTMzCzLScHMzLKcFMzMLMtJwczMspwUzMwsy0nBzMyynBSsLEmaLqlF0uYjqFc7wLHcJOklSX8zkNs1OxJOClbOfhMRp/WzznQgb1KQNPxIgoiILwC3Hklds4HmpGBlT9INkv4qZ75e0lU9FL8R+LCkzZL+WtIVktZJehR4RNJsST/O2dY/SroimT5T0mOSnpS0QdLkwXxfZkfCScEM1gCfBZA0jMz9oX7QQ9kVwL9FxGkR8ffJsjOAT0bE+T3tQFIlsCopd2ayz/oBit9swBxRc9eslETEDkmvSjodmAQ8HRGv9mMTP42Ivh4IczIwE/ipJIAK4MUjCthsEDkpmGX8E3AF8B4y/8X3x/6c6Xa6tsCrkp8CnouIDx1pgGZDwd1HZhn3k3km8AfI3FG2J28C7+hl/U6gWtJISeOAucnyXwHvkvQhyHQnSTrl6MM2G1huKZgBEXFIUiPw+4jo6KXoL4AOSc+Qebj83m7beUHSvcCzwG+Bp3O2/0ngHyQdS+Zv7/8Avo25FRXfOtvKkqTpwI8jYmYyPwx4CvhURPw6hXiuB/ZFxM1DvW+zXO4+snLVARybnFpaDWwDHkkpIdwEfIauYxNmqXBLwSwPSacC3++2uDUiPphGPGZDxUnBzMyy3H1kZmZZTgpmZpblpGBmZllOCmZmluWkYGZmWf8ftiFBACv9kSIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions.filter(['mse_x','y_true']).boxplot(by='y_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dEyAZ0gXMdJv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80kOEMh7MdMs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbgDq6S1MdQE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ce6f8f8780c24b8a9a8be1feb3201963",
      "52fc82463abb418894aed073037a8c5d",
      "1d94dcd1b5504c02a95d776694e486ea",
      "122254a95feb4ff4ae1d037697140986",
      "3a0445a1de304e9c9c10841070a4ea65",
      "d6789c5614b74d8cbeabf572274bbe0b",
      "8d9c6822587741b69ad159b52e83d1d0",
      "16c27b26b95343b1a0bfddd480914cf3",
      "47634b46376b4eb98250921cfc643ecf",
      "951722f5fc59402c84c5b71691902c7b",
      "a50d1108bd02445591f617933642f348"
     ]
    },
    "id": "2ZeRsStHjxkG",
    "outputId": "ce625eaa-1ac8-4619-fd1c-28ff81d94ac1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6f8f8780c24b8a9a8be1feb3201963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "288/288 [==============================] - 13s 23ms/step - loss: 0.5673 - accuracy: 0.6972 - val_loss: 0.4109 - val_accuracy: 0.7804\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.5416 - accuracy: 0.7058 - val_loss: 0.4293 - val_accuracy: 0.7781\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.5393 - accuracy: 0.7070 - val_loss: 0.4225 - val_accuracy: 0.7699\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.5365 - accuracy: 0.7088 - val_loss: 0.4271 - val_accuracy: 0.7754\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.5373 - accuracy: 0.7072 - val_loss: 0.4066 - val_accuracy: 0.7822\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.5363 - accuracy: 0.7057 - val_loss: 0.4695 - val_accuracy: 0.7758\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.5311 - accuracy: 0.7150 - val_loss: 0.4184 - val_accuracy: 0.7774\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.5283 - accuracy: 0.7152 - val_loss: 0.4396 - val_accuracy: 0.7594\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.5258 - accuracy: 0.7188 - val_loss: 0.4209 - val_accuracy: 0.7772\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.5222 - accuracy: 0.7176 - val_loss: 0.3922 - val_accuracy: 0.7974\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.5207 - accuracy: 0.7149 - val_loss: 0.3961 - val_accuracy: 0.7912\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.5213 - accuracy: 0.7151 - val_loss: 0.4597 - val_accuracy: 0.7269\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5154 - accuracy: 0.7198 - val_loss: 0.4365 - val_accuracy: 0.7806\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.5108 - accuracy: 0.7147 - val_loss: 0.4239 - val_accuracy: 0.7610\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.4921 - accuracy: 0.7261 - val_loss: 0.3404 - val_accuracy: 0.8417\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.4624 - accuracy: 0.7456 - val_loss: 0.3448 - val_accuracy: 0.8213\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.4309 - accuracy: 0.7778 - val_loss: 0.3235 - val_accuracy: 0.8390\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.3717 - accuracy: 0.8238 - val_loss: 0.3678 - val_accuracy: 0.8225\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.2875 - accuracy: 0.8722 - val_loss: 0.2818 - val_accuracy: 0.8676\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.2338 - accuracy: 0.8987 - val_loss: 0.2265 - val_accuracy: 0.8977\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.2160 - accuracy: 0.9059 - val_loss: 0.2563 - val_accuracy: 0.8875\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.2065 - accuracy: 0.9104 - val_loss: 0.2508 - val_accuracy: 0.8909\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1943 - accuracy: 0.9173 - val_loss: 0.2452 - val_accuracy: 0.8939\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1818 - accuracy: 0.9236 - val_loss: 0.2914 - val_accuracy: 0.8655\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1864 - accuracy: 0.9189 - val_loss: 0.3002 - val_accuracy: 0.8762\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1793 - accuracy: 0.9246 - val_loss: 0.2464 - val_accuracy: 0.8929\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1708 - accuracy: 0.9281 - val_loss: 0.3213 - val_accuracy: 0.8497\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1876 - accuracy: 0.9224 - val_loss: 0.2301 - val_accuracy: 0.8946\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1679 - accuracy: 0.9276 - val_loss: 0.2836 - val_accuracy: 0.8801\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1689 - accuracy: 0.9273 - val_loss: 0.2504 - val_accuracy: 0.8934\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1710 - accuracy: 0.9279 - val_loss: 0.2660 - val_accuracy: 0.8843\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1639 - accuracy: 0.9319 - val_loss: 0.2455 - val_accuracy: 0.8953\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1640 - accuracy: 0.9318 - val_loss: 0.3237 - val_accuracy: 0.8611\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1665 - accuracy: 0.9309 - val_loss: 0.2772 - val_accuracy: 0.8756\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1607 - accuracy: 0.9324 - val_loss: 0.2453 - val_accuracy: 0.8980\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1686 - accuracy: 0.9277 - val_loss: 0.2435 - val_accuracy: 0.8977\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1616 - accuracy: 0.9306 - val_loss: 0.3004 - val_accuracy: 0.8826\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1568 - accuracy: 0.9335 - val_loss: 0.2914 - val_accuracy: 0.8779\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1610 - accuracy: 0.9306 - val_loss: 0.2545 - val_accuracy: 0.8893\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1530 - accuracy: 0.9337 - val_loss: 0.2669 - val_accuracy: 0.8893\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1538 - accuracy: 0.9351 - val_loss: 0.2944 - val_accuracy: 0.8852\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1488 - accuracy: 0.9367 - val_loss: 0.2804 - val_accuracy: 0.8866\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1564 - accuracy: 0.9313 - val_loss: 0.2474 - val_accuracy: 0.8895\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1512 - accuracy: 0.9360 - val_loss: 0.2838 - val_accuracy: 0.8799\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1526 - accuracy: 0.9347 - val_loss: 0.3233 - val_accuracy: 0.8609\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1454 - accuracy: 0.9383 - val_loss: 0.2472 - val_accuracy: 0.8943\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1479 - accuracy: 0.9370 - val_loss: 0.2255 - val_accuracy: 0.9065\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1436 - accuracy: 0.9382 - val_loss: 0.2773 - val_accuracy: 0.8879\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1402 - accuracy: 0.9399 - val_loss: 0.2419 - val_accuracy: 0.8964\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1483 - accuracy: 0.9374 - val_loss: 0.2544 - val_accuracy: 0.8920\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1381 - accuracy: 0.9422 - val_loss: 0.2609 - val_accuracy: 0.8962\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1413 - accuracy: 0.9378 - val_loss: 0.2590 - val_accuracy: 0.8836\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1410 - accuracy: 0.9412 - val_loss: 0.2516 - val_accuracy: 0.8854\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1411 - accuracy: 0.9412 - val_loss: 0.2707 - val_accuracy: 0.8868\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1351 - accuracy: 0.9435 - val_loss: 0.2412 - val_accuracy: 0.9046\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1370 - accuracy: 0.9433 - val_loss: 0.2930 - val_accuracy: 0.8875\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1266 - accuracy: 0.9475 - val_loss: 0.2794 - val_accuracy: 0.8923\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1255 - accuracy: 0.9501 - val_loss: 0.4462 - val_accuracy: 0.8264\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1321 - accuracy: 0.9493 - val_loss: 0.2681 - val_accuracy: 0.8875\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1236 - accuracy: 0.9496 - val_loss: 0.2834 - val_accuracy: 0.8847\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1288 - accuracy: 0.9496 - val_loss: 0.2235 - val_accuracy: 0.9088\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1182 - accuracy: 0.9538 - val_loss: 0.2353 - val_accuracy: 0.9071\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1223 - accuracy: 0.9518 - val_loss: 0.2562 - val_accuracy: 0.9055\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1115 - accuracy: 0.9555 - val_loss: 0.2524 - val_accuracy: 0.9039\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1115 - accuracy: 0.9551 - val_loss: 0.3061 - val_accuracy: 0.8953\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1158 - accuracy: 0.9538 - val_loss: 0.3206 - val_accuracy: 0.8875\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1156 - accuracy: 0.9535 - val_loss: 0.2478 - val_accuracy: 0.9016\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1154 - accuracy: 0.9538 - val_loss: 0.2712 - val_accuracy: 0.8936\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1179 - accuracy: 0.9523 - val_loss: 0.3058 - val_accuracy: 0.8758\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1090 - accuracy: 0.9570 - val_loss: 0.2903 - val_accuracy: 0.8939\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1101 - accuracy: 0.9559 - val_loss: 0.2633 - val_accuracy: 0.8971\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1021 - accuracy: 0.9607 - val_loss: 0.3077 - val_accuracy: 0.8827\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1033 - accuracy: 0.9598 - val_loss: 0.2895 - val_accuracy: 0.8957\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1036 - accuracy: 0.9594 - val_loss: 0.3109 - val_accuracy: 0.8834\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0990 - accuracy: 0.9588 - val_loss: 0.3759 - val_accuracy: 0.8552\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1116 - accuracy: 0.9549 - val_loss: 0.2930 - val_accuracy: 0.8818\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0942 - accuracy: 0.9624 - val_loss: 0.2576 - val_accuracy: 0.9097\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0886 - accuracy: 0.9666 - val_loss: 0.3315 - val_accuracy: 0.8778\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0838 - accuracy: 0.9686 - val_loss: 0.2788 - val_accuracy: 0.9049\n",
      "Epoch 80/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0969 - accuracy: 0.9621 - val_loss: 0.2708 - val_accuracy: 0.9012\n",
      "Epoch 81/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0970 - accuracy: 0.9623 - val_loss: 0.3344 - val_accuracy: 0.8898\n",
      "Epoch 82/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0858 - accuracy: 0.9681 - val_loss: 0.2386 - val_accuracy: 0.9128\n",
      "Epoch 83/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0905 - accuracy: 0.9647 - val_loss: 0.2779 - val_accuracy: 0.9085\n",
      "Epoch 84/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0837 - accuracy: 0.9684 - val_loss: 0.3013 - val_accuracy: 0.9039\n",
      "Epoch 85/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0872 - accuracy: 0.9664 - val_loss: 0.3410 - val_accuracy: 0.8870\n",
      "Epoch 86/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0874 - accuracy: 0.9673 - val_loss: 0.2666 - val_accuracy: 0.9039\n",
      "Epoch 87/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0849 - accuracy: 0.9660 - val_loss: 0.3028 - val_accuracy: 0.9042\n",
      "Epoch 88/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0744 - accuracy: 0.9724 - val_loss: 0.2516 - val_accuracy: 0.9128\n",
      "Epoch 89/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0825 - accuracy: 0.9684 - val_loss: 0.2703 - val_accuracy: 0.9156\n",
      "Epoch 90/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1107 - accuracy: 0.9582 - val_loss: 0.3309 - val_accuracy: 0.8911\n",
      "Epoch 91/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0718 - accuracy: 0.9745 - val_loss: 0.2910 - val_accuracy: 0.9120\n",
      "Epoch 92/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0808 - accuracy: 0.9687 - val_loss: 0.3351 - val_accuracy: 0.8971\n",
      "Epoch 93/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0823 - accuracy: 0.9689 - val_loss: 0.3102 - val_accuracy: 0.9023\n",
      "Epoch 94/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0791 - accuracy: 0.9703 - val_loss: 0.2954 - val_accuracy: 0.9071\n",
      "Epoch 95/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0657 - accuracy: 0.9751 - val_loss: 0.2970 - val_accuracy: 0.9115\n",
      "Epoch 96/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0704 - accuracy: 0.9738 - val_loss: 0.2587 - val_accuracy: 0.9224\n",
      "Epoch 97/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0784 - accuracy: 0.9697 - val_loss: 0.3597 - val_accuracy: 0.8969\n",
      "Epoch 98/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0767 - accuracy: 0.9718 - val_loss: 0.3116 - val_accuracy: 0.8959\n",
      "Epoch 99/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0646 - accuracy: 0.9762 - val_loss: 0.2681 - val_accuracy: 0.9167\n",
      "Epoch 100/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0901 - accuracy: 0.9669 - val_loss: 0.3438 - val_accuracy: 0.8929\n",
      "Epoch 101/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0732 - accuracy: 0.9742 - val_loss: 0.4161 - val_accuracy: 0.8738\n",
      "Epoch 102/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0638 - accuracy: 0.9766 - val_loss: 0.3795 - val_accuracy: 0.8969\n",
      "Epoch 103/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0613 - accuracy: 0.9780 - val_loss: 0.3410 - val_accuracy: 0.9080\n",
      "Epoch 104/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0538 - accuracy: 0.9810 - val_loss: 0.3179 - val_accuracy: 0.9096\n",
      "Epoch 105/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0732 - accuracy: 0.9734 - val_loss: 0.3785 - val_accuracy: 0.8751\n",
      "Epoch 106/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0590 - accuracy: 0.9784 - val_loss: 0.3518 - val_accuracy: 0.9005\n",
      "Epoch 107/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0804 - accuracy: 0.9692 - val_loss: 0.3519 - val_accuracy: 0.8783\n",
      "Epoch 108/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0829 - accuracy: 0.9683 - val_loss: 0.3266 - val_accuracy: 0.9049\n",
      "Epoch 109/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0646 - accuracy: 0.9758 - val_loss: 0.2759 - val_accuracy: 0.9149\n",
      "Epoch 110/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0526 - accuracy: 0.9815 - val_loss: 0.3321 - val_accuracy: 0.9087\n",
      "Epoch 111/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0672 - accuracy: 0.9758 - val_loss: 0.3348 - val_accuracy: 0.8978\n",
      "Epoch 112/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0638 - accuracy: 0.9772 - val_loss: 0.3895 - val_accuracy: 0.8856\n",
      "Epoch 113/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0510 - accuracy: 0.9824 - val_loss: 0.2795 - val_accuracy: 0.9232\n",
      "Epoch 114/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0648 - accuracy: 0.9766 - val_loss: 0.2928 - val_accuracy: 0.9186\n",
      "Epoch 115/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0527 - accuracy: 0.9812 - val_loss: 0.2721 - val_accuracy: 0.9243\n",
      "Epoch 116/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0452 - accuracy: 0.9836 - val_loss: 0.3144 - val_accuracy: 0.9168\n",
      "Epoch 117/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1092 - accuracy: 0.9628 - val_loss: 0.2510 - val_accuracy: 0.9104\n",
      "Epoch 118/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0603 - accuracy: 0.9782 - val_loss: 0.3589 - val_accuracy: 0.9055\n",
      "Epoch 119/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0432 - accuracy: 0.9852 - val_loss: 0.2865 - val_accuracy: 0.9184\n",
      "Epoch 120/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0673 - accuracy: 0.9755 - val_loss: 0.3357 - val_accuracy: 0.9062\n",
      "Epoch 121/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0558 - accuracy: 0.9802 - val_loss: 0.3275 - val_accuracy: 0.9113\n",
      "Epoch 122/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0448 - accuracy: 0.9844 - val_loss: 0.4715 - val_accuracy: 0.8838\n",
      "Epoch 123/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0522 - accuracy: 0.9808 - val_loss: 0.3051 - val_accuracy: 0.9167\n",
      "Epoch 124/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0596 - accuracy: 0.9785 - val_loss: 0.3143 - val_accuracy: 0.9055\n",
      "Epoch 125/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0398 - accuracy: 0.9865 - val_loss: 0.3802 - val_accuracy: 0.9092\n",
      "Epoch 126/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0482 - accuracy: 0.9830 - val_loss: 0.2981 - val_accuracy: 0.9149\n",
      "Epoch 127/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0551 - accuracy: 0.9797 - val_loss: 0.3740 - val_accuracy: 0.9053\n",
      "Epoch 128/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0480 - accuracy: 0.9821 - val_loss: 0.2993 - val_accuracy: 0.9227\n",
      "Epoch 129/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0491 - accuracy: 0.9825 - val_loss: 0.3656 - val_accuracy: 0.9080\n",
      "Epoch 130/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0449 - accuracy: 0.9838 - val_loss: 0.3254 - val_accuracy: 0.9156\n",
      "Epoch 131/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1378 - accuracy: 0.9458 - val_loss: 0.3404 - val_accuracy: 0.8758\n",
      "Epoch 132/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1253 - accuracy: 0.9481 - val_loss: 0.2935 - val_accuracy: 0.9003\n",
      "Epoch 133/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0899 - accuracy: 0.9652 - val_loss: 0.2755 - val_accuracy: 0.9120\n",
      "Epoch 134/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0563 - accuracy: 0.9788 - val_loss: 0.2605 - val_accuracy: 0.9254\n",
      "Epoch 135/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0869 - accuracy: 0.9695 - val_loss: 0.3144 - val_accuracy: 0.9078\n",
      "Epoch 136/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0525 - accuracy: 0.9814 - val_loss: 0.2714 - val_accuracy: 0.9206\n",
      "Epoch 137/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0579 - accuracy: 0.9787 - val_loss: 0.3149 - val_accuracy: 0.9136\n",
      "Epoch 138/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0389 - accuracy: 0.9860 - val_loss: 0.4110 - val_accuracy: 0.8957\n",
      "Epoch 139/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0429 - accuracy: 0.9843 - val_loss: 0.3043 - val_accuracy: 0.9170\n",
      "Epoch 140/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0445 - accuracy: 0.9851 - val_loss: 0.3857 - val_accuracy: 0.8984\n",
      "Epoch 141/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0624 - accuracy: 0.9772 - val_loss: 0.2840 - val_accuracy: 0.9101\n",
      "Epoch 142/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0434 - accuracy: 0.9847 - val_loss: 0.3137 - val_accuracy: 0.9202\n",
      "Epoch 143/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0309 - accuracy: 0.9892 - val_loss: 0.3452 - val_accuracy: 0.9231\n",
      "Epoch 144/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0538 - accuracy: 0.9811 - val_loss: 0.3120 - val_accuracy: 0.9204\n",
      "Epoch 145/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0442 - accuracy: 0.9842 - val_loss: 0.3116 - val_accuracy: 0.9227\n",
      "Epoch 146/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0465 - accuracy: 0.9851 - val_loss: 0.3366 - val_accuracy: 0.9199\n",
      "Epoch 147/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0309 - accuracy: 0.9899 - val_loss: 0.3030 - val_accuracy: 0.9248\n",
      "Epoch 148/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0579 - accuracy: 0.9788 - val_loss: 0.3226 - val_accuracy: 0.9181\n",
      "Epoch 149/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0354 - accuracy: 0.9880 - val_loss: 0.3434 - val_accuracy: 0.9152\n",
      "Epoch 150/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0539 - accuracy: 0.9802 - val_loss: 0.3483 - val_accuracy: 0.8980\n",
      "Epoch 151/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0336 - accuracy: 0.9883 - val_loss: 0.4258 - val_accuracy: 0.9026\n",
      "Epoch 152/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0446 - accuracy: 0.9844 - val_loss: 0.3097 - val_accuracy: 0.9195\n",
      "Epoch 153/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0445 - accuracy: 0.9841 - val_loss: 0.3209 - val_accuracy: 0.9231\n",
      "Epoch 154/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0251 - accuracy: 0.9916 - val_loss: 0.3162 - val_accuracy: 0.9300\n",
      "Epoch 155/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0375 - accuracy: 0.9875 - val_loss: 0.5833 - val_accuracy: 0.8742\n",
      "Epoch 156/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0459 - accuracy: 0.9846 - val_loss: 0.3632 - val_accuracy: 0.9151\n",
      "Epoch 157/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0446 - accuracy: 0.9840 - val_loss: 0.2855 - val_accuracy: 0.9254\n",
      "Epoch 158/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0236 - accuracy: 0.9923 - val_loss: 0.3617 - val_accuracy: 0.9183\n",
      "Epoch 159/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0507 - accuracy: 0.9827 - val_loss: 0.3155 - val_accuracy: 0.9238\n",
      "Epoch 160/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0285 - accuracy: 0.9904 - val_loss: 0.3330 - val_accuracy: 0.9231\n",
      "Epoch 161/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0264 - accuracy: 0.9915 - val_loss: 0.3598 - val_accuracy: 0.9227\n",
      "Epoch 162/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0455 - accuracy: 0.9838 - val_loss: 0.3393 - val_accuracy: 0.9142\n",
      "Epoch 163/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0312 - accuracy: 0.9895 - val_loss: 0.3143 - val_accuracy: 0.9270\n",
      "Epoch 164/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0449 - accuracy: 0.9840 - val_loss: 0.2747 - val_accuracy: 0.9231\n",
      "Epoch 165/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0311 - accuracy: 0.9901 - val_loss: 0.4165 - val_accuracy: 0.8980\n",
      "Epoch 166/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0429 - accuracy: 0.9839 - val_loss: 0.3396 - val_accuracy: 0.9218\n",
      "Epoch 167/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.4299 - val_accuracy: 0.9074\n",
      "Epoch 168/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0525 - accuracy: 0.9799 - val_loss: 0.3118 - val_accuracy: 0.9293\n",
      "Epoch 169/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0328 - accuracy: 0.9889 - val_loss: 0.3036 - val_accuracy: 0.9280\n",
      "Epoch 170/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0295 - accuracy: 0.9896 - val_loss: 0.3738 - val_accuracy: 0.9142\n",
      "Epoch 171/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.4582 - val_accuracy: 0.9025\n",
      "Epoch 172/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0513 - accuracy: 0.9840 - val_loss: 0.3977 - val_accuracy: 0.9044\n",
      "Epoch 173/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0268 - accuracy: 0.9909 - val_loss: 0.3064 - val_accuracy: 0.9231\n",
      "Epoch 174/500\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9918Restoring model weights from the end of the best epoch: 154.\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0252 - accuracy: 0.9918 - val_loss: 0.3499 - val_accuracy: 0.9236\n",
      "Epoch 174: early stopping\n",
      "Number of iterations 1\n",
      "F1-scores:  [0.8679624664879356]\n",
      "Average F1-Score 0.8679624664879356\n",
      "Std Dev F1-Score 0.0\n",
      "Error bar F1-Score 0.0\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 14s 23ms/step - loss: 0.5768 - accuracy: 0.6985 - val_loss: 0.4149 - val_accuracy: 0.7582\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.5456 - accuracy: 0.6993 - val_loss: 0.4372 - val_accuracy: 0.7770\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.5374 - accuracy: 0.7085 - val_loss: 0.4337 - val_accuracy: 0.7816\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.5371 - accuracy: 0.7100 - val_loss: 0.4009 - val_accuracy: 0.7996\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.5321 - accuracy: 0.7140 - val_loss: 0.4176 - val_accuracy: 0.7870\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.5163 - accuracy: 0.7172 - val_loss: 0.3954 - val_accuracy: 0.7832\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.4511 - accuracy: 0.7596 - val_loss: 0.3898 - val_accuracy: 0.7951\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.4155 - accuracy: 0.7911 - val_loss: 0.4158 - val_accuracy: 0.7633\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.3715 - accuracy: 0.8223 - val_loss: 0.3638 - val_accuracy: 0.8307\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.3497 - accuracy: 0.8372 - val_loss: 0.3889 - val_accuracy: 0.8028\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.3056 - accuracy: 0.8608 - val_loss: 0.2717 - val_accuracy: 0.8689\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2572 - accuracy: 0.8838 - val_loss: 0.2668 - val_accuracy: 0.8810\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2393 - accuracy: 0.8908 - val_loss: 0.2384 - val_accuracy: 0.8909\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.2339 - accuracy: 0.8963 - val_loss: 0.2420 - val_accuracy: 0.8811\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2032 - accuracy: 0.9117 - val_loss: 0.2882 - val_accuracy: 0.8767\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2063 - accuracy: 0.9093 - val_loss: 0.2580 - val_accuracy: 0.8810\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2157 - accuracy: 0.9062 - val_loss: 0.3899 - val_accuracy: 0.8166\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2062 - accuracy: 0.9102 - val_loss: 0.2473 - val_accuracy: 0.8898\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1919 - accuracy: 0.9158 - val_loss: 0.2690 - val_accuracy: 0.8847\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1869 - accuracy: 0.9165 - val_loss: 0.2683 - val_accuracy: 0.8811\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1790 - accuracy: 0.9241 - val_loss: 0.2707 - val_accuracy: 0.8845\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1805 - accuracy: 0.9233 - val_loss: 0.2340 - val_accuracy: 0.8911\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1850 - accuracy: 0.9199 - val_loss: 0.2325 - val_accuracy: 0.8930\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2000 - accuracy: 0.9144 - val_loss: 0.2804 - val_accuracy: 0.8721\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1746 - accuracy: 0.9249 - val_loss: 0.2778 - val_accuracy: 0.8799\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1758 - accuracy: 0.9249 - val_loss: 0.2499 - val_accuracy: 0.8845\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1671 - accuracy: 0.9294 - val_loss: 0.3089 - val_accuracy: 0.8875\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1768 - accuracy: 0.9246 - val_loss: 0.3175 - val_accuracy: 0.8516\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1670 - accuracy: 0.9285 - val_loss: 0.2390 - val_accuracy: 0.8898\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1727 - accuracy: 0.9274 - val_loss: 0.3018 - val_accuracy: 0.8559\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1614 - accuracy: 0.9298 - val_loss: 0.2871 - val_accuracy: 0.8749\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1853 - accuracy: 0.9215 - val_loss: 0.2180 - val_accuracy: 0.9021\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1663 - accuracy: 0.9297 - val_loss: 0.2368 - val_accuracy: 0.8977\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1688 - accuracy: 0.9269 - val_loss: 0.2251 - val_accuracy: 0.8980\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1520 - accuracy: 0.9351 - val_loss: 0.3458 - val_accuracy: 0.8424\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1511 - accuracy: 0.9355 - val_loss: 0.2252 - val_accuracy: 0.9012\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1662 - accuracy: 0.9289 - val_loss: 0.2197 - val_accuracy: 0.9021\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1542 - accuracy: 0.9349 - val_loss: 0.2703 - val_accuracy: 0.8820\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1439 - accuracy: 0.9369 - val_loss: 0.2246 - val_accuracy: 0.8998\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1695 - accuracy: 0.9285 - val_loss: 0.3154 - val_accuracy: 0.8499\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1598 - accuracy: 0.9313 - val_loss: 0.3161 - val_accuracy: 0.8760\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1623 - accuracy: 0.9321 - val_loss: 0.2318 - val_accuracy: 0.9007\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1483 - accuracy: 0.9372 - val_loss: 0.2301 - val_accuracy: 0.8959\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1447 - accuracy: 0.9393 - val_loss: 0.2313 - val_accuracy: 0.8994\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1417 - accuracy: 0.9406 - val_loss: 0.2252 - val_accuracy: 0.8968\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1469 - accuracy: 0.9397 - val_loss: 0.2038 - val_accuracy: 0.9048\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1421 - accuracy: 0.9399 - val_loss: 0.2330 - val_accuracy: 0.9049\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1350 - accuracy: 0.9440 - val_loss: 0.2528 - val_accuracy: 0.8932\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1466 - accuracy: 0.9396 - val_loss: 0.2142 - val_accuracy: 0.9099\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1316 - accuracy: 0.9453 - val_loss: 0.2772 - val_accuracy: 0.8852\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1303 - accuracy: 0.9480 - val_loss: 0.2787 - val_accuracy: 0.8795\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1285 - accuracy: 0.9470 - val_loss: 0.2357 - val_accuracy: 0.8996\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1498 - accuracy: 0.9383 - val_loss: 0.2016 - val_accuracy: 0.9113\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1260 - accuracy: 0.9494 - val_loss: 0.2526 - val_accuracy: 0.8966\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1279 - accuracy: 0.9492 - val_loss: 0.2535 - val_accuracy: 0.8911\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1206 - accuracy: 0.9517 - val_loss: 0.2529 - val_accuracy: 0.8913\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1221 - accuracy: 0.9496 - val_loss: 0.2692 - val_accuracy: 0.8822\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1095 - accuracy: 0.9564 - val_loss: 0.2368 - val_accuracy: 0.9065\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1181 - accuracy: 0.9535 - val_loss: 0.2263 - val_accuracy: 0.9072\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1190 - accuracy: 0.9511 - val_loss: 0.2269 - val_accuracy: 0.9104\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1177 - accuracy: 0.9548 - val_loss: 0.2577 - val_accuracy: 0.8982\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1141 - accuracy: 0.9547 - val_loss: 0.2143 - val_accuracy: 0.9065\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1105 - accuracy: 0.9557 - val_loss: 0.2068 - val_accuracy: 0.9071\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1201 - accuracy: 0.9515 - val_loss: 0.2201 - val_accuracy: 0.9108\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1111 - accuracy: 0.9559 - val_loss: 0.2578 - val_accuracy: 0.8994\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1242 - accuracy: 0.9521 - val_loss: 0.2422 - val_accuracy: 0.9067\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0962 - accuracy: 0.9630 - val_loss: 0.2221 - val_accuracy: 0.9138\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1021 - accuracy: 0.9610 - val_loss: 0.2156 - val_accuracy: 0.9103\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0949 - accuracy: 0.9633 - val_loss: 0.2521 - val_accuracy: 0.9033\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1194 - accuracy: 0.9542 - val_loss: 0.2324 - val_accuracy: 0.9072\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0961 - accuracy: 0.9629 - val_loss: 0.2382 - val_accuracy: 0.9042\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0901 - accuracy: 0.9654 - val_loss: 0.2724 - val_accuracy: 0.8923\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1128 - accuracy: 0.9558 - val_loss: 0.2058 - val_accuracy: 0.9206\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1008 - accuracy: 0.9616 - val_loss: 0.2277 - val_accuracy: 0.9065\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0847 - accuracy: 0.9674 - val_loss: 0.2251 - val_accuracy: 0.9167\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0911 - accuracy: 0.9660 - val_loss: 0.2046 - val_accuracy: 0.9200\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0816 - accuracy: 0.9690 - val_loss: 0.2636 - val_accuracy: 0.8994\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0910 - accuracy: 0.9645 - val_loss: 0.3554 - val_accuracy: 0.8779\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0908 - accuracy: 0.9658 - val_loss: 0.2230 - val_accuracy: 0.9112\n",
      "Epoch 80/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0818 - accuracy: 0.9678 - val_loss: 0.2632 - val_accuracy: 0.9042\n",
      "Epoch 81/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0753 - accuracy: 0.9725 - val_loss: 0.2283 - val_accuracy: 0.9186\n",
      "Epoch 82/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0874 - accuracy: 0.9665 - val_loss: 0.2199 - val_accuracy: 0.9202\n",
      "Epoch 83/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0696 - accuracy: 0.9729 - val_loss: 0.2366 - val_accuracy: 0.9122\n",
      "Epoch 84/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0867 - accuracy: 0.9679 - val_loss: 0.2243 - val_accuracy: 0.9126\n",
      "Epoch 85/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0715 - accuracy: 0.9737 - val_loss: 0.2335 - val_accuracy: 0.9179\n",
      "Epoch 86/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0647 - accuracy: 0.9761 - val_loss: 0.1993 - val_accuracy: 0.9277\n",
      "Epoch 87/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0736 - accuracy: 0.9730 - val_loss: 0.2356 - val_accuracy: 0.9192\n",
      "Epoch 88/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0731 - accuracy: 0.9730 - val_loss: 0.2024 - val_accuracy: 0.9232\n",
      "Epoch 89/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0682 - accuracy: 0.9741 - val_loss: 0.2106 - val_accuracy: 0.9254\n",
      "Epoch 90/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0641 - accuracy: 0.9757 - val_loss: 0.2711 - val_accuracy: 0.9012\n",
      "Epoch 91/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0779 - accuracy: 0.9713 - val_loss: 0.2476 - val_accuracy: 0.9188\n",
      "Epoch 92/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0551 - accuracy: 0.9797 - val_loss: 0.3070 - val_accuracy: 0.9017\n",
      "Epoch 93/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0651 - accuracy: 0.9757 - val_loss: 0.1931 - val_accuracy: 0.9311\n",
      "Epoch 94/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0804 - accuracy: 0.9701 - val_loss: 0.2048 - val_accuracy: 0.9273\n",
      "Epoch 95/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.2442 - val_accuracy: 0.9188\n",
      "Epoch 96/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0773 - accuracy: 0.9705 - val_loss: 0.2334 - val_accuracy: 0.9199\n",
      "Epoch 97/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0560 - accuracy: 0.9793 - val_loss: 0.2722 - val_accuracy: 0.9090\n",
      "Epoch 98/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0657 - accuracy: 0.9769 - val_loss: 0.2068 - val_accuracy: 0.9311\n",
      "Epoch 99/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0731 - accuracy: 0.9723 - val_loss: 0.2400 - val_accuracy: 0.9049\n",
      "Epoch 100/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0559 - accuracy: 0.9803 - val_loss: 0.1945 - val_accuracy: 0.9350\n",
      "Epoch 101/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0566 - accuracy: 0.9798 - val_loss: 0.1956 - val_accuracy: 0.9307\n",
      "Epoch 102/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0633 - accuracy: 0.9768 - val_loss: 0.2508 - val_accuracy: 0.9208\n",
      "Epoch 103/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0475 - accuracy: 0.9829 - val_loss: 0.2007 - val_accuracy: 0.9380\n",
      "Epoch 104/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0578 - accuracy: 0.9791 - val_loss: 0.2177 - val_accuracy: 0.9270\n",
      "Epoch 105/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0676 - accuracy: 0.9748 - val_loss: 0.2765 - val_accuracy: 0.9129\n",
      "Epoch 106/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0585 - accuracy: 0.9774 - val_loss: 0.2211 - val_accuracy: 0.9257\n",
      "Epoch 107/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0609 - accuracy: 0.9788 - val_loss: 0.2225 - val_accuracy: 0.9240\n",
      "Epoch 108/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0472 - accuracy: 0.9824 - val_loss: 0.2362 - val_accuracy: 0.9229\n",
      "Epoch 109/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0521 - accuracy: 0.9815 - val_loss: 0.2325 - val_accuracy: 0.9247\n",
      "Epoch 110/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0487 - accuracy: 0.9821 - val_loss: 0.2061 - val_accuracy: 0.9293\n",
      "Epoch 111/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0471 - accuracy: 0.9837 - val_loss: 0.2195 - val_accuracy: 0.9298\n",
      "Epoch 112/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0517 - accuracy: 0.9821 - val_loss: 0.2735 - val_accuracy: 0.9186\n",
      "Epoch 113/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0397 - accuracy: 0.9862 - val_loss: 0.2836 - val_accuracy: 0.9104\n",
      "Epoch 114/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0457 - accuracy: 0.9836 - val_loss: 0.2028 - val_accuracy: 0.9343\n",
      "Epoch 115/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0418 - accuracy: 0.9853 - val_loss: 0.2293 - val_accuracy: 0.9266\n",
      "Epoch 116/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0706 - accuracy: 0.9744 - val_loss: 0.4848 - val_accuracy: 0.8193\n",
      "Epoch 117/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0903 - accuracy: 0.9649 - val_loss: 0.2181 - val_accuracy: 0.9273\n",
      "Epoch 118/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0464 - accuracy: 0.9833 - val_loss: 0.2228 - val_accuracy: 0.9245\n",
      "Epoch 119/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0442 - accuracy: 0.9843 - val_loss: 0.2881 - val_accuracy: 0.9195\n",
      "Epoch 120/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2801 - accuracy: 0.8788 - val_loss: 0.2261 - val_accuracy: 0.9074\n",
      "Epoch 121/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1007 - accuracy: 0.9614 - val_loss: 0.1986 - val_accuracy: 0.9287\n",
      "Epoch 122/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0727 - accuracy: 0.9728 - val_loss: 0.2043 - val_accuracy: 0.9286\n",
      "Epoch 123/500\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.0688 - accuracy: 0.9752Restoring model weights from the end of the best epoch: 103.\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0696 - accuracy: 0.9748 - val_loss: 0.2169 - val_accuracy: 0.9172\n",
      "Epoch 123: early stopping\n",
      "Number of iterations 2\n",
      "F1-scores:  [0.8679624664879356, 0.8810902896081771]\n",
      "Average F1-Score 0.8745263780480563\n",
      "Std Dev F1-Score 0.006563911560120761\n",
      "Error bar F1-Score 0.00464138637527016\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 14s 24ms/step - loss: 0.5734 - accuracy: 0.6972 - val_loss: 0.4347 - val_accuracy: 0.7592\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.5464 - accuracy: 0.6981 - val_loss: 0.4604 - val_accuracy: 0.7504\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.5384 - accuracy: 0.7062 - val_loss: 0.4397 - val_accuracy: 0.7672\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.5372 - accuracy: 0.7151 - val_loss: 0.4443 - val_accuracy: 0.7816\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.5309 - accuracy: 0.7171 - val_loss: 0.4176 - val_accuracy: 0.7982\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.5288 - accuracy: 0.7161 - val_loss: 0.4424 - val_accuracy: 0.7596\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.5244 - accuracy: 0.7148 - val_loss: 0.3790 - val_accuracy: 0.8051\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.5308 - accuracy: 0.7118 - val_loss: 0.4331 - val_accuracy: 0.7578\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.5327 - accuracy: 0.7140 - val_loss: 0.4324 - val_accuracy: 0.7752\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.5286 - accuracy: 0.7166 - val_loss: 0.4075 - val_accuracy: 0.7768\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.5177 - accuracy: 0.7185 - val_loss: 0.3893 - val_accuracy: 0.7983\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.5148 - accuracy: 0.7184 - val_loss: 0.4134 - val_accuracy: 0.7912\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.5100 - accuracy: 0.7154 - val_loss: 0.4118 - val_accuracy: 0.7857\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.5000 - accuracy: 0.7206 - val_loss: 0.3916 - val_accuracy: 0.7873\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.5037 - accuracy: 0.7177 - val_loss: 0.4263 - val_accuracy: 0.7797\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.4886 - accuracy: 0.7239 - val_loss: 0.3652 - val_accuracy: 0.8115\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.4711 - accuracy: 0.7399 - val_loss: 0.3847 - val_accuracy: 0.7957\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.4509 - accuracy: 0.7597 - val_loss: 0.3352 - val_accuracy: 0.8284\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.4233 - accuracy: 0.7850 - val_loss: 0.3454 - val_accuracy: 0.8149\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.3924 - accuracy: 0.8111 - val_loss: 0.3988 - val_accuracy: 0.7918\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.3563 - accuracy: 0.8350 - val_loss: 0.3391 - val_accuracy: 0.8172\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.3156 - accuracy: 0.8578 - val_loss: 0.3092 - val_accuracy: 0.8436\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2865 - accuracy: 0.8692 - val_loss: 0.3575 - val_accuracy: 0.8182\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2695 - accuracy: 0.8792 - val_loss: 0.2845 - val_accuracy: 0.8714\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2407 - accuracy: 0.8925 - val_loss: 0.2625 - val_accuracy: 0.8776\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2258 - accuracy: 0.9005 - val_loss: 0.3872 - val_accuracy: 0.8230\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2149 - accuracy: 0.9040 - val_loss: 0.2550 - val_accuracy: 0.8827\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2153 - accuracy: 0.9056 - val_loss: 0.2649 - val_accuracy: 0.8840\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2176 - accuracy: 0.9057 - val_loss: 0.2650 - val_accuracy: 0.8746\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2067 - accuracy: 0.9073 - val_loss: 0.2753 - val_accuracy: 0.8795\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1855 - accuracy: 0.9165 - val_loss: 0.3132 - val_accuracy: 0.8621\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2058 - accuracy: 0.9075 - val_loss: 0.2588 - val_accuracy: 0.8817\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1925 - accuracy: 0.9151 - val_loss: 0.2461 - val_accuracy: 0.8881\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1843 - accuracy: 0.9217 - val_loss: 0.2570 - val_accuracy: 0.8870\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1847 - accuracy: 0.9188 - val_loss: 0.2165 - val_accuracy: 0.9030\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1837 - accuracy: 0.9197 - val_loss: 0.2897 - val_accuracy: 0.8687\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1804 - accuracy: 0.9217 - val_loss: 0.2390 - val_accuracy: 0.8961\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1804 - accuracy: 0.9223 - val_loss: 0.2438 - val_accuracy: 0.8975\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2090 - accuracy: 0.9093 - val_loss: 0.3187 - val_accuracy: 0.8651\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1770 - accuracy: 0.9225 - val_loss: 0.3150 - val_accuracy: 0.8538\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1744 - accuracy: 0.9254 - val_loss: 0.2777 - val_accuracy: 0.8794\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1725 - accuracy: 0.9246 - val_loss: 0.2341 - val_accuracy: 0.8987\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1642 - accuracy: 0.9286 - val_loss: 0.2905 - val_accuracy: 0.8646\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1685 - accuracy: 0.9284 - val_loss: 0.2436 - val_accuracy: 0.8969\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1644 - accuracy: 0.9300 - val_loss: 0.2645 - val_accuracy: 0.9000\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1672 - accuracy: 0.9290 - val_loss: 0.2287 - val_accuracy: 0.8984\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1612 - accuracy: 0.9291 - val_loss: 0.3491 - val_accuracy: 0.8548\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1608 - accuracy: 0.9302 - val_loss: 0.2325 - val_accuracy: 0.8932\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1630 - accuracy: 0.9317 - val_loss: 0.2636 - val_accuracy: 0.8836\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1519 - accuracy: 0.9375 - val_loss: 0.2705 - val_accuracy: 0.8833\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1640 - accuracy: 0.9320 - val_loss: 0.2598 - val_accuracy: 0.8826\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1519 - accuracy: 0.9341 - val_loss: 0.2465 - val_accuracy: 0.8897\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1719 - accuracy: 0.9256 - val_loss: 0.2733 - val_accuracy: 0.8897\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1497 - accuracy: 0.9361 - val_loss: 0.2559 - val_accuracy: 0.8884\n",
      "Epoch 55/500\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.1541 - accuracy: 0.9356Restoring model weights from the end of the best epoch: 35.\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1543 - accuracy: 0.9355 - val_loss: 0.2437 - val_accuracy: 0.8980\n",
      "Epoch 55: early stopping\n",
      "Number of iterations 3\n",
      "F1-scores:  [0.8679624664879356, 0.8810902896081771, 0.8065201984408221]\n",
      "Average F1-Score 0.8518576515123115\n",
      "Std Dev F1-Score 0.03250331699202634\n",
      "Error bar F1-Score 0.018765798814902146\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 14s 24ms/step - loss: 0.5732 - accuracy: 0.6956 - val_loss: 0.4534 - val_accuracy: 0.7640\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.5511 - accuracy: 0.7020 - val_loss: 0.4296 - val_accuracy: 0.7582\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.5372 - accuracy: 0.7089 - val_loss: 0.4187 - val_accuracy: 0.7639\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.5363 - accuracy: 0.7117 - val_loss: 0.4100 - val_accuracy: 0.8015\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.4218 - accuracy: 0.7841 - val_loss: 0.4178 - val_accuracy: 0.7797\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.3132 - accuracy: 0.8551 - val_loss: 0.2921 - val_accuracy: 0.8607\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2912 - accuracy: 0.8702 - val_loss: 0.4058 - val_accuracy: 0.7987\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2789 - accuracy: 0.8748 - val_loss: 0.3276 - val_accuracy: 0.8513\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2697 - accuracy: 0.8797 - val_loss: 0.5520 - val_accuracy: 0.7189\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2611 - accuracy: 0.8864 - val_loss: 0.3697 - val_accuracy: 0.8330\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2590 - accuracy: 0.8858 - val_loss: 0.2865 - val_accuracy: 0.8593\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2513 - accuracy: 0.8888 - val_loss: 0.4065 - val_accuracy: 0.8070\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2666 - accuracy: 0.8810 - val_loss: 0.3269 - val_accuracy: 0.8435\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2461 - accuracy: 0.8899 - val_loss: 0.2917 - val_accuracy: 0.8632\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2405 - accuracy: 0.8953 - val_loss: 0.2897 - val_accuracy: 0.8639\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2435 - accuracy: 0.8960 - val_loss: 0.2906 - val_accuracy: 0.8674\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2331 - accuracy: 0.8979 - val_loss: 0.2721 - val_accuracy: 0.8689\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2511 - accuracy: 0.8898 - val_loss: 0.3392 - val_accuracy: 0.8424\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2328 - accuracy: 0.8975 - val_loss: 0.3278 - val_accuracy: 0.8499\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2383 - accuracy: 0.8944 - val_loss: 0.2893 - val_accuracy: 0.8570\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2239 - accuracy: 0.9049 - val_loss: 0.2775 - val_accuracy: 0.8650\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2305 - accuracy: 0.9020 - val_loss: 0.3264 - val_accuracy: 0.8468\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2366 - accuracy: 0.8982 - val_loss: 0.2840 - val_accuracy: 0.8646\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2119 - accuracy: 0.9112 - val_loss: 0.2618 - val_accuracy: 0.8753\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2108 - accuracy: 0.9093 - val_loss: 0.2560 - val_accuracy: 0.8776\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2086 - accuracy: 0.9103 - val_loss: 0.2775 - val_accuracy: 0.8744\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.2082 - accuracy: 0.9137 - val_loss: 0.2906 - val_accuracy: 0.8625\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1968 - accuracy: 0.9201 - val_loss: 0.2763 - val_accuracy: 0.8747\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1942 - accuracy: 0.9218 - val_loss: 0.3660 - val_accuracy: 0.8259\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1982 - accuracy: 0.9175 - val_loss: 0.3106 - val_accuracy: 0.8523\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1957 - accuracy: 0.9217 - val_loss: 0.2825 - val_accuracy: 0.8698\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1805 - accuracy: 0.9277 - val_loss: 0.3537 - val_accuracy: 0.8479\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1857 - accuracy: 0.9238 - val_loss: 0.2668 - val_accuracy: 0.8694\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1779 - accuracy: 0.9279 - val_loss: 0.4036 - val_accuracy: 0.8230\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1819 - accuracy: 0.9269 - val_loss: 0.2683 - val_accuracy: 0.8749\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1799 - accuracy: 0.9274 - val_loss: 0.2988 - val_accuracy: 0.8593\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1694 - accuracy: 0.9327 - val_loss: 0.2389 - val_accuracy: 0.8884\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1666 - accuracy: 0.9357 - val_loss: 0.3664 - val_accuracy: 0.8308\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1628 - accuracy: 0.9361 - val_loss: 0.2526 - val_accuracy: 0.8893\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1780 - accuracy: 0.9294 - val_loss: 0.3217 - val_accuracy: 0.8493\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1588 - accuracy: 0.9356 - val_loss: 0.2488 - val_accuracy: 0.8955\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1593 - accuracy: 0.9369 - val_loss: 0.3788 - val_accuracy: 0.8218\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1646 - accuracy: 0.9347 - val_loss: 0.4006 - val_accuracy: 0.8257\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1637 - accuracy: 0.9357 - val_loss: 0.2570 - val_accuracy: 0.8818\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1479 - accuracy: 0.9431 - val_loss: 0.2488 - val_accuracy: 0.8810\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1533 - accuracy: 0.9394 - val_loss: 0.2985 - val_accuracy: 0.8692\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1812 - accuracy: 0.9281 - val_loss: 0.2420 - val_accuracy: 0.8865\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1544 - accuracy: 0.9384 - val_loss: 0.2357 - val_accuracy: 0.8872\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1599 - accuracy: 0.9391 - val_loss: 0.2279 - val_accuracy: 0.8945\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1438 - accuracy: 0.9443 - val_loss: 0.2541 - val_accuracy: 0.8831\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1408 - accuracy: 0.9449 - val_loss: 0.2656 - val_accuracy: 0.8740\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1396 - accuracy: 0.9439 - val_loss: 0.2511 - val_accuracy: 0.8753\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1361 - accuracy: 0.9453 - val_loss: 0.2262 - val_accuracy: 0.8888\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1289 - accuracy: 0.9484 - val_loss: 0.2633 - val_accuracy: 0.8758\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1473 - accuracy: 0.9413 - val_loss: 0.2657 - val_accuracy: 0.8797\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1328 - accuracy: 0.9465 - val_loss: 0.2184 - val_accuracy: 0.8882\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1339 - accuracy: 0.9453 - val_loss: 0.2210 - val_accuracy: 0.8943\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1320 - accuracy: 0.9467 - val_loss: 0.2070 - val_accuracy: 0.9026\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1395 - accuracy: 0.9437 - val_loss: 0.2088 - val_accuracy: 0.9076\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1194 - accuracy: 0.9522 - val_loss: 0.2630 - val_accuracy: 0.8863\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1091 - accuracy: 0.9571 - val_loss: 0.1845 - val_accuracy: 0.9192\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1039 - accuracy: 0.9605 - val_loss: 0.2320 - val_accuracy: 0.9019\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1098 - accuracy: 0.9569 - val_loss: 0.2130 - val_accuracy: 0.9110\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1220 - accuracy: 0.9526 - val_loss: 0.2506 - val_accuracy: 0.9092\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1307 - accuracy: 0.9477 - val_loss: 0.2184 - val_accuracy: 0.9048\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1072 - accuracy: 0.9591 - val_loss: 0.2230 - val_accuracy: 0.9140\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1375 - accuracy: 0.9451 - val_loss: 0.2195 - val_accuracy: 0.9076\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1112 - accuracy: 0.9579 - val_loss: 0.1957 - val_accuracy: 0.9222\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1125 - accuracy: 0.9570 - val_loss: 0.2155 - val_accuracy: 0.9128\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1062 - accuracy: 0.9603 - val_loss: 0.2226 - val_accuracy: 0.9048\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1034 - accuracy: 0.9608 - val_loss: 0.1760 - val_accuracy: 0.9254\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0948 - accuracy: 0.9647 - val_loss: 0.1717 - val_accuracy: 0.9296\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0944 - accuracy: 0.9649 - val_loss: 0.1960 - val_accuracy: 0.9234\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1020 - accuracy: 0.9610 - val_loss: 0.1766 - val_accuracy: 0.9277\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0960 - accuracy: 0.9643 - val_loss: 0.1991 - val_accuracy: 0.9190\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1039 - accuracy: 0.9610 - val_loss: 0.1992 - val_accuracy: 0.9224\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0878 - accuracy: 0.9671 - val_loss: 0.1895 - val_accuracy: 0.9282\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1875 - accuracy: 0.9207 - val_loss: 0.3554 - val_accuracy: 0.8435\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1373 - accuracy: 0.9468 - val_loss: 0.1742 - val_accuracy: 0.9295\n",
      "Epoch 80/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1128 - accuracy: 0.9561 - val_loss: 0.2023 - val_accuracy: 0.9165\n",
      "Epoch 81/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1084 - accuracy: 0.9587 - val_loss: 0.1760 - val_accuracy: 0.9261\n",
      "Epoch 82/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1111 - accuracy: 0.9569 - val_loss: 0.1808 - val_accuracy: 0.9273\n",
      "Epoch 83/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0854 - accuracy: 0.9686 - val_loss: 0.2303 - val_accuracy: 0.9058\n",
      "Epoch 84/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0863 - accuracy: 0.9668 - val_loss: 0.1777 - val_accuracy: 0.9257\n",
      "Epoch 85/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0766 - accuracy: 0.9718 - val_loss: 0.1865 - val_accuracy: 0.9312\n",
      "Epoch 86/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0913 - accuracy: 0.9651 - val_loss: 0.2328 - val_accuracy: 0.9165\n",
      "Epoch 87/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0754 - accuracy: 0.9722 - val_loss: 0.1874 - val_accuracy: 0.9240\n",
      "Epoch 88/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0803 - accuracy: 0.9707 - val_loss: 0.2002 - val_accuracy: 0.9263\n",
      "Epoch 89/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0765 - accuracy: 0.9718 - val_loss: 0.1915 - val_accuracy: 0.9303\n",
      "Epoch 90/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0866 - accuracy: 0.9671 - val_loss: 0.2354 - val_accuracy: 0.9184\n",
      "Epoch 91/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1107 - accuracy: 0.9575 - val_loss: 0.1907 - val_accuracy: 0.9193\n",
      "Epoch 92/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0729 - accuracy: 0.9739 - val_loss: 0.2017 - val_accuracy: 0.9218\n",
      "Epoch 93/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0847 - accuracy: 0.9673 - val_loss: 0.2520 - val_accuracy: 0.9126\n",
      "Epoch 94/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0711 - accuracy: 0.9745 - val_loss: 0.1882 - val_accuracy: 0.9325\n",
      "Epoch 95/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0866 - accuracy: 0.9683 - val_loss: 0.2004 - val_accuracy: 0.9275\n",
      "Epoch 96/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0693 - accuracy: 0.9747 - val_loss: 0.3049 - val_accuracy: 0.8991\n",
      "Epoch 97/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0731 - accuracy: 0.9736 - val_loss: 0.2396 - val_accuracy: 0.9078\n",
      "Epoch 98/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0733 - accuracy: 0.9725 - val_loss: 0.1727 - val_accuracy: 0.9353\n",
      "Epoch 99/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0735 - accuracy: 0.9738 - val_loss: 0.1851 - val_accuracy: 0.9353\n",
      "Epoch 100/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0719 - accuracy: 0.9734 - val_loss: 0.2043 - val_accuracy: 0.9287\n",
      "Epoch 101/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0633 - accuracy: 0.9772 - val_loss: 0.1972 - val_accuracy: 0.9300\n",
      "Epoch 102/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0702 - accuracy: 0.9734 - val_loss: 0.1944 - val_accuracy: 0.9302\n",
      "Epoch 103/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0708 - accuracy: 0.9739 - val_loss: 0.2162 - val_accuracy: 0.9232\n",
      "Epoch 104/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0669 - accuracy: 0.9764 - val_loss: 0.2116 - val_accuracy: 0.9264\n",
      "Epoch 105/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0666 - accuracy: 0.9752 - val_loss: 0.2320 - val_accuracy: 0.9190\n",
      "Epoch 106/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0553 - accuracy: 0.9801 - val_loss: 0.2199 - val_accuracy: 0.9332\n",
      "Epoch 107/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1792 - accuracy: 0.9286 - val_loss: 0.2475 - val_accuracy: 0.9007\n",
      "Epoch 108/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0891 - accuracy: 0.9675 - val_loss: 0.2030 - val_accuracy: 0.9245\n",
      "Epoch 109/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0760 - accuracy: 0.9711 - val_loss: 0.2570 - val_accuracy: 0.9085\n",
      "Epoch 110/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0624 - accuracy: 0.9777 - val_loss: 0.1991 - val_accuracy: 0.9360\n",
      "Epoch 111/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0693 - accuracy: 0.9752 - val_loss: 0.2291 - val_accuracy: 0.9190\n",
      "Epoch 112/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.0632 - accuracy: 0.9778 - val_loss: 0.2119 - val_accuracy: 0.9351\n",
      "Epoch 113/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0619 - accuracy: 0.9773 - val_loss: 0.2155 - val_accuracy: 0.9298\n",
      "Epoch 114/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0722 - accuracy: 0.9727 - val_loss: 0.2360 - val_accuracy: 0.9298\n",
      "Epoch 115/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0554 - accuracy: 0.9806 - val_loss: 0.2238 - val_accuracy: 0.9277\n",
      "Epoch 116/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0690 - accuracy: 0.9749 - val_loss: 0.2287 - val_accuracy: 0.9218\n",
      "Epoch 117/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0489 - accuracy: 0.9826 - val_loss: 0.1964 - val_accuracy: 0.9394\n",
      "Epoch 118/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0633 - accuracy: 0.9766 - val_loss: 0.1976 - val_accuracy: 0.9312\n",
      "Epoch 119/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2491 - accuracy: 0.8928 - val_loss: 0.2626 - val_accuracy: 0.8868\n",
      "Epoch 120/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1473 - accuracy: 0.9443 - val_loss: 0.3006 - val_accuracy: 0.8763\n",
      "Epoch 121/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1076 - accuracy: 0.9592 - val_loss: 0.2143 - val_accuracy: 0.9174\n",
      "Epoch 122/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0847 - accuracy: 0.9686 - val_loss: 0.2267 - val_accuracy: 0.9156\n",
      "Epoch 123/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0888 - accuracy: 0.9683 - val_loss: 0.1836 - val_accuracy: 0.9332\n",
      "Epoch 124/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0714 - accuracy: 0.9738 - val_loss: 0.2934 - val_accuracy: 0.8929\n",
      "Epoch 125/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0719 - accuracy: 0.9732 - val_loss: 0.2137 - val_accuracy: 0.9259\n",
      "Epoch 126/500\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.0645 - accuracy: 0.9770 - val_loss: 0.2637 - val_accuracy: 0.9115\n",
      "Epoch 127/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0749 - accuracy: 0.9737 - val_loss: 0.1974 - val_accuracy: 0.9314\n",
      "Epoch 128/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0658 - accuracy: 0.9766 - val_loss: 0.2095 - val_accuracy: 0.9330\n",
      "Epoch 129/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0734 - accuracy: 0.9735 - val_loss: 0.1748 - val_accuracy: 0.9387\n",
      "Epoch 130/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0528 - accuracy: 0.9818 - val_loss: 0.1993 - val_accuracy: 0.9346\n",
      "Epoch 131/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0677 - accuracy: 0.9754 - val_loss: 0.2623 - val_accuracy: 0.9234\n",
      "Epoch 132/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0641 - accuracy: 0.9769 - val_loss: 0.1876 - val_accuracy: 0.9334\n",
      "Epoch 133/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0538 - accuracy: 0.9814 - val_loss: 0.2328 - val_accuracy: 0.9256\n",
      "Epoch 134/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0569 - accuracy: 0.9798 - val_loss: 0.2254 - val_accuracy: 0.9316\n",
      "Epoch 135/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0517 - accuracy: 0.9820 - val_loss: 0.2028 - val_accuracy: 0.9385\n",
      "Epoch 136/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0507 - accuracy: 0.9825 - val_loss: 0.1879 - val_accuracy: 0.9378\n",
      "Epoch 137/500\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.0483 - accuracy: 0.9817Restoring model weights from the end of the best epoch: 117.\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0483 - accuracy: 0.9817 - val_loss: 0.2191 - val_accuracy: 0.9351\n",
      "Epoch 137: early stopping\n",
      "Number of iterations 4\n",
      "F1-scores:  [0.8679624664879356, 0.8810902896081771, 0.8065201984408221, 0.8839741408642394]\n",
      "Average F1-Score 0.8598867738502936\n",
      "Std Dev F1-Score 0.03139664995135553\n",
      "Error bar F1-Score 0.015698324975677764\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 14s 24ms/step - loss: 0.5661 - accuracy: 0.7023 - val_loss: 0.4263 - val_accuracy: 0.7578\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.5390 - accuracy: 0.7047 - val_loss: 0.4677 - val_accuracy: 0.7138\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.5391 - accuracy: 0.7074 - val_loss: 0.4445 - val_accuracy: 0.7592\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.5398 - accuracy: 0.7031 - val_loss: 0.4531 - val_accuracy: 0.7454\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.5328 - accuracy: 0.7149 - val_loss: 0.4628 - val_accuracy: 0.7864\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.5368 - accuracy: 0.7136 - val_loss: 0.4185 - val_accuracy: 0.7944\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.5213 - accuracy: 0.7195 - val_loss: 0.3706 - val_accuracy: 0.8181\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.4919 - accuracy: 0.7308 - val_loss: 0.3518 - val_accuracy: 0.8380\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.4180 - accuracy: 0.7935 - val_loss: 0.3894 - val_accuracy: 0.8049\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.3141 - accuracy: 0.8646 - val_loss: 0.3288 - val_accuracy: 0.8381\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2769 - accuracy: 0.8827 - val_loss: 0.3408 - val_accuracy: 0.8292\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2582 - accuracy: 0.8900 - val_loss: 0.2925 - val_accuracy: 0.8516\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2506 - accuracy: 0.8939 - val_loss: 0.3252 - val_accuracy: 0.8344\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2373 - accuracy: 0.8968 - val_loss: 0.2844 - val_accuracy: 0.8570\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2209 - accuracy: 0.9037 - val_loss: 0.3234 - val_accuracy: 0.8328\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2137 - accuracy: 0.9072 - val_loss: 0.3129 - val_accuracy: 0.8392\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2038 - accuracy: 0.9082 - val_loss: 0.3065 - val_accuracy: 0.8612\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2081 - accuracy: 0.9093 - val_loss: 0.3121 - val_accuracy: 0.8509\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1947 - accuracy: 0.9162 - val_loss: 0.2678 - val_accuracy: 0.8687\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1819 - accuracy: 0.9236 - val_loss: 0.2821 - val_accuracy: 0.8781\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2140 - accuracy: 0.9051 - val_loss: 0.2729 - val_accuracy: 0.8776\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1842 - accuracy: 0.9209 - val_loss: 0.2830 - val_accuracy: 0.8740\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1790 - accuracy: 0.9243 - val_loss: 0.3211 - val_accuracy: 0.8595\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1740 - accuracy: 0.9276 - val_loss: 0.2760 - val_accuracy: 0.8758\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1776 - accuracy: 0.9235 - val_loss: 0.2480 - val_accuracy: 0.8829\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1666 - accuracy: 0.9286 - val_loss: 0.2533 - val_accuracy: 0.8840\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1675 - accuracy: 0.9281 - val_loss: 0.3037 - val_accuracy: 0.8650\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1563 - accuracy: 0.9328 - val_loss: 0.2165 - val_accuracy: 0.9023\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1569 - accuracy: 0.9340 - val_loss: 0.2525 - val_accuracy: 0.8872\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1587 - accuracy: 0.9318 - val_loss: 0.2842 - val_accuracy: 0.8738\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1516 - accuracy: 0.9365 - val_loss: 0.2909 - val_accuracy: 0.8738\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1585 - accuracy: 0.9321 - val_loss: 0.2526 - val_accuracy: 0.8866\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1554 - accuracy: 0.9354 - val_loss: 0.2593 - val_accuracy: 0.8731\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1438 - accuracy: 0.9404 - val_loss: 0.2517 - val_accuracy: 0.8879\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1450 - accuracy: 0.9400 - val_loss: 0.2266 - val_accuracy: 0.8993\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1377 - accuracy: 0.9448 - val_loss: 0.1956 - val_accuracy: 0.9120\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1488 - accuracy: 0.9383 - val_loss: 0.2405 - val_accuracy: 0.8889\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1298 - accuracy: 0.9456 - val_loss: 0.2502 - val_accuracy: 0.8961\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1441 - accuracy: 0.9389 - val_loss: 0.2466 - val_accuracy: 0.8932\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1347 - accuracy: 0.9451 - val_loss: 0.2188 - val_accuracy: 0.9062\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1585 - accuracy: 0.9330 - val_loss: 0.2128 - val_accuracy: 0.9035\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1224 - accuracy: 0.9503 - val_loss: 0.3053 - val_accuracy: 0.8715\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1239 - accuracy: 0.9517 - val_loss: 0.2639 - val_accuracy: 0.8939\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1570 - accuracy: 0.9356 - val_loss: 0.2364 - val_accuracy: 0.9001\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1301 - accuracy: 0.9476 - val_loss: 0.1989 - val_accuracy: 0.9168\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1215 - accuracy: 0.9516 - val_loss: 0.2389 - val_accuracy: 0.8989\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1130 - accuracy: 0.9561 - val_loss: 0.2258 - val_accuracy: 0.9039\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1251 - accuracy: 0.9516 - val_loss: 0.2043 - val_accuracy: 0.9168\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1119 - accuracy: 0.9559 - val_loss: 0.1906 - val_accuracy: 0.9197\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1068 - accuracy: 0.9590 - val_loss: 0.2128 - val_accuracy: 0.9181\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1138 - accuracy: 0.9541 - val_loss: 0.2088 - val_accuracy: 0.9202\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1025 - accuracy: 0.9616 - val_loss: 0.2209 - val_accuracy: 0.9120\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1016 - accuracy: 0.9610 - val_loss: 0.2889 - val_accuracy: 0.8882\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1004 - accuracy: 0.9616 - val_loss: 0.2555 - val_accuracy: 0.8957\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1058 - accuracy: 0.9601 - val_loss: 0.2025 - val_accuracy: 0.9225\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1948 - accuracy: 0.9148 - val_loss: 0.3495 - val_accuracy: 0.8404\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2600 - accuracy: 0.8814 - val_loss: 0.2326 - val_accuracy: 0.8891\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1830 - accuracy: 0.9240 - val_loss: 0.2324 - val_accuracy: 0.9035\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1516 - accuracy: 0.9390 - val_loss: 0.2340 - val_accuracy: 0.9028\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1426 - accuracy: 0.9436 - val_loss: 0.2434 - val_accuracy: 0.8952\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1544 - accuracy: 0.9412 - val_loss: 0.2548 - val_accuracy: 0.8957\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1333 - accuracy: 0.9489 - val_loss: 0.3252 - val_accuracy: 0.8767\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1205 - accuracy: 0.9542 - val_loss: 0.2163 - val_accuracy: 0.9099\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1167 - accuracy: 0.9561 - val_loss: 0.1965 - val_accuracy: 0.9243\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1118 - accuracy: 0.9573 - val_loss: 0.2203 - val_accuracy: 0.9138\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0982 - accuracy: 0.9646 - val_loss: 0.1849 - val_accuracy: 0.9300\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0949 - accuracy: 0.9653 - val_loss: 0.2176 - val_accuracy: 0.9186\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1050 - accuracy: 0.9610 - val_loss: 0.2853 - val_accuracy: 0.9019\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0903 - accuracy: 0.9648 - val_loss: 0.2115 - val_accuracy: 0.9218\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0932 - accuracy: 0.9655 - val_loss: 0.1799 - val_accuracy: 0.9284\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0930 - accuracy: 0.9656 - val_loss: 0.2020 - val_accuracy: 0.9208\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0884 - accuracy: 0.9672 - val_loss: 0.2018 - val_accuracy: 0.9200\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1005 - accuracy: 0.9623 - val_loss: 0.2157 - val_accuracy: 0.9268\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0881 - accuracy: 0.9670 - val_loss: 0.1858 - val_accuracy: 0.9286\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0969 - accuracy: 0.9655 - val_loss: 0.2079 - val_accuracy: 0.9088\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0873 - accuracy: 0.9678 - val_loss: 0.2663 - val_accuracy: 0.8961\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0809 - accuracy: 0.9705 - val_loss: 0.2168 - val_accuracy: 0.9200\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0810 - accuracy: 0.9700 - val_loss: 0.1958 - val_accuracy: 0.9279\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.0795 - accuracy: 0.9706 - val_loss: 0.2072 - val_accuracy: 0.9319\n",
      "Epoch 80/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0758 - accuracy: 0.9728 - val_loss: 0.3181 - val_accuracy: 0.8904\n",
      "Epoch 81/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0796 - accuracy: 0.9710 - val_loss: 0.1940 - val_accuracy: 0.9300\n",
      "Epoch 82/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0844 - accuracy: 0.9687 - val_loss: 0.2440 - val_accuracy: 0.8987\n",
      "Epoch 83/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0770 - accuracy: 0.9720 - val_loss: 0.2217 - val_accuracy: 0.9248\n",
      "Epoch 84/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0684 - accuracy: 0.9755 - val_loss: 0.2497 - val_accuracy: 0.9161\n",
      "Epoch 85/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0663 - accuracy: 0.9763 - val_loss: 0.2108 - val_accuracy: 0.9287\n",
      "Epoch 86/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0811 - accuracy: 0.9690 - val_loss: 0.2475 - val_accuracy: 0.9184\n",
      "Epoch 87/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0620 - accuracy: 0.9773 - val_loss: 0.2515 - val_accuracy: 0.9188\n",
      "Epoch 88/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0575 - accuracy: 0.9795 - val_loss: 0.2036 - val_accuracy: 0.9383\n",
      "Epoch 89/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0670 - accuracy: 0.9751 - val_loss: 0.3892 - val_accuracy: 0.8888\n",
      "Epoch 90/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0654 - accuracy: 0.9758 - val_loss: 0.2025 - val_accuracy: 0.9305\n",
      "Epoch 91/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0564 - accuracy: 0.9795 - val_loss: 0.3220 - val_accuracy: 0.9044\n",
      "Epoch 92/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0630 - accuracy: 0.9767 - val_loss: 0.2296 - val_accuracy: 0.9252\n",
      "Epoch 93/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0556 - accuracy: 0.9801 - val_loss: 0.2457 - val_accuracy: 0.9167\n",
      "Epoch 94/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0675 - accuracy: 0.9754 - val_loss: 0.1764 - val_accuracy: 0.9383\n",
      "Epoch 95/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0549 - accuracy: 0.9796 - val_loss: 0.1905 - val_accuracy: 0.9415\n",
      "Epoch 96/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0711 - accuracy: 0.9737 - val_loss: 0.2119 - val_accuracy: 0.9307\n",
      "Epoch 97/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0784 - accuracy: 0.9710 - val_loss: 0.2696 - val_accuracy: 0.8996\n",
      "Epoch 98/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0677 - accuracy: 0.9745 - val_loss: 0.2056 - val_accuracy: 0.9264\n",
      "Epoch 99/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0504 - accuracy: 0.9823 - val_loss: 0.2325 - val_accuracy: 0.9316\n",
      "Epoch 100/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0545 - accuracy: 0.9802 - val_loss: 0.2527 - val_accuracy: 0.9275\n",
      "Epoch 101/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0609 - accuracy: 0.9782 - val_loss: 0.1769 - val_accuracy: 0.9389\n",
      "Epoch 102/500\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.0432 - accuracy: 0.9854 - val_loss: 0.2427 - val_accuracy: 0.9277\n",
      "Epoch 103/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0473 - accuracy: 0.9825 - val_loss: 0.1865 - val_accuracy: 0.9407\n",
      "Epoch 104/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0426 - accuracy: 0.9844 - val_loss: 0.2492 - val_accuracy: 0.9133\n",
      "Epoch 105/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0422 - accuracy: 0.9845 - val_loss: 0.1977 - val_accuracy: 0.9398\n",
      "Epoch 106/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0555 - accuracy: 0.9794 - val_loss: 0.1837 - val_accuracy: 0.9387\n",
      "Epoch 107/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0454 - accuracy: 0.9837 - val_loss: 0.2258 - val_accuracy: 0.9282\n",
      "Epoch 108/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0491 - accuracy: 0.9832 - val_loss: 0.1964 - val_accuracy: 0.9415\n",
      "Epoch 109/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0377 - accuracy: 0.9865 - val_loss: 0.2351 - val_accuracy: 0.9248\n",
      "Epoch 110/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0466 - accuracy: 0.9834 - val_loss: 0.2045 - val_accuracy: 0.9391\n",
      "Epoch 111/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0492 - accuracy: 0.9825 - val_loss: 0.2051 - val_accuracy: 0.9307\n",
      "Epoch 112/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0364 - accuracy: 0.9870 - val_loss: 0.2905 - val_accuracy: 0.9211\n",
      "Epoch 113/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0633 - accuracy: 0.9775 - val_loss: 0.1710 - val_accuracy: 0.9494\n",
      "Epoch 114/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0426 - accuracy: 0.9847 - val_loss: 0.1986 - val_accuracy: 0.9359\n",
      "Epoch 115/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0437 - accuracy: 0.9843 - val_loss: 0.1547 - val_accuracy: 0.9444\n",
      "Epoch 116/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0573 - accuracy: 0.9796 - val_loss: 0.2187 - val_accuracy: 0.9433\n",
      "Epoch 117/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2277 - accuracy: 0.9028 - val_loss: 0.3341 - val_accuracy: 0.8298\n",
      "Epoch 118/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2700 - accuracy: 0.8764 - val_loss: 0.3364 - val_accuracy: 0.8250\n",
      "Epoch 119/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2296 - accuracy: 0.9035 - val_loss: 0.3472 - val_accuracy: 0.8506\n",
      "Epoch 120/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1900 - accuracy: 0.9287 - val_loss: 0.2575 - val_accuracy: 0.8840\n",
      "Epoch 121/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1608 - accuracy: 0.9422 - val_loss: 0.3102 - val_accuracy: 0.8696\n",
      "Epoch 122/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1521 - accuracy: 0.9415 - val_loss: 0.3307 - val_accuracy: 0.8474\n",
      "Epoch 123/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1379 - accuracy: 0.9493 - val_loss: 0.2472 - val_accuracy: 0.8902\n",
      "Epoch 124/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1305 - accuracy: 0.9499 - val_loss: 0.2391 - val_accuracy: 0.8985\n",
      "Epoch 125/500\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1141 - accuracy: 0.9572 - val_loss: 0.1807 - val_accuracy: 0.9206\n",
      "Epoch 126/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1102 - accuracy: 0.9588 - val_loss: 0.1920 - val_accuracy: 0.9147\n",
      "Epoch 127/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1185 - accuracy: 0.9569 - val_loss: 0.2349 - val_accuracy: 0.8946\n",
      "Epoch 128/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1297 - accuracy: 0.9508 - val_loss: 0.1645 - val_accuracy: 0.9291\n",
      "Epoch 129/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1137 - accuracy: 0.9569 - val_loss: 0.1754 - val_accuracy: 0.9284\n",
      "Epoch 130/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1116 - accuracy: 0.9560 - val_loss: 0.1797 - val_accuracy: 0.9222\n",
      "Epoch 131/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1062 - accuracy: 0.9597 - val_loss: 0.1537 - val_accuracy: 0.9250\n",
      "Epoch 132/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1530 - accuracy: 0.9438 - val_loss: 0.2573 - val_accuracy: 0.8891\n",
      "Epoch 133/500\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1275 - accuracy: 0.9546Restoring model weights from the end of the best epoch: 113.\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1275 - accuracy: 0.9546 - val_loss: 0.1988 - val_accuracy: 0.9138\n",
      "Epoch 133: early stopping\n",
      "Number of iterations 5\n",
      "F1-scores:  [0.8679624664879356, 0.8810902896081771, 0.8065201984408221, 0.8839741408642394, 0.9016223679668622]\n",
      "Average F1-Score 0.8682338926736073\n",
      "Std Dev F1-Score 0.03266951596115921\n",
      "Error bar F1-Score 0.014610251696233274\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 14s 27ms/step - loss: 0.5749 - accuracy: 0.6978 - val_loss: 0.4429 - val_accuracy: 0.7578\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.5412 - accuracy: 0.7062 - val_loss: 0.4329 - val_accuracy: 0.7845\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.5404 - accuracy: 0.7051 - val_loss: 0.4229 - val_accuracy: 0.7838\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.5374 - accuracy: 0.7094 - val_loss: 0.4170 - val_accuracy: 0.7914\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5343 - accuracy: 0.7106 - val_loss: 0.4195 - val_accuracy: 0.7925\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.5316 - accuracy: 0.7158 - val_loss: 0.4107 - val_accuracy: 0.8022\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.5263 - accuracy: 0.7171 - val_loss: 0.4170 - val_accuracy: 0.7839\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.5082 - accuracy: 0.7206 - val_loss: 0.3824 - val_accuracy: 0.7955\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.4846 - accuracy: 0.7289 - val_loss: 0.3619 - val_accuracy: 0.8021\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.4580 - accuracy: 0.7502 - val_loss: 0.3318 - val_accuracy: 0.8392\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.3967 - accuracy: 0.8057 - val_loss: 0.4131 - val_accuracy: 0.7935\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.3107 - accuracy: 0.8614 - val_loss: 0.4635 - val_accuracy: 0.7740\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2689 - accuracy: 0.8810 - val_loss: 0.3950 - val_accuracy: 0.8207\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2433 - accuracy: 0.8925 - val_loss: 0.2558 - val_accuracy: 0.8857\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2319 - accuracy: 0.8989 - val_loss: 0.2502 - val_accuracy: 0.8870\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.2256 - accuracy: 0.9004 - val_loss: 0.3109 - val_accuracy: 0.8669\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2257 - accuracy: 0.9007 - val_loss: 0.2610 - val_accuracy: 0.8664\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2155 - accuracy: 0.9031 - val_loss: 0.2797 - val_accuracy: 0.8801\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2056 - accuracy: 0.9122 - val_loss: 0.2286 - val_accuracy: 0.8991\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1918 - accuracy: 0.9167 - val_loss: 0.3037 - val_accuracy: 0.8733\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1915 - accuracy: 0.9173 - val_loss: 0.2865 - val_accuracy: 0.8815\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1873 - accuracy: 0.9172 - val_loss: 0.3023 - val_accuracy: 0.8685\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1788 - accuracy: 0.9239 - val_loss: 0.3242 - val_accuracy: 0.8689\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1707 - accuracy: 0.9292 - val_loss: 0.2393 - val_accuracy: 0.8918\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1727 - accuracy: 0.9254 - val_loss: 0.2222 - val_accuracy: 0.9005\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1680 - accuracy: 0.9286 - val_loss: 0.3095 - val_accuracy: 0.8660\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1590 - accuracy: 0.9323 - val_loss: 0.2047 - val_accuracy: 0.9085\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1628 - accuracy: 0.9340 - val_loss: 0.3905 - val_accuracy: 0.8104\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1658 - accuracy: 0.9307 - val_loss: 0.2735 - val_accuracy: 0.8889\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1554 - accuracy: 0.9337 - val_loss: 0.2925 - val_accuracy: 0.8829\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1463 - accuracy: 0.9399 - val_loss: 0.2321 - val_accuracy: 0.9042\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1499 - accuracy: 0.9394 - val_loss: 0.2443 - val_accuracy: 0.9019\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1428 - accuracy: 0.9400 - val_loss: 0.2291 - val_accuracy: 0.9014\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1347 - accuracy: 0.9459 - val_loss: 0.2926 - val_accuracy: 0.8820\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1465 - accuracy: 0.9390 - val_loss: 0.2485 - val_accuracy: 0.9000\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1344 - accuracy: 0.9445 - val_loss: 0.2562 - val_accuracy: 0.8975\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1299 - accuracy: 0.9476 - val_loss: 0.2092 - val_accuracy: 0.9131\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1357 - accuracy: 0.9445 - val_loss: 0.2254 - val_accuracy: 0.9074\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1272 - accuracy: 0.9489 - val_loss: 0.2026 - val_accuracy: 0.9115\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1235 - accuracy: 0.9502 - val_loss: 0.2468 - val_accuracy: 0.9025\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1196 - accuracy: 0.9506 - val_loss: 0.3318 - val_accuracy: 0.8575\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1382 - accuracy: 0.9415 - val_loss: 0.2205 - val_accuracy: 0.9103\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1155 - accuracy: 0.9540 - val_loss: 0.3701 - val_accuracy: 0.8479\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1220 - accuracy: 0.9493 - val_loss: 0.2137 - val_accuracy: 0.9142\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1141 - accuracy: 0.9538 - val_loss: 0.2618 - val_accuracy: 0.9026\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1211 - accuracy: 0.9525 - val_loss: 0.2287 - val_accuracy: 0.9057\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1062 - accuracy: 0.9582 - val_loss: 0.2361 - val_accuracy: 0.9115\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1069 - accuracy: 0.9586 - val_loss: 0.2124 - val_accuracy: 0.9168\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1063 - accuracy: 0.9589 - val_loss: 0.2502 - val_accuracy: 0.9030\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1098 - accuracy: 0.9562 - val_loss: 0.2076 - val_accuracy: 0.9184\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1014 - accuracy: 0.9593 - val_loss: 0.2746 - val_accuracy: 0.8895\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0997 - accuracy: 0.9605 - val_loss: 0.2206 - val_accuracy: 0.9108\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1013 - accuracy: 0.9621 - val_loss: 0.2282 - val_accuracy: 0.9094\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0908 - accuracy: 0.9655 - val_loss: 0.2776 - val_accuracy: 0.8897\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0933 - accuracy: 0.9629 - val_loss: 0.3323 - val_accuracy: 0.8717\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1016 - accuracy: 0.9602 - val_loss: 0.1889 - val_accuracy: 0.9261\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1026 - accuracy: 0.9582 - val_loss: 0.3282 - val_accuracy: 0.8747\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0853 - accuracy: 0.9671 - val_loss: 0.2615 - val_accuracy: 0.9044\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0870 - accuracy: 0.9657 - val_loss: 0.2249 - val_accuracy: 0.9156\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0881 - accuracy: 0.9654 - val_loss: 0.2781 - val_accuracy: 0.9019\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0751 - accuracy: 0.9710 - val_loss: 0.2515 - val_accuracy: 0.9170\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0831 - accuracy: 0.9680 - val_loss: 0.3257 - val_accuracy: 0.8865\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0746 - accuracy: 0.9719 - val_loss: 0.2556 - val_accuracy: 0.9138\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0784 - accuracy: 0.9701 - val_loss: 0.2849 - val_accuracy: 0.9060\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0751 - accuracy: 0.9698 - val_loss: 0.2915 - val_accuracy: 0.9012\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0877 - accuracy: 0.9669 - val_loss: 0.2525 - val_accuracy: 0.9058\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0705 - accuracy: 0.9721 - val_loss: 0.2340 - val_accuracy: 0.9225\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0678 - accuracy: 0.9737 - val_loss: 0.2535 - val_accuracy: 0.9234\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0738 - accuracy: 0.9724 - val_loss: 0.2291 - val_accuracy: 0.9231\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0755 - accuracy: 0.9718 - val_loss: 0.2559 - val_accuracy: 0.9133\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0666 - accuracy: 0.9746 - val_loss: 0.2360 - val_accuracy: 0.9190\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0628 - accuracy: 0.9761 - val_loss: 0.2466 - val_accuracy: 0.9156\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0763 - accuracy: 0.9722 - val_loss: 0.3255 - val_accuracy: 0.8879\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0782 - accuracy: 0.9711 - val_loss: 0.2203 - val_accuracy: 0.9264\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0648 - accuracy: 0.9766 - val_loss: 0.2952 - val_accuracy: 0.9069\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0844 - accuracy: 0.9687 - val_loss: 0.3184 - val_accuracy: 0.9017\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0597 - accuracy: 0.9776 - val_loss: 0.2593 - val_accuracy: 0.9204\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0763 - accuracy: 0.9713 - val_loss: 0.2634 - val_accuracy: 0.9154\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0587 - accuracy: 0.9788 - val_loss: 0.3816 - val_accuracy: 0.8717\n",
      "Epoch 80/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0636 - accuracy: 0.9766 - val_loss: 0.2581 - val_accuracy: 0.9163\n",
      "Epoch 81/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0534 - accuracy: 0.9800 - val_loss: 0.2424 - val_accuracy: 0.9197\n",
      "Epoch 82/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0763 - accuracy: 0.9718 - val_loss: 0.2128 - val_accuracy: 0.9296\n",
      "Epoch 83/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0491 - accuracy: 0.9826 - val_loss: 0.3107 - val_accuracy: 0.9049\n",
      "Epoch 84/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0629 - accuracy: 0.9766 - val_loss: 0.4465 - val_accuracy: 0.8742\n",
      "Epoch 85/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1186 - accuracy: 0.9558 - val_loss: 0.2140 - val_accuracy: 0.9248\n",
      "Epoch 86/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0560 - accuracy: 0.9795 - val_loss: 0.2781 - val_accuracy: 0.9124\n",
      "Epoch 87/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0612 - accuracy: 0.9767 - val_loss: 0.2289 - val_accuracy: 0.9286\n",
      "Epoch 88/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0437 - accuracy: 0.9840 - val_loss: 0.2809 - val_accuracy: 0.9213\n",
      "Epoch 89/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0621 - accuracy: 0.9767 - val_loss: 0.2672 - val_accuracy: 0.9264\n",
      "Epoch 90/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0621 - accuracy: 0.9768 - val_loss: 0.2452 - val_accuracy: 0.9259\n",
      "Epoch 91/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0561 - accuracy: 0.9794 - val_loss: 0.2604 - val_accuracy: 0.9103\n",
      "Epoch 92/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0549 - accuracy: 0.9797 - val_loss: 0.2681 - val_accuracy: 0.9236\n",
      "Epoch 93/500\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.0433 - accuracy: 0.9837 - val_loss: 0.2523 - val_accuracy: 0.9296\n",
      "Epoch 94/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0637 - accuracy: 0.9749 - val_loss: 0.2336 - val_accuracy: 0.9296\n",
      "Epoch 95/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0492 - accuracy: 0.9831 - val_loss: 0.4053 - val_accuracy: 0.8900\n",
      "Epoch 96/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0654 - accuracy: 0.9761 - val_loss: 0.2423 - val_accuracy: 0.9300\n",
      "Epoch 97/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0494 - accuracy: 0.9810 - val_loss: 0.3748 - val_accuracy: 0.8870\n",
      "Epoch 98/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.0483 - accuracy: 0.9820 - val_loss: 0.2910 - val_accuracy: 0.9238\n",
      "Epoch 99/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0428 - accuracy: 0.9842 - val_loss: 0.2929 - val_accuracy: 0.9156\n",
      "Epoch 100/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0567 - accuracy: 0.9791 - val_loss: 0.2594 - val_accuracy: 0.9215\n",
      "Epoch 101/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0680 - accuracy: 0.9747 - val_loss: 0.2434 - val_accuracy: 0.9264\n",
      "Epoch 102/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0443 - accuracy: 0.9840 - val_loss: 0.2689 - val_accuracy: 0.9131\n",
      "Epoch 103/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0505 - accuracy: 0.9819 - val_loss: 0.2564 - val_accuracy: 0.9240\n",
      "Epoch 104/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0367 - accuracy: 0.9855 - val_loss: 0.2842 - val_accuracy: 0.9252\n",
      "Epoch 105/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0443 - accuracy: 0.9844 - val_loss: 0.2794 - val_accuracy: 0.9256\n",
      "Epoch 106/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0486 - accuracy: 0.9819 - val_loss: 0.2939 - val_accuracy: 0.9083\n",
      "Epoch 107/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0581 - accuracy: 0.9784 - val_loss: 0.2711 - val_accuracy: 0.9229\n",
      "Epoch 108/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0434 - accuracy: 0.9845 - val_loss: 0.2813 - val_accuracy: 0.9197\n",
      "Epoch 109/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0557 - accuracy: 0.9805 - val_loss: 0.2386 - val_accuracy: 0.9289\n",
      "Epoch 110/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0768 - accuracy: 0.9712 - val_loss: 0.2614 - val_accuracy: 0.9240\n",
      "Epoch 111/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0471 - accuracy: 0.9850 - val_loss: 0.3708 - val_accuracy: 0.8826\n",
      "Epoch 112/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0420 - accuracy: 0.9850 - val_loss: 0.2452 - val_accuracy: 0.9314\n",
      "Epoch 113/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0412 - accuracy: 0.9847 - val_loss: 0.2687 - val_accuracy: 0.9287\n",
      "Epoch 114/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0349 - accuracy: 0.9877 - val_loss: 0.2825 - val_accuracy: 0.9248\n",
      "Epoch 115/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0382 - accuracy: 0.9862 - val_loss: 0.2805 - val_accuracy: 0.9261\n",
      "Epoch 116/500\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.0477 - accuracy: 0.9828 - val_loss: 0.2476 - val_accuracy: 0.9240\n",
      "Epoch 117/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0393 - accuracy: 0.9859 - val_loss: 0.3088 - val_accuracy: 0.9092\n",
      "Epoch 118/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0452 - accuracy: 0.9830 - val_loss: 0.2475 - val_accuracy: 0.9280\n",
      "Epoch 119/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0263 - accuracy: 0.9911 - val_loss: 0.2848 - val_accuracy: 0.9266\n",
      "Epoch 120/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0689 - accuracy: 0.9749 - val_loss: 0.2563 - val_accuracy: 0.9181\n",
      "Epoch 121/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0352 - accuracy: 0.9880 - val_loss: 0.4270 - val_accuracy: 0.8898\n",
      "Epoch 122/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0524 - accuracy: 0.9804 - val_loss: 0.2545 - val_accuracy: 0.9280\n",
      "Epoch 123/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0259 - accuracy: 0.9907 - val_loss: 0.2856 - val_accuracy: 0.9305\n",
      "Epoch 124/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1423 - accuracy: 0.9454 - val_loss: 0.4332 - val_accuracy: 0.8008\n",
      "Epoch 125/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.3270 - accuracy: 0.8528 - val_loss: 0.3236 - val_accuracy: 0.8468\n",
      "Epoch 126/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2234 - accuracy: 0.9057 - val_loss: 0.2396 - val_accuracy: 0.8921\n",
      "Epoch 127/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1742 - accuracy: 0.9302 - val_loss: 0.2606 - val_accuracy: 0.8786\n",
      "Epoch 128/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1606 - accuracy: 0.9373 - val_loss: 0.2688 - val_accuracy: 0.8973\n",
      "Epoch 129/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1210 - accuracy: 0.9551 - val_loss: 0.3059 - val_accuracy: 0.8905\n",
      "Epoch 130/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1145 - accuracy: 0.9572 - val_loss: 0.2425 - val_accuracy: 0.9069\n",
      "Epoch 131/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1038 - accuracy: 0.9626 - val_loss: 0.2259 - val_accuracy: 0.9129\n",
      "Epoch 132/500\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1271 - accuracy: 0.9519Restoring model weights from the end of the best epoch: 112.\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1269 - accuracy: 0.9520 - val_loss: 0.2758 - val_accuracy: 0.8984\n",
      "Epoch 132: early stopping\n",
      "Number of iterations 6\n",
      "F1-scores:  [0.8679624664879356, 0.8810902896081771, 0.8065201984408221, 0.8839741408642394, 0.9016223679668622, 0.8689748811948406]\n",
      "Average F1-Score 0.8683573907604795\n",
      "Std Dev F1-Score 0.029824329886313772\n",
      "Error bar F1-Score 0.012175731690317897\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 13s 25ms/step - loss: 0.5758 - accuracy: 0.6995 - val_loss: 0.4888 - val_accuracy: 0.7578\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.5490 - accuracy: 0.6992 - val_loss: 0.4226 - val_accuracy: 0.7578\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5405 - accuracy: 0.7071 - val_loss: 0.4529 - val_accuracy: 0.7557\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.5372 - accuracy: 0.7107 - val_loss: 0.4228 - val_accuracy: 0.7695\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.5327 - accuracy: 0.7131 - val_loss: 0.4095 - val_accuracy: 0.7871\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.5304 - accuracy: 0.7167 - val_loss: 0.4233 - val_accuracy: 0.7878\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.5210 - accuracy: 0.7197 - val_loss: 0.3968 - val_accuracy: 0.7887\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.5051 - accuracy: 0.7271 - val_loss: 0.3980 - val_accuracy: 0.7761\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.4790 - accuracy: 0.7361 - val_loss: 0.3475 - val_accuracy: 0.8301\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.4487 - accuracy: 0.7568 - val_loss: 0.3745 - val_accuracy: 0.7878\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.3924 - accuracy: 0.8067 - val_loss: 0.3284 - val_accuracy: 0.8312\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.3390 - accuracy: 0.8427 - val_loss: 0.3513 - val_accuracy: 0.8085\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2888 - accuracy: 0.8682 - val_loss: 0.3313 - val_accuracy: 0.8310\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2418 - accuracy: 0.8926 - val_loss: 0.3377 - val_accuracy: 0.8475\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2238 - accuracy: 0.9012 - val_loss: 0.2660 - val_accuracy: 0.8774\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2216 - accuracy: 0.9031 - val_loss: 0.3449 - val_accuracy: 0.8367\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2107 - accuracy: 0.9097 - val_loss: 0.2986 - val_accuracy: 0.8605\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2004 - accuracy: 0.9149 - val_loss: 0.2681 - val_accuracy: 0.8749\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.3909 - accuracy: 0.8032 - val_loss: 0.2850 - val_accuracy: 0.8586\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2011 - accuracy: 0.9135 - val_loss: 0.2583 - val_accuracy: 0.8875\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1976 - accuracy: 0.9138 - val_loss: 0.3778 - val_accuracy: 0.8387\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1828 - accuracy: 0.9213 - val_loss: 0.3477 - val_accuracy: 0.8419\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1777 - accuracy: 0.9240 - val_loss: 0.2484 - val_accuracy: 0.8952\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1781 - accuracy: 0.9246 - val_loss: 0.4179 - val_accuracy: 0.8177\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1718 - accuracy: 0.9256 - val_loss: 0.2725 - val_accuracy: 0.8717\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2098 - accuracy: 0.9134 - val_loss: 0.3320 - val_accuracy: 0.8491\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2084 - accuracy: 0.9139 - val_loss: 0.2684 - val_accuracy: 0.8794\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1587 - accuracy: 0.9343 - val_loss: 0.2913 - val_accuracy: 0.8781\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1881 - accuracy: 0.9193 - val_loss: 0.2776 - val_accuracy: 0.8744\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1480 - accuracy: 0.9402 - val_loss: 0.2547 - val_accuracy: 0.8884\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1971 - accuracy: 0.9162 - val_loss: 0.3075 - val_accuracy: 0.8639\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2243 - accuracy: 0.8991 - val_loss: 0.2708 - val_accuracy: 0.8770\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1842 - accuracy: 0.9210 - val_loss: 0.3000 - val_accuracy: 0.8778\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 5s 19ms/step - loss: 0.1600 - accuracy: 0.9340 - val_loss: 0.2493 - val_accuracy: 0.8955\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1488 - accuracy: 0.9400 - val_loss: 0.3160 - val_accuracy: 0.8730\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1410 - accuracy: 0.9438 - val_loss: 0.2951 - val_accuracy: 0.8756\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1438 - accuracy: 0.9415 - val_loss: 0.2725 - val_accuracy: 0.8843\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1347 - accuracy: 0.9446 - val_loss: 0.2411 - val_accuracy: 0.9017\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1305 - accuracy: 0.9473 - val_loss: 0.2491 - val_accuracy: 0.9026\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1316 - accuracy: 0.9478 - val_loss: 0.2538 - val_accuracy: 0.8971\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1306 - accuracy: 0.9481 - val_loss: 0.3139 - val_accuracy: 0.8740\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1254 - accuracy: 0.9496 - val_loss: 0.2852 - val_accuracy: 0.8897\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1257 - accuracy: 0.9491 - val_loss: 0.2025 - val_accuracy: 0.9144\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1234 - accuracy: 0.9502 - val_loss: 0.2794 - val_accuracy: 0.8941\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1226 - accuracy: 0.9507 - val_loss: 0.2841 - val_accuracy: 0.8873\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1131 - accuracy: 0.9543 - val_loss: 0.2064 - val_accuracy: 0.9215\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1266 - accuracy: 0.9498 - val_loss: 0.2654 - val_accuracy: 0.8946\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1178 - accuracy: 0.9535 - val_loss: 0.3175 - val_accuracy: 0.8746\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1116 - accuracy: 0.9568 - val_loss: 0.2408 - val_accuracy: 0.9115\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1058 - accuracy: 0.9584 - val_loss: 0.2073 - val_accuracy: 0.9193\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1062 - accuracy: 0.9593 - val_loss: 0.2611 - val_accuracy: 0.9028\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1136 - accuracy: 0.9561 - val_loss: 0.2463 - val_accuracy: 0.9003\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1056 - accuracy: 0.9593 - val_loss: 0.3189 - val_accuracy: 0.8827\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1359 - accuracy: 0.9463 - val_loss: 0.2173 - val_accuracy: 0.9165\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.0973 - accuracy: 0.9624 - val_loss: 0.2285 - val_accuracy: 0.9088\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1628 - accuracy: 0.9355 - val_loss: 0.3771 - val_accuracy: 0.8406\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2215 - accuracy: 0.9051 - val_loss: 0.3074 - val_accuracy: 0.8682\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.4856 - accuracy: 0.7426 - val_loss: 0.3359 - val_accuracy: 0.8383\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.3931 - accuracy: 0.8093 - val_loss: 0.3380 - val_accuracy: 0.8438\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2951 - accuracy: 0.8665 - val_loss: 0.3263 - val_accuracy: 0.8484\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2468 - accuracy: 0.8923 - val_loss: 0.2657 - val_accuracy: 0.8810\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2340 - accuracy: 0.8987 - val_loss: 0.2587 - val_accuracy: 0.8868\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2363 - accuracy: 0.8972 - val_loss: 0.3826 - val_accuracy: 0.8182\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2185 - accuracy: 0.9033 - val_loss: 0.2848 - val_accuracy: 0.8754\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.2056 - accuracy: 0.9107 - val_loss: 0.2590 - val_accuracy: 0.8893\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1933 - accuracy: 0.9155Restoring model weights from the end of the best epoch: 46.\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1933 - accuracy: 0.9155 - val_loss: 0.2518 - val_accuracy: 0.8941\n",
      "Epoch 66: early stopping\n",
      "Number of iterations 7\n",
      "F1-scores:  [0.8679624664879356, 0.8810902896081771, 0.8065201984408221, 0.8839741408642394, 0.9016223679668622, 0.8689748811948406, 0.8498641304347827]\n",
      "Average F1-Score 0.865715496428237\n",
      "Std Dev F1-Score 0.028360151512895854\n",
      "Error bar F1-Score 0.01071912972103352\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 14s 25ms/step - loss: 0.5772 - accuracy: 0.6973 - val_loss: 0.4467 - val_accuracy: 0.7578\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5427 - accuracy: 0.7007 - val_loss: 0.4224 - val_accuracy: 0.7740\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5257 - accuracy: 0.7094 - val_loss: 0.3776 - val_accuracy: 0.7624\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.5340 - accuracy: 0.7104 - val_loss: 0.4143 - val_accuracy: 0.7770\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5351 - accuracy: 0.7092 - val_loss: 0.4453 - val_accuracy: 0.7822\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.5339 - accuracy: 0.7111 - val_loss: 0.3998 - val_accuracy: 0.7887\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.4521 - accuracy: 0.7532 - val_loss: 0.3226 - val_accuracy: 0.8317\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.3529 - accuracy: 0.8326 - val_loss: 0.3862 - val_accuracy: 0.7966\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.3175 - accuracy: 0.8511 - val_loss: 0.3583 - val_accuracy: 0.8102\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2871 - accuracy: 0.8677 - val_loss: 0.3590 - val_accuracy: 0.8156\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2798 - accuracy: 0.8728 - val_loss: 0.2983 - val_accuracy: 0.8539\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2780 - accuracy: 0.8741 - val_loss: 0.3339 - val_accuracy: 0.8372\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2688 - accuracy: 0.8781 - val_loss: 0.4923 - val_accuracy: 0.7564\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2657 - accuracy: 0.8800 - val_loss: 0.3670 - val_accuracy: 0.8253\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2699 - accuracy: 0.8783 - val_loss: 0.3341 - val_accuracy: 0.8323\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2542 - accuracy: 0.8841 - val_loss: 0.3164 - val_accuracy: 0.8438\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2842 - accuracy: 0.8727 - val_loss: 0.2940 - val_accuracy: 0.8470\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2650 - accuracy: 0.8757 - val_loss: 0.2940 - val_accuracy: 0.8532\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.2557 - accuracy: 0.8772 - val_loss: 0.3020 - val_accuracy: 0.8371\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2654 - accuracy: 0.8725 - val_loss: 0.4092 - val_accuracy: 0.7807\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2603 - accuracy: 0.8760 - val_loss: 0.3327 - val_accuracy: 0.8374\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2495 - accuracy: 0.8819 - val_loss: 0.3895 - val_accuracy: 0.8008\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2586 - accuracy: 0.8760 - val_loss: 0.3476 - val_accuracy: 0.8268\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2549 - accuracy: 0.8790 - val_loss: 0.3055 - val_accuracy: 0.8538\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2640 - accuracy: 0.8772 - val_loss: 0.4509 - val_accuracy: 0.7910\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2568 - accuracy: 0.8769 - val_loss: 0.2759 - val_accuracy: 0.8447\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2577 - accuracy: 0.8794 - val_loss: 0.3034 - val_accuracy: 0.8401\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2503 - accuracy: 0.8812 - val_loss: 0.2860 - val_accuracy: 0.8470\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2556 - accuracy: 0.8797 - val_loss: 0.2906 - val_accuracy: 0.8433\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2611 - accuracy: 0.8808 - val_loss: 0.3214 - val_accuracy: 0.8362\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2482 - accuracy: 0.8838 - val_loss: 0.2826 - val_accuracy: 0.8554\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2486 - accuracy: 0.8871 - val_loss: 0.3456 - val_accuracy: 0.8266\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2327 - accuracy: 0.8978 - val_loss: 0.2818 - val_accuracy: 0.8674\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2280 - accuracy: 0.9040 - val_loss: 0.2877 - val_accuracy: 0.8669\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2418 - accuracy: 0.8919 - val_loss: 0.3683 - val_accuracy: 0.8218\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2278 - accuracy: 0.9057 - val_loss: 0.3126 - val_accuracy: 0.8643\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2149 - accuracy: 0.9131 - val_loss: 0.2631 - val_accuracy: 0.8854\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2112 - accuracy: 0.9166 - val_loss: 0.2732 - val_accuracy: 0.8850\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2007 - accuracy: 0.9230 - val_loss: 0.3091 - val_accuracy: 0.8573\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2081 - accuracy: 0.9203 - val_loss: 0.2928 - val_accuracy: 0.8705\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1710 - accuracy: 0.9381 - val_loss: 0.2919 - val_accuracy: 0.8799\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1933 - accuracy: 0.9269 - val_loss: 0.2813 - val_accuracy: 0.8822\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1757 - accuracy: 0.9351 - val_loss: 0.2464 - val_accuracy: 0.9005\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1769 - accuracy: 0.9337 - val_loss: 0.2577 - val_accuracy: 0.8895\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2688 - accuracy: 0.8811 - val_loss: 0.2892 - val_accuracy: 0.8491\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2724 - accuracy: 0.8732 - val_loss: 0.3513 - val_accuracy: 0.8250\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2393 - accuracy: 0.8872 - val_loss: 0.3490 - val_accuracy: 0.8255\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.2251 - accuracy: 0.9114 - val_loss: 0.3190 - val_accuracy: 0.8696\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1797 - accuracy: 0.9334 - val_loss: 0.2976 - val_accuracy: 0.8808\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1689 - accuracy: 0.9387 - val_loss: 0.3232 - val_accuracy: 0.8520\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1452 - accuracy: 0.9482 - val_loss: 0.2699 - val_accuracy: 0.8866\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1642 - accuracy: 0.9401 - val_loss: 0.2869 - val_accuracy: 0.8719\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1473 - accuracy: 0.9469 - val_loss: 0.2792 - val_accuracy: 0.8792\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1314 - accuracy: 0.9529 - val_loss: 0.2341 - val_accuracy: 0.9003\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1469 - accuracy: 0.9461 - val_loss: 0.2371 - val_accuracy: 0.9037\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1477 - accuracy: 0.9454 - val_loss: 0.2905 - val_accuracy: 0.8728\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1364 - accuracy: 0.9506 - val_loss: 0.2307 - val_accuracy: 0.9072\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1490 - accuracy: 0.9454 - val_loss: 0.2108 - val_accuracy: 0.9069\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1317 - accuracy: 0.9522 - val_loss: 0.2003 - val_accuracy: 0.9136\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1265 - accuracy: 0.9545 - val_loss: 0.2232 - val_accuracy: 0.9028\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1333 - accuracy: 0.9517 - val_loss: 0.1929 - val_accuracy: 0.9181\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1282 - accuracy: 0.9542 - val_loss: 0.2159 - val_accuracy: 0.9053\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1292 - accuracy: 0.9528 - val_loss: 0.2242 - val_accuracy: 0.9046\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1310 - accuracy: 0.9515 - val_loss: 0.2013 - val_accuracy: 0.9080\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1566 - accuracy: 0.9427 - val_loss: 0.3192 - val_accuracy: 0.8683\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1976 - accuracy: 0.9171 - val_loss: 0.2007 - val_accuracy: 0.9044\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2914 - accuracy: 0.8781 - val_loss: 0.3145 - val_accuracy: 0.8429\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2516 - accuracy: 0.8809 - val_loss: 0.3135 - val_accuracy: 0.8372\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2662 - accuracy: 0.8754 - val_loss: 0.3151 - val_accuracy: 0.8387\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2624 - accuracy: 0.8777 - val_loss: 0.2993 - val_accuracy: 0.8445\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2451 - accuracy: 0.8882 - val_loss: 0.3278 - val_accuracy: 0.8481\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1837 - accuracy: 0.9296 - val_loss: 0.2756 - val_accuracy: 0.8790\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1437 - accuracy: 0.9484 - val_loss: 0.2057 - val_accuracy: 0.9087\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1310 - accuracy: 0.9531 - val_loss: 0.2108 - val_accuracy: 0.9060\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1794 - accuracy: 0.9322 - val_loss: 0.2449 - val_accuracy: 0.8811\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1224 - accuracy: 0.9564 - val_loss: 0.1908 - val_accuracy: 0.9161\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1395 - accuracy: 0.9483 - val_loss: 0.2368 - val_accuracy: 0.8868\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1214 - accuracy: 0.9555 - val_loss: 0.2102 - val_accuracy: 0.9190\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1241 - accuracy: 0.9541 - val_loss: 0.2120 - val_accuracy: 0.9055\n",
      "Epoch 80/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1244 - accuracy: 0.9552 - val_loss: 0.1978 - val_accuracy: 0.9151\n",
      "Epoch 81/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1261 - accuracy: 0.9537 - val_loss: 0.3308 - val_accuracy: 0.8333\n",
      "Epoch 82/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1241 - accuracy: 0.9549 - val_loss: 0.2035 - val_accuracy: 0.9103\n",
      "Epoch 83/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1186 - accuracy: 0.9567 - val_loss: 0.1964 - val_accuracy: 0.9156\n",
      "Epoch 84/500\n",
      "288/288 [==============================] - 6s 19ms/step - loss: 0.1171 - accuracy: 0.9560 - val_loss: 0.1745 - val_accuracy: 0.9195\n",
      "Epoch 85/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1189 - accuracy: 0.9560 - val_loss: 0.1904 - val_accuracy: 0.9147\n",
      "Epoch 86/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1358 - accuracy: 0.9486 - val_loss: 0.2062 - val_accuracy: 0.9069\n",
      "Epoch 87/500\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1355 - accuracy: 0.9496 - val_loss: 0.2208 - val_accuracy: 0.8996\n",
      "Epoch 88/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1102 - accuracy: 0.9573 - val_loss: 0.1735 - val_accuracy: 0.9193\n",
      "Epoch 89/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1726 - accuracy: 0.9321 - val_loss: 0.3287 - val_accuracy: 0.8491\n",
      "Epoch 90/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1712 - accuracy: 0.9357 - val_loss: 0.1920 - val_accuracy: 0.9085\n",
      "Epoch 91/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1424 - accuracy: 0.9495 - val_loss: 0.1904 - val_accuracy: 0.9088\n",
      "Epoch 92/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1177 - accuracy: 0.9567 - val_loss: 0.2029 - val_accuracy: 0.9115\n",
      "Epoch 93/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1105 - accuracy: 0.9585 - val_loss: 0.1716 - val_accuracy: 0.9273\n",
      "Epoch 94/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1168 - accuracy: 0.9548 - val_loss: 0.1698 - val_accuracy: 0.9273\n",
      "Epoch 95/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1166 - accuracy: 0.9567 - val_loss: 0.3193 - val_accuracy: 0.8753\n",
      "Epoch 96/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1249 - accuracy: 0.9523 - val_loss: 0.1660 - val_accuracy: 0.9227\n",
      "Epoch 97/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1083 - accuracy: 0.9589 - val_loss: 0.1525 - val_accuracy: 0.9240\n",
      "Epoch 98/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1101 - accuracy: 0.9572 - val_loss: 0.2182 - val_accuracy: 0.8868\n",
      "Epoch 99/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1145 - accuracy: 0.9575 - val_loss: 0.1707 - val_accuracy: 0.9193\n",
      "Epoch 100/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1331 - accuracy: 0.9482 - val_loss: 0.2230 - val_accuracy: 0.9120\n",
      "Epoch 101/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1300 - accuracy: 0.9496 - val_loss: 0.1696 - val_accuracy: 0.9161\n",
      "Epoch 102/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1944 - accuracy: 0.9238 - val_loss: 0.2001 - val_accuracy: 0.9067\n",
      "Epoch 103/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1489 - accuracy: 0.9465 - val_loss: 0.5169 - val_accuracy: 0.7754\n",
      "Epoch 104/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1879 - accuracy: 0.9232 - val_loss: 0.1769 - val_accuracy: 0.9053\n",
      "Epoch 105/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1180 - accuracy: 0.9557 - val_loss: 0.1807 - val_accuracy: 0.9222\n",
      "Epoch 106/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1225 - accuracy: 0.9546 - val_loss: 0.1592 - val_accuracy: 0.9286\n",
      "Epoch 107/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1133 - accuracy: 0.9562 - val_loss: 0.1620 - val_accuracy: 0.9268\n",
      "Epoch 108/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1483 - accuracy: 0.9450 - val_loss: 0.1780 - val_accuracy: 0.9206\n",
      "Epoch 109/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1187 - accuracy: 0.9554 - val_loss: 0.1705 - val_accuracy: 0.9192\n",
      "Epoch 110/500\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1141 - accuracy: 0.9565 - val_loss: 0.2189 - val_accuracy: 0.9016\n",
      "Epoch 111/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1340 - accuracy: 0.9497 - val_loss: 0.1685 - val_accuracy: 0.9261\n",
      "Epoch 112/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1024 - accuracy: 0.9609 - val_loss: 0.2231 - val_accuracy: 0.9186\n",
      "Epoch 113/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1398 - accuracy: 0.9465 - val_loss: 0.2845 - val_accuracy: 0.8678\n",
      "Epoch 114/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1059 - accuracy: 0.9588 - val_loss: 0.1643 - val_accuracy: 0.9224\n",
      "Epoch 115/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1018 - accuracy: 0.9618 - val_loss: 0.1942 - val_accuracy: 0.9199\n",
      "Epoch 116/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1048 - accuracy: 0.9580 - val_loss: 0.1513 - val_accuracy: 0.9353\n",
      "Epoch 117/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1036 - accuracy: 0.9594 - val_loss: 0.2063 - val_accuracy: 0.9218\n",
      "Epoch 118/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1053 - accuracy: 0.9594 - val_loss: 0.1481 - val_accuracy: 0.9376\n",
      "Epoch 119/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1040 - accuracy: 0.9599 - val_loss: 0.4724 - val_accuracy: 0.8211\n",
      "Epoch 120/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1176 - accuracy: 0.9545 - val_loss: 0.1540 - val_accuracy: 0.9334\n",
      "Epoch 121/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1120 - accuracy: 0.9554 - val_loss: 0.1757 - val_accuracy: 0.9268\n",
      "Epoch 122/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0956 - accuracy: 0.9623 - val_loss: 0.1573 - val_accuracy: 0.9341\n",
      "Epoch 123/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1390 - accuracy: 0.9488 - val_loss: 0.2410 - val_accuracy: 0.8950\n",
      "Epoch 124/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1137 - accuracy: 0.9576 - val_loss: 0.1772 - val_accuracy: 0.9176\n",
      "Epoch 125/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2777 - accuracy: 0.8741 - val_loss: 0.5635 - val_accuracy: 0.6855\n",
      "Epoch 126/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.3464 - accuracy: 0.8327 - val_loss: 0.3530 - val_accuracy: 0.8332\n",
      "Epoch 127/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1997 - accuracy: 0.9233 - val_loss: 0.2672 - val_accuracy: 0.8918\n",
      "Epoch 128/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2197 - accuracy: 0.9116 - val_loss: 0.3276 - val_accuracy: 0.8428\n",
      "Epoch 129/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2368 - accuracy: 0.9022 - val_loss: 0.2637 - val_accuracy: 0.8870\n",
      "Epoch 130/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2116 - accuracy: 0.9210 - val_loss: 0.3047 - val_accuracy: 0.8769\n",
      "Epoch 131/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1578 - accuracy: 0.9457 - val_loss: 0.2625 - val_accuracy: 0.8998\n",
      "Epoch 132/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1615 - accuracy: 0.9437 - val_loss: 0.2677 - val_accuracy: 0.8934\n",
      "Epoch 133/500\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.1518 - accuracy: 0.9478 - val_loss: 0.2542 - val_accuracy: 0.8943\n",
      "Epoch 134/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1724 - accuracy: 0.9398 - val_loss: 0.4249 - val_accuracy: 0.8378\n",
      "Epoch 135/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1632 - accuracy: 0.9430 - val_loss: 0.2337 - val_accuracy: 0.8948\n",
      "Epoch 136/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2293 - accuracy: 0.9166 - val_loss: 0.2420 - val_accuracy: 0.8831\n",
      "Epoch 137/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1641 - accuracy: 0.9438 - val_loss: 0.3474 - val_accuracy: 0.8470\n",
      "Epoch 138/500\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.2590 - accuracy: 0.8779Restoring model weights from the end of the best epoch: 118.\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2594 - accuracy: 0.8778 - val_loss: 0.4031 - val_accuracy: 0.7843\n",
      "Epoch 138: early stopping\n",
      "Number of iterations 8\n",
      "F1-scores:  [0.8679624664879356, 0.8810902896081771, 0.8065201984408221, 0.8839741408642394, 0.9016223679668622, 0.8689748811948406, 0.8498641304347827, 0.8742386241490505]\n",
      "Average F1-Score 0.8667808873933388\n",
      "Std Dev F1-Score 0.026677824592060535\n",
      "Error bar F1-Score 0.009432035338175621\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 15s 26ms/step - loss: 0.5755 - accuracy: 0.6978 - val_loss: 0.4521 - val_accuracy: 0.7578\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5411 - accuracy: 0.7030 - val_loss: 0.4451 - val_accuracy: 0.7578\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5385 - accuracy: 0.7083 - val_loss: 0.4079 - val_accuracy: 0.7827\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5397 - accuracy: 0.7083 - val_loss: 0.4415 - val_accuracy: 0.7656\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5334 - accuracy: 0.7087 - val_loss: 0.4407 - val_accuracy: 0.7584\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5234 - accuracy: 0.7141 - val_loss: 0.4031 - val_accuracy: 0.8053\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5112 - accuracy: 0.7120 - val_loss: 0.3790 - val_accuracy: 0.8152\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.4924 - accuracy: 0.7210 - val_loss: 0.3779 - val_accuracy: 0.8003\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.4670 - accuracy: 0.7432 - val_loss: 0.3395 - val_accuracy: 0.8316\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.4661 - accuracy: 0.7480 - val_loss: 0.3388 - val_accuracy: 0.8472\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.4341 - accuracy: 0.7762 - val_loss: 0.3631 - val_accuracy: 0.8127\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.3952 - accuracy: 0.8115 - val_loss: 0.3480 - val_accuracy: 0.8278\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.3959 - accuracy: 0.8085 - val_loss: 0.3019 - val_accuracy: 0.8502\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2729 - accuracy: 0.8809 - val_loss: 0.2430 - val_accuracy: 0.8802\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.2546 - accuracy: 0.8862 - val_loss: 0.2642 - val_accuracy: 0.8754\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2245 - accuracy: 0.9002 - val_loss: 0.2431 - val_accuracy: 0.8882\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2081 - accuracy: 0.9083 - val_loss: 0.2623 - val_accuracy: 0.8815\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2072 - accuracy: 0.9080 - val_loss: 0.2519 - val_accuracy: 0.8822\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1862 - accuracy: 0.9195 - val_loss: 0.3027 - val_accuracy: 0.8646\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1837 - accuracy: 0.9190 - val_loss: 0.4047 - val_accuracy: 0.8264\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1818 - accuracy: 0.9218 - val_loss: 0.2145 - val_accuracy: 0.9021\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1752 - accuracy: 0.9233 - val_loss: 0.2750 - val_accuracy: 0.8834\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1798 - accuracy: 0.9226 - val_loss: 0.2215 - val_accuracy: 0.8977\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1807 - accuracy: 0.9235 - val_loss: 0.2087 - val_accuracy: 0.9028\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1651 - accuracy: 0.9306 - val_loss: 0.2249 - val_accuracy: 0.9030\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1700 - accuracy: 0.9269 - val_loss: 0.2363 - val_accuracy: 0.8891\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1639 - accuracy: 0.9293 - val_loss: 0.2102 - val_accuracy: 0.9064\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1674 - accuracy: 0.9270 - val_loss: 0.2375 - val_accuracy: 0.8948\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1657 - accuracy: 0.9290 - val_loss: 0.2409 - val_accuracy: 0.8852\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1663 - accuracy: 0.9283 - val_loss: 0.2114 - val_accuracy: 0.9019\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1605 - accuracy: 0.9323 - val_loss: 0.2347 - val_accuracy: 0.8966\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1584 - accuracy: 0.9334 - val_loss: 0.2605 - val_accuracy: 0.8818\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1508 - accuracy: 0.9356 - val_loss: 0.2393 - val_accuracy: 0.9001\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1596 - accuracy: 0.9331 - val_loss: 0.2826 - val_accuracy: 0.8781\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1445 - accuracy: 0.9402 - val_loss: 0.2923 - val_accuracy: 0.8854\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1489 - accuracy: 0.9378 - val_loss: 0.2830 - val_accuracy: 0.8879\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1497 - accuracy: 0.9362 - val_loss: 0.2599 - val_accuracy: 0.8879\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.1537 - accuracy: 0.9352 - val_loss: 0.2531 - val_accuracy: 0.8929\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1433 - accuracy: 0.9390 - val_loss: 0.2610 - val_accuracy: 0.8955\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1402 - accuracy: 0.9423 - val_loss: 0.2425 - val_accuracy: 0.9032\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1333 - accuracy: 0.9449 - val_loss: 0.2725 - val_accuracy: 0.8939\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1340 - accuracy: 0.9449 - val_loss: 0.2352 - val_accuracy: 0.8980\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1285 - accuracy: 0.9474 - val_loss: 0.2871 - val_accuracy: 0.8847\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1321 - accuracy: 0.9450 - val_loss: 0.2306 - val_accuracy: 0.9058\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1415 - accuracy: 0.9408 - val_loss: 0.2077 - val_accuracy: 0.9140\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1189 - accuracy: 0.9510 - val_loss: 0.2741 - val_accuracy: 0.8907\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1465 - accuracy: 0.9388 - val_loss: 0.3194 - val_accuracy: 0.8703\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1238 - accuracy: 0.9493 - val_loss: 0.2209 - val_accuracy: 0.9108\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1229 - accuracy: 0.9493 - val_loss: 0.2695 - val_accuracy: 0.8955\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1251 - accuracy: 0.9484 - val_loss: 0.2436 - val_accuracy: 0.9019\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1198 - accuracy: 0.9508 - val_loss: 0.3217 - val_accuracy: 0.8712\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1160 - accuracy: 0.9532 - val_loss: 0.2910 - val_accuracy: 0.8801\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1172 - accuracy: 0.9523 - val_loss: 0.3269 - val_accuracy: 0.8706\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1282 - accuracy: 0.9482 - val_loss: 0.1964 - val_accuracy: 0.9144\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1205 - accuracy: 0.9527 - val_loss: 0.2420 - val_accuracy: 0.9026\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1177 - accuracy: 0.9517 - val_loss: 0.2296 - val_accuracy: 0.9072\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1294 - accuracy: 0.9461 - val_loss: 0.2118 - val_accuracy: 0.9188\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1102 - accuracy: 0.9560 - val_loss: 0.2489 - val_accuracy: 0.9117\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1046 - accuracy: 0.9590 - val_loss: 0.2505 - val_accuracy: 0.9003\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1088 - accuracy: 0.9569 - val_loss: 0.2653 - val_accuracy: 0.9030\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1000 - accuracy: 0.9616 - val_loss: 0.2631 - val_accuracy: 0.9042\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1052 - accuracy: 0.9577 - val_loss: 0.3450 - val_accuracy: 0.8802\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1061 - accuracy: 0.9573 - val_loss: 0.2625 - val_accuracy: 0.8984\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1050 - accuracy: 0.9572 - val_loss: 0.2411 - val_accuracy: 0.9110\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1012 - accuracy: 0.9603 - val_loss: 0.3250 - val_accuracy: 0.8856\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0969 - accuracy: 0.9609 - val_loss: 0.2609 - val_accuracy: 0.9108\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0926 - accuracy: 0.9647 - val_loss: 0.2850 - val_accuracy: 0.8991\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1073 - accuracy: 0.9573 - val_loss: 0.2405 - val_accuracy: 0.9048\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0975 - accuracy: 0.9627 - val_loss: 0.2309 - val_accuracy: 0.9135\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0941 - accuracy: 0.9632 - val_loss: 0.2863 - val_accuracy: 0.8985\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1069 - accuracy: 0.9569 - val_loss: 0.2941 - val_accuracy: 0.8964\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0941 - accuracy: 0.9626 - val_loss: 0.2642 - val_accuracy: 0.9108\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0850 - accuracy: 0.9671 - val_loss: 0.2321 - val_accuracy: 0.9192\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0933 - accuracy: 0.9635 - val_loss: 0.2630 - val_accuracy: 0.9055\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0879 - accuracy: 0.9658 - val_loss: 0.2263 - val_accuracy: 0.9067\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0922 - accuracy: 0.9640 - val_loss: 0.2433 - val_accuracy: 0.9122\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0970 - accuracy: 0.9618 - val_loss: 0.2320 - val_accuracy: 0.9110\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0805 - accuracy: 0.9691 - val_loss: 0.3066 - val_accuracy: 0.8932\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0941 - accuracy: 0.9640 - val_loss: 0.2607 - val_accuracy: 0.9131\n",
      "Epoch 80/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0980 - accuracy: 0.9625 - val_loss: 0.2421 - val_accuracy: 0.9135\n",
      "Epoch 81/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0938 - accuracy: 0.9627 - val_loss: 0.2163 - val_accuracy: 0.9154\n",
      "Epoch 82/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0828 - accuracy: 0.9676 - val_loss: 0.2355 - val_accuracy: 0.9172\n",
      "Epoch 83/500\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.0764 - accuracy: 0.9698 - val_loss: 0.2756 - val_accuracy: 0.9039\n",
      "Epoch 84/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0787 - accuracy: 0.9699 - val_loss: 0.2719 - val_accuracy: 0.9144\n",
      "Epoch 85/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0724 - accuracy: 0.9726 - val_loss: 0.2772 - val_accuracy: 0.9140\n",
      "Epoch 86/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0913 - accuracy: 0.9646 - val_loss: 0.2780 - val_accuracy: 0.9003\n",
      "Epoch 87/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0979 - accuracy: 0.9612 - val_loss: 0.2857 - val_accuracy: 0.9041\n",
      "Epoch 88/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0778 - accuracy: 0.9690 - val_loss: 0.2975 - val_accuracy: 0.9003\n",
      "Epoch 89/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0751 - accuracy: 0.9705 - val_loss: 0.4380 - val_accuracy: 0.8609\n",
      "Epoch 90/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0753 - accuracy: 0.9698 - val_loss: 0.2460 - val_accuracy: 0.9151\n",
      "Epoch 91/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0777 - accuracy: 0.9705 - val_loss: 0.2339 - val_accuracy: 0.9129\n",
      "Epoch 92/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0679 - accuracy: 0.9743 - val_loss: 0.2818 - val_accuracy: 0.9094\n",
      "Epoch 93/500\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.0708 - accuracy: 0.9738Restoring model weights from the end of the best epoch: 73.\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.0711 - accuracy: 0.9738 - val_loss: 0.3070 - val_accuracy: 0.8955\n",
      "Epoch 93: early stopping\n",
      "Number of iterations 9\n",
      "F1-scores:  [0.8679624664879356, 0.8810902896081771, 0.8065201984408221, 0.8839741408642394, 0.9016223679668622, 0.8689748811948406, 0.8498641304347827, 0.8742386241490505, 0.847571189279732]\n",
      "Average F1-Score 0.8646464764918269\n",
      "Std Dev F1-Score 0.025866455566719085\n",
      "Error bar F1-Score 0.008622151855573029\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 14s 26ms/step - loss: 0.5736 - accuracy: 0.6960 - val_loss: 0.4589 - val_accuracy: 0.7576\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5411 - accuracy: 0.7021 - val_loss: 0.4330 - val_accuracy: 0.7578\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5418 - accuracy: 0.7040 - val_loss: 0.4273 - val_accuracy: 0.7731\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5373 - accuracy: 0.7108 - val_loss: 0.4318 - val_accuracy: 0.7921\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5342 - accuracy: 0.7132 - val_loss: 0.4375 - val_accuracy: 0.7795\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5323 - accuracy: 0.7128 - val_loss: 0.4055 - val_accuracy: 0.7937\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.5278 - accuracy: 0.7145 - val_loss: 0.4117 - val_accuracy: 0.7862\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.5216 - accuracy: 0.7206 - val_loss: 0.4086 - val_accuracy: 0.8115\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5202 - accuracy: 0.7208 - val_loss: 0.4178 - val_accuracy: 0.7836\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5158 - accuracy: 0.7183 - val_loss: 0.4267 - val_accuracy: 0.8022\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.5048 - accuracy: 0.7210 - val_loss: 0.3597 - val_accuracy: 0.8063\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.5129 - accuracy: 0.7215 - val_loss: 0.3966 - val_accuracy: 0.7942\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.5141 - accuracy: 0.7164 - val_loss: 0.3674 - val_accuracy: 0.8092\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.4426 - accuracy: 0.7669 - val_loss: 0.3181 - val_accuracy: 0.8506\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.3751 - accuracy: 0.8212 - val_loss: 0.4086 - val_accuracy: 0.7848\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.3108 - accuracy: 0.8600 - val_loss: 0.3587 - val_accuracy: 0.8358\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.3109 - accuracy: 0.8570 - val_loss: 0.4580 - val_accuracy: 0.7768\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2841 - accuracy: 0.8722 - val_loss: 0.3631 - val_accuracy: 0.8285\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2676 - accuracy: 0.8828 - val_loss: 0.3314 - val_accuracy: 0.8426\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2683 - accuracy: 0.8801 - val_loss: 0.3945 - val_accuracy: 0.8262\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2583 - accuracy: 0.8872 - val_loss: 0.3028 - val_accuracy: 0.8522\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2641 - accuracy: 0.8860 - val_loss: 0.3626 - val_accuracy: 0.8225\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2532 - accuracy: 0.8910 - val_loss: 0.4241 - val_accuracy: 0.8028\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2613 - accuracy: 0.8864 - val_loss: 0.4152 - val_accuracy: 0.8095\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2567 - accuracy: 0.8875 - val_loss: 0.3199 - val_accuracy: 0.8486\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2450 - accuracy: 0.8952 - val_loss: 0.3695 - val_accuracy: 0.8291\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2552 - accuracy: 0.8886 - val_loss: 0.3838 - val_accuracy: 0.8156\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2422 - accuracy: 0.8969 - val_loss: 0.3800 - val_accuracy: 0.8248\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.2618 - accuracy: 0.8858 - val_loss: 0.3520 - val_accuracy: 0.8300\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.2385 - accuracy: 0.8984 - val_loss: 0.2883 - val_accuracy: 0.8648\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2405 - accuracy: 0.8936 - val_loss: 0.3518 - val_accuracy: 0.8426\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2441 - accuracy: 0.8943 - val_loss: 0.3730 - val_accuracy: 0.8202\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2372 - accuracy: 0.8956 - val_loss: 0.2963 - val_accuracy: 0.8575\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2341 - accuracy: 0.8994 - val_loss: 0.2994 - val_accuracy: 0.8612\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2292 - accuracy: 0.9031 - val_loss: 0.3823 - val_accuracy: 0.8314\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2308 - accuracy: 0.8998 - val_loss: 0.2958 - val_accuracy: 0.8564\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2384 - accuracy: 0.8973 - val_loss: 0.2994 - val_accuracy: 0.8536\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2321 - accuracy: 0.8999 - val_loss: 0.2977 - val_accuracy: 0.8541\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2372 - accuracy: 0.8982 - val_loss: 0.2855 - val_accuracy: 0.8630\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2267 - accuracy: 0.9017 - val_loss: 0.2720 - val_accuracy: 0.8696\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2321 - accuracy: 0.9004 - val_loss: 0.3078 - val_accuracy: 0.8653\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2280 - accuracy: 0.9031 - val_loss: 0.2791 - val_accuracy: 0.8566\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2281 - accuracy: 0.9010 - val_loss: 0.3203 - val_accuracy: 0.8470\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2240 - accuracy: 0.9038 - val_loss: 0.3097 - val_accuracy: 0.8493\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2395 - accuracy: 0.8951 - val_loss: 0.3175 - val_accuracy: 0.8481\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2214 - accuracy: 0.9069 - val_loss: 0.2605 - val_accuracy: 0.8778\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2163 - accuracy: 0.9077 - val_loss: 0.3179 - val_accuracy: 0.8445\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2182 - accuracy: 0.9073 - val_loss: 0.3101 - val_accuracy: 0.8443\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2122 - accuracy: 0.9087 - val_loss: 0.2582 - val_accuracy: 0.8705\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2313 - accuracy: 0.9010 - val_loss: 0.2887 - val_accuracy: 0.8591\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 7s 23ms/step - loss: 0.2227 - accuracy: 0.9052 - val_loss: 0.3530 - val_accuracy: 0.8321\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 6s 22ms/step - loss: 0.2134 - accuracy: 0.9086 - val_loss: 0.2772 - val_accuracy: 0.8571\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2136 - accuracy: 0.9061 - val_loss: 0.2720 - val_accuracy: 0.8728\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2035 - accuracy: 0.9129 - val_loss: 0.2923 - val_accuracy: 0.8564\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.2020 - accuracy: 0.9146 - val_loss: 0.4320 - val_accuracy: 0.7850\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1987 - accuracy: 0.9153 - val_loss: 0.2743 - val_accuracy: 0.8628\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.2024 - accuracy: 0.9156 - val_loss: 0.3276 - val_accuracy: 0.8307\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1882 - accuracy: 0.9209 - val_loss: 0.2844 - val_accuracy: 0.8511\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1929 - accuracy: 0.9203 - val_loss: 0.2624 - val_accuracy: 0.8682\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1815 - accuracy: 0.9268 - val_loss: 0.3686 - val_accuracy: 0.8397\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.1733 - accuracy: 0.9297 - val_loss: 0.3086 - val_accuracy: 0.8612\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1772 - accuracy: 0.9284 - val_loss: 0.2760 - val_accuracy: 0.8616\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1715 - accuracy: 0.9285 - val_loss: 0.2831 - val_accuracy: 0.8744\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1688 - accuracy: 0.9311 - val_loss: 0.2276 - val_accuracy: 0.8881\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1665 - accuracy: 0.9323 - val_loss: 0.2233 - val_accuracy: 0.9042\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1520 - accuracy: 0.9394 - val_loss: 0.2415 - val_accuracy: 0.8886\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1469 - accuracy: 0.9411 - val_loss: 0.2596 - val_accuracy: 0.8808\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1537 - accuracy: 0.9376 - val_loss: 0.2585 - val_accuracy: 0.8826\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1381 - accuracy: 0.9446 - val_loss: 0.2173 - val_accuracy: 0.8998\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1491 - accuracy: 0.9399 - val_loss: 0.2344 - val_accuracy: 0.8877\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1408 - accuracy: 0.9446 - val_loss: 0.2949 - val_accuracy: 0.8618\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1308 - accuracy: 0.9471 - val_loss: 0.2467 - val_accuracy: 0.8794\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1236 - accuracy: 0.9508 - val_loss: 0.3038 - val_accuracy: 0.8611\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1532 - accuracy: 0.9389 - val_loss: 0.2487 - val_accuracy: 0.8918\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1121 - accuracy: 0.9569 - val_loss: 0.2432 - val_accuracy: 0.8927\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1349 - accuracy: 0.9465 - val_loss: 0.2564 - val_accuracy: 0.8895\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1321 - accuracy: 0.9477 - val_loss: 0.2409 - val_accuracy: 0.8877\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1251 - accuracy: 0.9514 - val_loss: 0.1989 - val_accuracy: 0.9096\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1151 - accuracy: 0.9534 - val_loss: 0.2289 - val_accuracy: 0.9019\n",
      "Epoch 80/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1279 - accuracy: 0.9494 - val_loss: 0.2532 - val_accuracy: 0.8795\n",
      "Epoch 81/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1037 - accuracy: 0.9592 - val_loss: 0.3153 - val_accuracy: 0.8772\n",
      "Epoch 82/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1223 - accuracy: 0.9516 - val_loss: 0.1870 - val_accuracy: 0.9135\n",
      "Epoch 83/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1092 - accuracy: 0.9558 - val_loss: 0.2155 - val_accuracy: 0.8961\n",
      "Epoch 84/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1262 - accuracy: 0.9513 - val_loss: 0.2369 - val_accuracy: 0.8936\n",
      "Epoch 85/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1160 - accuracy: 0.9546 - val_loss: 0.2354 - val_accuracy: 0.9000\n",
      "Epoch 86/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1402 - accuracy: 0.9455 - val_loss: 0.2172 - val_accuracy: 0.9035\n",
      "Epoch 87/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1072 - accuracy: 0.9573 - val_loss: 0.2435 - val_accuracy: 0.8957\n",
      "Epoch 88/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1128 - accuracy: 0.9562 - val_loss: 0.1846 - val_accuracy: 0.9232\n",
      "Epoch 89/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1087 - accuracy: 0.9587 - val_loss: 0.2671 - val_accuracy: 0.8836\n",
      "Epoch 90/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1090 - accuracy: 0.9566 - val_loss: 0.1753 - val_accuracy: 0.9243\n",
      "Epoch 91/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0943 - accuracy: 0.9634 - val_loss: 0.1990 - val_accuracy: 0.9199\n",
      "Epoch 92/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1212 - accuracy: 0.9526 - val_loss: 0.2426 - val_accuracy: 0.9051\n",
      "Epoch 93/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0939 - accuracy: 0.9625 - val_loss: 0.2318 - val_accuracy: 0.9083\n",
      "Epoch 94/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1076 - accuracy: 0.9588 - val_loss: 0.2284 - val_accuracy: 0.9186\n",
      "Epoch 95/500\n",
      "288/288 [==============================] - 7s 24ms/step - loss: 0.1014 - accuracy: 0.9607 - val_loss: 0.1957 - val_accuracy: 0.9192\n",
      "Epoch 96/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0932 - accuracy: 0.9635 - val_loss: 0.1928 - val_accuracy: 0.9271\n",
      "Epoch 97/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1128 - accuracy: 0.9576 - val_loss: 0.3145 - val_accuracy: 0.8648\n",
      "Epoch 98/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0952 - accuracy: 0.9632 - val_loss: 0.2683 - val_accuracy: 0.8996\n",
      "Epoch 99/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1012 - accuracy: 0.9609 - val_loss: 0.1872 - val_accuracy: 0.9220\n",
      "Epoch 100/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0962 - accuracy: 0.9635 - val_loss: 0.1746 - val_accuracy: 0.9284\n",
      "Epoch 101/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0957 - accuracy: 0.9635 - val_loss: 0.2429 - val_accuracy: 0.9179\n",
      "Epoch 102/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0940 - accuracy: 0.9643 - val_loss: 0.2110 - val_accuracy: 0.9186\n",
      "Epoch 103/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0824 - accuracy: 0.9681 - val_loss: 0.2043 - val_accuracy: 0.9302\n",
      "Epoch 104/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0807 - accuracy: 0.9686 - val_loss: 0.2572 - val_accuracy: 0.9044\n",
      "Epoch 105/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1016 - accuracy: 0.9607 - val_loss: 0.2605 - val_accuracy: 0.8815\n",
      "Epoch 106/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0812 - accuracy: 0.9688 - val_loss: 0.2703 - val_accuracy: 0.9120\n",
      "Epoch 107/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0826 - accuracy: 0.9685 - val_loss: 0.2413 - val_accuracy: 0.9142\n",
      "Epoch 108/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0846 - accuracy: 0.9675 - val_loss: 0.1647 - val_accuracy: 0.9399\n",
      "Epoch 109/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0944 - accuracy: 0.9636 - val_loss: 0.2075 - val_accuracy: 0.9277\n",
      "Epoch 110/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0872 - accuracy: 0.9675 - val_loss: 0.2314 - val_accuracy: 0.9238\n",
      "Epoch 111/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0777 - accuracy: 0.9701 - val_loss: 0.2004 - val_accuracy: 0.9264\n",
      "Epoch 112/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0874 - accuracy: 0.9685 - val_loss: 0.2172 - val_accuracy: 0.9248\n",
      "Epoch 113/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0813 - accuracy: 0.9696 - val_loss: 0.2621 - val_accuracy: 0.9133\n",
      "Epoch 114/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0787 - accuracy: 0.9696 - val_loss: 0.2827 - val_accuracy: 0.9007\n",
      "Epoch 115/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1038 - accuracy: 0.9599 - val_loss: 0.2028 - val_accuracy: 0.9355\n",
      "Epoch 116/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0796 - accuracy: 0.9695 - val_loss: 0.1660 - val_accuracy: 0.9341\n",
      "Epoch 117/500\n",
      "288/288 [==============================] - 7s 25ms/step - loss: 0.0767 - accuracy: 0.9704 - val_loss: 0.2118 - val_accuracy: 0.9241\n",
      "Epoch 118/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1249 - accuracy: 0.9510 - val_loss: 0.2021 - val_accuracy: 0.9129\n",
      "Epoch 119/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0749 - accuracy: 0.9723 - val_loss: 0.1969 - val_accuracy: 0.9282\n",
      "Epoch 120/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0682 - accuracy: 0.9745 - val_loss: 0.2191 - val_accuracy: 0.9202\n",
      "Epoch 121/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0685 - accuracy: 0.9750 - val_loss: 0.2661 - val_accuracy: 0.9053\n",
      "Epoch 122/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0813 - accuracy: 0.9703 - val_loss: 0.2128 - val_accuracy: 0.9295\n",
      "Epoch 123/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0735 - accuracy: 0.9728 - val_loss: 0.2303 - val_accuracy: 0.9186\n",
      "Epoch 124/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0794 - accuracy: 0.9710 - val_loss: 0.1863 - val_accuracy: 0.9248\n",
      "Epoch 125/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0676 - accuracy: 0.9747 - val_loss: 0.1902 - val_accuracy: 0.9334\n",
      "Epoch 126/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0734 - accuracy: 0.9729 - val_loss: 0.2312 - val_accuracy: 0.9291\n",
      "Epoch 127/500\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.1132 - accuracy: 0.9553 - val_loss: 0.1880 - val_accuracy: 0.9263\n",
      "Epoch 128/500\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.0698 - accuracy: 0.9738Restoring model weights from the end of the best epoch: 108.\n",
      "288/288 [==============================] - 6s 21ms/step - loss: 0.0705 - accuracy: 0.9735 - val_loss: 0.2193 - val_accuracy: 0.9236\n",
      "Epoch 128: early stopping\n",
      "Number of iterations 10\n",
      "F1-scores:  [0.8679624664879356, 0.8810902896081771, 0.8065201984408221, 0.8839741408642394, 0.9016223679668622, 0.8689748811948406, 0.8498641304347827, 0.8742386241490505, 0.847571189279732, 0.884483937115516]\n",
      "Average F1-Score 0.8666302225541959\n",
      "Std Dev F1-Score 0.025250414000293632\n",
      "Error bar F1-Score 0.007984882010313143\n"
     ]
    }
   ],
   "source": [
    "###Collect F-Score 10 times\n",
    "import sklearn\n",
    "from tqdm.notebook import tqdm\n",
    "def calc_f1_score(X_train_scaled,X_test_scaled,X_train_scaled_f,X_test_scaled_f,y_train,y_test,earlystop):\n",
    "  input_1 = Input((X_train_scaled.shape[1], X_train_scaled.shape[2]))\n",
    "  input_2 = Input((X_train_scaled_f.shape[1], X_train_scaled_f.shape[2]))\n",
    "  x1=LSTM(units = 100, return_sequences = True)(input_1)\n",
    "  x1=LSTM(units = 50)(x1)\n",
    "  x2=LSTM(units = 100, return_sequences = True)(input_2)\n",
    "  x2=LSTM(units = 50)(x2)\n",
    "  x = layers.concatenate([x1, x2])\n",
    "  output_layer = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "  classifier=keras.Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "  # Compiling the RNN\n",
    "  classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  classifier.fit([X_train_scaled,X_train_scaled_f], y_train[:,0], epochs = 500, batch_size = 64,validation_data=([X_test_scaled,X_test_scaled_f],y_test[:,0]),callbacks=[earlystop])\n",
    "  y_pred = classifier.predict([X_test_scaled,X_test_scaled_f])\n",
    "  y_pred= (y_pred>=0.5).astype(int)\n",
    "  return(sklearn.metrics.f1_score(y_test[:,0],y_pred))\n",
    "\n",
    "f1_score_list=[]\n",
    "for i in tqdm(range(10)):\n",
    "  f1_score_list=f1_score_list+[calc_f1_score(X_train_scaled,X_test_scaled,X_train_scaled_f,X_test_scaled_f,y_train,y_test,earlystop)]\n",
    "  print(\"Number of iterations\",len(f1_score_list))\n",
    "  print(\"F1-scores: \",f1_score_list)\n",
    "  print(\"Average F1-Score\",np.mean(f1_score_list))\n",
    "  print(\"Std Dev F1-Score\",np.std(f1_score_list))\n",
    "  print(\"Error bar F1-Score\",np.std(f1_score_list)/np.sqrt(len(f1_score_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average F1-Score 0.8666302225541959\n",
    "# Std Dev F1-Score 0.025250414000293632\n",
    "# Error bar F1-Score 0.007984882010313143"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_1d_freq_exp2_v2.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "122254a95feb4ff4ae1d037697140986": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_951722f5fc59402c84c5b71691902c7b",
      "placeholder": "​",
      "style": "IPY_MODEL_a50d1108bd02445591f617933642f348",
      "value": " 10/10 [1:55:27&lt;00:00, 701.21s/it]"
     }
    },
    "16c27b26b95343b1a0bfddd480914cf3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18f1e3284fdf488ab0717338a1b6210a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d94dcd1b5504c02a95d776694e486ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16c27b26b95343b1a0bfddd480914cf3",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_47634b46376b4eb98250921cfc643ecf",
      "value": 10
     }
    },
    "299a5265721d4883b8176021edb0ce3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a0445a1de304e9c9c10841070a4ea65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f766d60b6074c7d8707fbbc3c036f3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_299a5265721d4883b8176021edb0ce3f",
      "placeholder": "​",
      "style": "IPY_MODEL_bf5bea7b1f8445b0a029d31fef8dd9bc",
      "value": "100%"
     }
    },
    "42a5fc0c683c4824bc8037b16db000b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "47634b46376b4eb98250921cfc643ecf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52fc82463abb418894aed073037a8c5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6789c5614b74d8cbeabf572274bbe0b",
      "placeholder": "​",
      "style": "IPY_MODEL_8d9c6822587741b69ad159b52e83d1d0",
      "value": "100%"
     }
    },
    "5988ee1af52e48c9a84ac2a1098d8715": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88b88871c13c43c8a316bda26746e5e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d9c6822587741b69ad159b52e83d1d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "951722f5fc59402c84c5b71691902c7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a48f863140a945e69f1541448112299f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a50d1108bd02445591f617933642f348": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf5bea7b1f8445b0a029d31fef8dd9bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c5646d69ee584af6af9d9612dd3ccf5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3f766d60b6074c7d8707fbbc3c036f3b",
       "IPY_MODEL_ebf30135af1045959aaa9c332786c9b4",
       "IPY_MODEL_f36681ab94594e7094c62f27e87b1afe"
      ],
      "layout": "IPY_MODEL_a48f863140a945e69f1541448112299f"
     }
    },
    "ce6f8f8780c24b8a9a8be1feb3201963": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_52fc82463abb418894aed073037a8c5d",
       "IPY_MODEL_1d94dcd1b5504c02a95d776694e486ea",
       "IPY_MODEL_122254a95feb4ff4ae1d037697140986"
      ],
      "layout": "IPY_MODEL_3a0445a1de304e9c9c10841070a4ea65"
     }
    },
    "d6789c5614b74d8cbeabf572274bbe0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebf30135af1045959aaa9c332786c9b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5988ee1af52e48c9a84ac2a1098d8715",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_42a5fc0c683c4824bc8037b16db000b6",
      "value": 10
     }
    },
    "f36681ab94594e7094c62f27e87b1afe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88b88871c13c43c8a316bda26746e5e7",
      "placeholder": "​",
      "style": "IPY_MODEL_18f1e3284fdf488ab0717338a1b6210a",
      "value": " 10/10 [1:23:16&lt;00:00, 631.43s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
