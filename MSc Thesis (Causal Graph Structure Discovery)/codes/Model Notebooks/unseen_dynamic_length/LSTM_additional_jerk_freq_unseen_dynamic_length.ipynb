{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JYsWwiwnPzi",
    "outputId": "2b984a01-2a08-4c2a-fec4-8f5d03265b11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 21 09:52:55 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdNIB899nhlq",
    "outputId": "c8a30daf-0356-44ae-9ab2-f03f3f54408d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#mounting google drive on colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GfSazzTdnmaM"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bXN_d9Evntel"
   },
   "outputs": [],
   "source": [
    "X_train=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_X_trainv7_exp2_exp5.npy\")\n",
    "y_train=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_y_trainv7_exp2_exp5.npy\").astype(int)\n",
    "\n",
    "X_test=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_X_testv7_exp2_exp5.npy\")\n",
    "y_test=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_y_testv7_exp2_exp5.npy\").astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NVkzHpArmQFD",
    "outputId": "e8ac05f8-c251-4b76-8c80-d2b536097efc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/scipy/signal/spectral.py:1966: UserWarning: nperseg = 256 is greater than input length  = 50, using nperseg = 50\n",
      "  .format(nperseg, input_length))\n"
     ]
    }
   ],
   "source": [
    "def calc_freq_signal(arr):\n",
    "    freqs, psd = signal.welch(arr, fs=10)\n",
    "    return psd\n",
    "\n",
    "X_train_f=np.apply_along_axis(calc_freq_signal, 1, X_train)\n",
    "X_test_f=np.apply_along_axis(calc_freq_signal, 1, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6MFvsoGCeuLr"
   },
   "outputs": [],
   "source": [
    "X_train_1d=np.gradient(X_train,axis=1)\n",
    "X_test_1d=np.gradient(X_test,axis=1)\n",
    "X_train=np.dstack([X_train,X_train_1d])\n",
    "X_test=np.dstack([X_test,X_test_1d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X86rj9C3fCRa",
    "outputId": "a2bb7d82-8203-4580-b883-d3320631939b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18424, 50, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GxsigJWlDahT"
   },
   "outputs": [],
   "source": [
    "def custom_scaler(X, range=(0, 1),min=None,max=None):\n",
    "    mi, ma = range\n",
    "    if(min==None):\n",
    "      min=X.min()\n",
    "      max=X.max()\n",
    "      print(\"\\nTrain_Scaling:- min=\",min,\" max=\",max)\n",
    "    X_std = (X - min) / (max - min)\n",
    "    X_scaled = X_std * (ma - mi) + mi\n",
    "    return min,max,X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JceKGdin-e6",
    "outputId": "dbec4439-5c59-4a2f-92a3-97b821ecf57f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train_Scaling:- min= -24.132592179310038  max= 28.36396103067893\n",
      "\n",
      "Train_Scaling:- min= -31.27613373276081  max= 33.197802245887985\n",
      "\n",
      "Train_Scaling:- min= -11.72770325673539  max= 13.779106439601684\n",
      "\n",
      "Train_Scaling:- min= -19.048373985970322  max= 18.311546903226954\n",
      "Frequency signals scaling:-------------\n",
      "\n",
      "Train_Scaling:- min= 0.0  max= 423.0426963359623\n",
      "\n",
      "Train_Scaling:- min= 0.0  max= 988.3390100809438\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "#X_train contains 8 signals x1,x2,y1,y2,x1d,2d,y1d,y2d\n",
    "X_train_scaled=copy.copy(X_train)\n",
    "X_test_scaled=copy.copy(X_test)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,0:2]=custom_scaler(X_train_scaled[:,:,0:2],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,0:2]=custom_scaler(X_test_scaled[:,:,0:2],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,2:4]=custom_scaler(X_train_scaled[:,:,2:4],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,2:4]=custom_scaler(X_test_scaled[:,:,2:4],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,4:6]=custom_scaler(X_train_scaled[:,:,4:6],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,4:6]=custom_scaler(X_test_scaled[:,:,4:6],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,6:8]=custom_scaler(X_train_scaled[:,:,6:8],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,6:8]=custom_scaler(X_test_scaled[:,:,6:8],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "\n",
    "print(\"Frequency signals scaling:-------------\")\n",
    "#X_train contains 8 signals x1f,x2f,y1f,y2f\n",
    "X_train_scaled_f=copy.copy(X_train_f)\n",
    "X_test_scaled_f=copy.copy(X_test_f)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled_f[:,:,0:2]=custom_scaler(X_train_scaled_f[:,:,0:2],range=(0,1))\n",
    "_,_,X_test_scaled_f[:,:,0:2]=custom_scaler(X_test_scaled_f[:,:,0:2],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled_f[:,:,2:4]=custom_scaler(X_train_scaled_f[:,:,2:4],range=(0,1))\n",
    "_,_,X_test_scaled_f[:,:,2:4]=custom_scaler(X_test_scaled_f[:,:,2:4],range=(0,1),min=min_temp,max=max_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L7JWtkWdfSCb",
    "outputId": "83741082-44bb-43b9-8afe-cf88d351f692"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18424, 50, 8)\n",
      "(18424, 26, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(X_train_scaled_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "u8CMIO_ToBr9"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Part 2 - Building the RNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "\n",
    "input_1 = Input((X_train_scaled.shape[1], X_train_scaled.shape[2]))\n",
    "input_2 = Input((X_train_scaled_f.shape[1], X_train_scaled_f.shape[2]))\n",
    "\n",
    "x1=LSTM(units = 100, return_sequences = True)(input_1)\n",
    "x1=LSTM(units = 50)(x1)\n",
    "\n",
    "x2=LSTM(units = 100, return_sequences = True)(input_2)\n",
    "x2=LSTM(units = 50)(x2)\n",
    "\n",
    "x = layers.concatenate([x1, x2])\n",
    "\n",
    "output_layer = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "classifier=keras.Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "\n",
    "# Compiling the RNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uf-jNI2KZJUu"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_exp5_v2.h5\",\n",
    "                             monitor=\"val_accuracy\",\n",
    "                             mode=\"max\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', # value being monitored for improvement\n",
    "                          min_delta = 0, #Abs value and is the min change required before we stop\n",
    "                          patience = 20, #Number of epochs we wait before stopping \n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True) #keeps the best weigths once stopped\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop,checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcUvZBOYoFNC",
    "outputId": "2a15e6d1-c525-4fc5-f0a5-c25fa0b31e33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.5694 - accuracy: 0.7007\n",
      "Epoch 1: val_accuracy improved from -inf to 0.76979, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_exp5_v2.h5\n",
      "288/288 [==============================] - 16s 21ms/step - loss: 0.5695 - accuracy: 0.7008 - val_loss: 0.4411 - val_accuracy: 0.7698\n",
      "Epoch 2/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.5379 - accuracy: 0.7044\n",
      "Epoch 2: val_accuracy improved from 0.76979 to 0.80080, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_exp5_v2.h5\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.5379 - accuracy: 0.7044 - val_loss: 0.4173 - val_accuracy: 0.8008\n",
      "Epoch 3/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.4522 - accuracy: 0.7683\n",
      "Epoch 3: val_accuracy improved from 0.80080 to 0.84133, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_exp5_v2.h5\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.4522 - accuracy: 0.7683 - val_loss: 0.3327 - val_accuracy: 0.8413\n",
      "Epoch 4/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.3922 - accuracy: 0.8091\n",
      "Epoch 4: val_accuracy did not improve from 0.84133\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3921 - accuracy: 0.8091 - val_loss: 0.4658 - val_accuracy: 0.7480\n",
      "Epoch 5/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.3720 - accuracy: 0.8246\n",
      "Epoch 5: val_accuracy did not improve from 0.84133\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3720 - accuracy: 0.8246 - val_loss: 0.3508 - val_accuracy: 0.8159\n",
      "Epoch 6/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.3691 - accuracy: 0.8232\n",
      "Epoch 6: val_accuracy did not improve from 0.84133\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3697 - accuracy: 0.8231 - val_loss: 0.3400 - val_accuracy: 0.8285\n",
      "Epoch 7/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.3599 - accuracy: 0.8324\n",
      "Epoch 7: val_accuracy did not improve from 0.84133\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.3603 - accuracy: 0.8322 - val_loss: 0.3612 - val_accuracy: 0.8089\n",
      "Epoch 8/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.3610 - accuracy: 0.8333\n",
      "Epoch 8: val_accuracy did not improve from 0.84133\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.3610 - accuracy: 0.8333 - val_loss: 0.3897 - val_accuracy: 0.7973\n",
      "Epoch 9/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.3481 - accuracy: 0.8363\n",
      "Epoch 9: val_accuracy did not improve from 0.84133\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3480 - accuracy: 0.8363 - val_loss: 0.3640 - val_accuracy: 0.8141\n",
      "Epoch 10/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.3402 - accuracy: 0.8442\n",
      "Epoch 10: val_accuracy did not improve from 0.84133\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3402 - accuracy: 0.8443 - val_loss: 0.4397 - val_accuracy: 0.7833\n",
      "Epoch 11/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.3510 - accuracy: 0.8381\n",
      "Epoch 11: val_accuracy improved from 0.84133 to 0.85016, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_exp5_v2.h5\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.3503 - accuracy: 0.8385 - val_loss: 0.3097 - val_accuracy: 0.8502\n",
      "Epoch 12/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.3347 - accuracy: 0.8467\n",
      "Epoch 12: val_accuracy did not improve from 0.85016\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.3346 - accuracy: 0.8467 - val_loss: 0.3540 - val_accuracy: 0.8218\n",
      "Epoch 13/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.3207 - accuracy: 0.8561\n",
      "Epoch 13: val_accuracy did not improve from 0.85016\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.3200 - accuracy: 0.8565 - val_loss: 0.3499 - val_accuracy: 0.8306\n",
      "Epoch 14/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.3062 - accuracy: 0.8618\n",
      "Epoch 14: val_accuracy improved from 0.85016 to 0.85969, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_exp5_v2.h5\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3062 - accuracy: 0.8618 - val_loss: 0.2926 - val_accuracy: 0.8597\n",
      "Epoch 15/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.3148 - accuracy: 0.8583\n",
      "Epoch 15: val_accuracy did not improve from 0.85969\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3147 - accuracy: 0.8583 - val_loss: 0.3033 - val_accuracy: 0.8550\n",
      "Epoch 16/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.3031 - accuracy: 0.8638\n",
      "Epoch 16: val_accuracy did not improve from 0.85969\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3029 - accuracy: 0.8641 - val_loss: 0.3628 - val_accuracy: 0.8372\n",
      "Epoch 17/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.3061 - accuracy: 0.8642\n",
      "Epoch 17: val_accuracy did not improve from 0.85969\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3062 - accuracy: 0.8640 - val_loss: 0.3249 - val_accuracy: 0.8379\n",
      "Epoch 18/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.2977 - accuracy: 0.8695\n",
      "Epoch 18: val_accuracy improved from 0.85969 to 0.87008, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_exp5_v2.h5\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2970 - accuracy: 0.8698 - val_loss: 0.2835 - val_accuracy: 0.8701\n",
      "Epoch 19/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.2956 - accuracy: 0.8679\n",
      "Epoch 19: val_accuracy did not improve from 0.87008\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2955 - accuracy: 0.8679 - val_loss: 0.3686 - val_accuracy: 0.8152\n",
      "Epoch 20/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.2992 - accuracy: 0.8669\n",
      "Epoch 20: val_accuracy did not improve from 0.87008\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2991 - accuracy: 0.8670 - val_loss: 0.3134 - val_accuracy: 0.8541\n",
      "Epoch 21/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.2960 - accuracy: 0.8677\n",
      "Epoch 21: val_accuracy did not improve from 0.87008\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2957 - accuracy: 0.8678 - val_loss: 0.3408 - val_accuracy: 0.8347\n",
      "Epoch 22/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.3101 - accuracy: 0.8607\n",
      "Epoch 22: val_accuracy did not improve from 0.87008\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3102 - accuracy: 0.8607 - val_loss: 0.2895 - val_accuracy: 0.8647\n",
      "Epoch 23/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.2960 - accuracy: 0.8708\n",
      "Epoch 23: val_accuracy did not improve from 0.87008\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2960 - accuracy: 0.8705 - val_loss: 0.2915 - val_accuracy: 0.8635\n",
      "Epoch 24/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.2976 - accuracy: 0.8667\n",
      "Epoch 24: val_accuracy did not improve from 0.87008\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2978 - accuracy: 0.8666 - val_loss: 0.3195 - val_accuracy: 0.8441\n",
      "Epoch 25/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.2936 - accuracy: 0.8676\n",
      "Epoch 25: val_accuracy improved from 0.87008 to 0.87234, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_exp5_v2.h5\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2933 - accuracy: 0.8678 - val_loss: 0.2748 - val_accuracy: 0.8723\n",
      "Epoch 26/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.2981 - accuracy: 0.8681\n",
      "Epoch 26: val_accuracy did not improve from 0.87234\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2981 - accuracy: 0.8681 - val_loss: 0.2746 - val_accuracy: 0.8716\n",
      "Epoch 27/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.2877 - accuracy: 0.8723\n",
      "Epoch 27: val_accuracy did not improve from 0.87234\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2877 - accuracy: 0.8723 - val_loss: 0.3050 - val_accuracy: 0.8562\n",
      "Epoch 28/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.2868 - accuracy: 0.8716\n",
      "Epoch 28: val_accuracy did not improve from 0.87234\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2866 - accuracy: 0.8716 - val_loss: 0.2861 - val_accuracy: 0.8632\n",
      "Epoch 29/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.2777 - accuracy: 0.8761\n",
      "Epoch 29: val_accuracy did not improve from 0.87234\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2777 - accuracy: 0.8761 - val_loss: 0.2732 - val_accuracy: 0.8689\n",
      "Epoch 30/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.2755 - accuracy: 0.8765\n",
      "Epoch 30: val_accuracy did not improve from 0.87234\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2755 - accuracy: 0.8766 - val_loss: 0.3032 - val_accuracy: 0.8547\n",
      "Epoch 31/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.2806 - accuracy: 0.8755\n",
      "Epoch 31: val_accuracy did not improve from 0.87234\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2806 - accuracy: 0.8755 - val_loss: 0.3154 - val_accuracy: 0.8441\n",
      "Epoch 32/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.2756 - accuracy: 0.8783\n",
      "Epoch 32: val_accuracy did not improve from 0.87234\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2756 - accuracy: 0.8783 - val_loss: 0.2751 - val_accuracy: 0.8613\n",
      "Epoch 33/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.2694 - accuracy: 0.8817\n",
      "Epoch 33: val_accuracy did not improve from 0.87234\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2697 - accuracy: 0.8815 - val_loss: 0.3070 - val_accuracy: 0.8496\n",
      "Epoch 34/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.2673 - accuracy: 0.8814\n",
      "Epoch 34: val_accuracy did not improve from 0.87234\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2668 - accuracy: 0.8816 - val_loss: 0.2611 - val_accuracy: 0.8716\n",
      "Epoch 35/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.2588 - accuracy: 0.8863\n",
      "Epoch 35: val_accuracy improved from 0.87234 to 0.88221, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_exp5_v2.h5\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2581 - accuracy: 0.8866 - val_loss: 0.2607 - val_accuracy: 0.8822\n",
      "Epoch 36/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.2525 - accuracy: 0.8897\n",
      "Epoch 36: val_accuracy did not improve from 0.88221\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2529 - accuracy: 0.8894 - val_loss: 0.2707 - val_accuracy: 0.8578\n",
      "Epoch 37/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.2397 - accuracy: 0.8999\n",
      "Epoch 37: val_accuracy did not improve from 0.88221\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2396 - accuracy: 0.9000 - val_loss: 0.3012 - val_accuracy: 0.8630\n",
      "Epoch 38/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.2392 - accuracy: 0.8979\n",
      "Epoch 38: val_accuracy did not improve from 0.88221\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2393 - accuracy: 0.8977 - val_loss: 0.2619 - val_accuracy: 0.8793\n",
      "Epoch 39/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.2270 - accuracy: 0.9022\n",
      "Epoch 39: val_accuracy did not improve from 0.88221\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2273 - accuracy: 0.9019 - val_loss: 0.2526 - val_accuracy: 0.8760\n",
      "Epoch 40/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.2251 - accuracy: 0.9050\n",
      "Epoch 40: val_accuracy improved from 0.88221 to 0.89260, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_exp5_v2.h5\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2250 - accuracy: 0.9050 - val_loss: 0.2620 - val_accuracy: 0.8926\n",
      "Epoch 41/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.2184 - accuracy: 0.9082\n",
      "Epoch 41: val_accuracy did not improve from 0.89260\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2179 - accuracy: 0.9087 - val_loss: 0.2671 - val_accuracy: 0.8820\n",
      "Epoch 42/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.2090 - accuracy: 0.9145\n",
      "Epoch 42: val_accuracy did not improve from 0.89260\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2098 - accuracy: 0.9141 - val_loss: 0.2658 - val_accuracy: 0.8729\n",
      "Epoch 43/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.2050 - accuracy: 0.9150\n",
      "Epoch 43: val_accuracy improved from 0.89260 to 0.90074, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_exp5_v2.h5\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2050 - accuracy: 0.9150 - val_loss: 0.2480 - val_accuracy: 0.9007\n",
      "Epoch 44/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.2919 - accuracy: 0.8708\n",
      "Epoch 44: val_accuracy did not improve from 0.90074\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2912 - accuracy: 0.8711 - val_loss: 0.3017 - val_accuracy: 0.8640\n",
      "Epoch 45/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.2355 - accuracy: 0.8971\n",
      "Epoch 45: val_accuracy did not improve from 0.90074\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2350 - accuracy: 0.8973 - val_loss: 0.2501 - val_accuracy: 0.8832\n",
      "Epoch 46/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.2199 - accuracy: 0.9083\n",
      "Epoch 46: val_accuracy did not improve from 0.90074\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2199 - accuracy: 0.9083 - val_loss: 0.2277 - val_accuracy: 0.8955\n",
      "Epoch 47/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.2451 - accuracy: 0.8959\n",
      "Epoch 47: val_accuracy did not improve from 0.90074\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2439 - accuracy: 0.8965 - val_loss: 0.2374 - val_accuracy: 0.8992\n",
      "Epoch 48/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1943 - accuracy: 0.9190\n",
      "Epoch 48: val_accuracy did not improve from 0.90074\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1943 - accuracy: 0.9190 - val_loss: 0.2352 - val_accuracy: 0.8793\n",
      "Epoch 49/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.1927 - accuracy: 0.9209\n",
      "Epoch 49: val_accuracy did not improve from 0.90074\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1918 - accuracy: 0.9214 - val_loss: 0.2442 - val_accuracy: 0.8884\n",
      "Epoch 50/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1963 - accuracy: 0.9178\n",
      "Epoch 50: val_accuracy improved from 0.90074 to 0.90213, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_exp5_v2.h5\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1963 - accuracy: 0.9178 - val_loss: 0.2253 - val_accuracy: 0.9021\n",
      "Epoch 51/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.1835 - accuracy: 0.9244\n",
      "Epoch 51: val_accuracy did not improve from 0.90213\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1832 - accuracy: 0.9244 - val_loss: 0.1993 - val_accuracy: 0.8992\n",
      "Epoch 52/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.2093 - accuracy: 0.9116\n",
      "Epoch 52: val_accuracy did not improve from 0.90213\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2093 - accuracy: 0.9116 - val_loss: 0.2616 - val_accuracy: 0.8763\n",
      "Epoch 53/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.2057 - accuracy: 0.9143\n",
      "Epoch 53: val_accuracy did not improve from 0.90213\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2056 - accuracy: 0.9145 - val_loss: 0.2554 - val_accuracy: 0.8902\n",
      "Epoch 54/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1817 - accuracy: 0.9251\n",
      "Epoch 54: val_accuracy did not improve from 0.90213\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1823 - accuracy: 0.9247 - val_loss: 0.3242 - val_accuracy: 0.8535\n",
      "Epoch 55/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1848 - accuracy: 0.9231\n",
      "Epoch 55: val_accuracy improved from 0.90213 to 0.90490, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_exp5_v2.h5\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1846 - accuracy: 0.9231 - val_loss: 0.1978 - val_accuracy: 0.9049\n",
      "Epoch 56/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1912 - accuracy: 0.9212\n",
      "Epoch 56: val_accuracy did not improve from 0.90490\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1917 - accuracy: 0.9210 - val_loss: 0.2788 - val_accuracy: 0.8735\n",
      "Epoch 57/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.1834 - accuracy: 0.9232\n",
      "Epoch 57: val_accuracy improved from 0.90490 to 0.91114, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_exp5_v2.h5\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1828 - accuracy: 0.9234 - val_loss: 0.1817 - val_accuracy: 0.9111\n",
      "Epoch 58/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.1933 - accuracy: 0.9191\n",
      "Epoch 58: val_accuracy did not improve from 0.91114\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1926 - accuracy: 0.9195 - val_loss: 0.2049 - val_accuracy: 0.9092\n",
      "Epoch 59/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.1819 - accuracy: 0.9260\n",
      "Epoch 59: val_accuracy did not improve from 0.91114\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1816 - accuracy: 0.9263 - val_loss: 0.2179 - val_accuracy: 0.9030\n",
      "Epoch 60/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1834 - accuracy: 0.9254\n",
      "Epoch 60: val_accuracy improved from 0.91114 to 0.91737, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_exp5_v2.h5\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1831 - accuracy: 0.9256 - val_loss: 0.1851 - val_accuracy: 0.9174\n",
      "Epoch 61/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.1623 - accuracy: 0.9343\n",
      "Epoch 61: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1620 - accuracy: 0.9345 - val_loss: 0.2024 - val_accuracy: 0.9047\n",
      "Epoch 62/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.2835 - accuracy: 0.8735\n",
      "Epoch 62: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2836 - accuracy: 0.8734 - val_loss: 0.2939 - val_accuracy: 0.8689\n",
      "Epoch 63/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.2924 - accuracy: 0.8680\n",
      "Epoch 63: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2923 - accuracy: 0.8682 - val_loss: 0.2560 - val_accuracy: 0.8761\n",
      "Epoch 64/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.2603 - accuracy: 0.8836\n",
      "Epoch 64: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2597 - accuracy: 0.8836 - val_loss: 0.2117 - val_accuracy: 0.8917\n",
      "Epoch 65/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.2078 - accuracy: 0.9126\n",
      "Epoch 65: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2079 - accuracy: 0.9126 - val_loss: 0.1862 - val_accuracy: 0.9046\n",
      "Epoch 66/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.3654 - accuracy: 0.8187\n",
      "Epoch 66: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3650 - accuracy: 0.8194 - val_loss: 0.3311 - val_accuracy: 0.8524\n",
      "Epoch 67/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.3371 - accuracy: 0.8475\n",
      "Epoch 67: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3372 - accuracy: 0.8475 - val_loss: 0.3062 - val_accuracy: 0.8741\n",
      "Epoch 68/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.2988 - accuracy: 0.8666\n",
      "Epoch 68: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2983 - accuracy: 0.8670 - val_loss: 0.2963 - val_accuracy: 0.8538\n",
      "Epoch 69/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.3007 - accuracy: 0.8662\n",
      "Epoch 69: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3008 - accuracy: 0.8660 - val_loss: 0.3421 - val_accuracy: 0.8283\n",
      "Epoch 70/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.2444 - accuracy: 0.8965\n",
      "Epoch 70: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2444 - accuracy: 0.8965 - val_loss: 0.3084 - val_accuracy: 0.8457\n",
      "Epoch 71/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.2411 - accuracy: 0.8987\n",
      "Epoch 71: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2411 - accuracy: 0.8987 - val_loss: 0.2819 - val_accuracy: 0.8554\n",
      "Epoch 72/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.2180 - accuracy: 0.9122\n",
      "Epoch 72: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2179 - accuracy: 0.9122 - val_loss: 0.2318 - val_accuracy: 0.8893\n",
      "Epoch 73/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.2110 - accuracy: 0.9157\n",
      "Epoch 73: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2103 - accuracy: 0.9158 - val_loss: 0.2797 - val_accuracy: 0.8836\n",
      "Epoch 74/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.2881 - accuracy: 0.8793\n",
      "Epoch 74: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2881 - accuracy: 0.8793 - val_loss: 0.2775 - val_accuracy: 0.8813\n",
      "Epoch 75/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.9087\n",
      "Epoch 75: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2232 - accuracy: 0.9087 - val_loss: 0.2695 - val_accuracy: 0.8723\n",
      "Epoch 76/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.2278 - accuracy: 0.9048\n",
      "Epoch 76: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2277 - accuracy: 0.9048 - val_loss: 0.2701 - val_accuracy: 0.8710\n",
      "Epoch 77/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1939 - accuracy: 0.9219\n",
      "Epoch 77: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1939 - accuracy: 0.9219 - val_loss: 0.2713 - val_accuracy: 0.8841\n",
      "Epoch 78/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1990 - accuracy: 0.9195\n",
      "Epoch 78: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1990 - accuracy: 0.9195 - val_loss: 0.2664 - val_accuracy: 0.8749\n",
      "Epoch 79/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.2392 - accuracy: 0.9005\n",
      "Epoch 79: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2392 - accuracy: 0.9005 - val_loss: 0.2577 - val_accuracy: 0.8796\n",
      "Epoch 80/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.2083 - accuracy: 0.9166Restoring model weights from the end of the best epoch: 60.\n",
      "\n",
      "Epoch 80: val_accuracy did not improve from 0.91737\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2083 - accuracy: 0.9166 - val_loss: 0.2278 - val_accuracy: 0.8888\n",
      "Epoch 80: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "history=classifier.fit([X_train_scaled,X_train_scaled_f], y_train[:,0], epochs = 200, batch_size = 64,validation_data=([X_test_scaled,X_test_scaled_f],y_test[:,0]),callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7puZMrQ6rZ8B",
    "outputId": "386a61e0-2aee-492d-931c-92608253388a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 1s 5ms/step - loss: 0.1851 - accuracy: 0.9174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18510152399539948, 0.9173739552497864]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate([X_test_scaled,X_test_scaled_f],y_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "pXaIqqGvsq2-",
    "outputId": "7e0bbd5b-c337-4d12-d802-5cd917b366dc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def display_learning_curves(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    ax1.plot(history.history[\"loss\"])\n",
    "    ax1.plot(history.history[\"val_loss\"])\n",
    "    ax1.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "    ax2.plot(history.history[\"accuracy\"])\n",
    "    ax2.plot(history.history[\"val_accuracy\"])\n",
    "    ax2.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "display_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jzJ3rz1JZlM7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "L0VKJswYTc4O"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "temp=tf.keras.models.load_model(\"./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp2_exp5_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9bgdUJETn0g",
    "outputId": "04f2f7bd-8e0e-4e59-9d27-9d97ca33ae92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5773/5773 [==============================] - 30s 5ms/step - loss: 0.1851 - accuracy: 0.9174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1851012408733368, 0.9173739552497864]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.evaluate([X_test_scaled,X_test_scaled_f], y_test[:,0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbTiJwqAZhcj",
    "outputId": "62ddcb1e-f1f6-49dc-b2cc-40b8604d8bbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 3s 8ms/step - loss: 0.1851 - accuracy: 0.9174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18510152399539948, 0.9173739552497864]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.evaluate([X_test_scaled,X_test_scaled_f], y_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "RD4YF1AuT2tn"
   },
   "outputs": [],
   "source": [
    "y_pred = temp.predict([X_test_scaled,X_test_scaled_f])\n",
    "y_pred= (y_pred>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjx-DjHUWp52",
    "outputId": "7871dd46-0ff2-4946-d392-112125b1e037"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ipevqB9rXDeW"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rSeo2ltUXffg",
    "outputId": "f62abccb-897d-46f3-b89e-97987a48096d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4134,  244],\n",
       "       [ 233, 1162]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eM1TBa2IXtj2",
    "outputId": "7566d291-47b0-4fdc-c68e-94c58e16b4fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9173739823315434"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9V2DcARYNq6",
    "outputId": "18cf9c21-1dac-4a78-aee6-52b90be683b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.829703677258122"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwAjeUnMYQ1O",
    "outputId": "e4164c47-1df4-45a0-d39b-a9772642250b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      4378\n",
      "           1       0.83      0.83      0.83      1395\n",
      "\n",
      "    accuracy                           0.92      5773\n",
      "   macro avg       0.89      0.89      0.89      5773\n",
      "weighted avg       0.92      0.92      0.92      5773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test[:,0],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "46f7e55be9584f1ea1f87850465255c0",
      "595c6a0b563e4e16a11282e364c00bc4",
      "fa98ea8875994aadbf9fd2d1f75ed846",
      "e21941e7fdb74d0bb5ffaafe9a71cc6e",
      "574c975037274b6ab2156ea2339ff8b9",
      "601c20f1fd4d402180361057b4a0b644",
      "024f22fc52ce45fe84edc5ded351e881",
      "f6c81751c92d4de192451e008f1963a6",
      "f46b22ef7b7348309a7d8be7292a1cab",
      "5558f7c0156a4913bc10042f6e31f444",
      "cd9bd3cd58e7420dbafb57a2cdb1cfc9"
     ]
    },
    "id": "QPN2XdzLqpp_",
    "outputId": "e9ba05c3-7396-4e96-d58d-f798ea1ec46d"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017243385314941406,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f7e55be9584f1ea1f87850465255c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "288/288 [==============================] - 10s 17ms/step - loss: 0.5654 - accuracy: 0.6999 - val_loss: 0.4248 - val_accuracy: 0.7584\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.5425 - accuracy: 0.7069 - val_loss: 0.4618 - val_accuracy: 0.7684\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.5346 - accuracy: 0.7112 - val_loss: 0.4237 - val_accuracy: 0.7644\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.5222 - accuracy: 0.7201 - val_loss: 0.3767 - val_accuracy: 0.7970\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.4591 - accuracy: 0.7551 - val_loss: 0.3463 - val_accuracy: 0.8327\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3984 - accuracy: 0.8041 - val_loss: 0.3133 - val_accuracy: 0.8470\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3785 - accuracy: 0.8171 - val_loss: 0.3342 - val_accuracy: 0.8308\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3747 - accuracy: 0.8212 - val_loss: 0.3346 - val_accuracy: 0.8309\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3562 - accuracy: 0.8330 - val_loss: 0.3751 - val_accuracy: 0.7985\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3507 - accuracy: 0.8356 - val_loss: 0.3044 - val_accuracy: 0.8439\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3417 - accuracy: 0.8412 - val_loss: 0.3154 - val_accuracy: 0.8327\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.3438 - accuracy: 0.8414 - val_loss: 0.3515 - val_accuracy: 0.8204\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 6s 20ms/step - loss: 0.3404 - accuracy: 0.8429 - val_loss: 0.3262 - val_accuracy: 0.8443\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3269 - accuracy: 0.8501 - val_loss: 0.2834 - val_accuracy: 0.8585\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3193 - accuracy: 0.8553 - val_loss: 0.3056 - val_accuracy: 0.8536\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3192 - accuracy: 0.8551 - val_loss: 0.3168 - val_accuracy: 0.8403\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2987 - accuracy: 0.8682 - val_loss: 0.3420 - val_accuracy: 0.8379\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2927 - accuracy: 0.8710 - val_loss: 0.3056 - val_accuracy: 0.8588\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3150 - accuracy: 0.8580 - val_loss: 0.3308 - val_accuracy: 0.8386\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2919 - accuracy: 0.8734 - val_loss: 0.2823 - val_accuracy: 0.8658\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2846 - accuracy: 0.8779 - val_loss: 0.3181 - val_accuracy: 0.8470\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2721 - accuracy: 0.8800 - val_loss: 0.2743 - val_accuracy: 0.8699\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2701 - accuracy: 0.8843 - val_loss: 0.3084 - val_accuracy: 0.8585\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2667 - accuracy: 0.8837 - val_loss: 0.2714 - val_accuracy: 0.8748\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2617 - accuracy: 0.8874 - val_loss: 0.3195 - val_accuracy: 0.8363\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2610 - accuracy: 0.8861 - val_loss: 0.2752 - val_accuracy: 0.8706\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2540 - accuracy: 0.8927 - val_loss: 0.3176 - val_accuracy: 0.8418\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2559 - accuracy: 0.8880 - val_loss: 0.2629 - val_accuracy: 0.8718\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.2514 - accuracy: 0.8912 - val_loss: 0.2700 - val_accuracy: 0.8696\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2466 - accuracy: 0.8956 - val_loss: 0.2957 - val_accuracy: 0.8571\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2405 - accuracy: 0.8985 - val_loss: 0.2756 - val_accuracy: 0.8642\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2382 - accuracy: 0.8968 - val_loss: 0.2629 - val_accuracy: 0.8727\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2289 - accuracy: 0.9016 - val_loss: 0.2478 - val_accuracy: 0.8824\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2310 - accuracy: 0.9005 - val_loss: 0.3002 - val_accuracy: 0.8697\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2263 - accuracy: 0.9031 - val_loss: 0.3027 - val_accuracy: 0.8625\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2230 - accuracy: 0.9030 - val_loss: 0.2976 - val_accuracy: 0.8562\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2184 - accuracy: 0.9041 - val_loss: 0.3451 - val_accuracy: 0.8441\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2148 - accuracy: 0.9087 - val_loss: 0.3011 - val_accuracy: 0.8590\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2060 - accuracy: 0.9089 - val_loss: 0.2239 - val_accuracy: 0.8923\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2107 - accuracy: 0.9095 - val_loss: 0.2738 - val_accuracy: 0.8713\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2018 - accuracy: 0.9114 - val_loss: 0.2585 - val_accuracy: 0.8803\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1926 - accuracy: 0.9160 - val_loss: 0.3000 - val_accuracy: 0.8711\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1862 - accuracy: 0.9198 - val_loss: 0.2550 - val_accuracy: 0.8829\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1883 - accuracy: 0.9204 - val_loss: 0.2205 - val_accuracy: 0.9027\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1790 - accuracy: 0.9229 - val_loss: 0.2498 - val_accuracy: 0.8976\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1802 - accuracy: 0.9234 - val_loss: 0.2436 - val_accuracy: 0.8905\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1735 - accuracy: 0.9274 - val_loss: 0.2301 - val_accuracy: 0.9011\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1670 - accuracy: 0.9287 - val_loss: 0.2662 - val_accuracy: 0.8872\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1629 - accuracy: 0.9311 - val_loss: 0.2267 - val_accuracy: 0.8962\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1566 - accuracy: 0.9338 - val_loss: 0.2357 - val_accuracy: 0.9020\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1546 - accuracy: 0.9331 - val_loss: 0.2721 - val_accuracy: 0.8860\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1571 - accuracy: 0.9330 - val_loss: 0.2021 - val_accuracy: 0.9186\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1416 - accuracy: 0.9418 - val_loss: 0.2367 - val_accuracy: 0.9039\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1471 - accuracy: 0.9390 - val_loss: 0.1959 - val_accuracy: 0.9195\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1452 - accuracy: 0.9407 - val_loss: 0.2723 - val_accuracy: 0.8902\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1364 - accuracy: 0.9437 - val_loss: 0.2307 - val_accuracy: 0.9047\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1355 - accuracy: 0.9444 - val_loss: 0.3022 - val_accuracy: 0.8822\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1290 - accuracy: 0.9475 - val_loss: 0.2532 - val_accuracy: 0.8943\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1237 - accuracy: 0.9509 - val_loss: 0.3796 - val_accuracy: 0.8666\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1244 - accuracy: 0.9499 - val_loss: 0.2221 - val_accuracy: 0.9146\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1225 - accuracy: 0.9512 - val_loss: 0.2034 - val_accuracy: 0.9182\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1238 - accuracy: 0.9497 - val_loss: 0.2330 - val_accuracy: 0.9124\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1044 - accuracy: 0.9590 - val_loss: 0.2414 - val_accuracy: 0.9110\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1209 - accuracy: 0.9516 - val_loss: 0.2907 - val_accuracy: 0.8978\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1020 - accuracy: 0.9585 - val_loss: 0.2716 - val_accuracy: 0.8985\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1080 - accuracy: 0.9576 - val_loss: 0.2314 - val_accuracy: 0.9160\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0987 - accuracy: 0.9612 - val_loss: 0.2556 - val_accuracy: 0.9037\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0980 - accuracy: 0.9602 - val_loss: 0.2574 - val_accuracy: 0.9007\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0997 - accuracy: 0.9614 - val_loss: 0.2450 - val_accuracy: 0.9091\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0981 - accuracy: 0.9613 - val_loss: 0.2465 - val_accuracy: 0.9087\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0945 - accuracy: 0.9624 - val_loss: 0.2282 - val_accuracy: 0.9179\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0879 - accuracy: 0.9666 - val_loss: 0.2458 - val_accuracy: 0.8997\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0962 - accuracy: 0.9627 - val_loss: 0.2518 - val_accuracy: 0.9141\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.9671Restoring model weights from the end of the best epoch: 54.\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0865 - accuracy: 0.9671 - val_loss: 0.3452 - val_accuracy: 0.8775\n",
      "Epoch 74: early stopping\n",
      "Number of iterations 1\n",
      "F1-scores:  [0.8360944659851957]\n",
      "Average F1-Score 0.8360944659851957\n",
      "Std Dev F1-Score 0.0\n",
      "Error bar F1-Score 0.0\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 10s 18ms/step - loss: 0.5759 - accuracy: 0.6978 - val_loss: 0.4308 - val_accuracy: 0.7580\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.5437 - accuracy: 0.7020 - val_loss: 0.4196 - val_accuracy: 0.7774\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.5201 - accuracy: 0.7140 - val_loss: 0.3544 - val_accuracy: 0.8076\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.4411 - accuracy: 0.7704 - val_loss: 0.3531 - val_accuracy: 0.8316\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.4094 - accuracy: 0.7952 - val_loss: 0.3060 - val_accuracy: 0.8444\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3833 - accuracy: 0.8163 - val_loss: 0.3770 - val_accuracy: 0.7880\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3704 - accuracy: 0.8260 - val_loss: 0.3402 - val_accuracy: 0.8393\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3642 - accuracy: 0.8296 - val_loss: 0.2867 - val_accuracy: 0.8580\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3519 - accuracy: 0.8374 - val_loss: 0.3443 - val_accuracy: 0.8195\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3462 - accuracy: 0.8402 - val_loss: 0.2833 - val_accuracy: 0.8587\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3447 - accuracy: 0.8412 - val_loss: 0.3466 - val_accuracy: 0.8171\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3386 - accuracy: 0.8434 - val_loss: 0.3079 - val_accuracy: 0.8498\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3311 - accuracy: 0.8479 - val_loss: 0.3028 - val_accuracy: 0.8512\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3261 - accuracy: 0.8507 - val_loss: 0.3285 - val_accuracy: 0.8384\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.3133 - accuracy: 0.8575 - val_loss: 0.3338 - val_accuracy: 0.8296\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3026 - accuracy: 0.8664 - val_loss: 0.3483 - val_accuracy: 0.8271\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.3007 - accuracy: 0.8652 - val_loss: 0.2965 - val_accuracy: 0.8365\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2951 - accuracy: 0.8676 - val_loss: 0.2628 - val_accuracy: 0.8638\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2763 - accuracy: 0.8732 - val_loss: 0.2478 - val_accuracy: 0.8817\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2781 - accuracy: 0.8730 - val_loss: 0.2818 - val_accuracy: 0.8559\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2727 - accuracy: 0.8763 - val_loss: 0.2984 - val_accuracy: 0.8380\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2650 - accuracy: 0.8803 - val_loss: 0.2314 - val_accuracy: 0.8895\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2571 - accuracy: 0.8804 - val_loss: 0.2550 - val_accuracy: 0.8708\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2606 - accuracy: 0.8838 - val_loss: 0.2778 - val_accuracy: 0.8637\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2455 - accuracy: 0.8880 - val_loss: 0.2541 - val_accuracy: 0.8871\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2479 - accuracy: 0.8888 - val_loss: 0.2342 - val_accuracy: 0.8936\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2406 - accuracy: 0.8930 - val_loss: 0.2994 - val_accuracy: 0.8611\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2377 - accuracy: 0.8932 - val_loss: 0.2632 - val_accuracy: 0.8770\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2306 - accuracy: 0.8972 - val_loss: 0.2224 - val_accuracy: 0.8936\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2307 - accuracy: 0.8965 - val_loss: 0.2280 - val_accuracy: 0.8878\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2463 - accuracy: 0.8902 - val_loss: 0.2302 - val_accuracy: 0.8883\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2446 - accuracy: 0.8933 - val_loss: 0.2403 - val_accuracy: 0.8841\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2296 - accuracy: 0.8973 - val_loss: 0.2748 - val_accuracy: 0.8632\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2294 - accuracy: 0.8986 - val_loss: 0.2503 - val_accuracy: 0.8800\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2228 - accuracy: 0.9027 - val_loss: 0.2433 - val_accuracy: 0.8852\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2140 - accuracy: 0.9065 - val_loss: 0.2413 - val_accuracy: 0.8902\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2179 - accuracy: 0.9039 - val_loss: 0.2653 - val_accuracy: 0.8746\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2223 - accuracy: 0.9028 - val_loss: 0.2267 - val_accuracy: 0.8853\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2104 - accuracy: 0.9106 - val_loss: 0.2540 - val_accuracy: 0.8770\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1983 - accuracy: 0.9161 - val_loss: 0.2496 - val_accuracy: 0.8808\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1995 - accuracy: 0.9141 - val_loss: 0.2345 - val_accuracy: 0.8864\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1922 - accuracy: 0.9189 - val_loss: 0.2275 - val_accuracy: 0.8942\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2053 - accuracy: 0.9122 - val_loss: 0.2819 - val_accuracy: 0.8689\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1953 - accuracy: 0.9157 - val_loss: 0.2638 - val_accuracy: 0.8815\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1889 - accuracy: 0.9197 - val_loss: 0.2391 - val_accuracy: 0.8883\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1912 - accuracy: 0.9181 - val_loss: 0.2164 - val_accuracy: 0.9023\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1790 - accuracy: 0.9255 - val_loss: 0.2253 - val_accuracy: 0.8997\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1772 - accuracy: 0.9261 - val_loss: 0.2292 - val_accuracy: 0.9016\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1696 - accuracy: 0.9290 - val_loss: 0.2982 - val_accuracy: 0.8710\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1705 - accuracy: 0.9280 - val_loss: 0.2701 - val_accuracy: 0.8803\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1796 - accuracy: 0.9253 - val_loss: 0.2686 - val_accuracy: 0.8774\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1610 - accuracy: 0.9328 - val_loss: 0.2290 - val_accuracy: 0.9004\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1714 - accuracy: 0.9287 - val_loss: 0.2595 - val_accuracy: 0.8843\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1575 - accuracy: 0.9349 - val_loss: 0.3335 - val_accuracy: 0.8694\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1583 - accuracy: 0.9347 - val_loss: 0.3243 - val_accuracy: 0.8600\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1496 - accuracy: 0.9393 - val_loss: 0.2371 - val_accuracy: 0.9018\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1453 - accuracy: 0.9398 - val_loss: 0.2815 - val_accuracy: 0.8822\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1453 - accuracy: 0.9411 - val_loss: 0.2489 - val_accuracy: 0.8975\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1371 - accuracy: 0.9439 - val_loss: 0.2864 - val_accuracy: 0.8839\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1367 - accuracy: 0.9456 - val_loss: 0.2856 - val_accuracy: 0.8829\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1285 - accuracy: 0.9476 - val_loss: 0.2604 - val_accuracy: 0.8987\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1255 - accuracy: 0.9485 - val_loss: 0.2546 - val_accuracy: 0.8959\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1357 - accuracy: 0.9446 - val_loss: 0.2741 - val_accuracy: 0.8883\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1292 - accuracy: 0.9471 - val_loss: 0.2662 - val_accuracy: 0.8945\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1191 - accuracy: 0.9526 - val_loss: 0.2344 - val_accuracy: 0.9051\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1175 - accuracy: 0.9513 - val_loss: 0.3244 - val_accuracy: 0.8753\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1238 - accuracy: 0.9510 - val_loss: 0.3146 - val_accuracy: 0.8768\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1158 - accuracy: 0.9527 - val_loss: 0.2429 - val_accuracy: 0.9027\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1109 - accuracy: 0.9559 - val_loss: 0.3369 - val_accuracy: 0.8857\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1162 - accuracy: 0.9534 - val_loss: 0.2534 - val_accuracy: 0.9073\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1122 - accuracy: 0.9553 - val_loss: 0.2839 - val_accuracy: 0.8964\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1092 - accuracy: 0.9552 - val_loss: 0.2907 - val_accuracy: 0.8897\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1055 - accuracy: 0.9572 - val_loss: 0.3805 - val_accuracy: 0.8782\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1048 - accuracy: 0.9588 - val_loss: 0.3499 - val_accuracy: 0.8789\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1054 - accuracy: 0.9583 - val_loss: 0.2858 - val_accuracy: 0.8881\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.0976 - accuracy: 0.9622 - val_loss: 0.3449 - val_accuracy: 0.8853\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1000 - accuracy: 0.9610 - val_loss: 0.2996 - val_accuracy: 0.8884\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0924 - accuracy: 0.9639 - val_loss: 0.2868 - val_accuracy: 0.8994\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1512 - accuracy: 0.9411 - val_loss: 0.2640 - val_accuracy: 0.8929\n",
      "Epoch 80/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1323 - accuracy: 0.9466 - val_loss: 0.2632 - val_accuracy: 0.8975\n",
      "Epoch 81/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.1105 - accuracy: 0.9572 - val_loss: 0.3095 - val_accuracy: 0.8931\n",
      "Epoch 82/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0991 - accuracy: 0.9605 - val_loss: 0.3187 - val_accuracy: 0.8902\n",
      "Epoch 83/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0923 - accuracy: 0.9636 - val_loss: 0.3830 - val_accuracy: 0.8781\n",
      "Epoch 84/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0891 - accuracy: 0.9662 - val_loss: 0.3245 - val_accuracy: 0.8985\n",
      "Epoch 85/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.0861 - accuracy: 0.9663 - val_loss: 0.2470 - val_accuracy: 0.9120\n",
      "Epoch 86/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.0795 - accuracy: 0.9685 - val_loss: 0.2959 - val_accuracy: 0.9023\n",
      "Epoch 87/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0849 - accuracy: 0.9658 - val_loss: 0.3495 - val_accuracy: 0.8878\n",
      "Epoch 88/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0897 - accuracy: 0.9654 - val_loss: 0.2834 - val_accuracy: 0.9025\n",
      "Epoch 89/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.0781 - accuracy: 0.9690 - val_loss: 0.3797 - val_accuracy: 0.8819\n",
      "Epoch 90/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.0775 - accuracy: 0.9709 - val_loss: 0.3630 - val_accuracy: 0.8902\n",
      "Epoch 91/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.0845 - accuracy: 0.9680 - val_loss: 0.3356 - val_accuracy: 0.8947\n",
      "Epoch 92/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.0692 - accuracy: 0.9729 - val_loss: 0.3520 - val_accuracy: 0.8952\n",
      "Epoch 93/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.0661 - accuracy: 0.9757 - val_loss: 0.3493 - val_accuracy: 0.8954\n",
      "Epoch 94/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.0765 - accuracy: 0.9704 - val_loss: 0.3781 - val_accuracy: 0.8853\n",
      "Epoch 95/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.0642 - accuracy: 0.9742 - val_loss: 0.3508 - val_accuracy: 0.8945\n",
      "Epoch 96/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.0707 - accuracy: 0.9744 - val_loss: 0.3302 - val_accuracy: 0.8926\n",
      "Epoch 97/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.0687 - accuracy: 0.9736 - val_loss: 0.3423 - val_accuracy: 0.9009\n",
      "Epoch 98/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.0629 - accuracy: 0.9769 - val_loss: 0.3590 - val_accuracy: 0.8966\n",
      "Epoch 99/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.0676 - accuracy: 0.9755 - val_loss: 0.3440 - val_accuracy: 0.9004\n",
      "Epoch 100/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0720 - accuracy: 0.9713 - val_loss: 0.3660 - val_accuracy: 0.8781\n",
      "Epoch 101/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.0669 - accuracy: 0.9739 - val_loss: 0.3469 - val_accuracy: 0.9023\n",
      "Epoch 102/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.0637 - accuracy: 0.9765 - val_loss: 0.3589 - val_accuracy: 0.8978\n",
      "Epoch 103/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.0620 - accuracy: 0.9777 - val_loss: 0.3953 - val_accuracy: 0.8796\n",
      "Epoch 104/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.0572 - accuracy: 0.9786 - val_loss: 0.3545 - val_accuracy: 0.8957\n",
      "Epoch 105/500\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.0554 - accuracy: 0.9791Restoring model weights from the end of the best epoch: 85.\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.0552 - accuracy: 0.9792 - val_loss: 0.4116 - val_accuracy: 0.8912\n",
      "Epoch 105: early stopping\n",
      "Number of iterations 2\n",
      "F1-scores:  [0.8360944659851957, 0.8121301775147929]\n",
      "Average F1-Score 0.8241123217499943\n",
      "Std Dev F1-Score 0.011982144235201386\n",
      "Error bar F1-Score 0.008472655441866197\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 11s 18ms/step - loss: 0.5739 - accuracy: 0.6972 - val_loss: 0.4478 - val_accuracy: 0.7584\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5382 - accuracy: 0.7042 - val_loss: 0.4334 - val_accuracy: 0.7729\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5349 - accuracy: 0.7137 - val_loss: 0.4252 - val_accuracy: 0.7828\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5312 - accuracy: 0.7165 - val_loss: 0.4208 - val_accuracy: 0.7783\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5244 - accuracy: 0.7160 - val_loss: 0.4321 - val_accuracy: 0.7767\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5239 - accuracy: 0.7162 - val_loss: 0.4711 - val_accuracy: 0.7757\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5193 - accuracy: 0.7171 - val_loss: 0.4297 - val_accuracy: 0.7760\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5203 - accuracy: 0.7155 - val_loss: 0.4067 - val_accuracy: 0.7805\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5153 - accuracy: 0.7188 - val_loss: 0.4129 - val_accuracy: 0.7785\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5138 - accuracy: 0.7168 - val_loss: 0.4201 - val_accuracy: 0.7828\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5117 - accuracy: 0.7208 - val_loss: 0.4051 - val_accuracy: 0.7954\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5141 - accuracy: 0.7186 - val_loss: 0.4327 - val_accuracy: 0.7748\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5117 - accuracy: 0.7225 - val_loss: 0.4427 - val_accuracy: 0.7772\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5113 - accuracy: 0.7195 - val_loss: 0.4163 - val_accuracy: 0.7814\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5090 - accuracy: 0.7217 - val_loss: 0.4067 - val_accuracy: 0.7791\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5118 - accuracy: 0.7199 - val_loss: 0.4187 - val_accuracy: 0.7764\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5084 - accuracy: 0.7217 - val_loss: 0.4171 - val_accuracy: 0.7798\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5063 - accuracy: 0.7209 - val_loss: 0.4081 - val_accuracy: 0.7821\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5072 - accuracy: 0.7227 - val_loss: 0.4061 - val_accuracy: 0.7882\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5078 - accuracy: 0.7228 - val_loss: 0.4052 - val_accuracy: 0.7788\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5064 - accuracy: 0.7217 - val_loss: 0.4116 - val_accuracy: 0.7902\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.4999 - accuracy: 0.7192 - val_loss: 0.3901 - val_accuracy: 0.7944\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.4947 - accuracy: 0.7245 - val_loss: 0.3737 - val_accuracy: 0.7996\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.4916 - accuracy: 0.7277 - val_loss: 0.3835 - val_accuracy: 0.7894\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.4814 - accuracy: 0.7342 - val_loss: 0.3918 - val_accuracy: 0.7904\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.4784 - accuracy: 0.7372 - val_loss: 0.3660 - val_accuracy: 0.8122\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.4726 - accuracy: 0.7448 - val_loss: 0.3941 - val_accuracy: 0.7921\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.4720 - accuracy: 0.7389 - val_loss: 0.3967 - val_accuracy: 0.7939\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.4639 - accuracy: 0.7524 - val_loss: 0.3884 - val_accuracy: 0.7977\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.4616 - accuracy: 0.7531 - val_loss: 0.3645 - val_accuracy: 0.8018\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.4591 - accuracy: 0.7558 - val_loss: 0.3666 - val_accuracy: 0.8027\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.4550 - accuracy: 0.7565 - val_loss: 0.3706 - val_accuracy: 0.8100\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.4430 - accuracy: 0.7675 - val_loss: 0.3525 - val_accuracy: 0.8162\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.4356 - accuracy: 0.7731 - val_loss: 0.3416 - val_accuracy: 0.8275\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.4205 - accuracy: 0.7819 - val_loss: 0.2988 - val_accuracy: 0.8535\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.3715 - accuracy: 0.8189 - val_loss: 0.3314 - val_accuracy: 0.8323\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.3342 - accuracy: 0.8478 - val_loss: 0.3934 - val_accuracy: 0.8107\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.3120 - accuracy: 0.8611 - val_loss: 0.3120 - val_accuracy: 0.8548\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2912 - accuracy: 0.8737 - val_loss: 0.3169 - val_accuracy: 0.8514\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2749 - accuracy: 0.8799 - val_loss: 0.2948 - val_accuracy: 0.8635\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2674 - accuracy: 0.8842 - val_loss: 0.3345 - val_accuracy: 0.8413\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2476 - accuracy: 0.8919 - val_loss: 0.2916 - val_accuracy: 0.8618\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2465 - accuracy: 0.8906 - val_loss: 0.2938 - val_accuracy: 0.8602\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2349 - accuracy: 0.8986 - val_loss: 0.2807 - val_accuracy: 0.8633\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2264 - accuracy: 0.9017 - val_loss: 0.3115 - val_accuracy: 0.8583\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2270 - accuracy: 0.9020 - val_loss: 0.2611 - val_accuracy: 0.8824\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2184 - accuracy: 0.9058 - val_loss: 0.2958 - val_accuracy: 0.8583\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2137 - accuracy: 0.9063 - val_loss: 0.2658 - val_accuracy: 0.8817\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2143 - accuracy: 0.9096 - val_loss: 0.2817 - val_accuracy: 0.8706\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2020 - accuracy: 0.9138 - val_loss: 0.3364 - val_accuracy: 0.8483\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1980 - accuracy: 0.9166 - val_loss: 0.2533 - val_accuracy: 0.8858\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1983 - accuracy: 0.9182 - val_loss: 0.2753 - val_accuracy: 0.8774\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1940 - accuracy: 0.9195 - val_loss: 0.2845 - val_accuracy: 0.8805\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1843 - accuracy: 0.9228 - val_loss: 0.2690 - val_accuracy: 0.8878\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1868 - accuracy: 0.9216 - val_loss: 0.2450 - val_accuracy: 0.8914\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1841 - accuracy: 0.9215 - val_loss: 0.3581 - val_accuracy: 0.8470\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1824 - accuracy: 0.9236 - val_loss: 0.2805 - val_accuracy: 0.8831\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1748 - accuracy: 0.9284 - val_loss: 0.2649 - val_accuracy: 0.8881\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1627 - accuracy: 0.9336 - val_loss: 0.2588 - val_accuracy: 0.8955\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1638 - accuracy: 0.9319 - val_loss: 0.2262 - val_accuracy: 0.9082\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1780 - accuracy: 0.9258 - val_loss: 0.2520 - val_accuracy: 0.8961\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1649 - accuracy: 0.9312 - val_loss: 0.3496 - val_accuracy: 0.8684\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1609 - accuracy: 0.9326 - val_loss: 0.2502 - val_accuracy: 0.8995\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1534 - accuracy: 0.9366 - val_loss: 0.3336 - val_accuracy: 0.8775\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1497 - accuracy: 0.9379 - val_loss: 0.2992 - val_accuracy: 0.8855\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1550 - accuracy: 0.9371 - val_loss: 0.2705 - val_accuracy: 0.8909\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1408 - accuracy: 0.9418 - val_loss: 0.2631 - val_accuracy: 0.8909\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1430 - accuracy: 0.9401 - val_loss: 0.3058 - val_accuracy: 0.8805\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1435 - accuracy: 0.9401 - val_loss: 0.3129 - val_accuracy: 0.8848\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1386 - accuracy: 0.9440 - val_loss: 0.2997 - val_accuracy: 0.8845\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1383 - accuracy: 0.9438 - val_loss: 0.3290 - val_accuracy: 0.8706\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1313 - accuracy: 0.9465 - val_loss: 0.3361 - val_accuracy: 0.8732\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1335 - accuracy: 0.9445 - val_loss: 0.3156 - val_accuracy: 0.8841\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1312 - accuracy: 0.9451 - val_loss: 0.3127 - val_accuracy: 0.8891\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1274 - accuracy: 0.9476 - val_loss: 0.3245 - val_accuracy: 0.8741\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1233 - accuracy: 0.9493 - val_loss: 0.3035 - val_accuracy: 0.8935\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1275 - accuracy: 0.9488 - val_loss: 0.4207 - val_accuracy: 0.8573\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1162 - accuracy: 0.9527 - val_loss: 0.3057 - val_accuracy: 0.8917\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1206 - accuracy: 0.9507 - val_loss: 0.3599 - val_accuracy: 0.8727\n",
      "Epoch 80/500\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.9529Restoring model weights from the end of the best epoch: 60.\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1148 - accuracy: 0.9531 - val_loss: 0.3469 - val_accuracy: 0.8824\n",
      "Epoch 80: early stopping\n",
      "Number of iterations 3\n",
      "F1-scores:  [0.8360944659851957, 0.8121301775147929, 0.8251978891820579]\n",
      "Average F1-Score 0.8244741775606821\n",
      "Std Dev F1-Score 0.00979675454275056\n",
      "Error bar F1-Score 0.0056561588724417244\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 11s 19ms/step - loss: 0.5801 - accuracy: 0.6974 - val_loss: 0.4472 - val_accuracy: 0.7584\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5469 - accuracy: 0.7019 - val_loss: 0.4469 - val_accuracy: 0.7584\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5320 - accuracy: 0.7111 - val_loss: 0.4152 - val_accuracy: 0.7745\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5060 - accuracy: 0.7223 - val_loss: 0.3801 - val_accuracy: 0.7909\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.4562 - accuracy: 0.7513 - val_loss: 0.3187 - val_accuracy: 0.8268\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.3669 - accuracy: 0.8251 - val_loss: 0.2911 - val_accuracy: 0.8630\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.3233 - accuracy: 0.8531 - val_loss: 0.2634 - val_accuracy: 0.8718\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3071 - accuracy: 0.8592 - val_loss: 0.2493 - val_accuracy: 0.8789\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2738 - accuracy: 0.8741 - val_loss: 0.2784 - val_accuracy: 0.8720\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2722 - accuracy: 0.8758 - val_loss: 0.2538 - val_accuracy: 0.8805\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2666 - accuracy: 0.8794 - val_loss: 0.2560 - val_accuracy: 0.8749\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2591 - accuracy: 0.8816 - val_loss: 0.2512 - val_accuracy: 0.8782\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2461 - accuracy: 0.8878 - val_loss: 0.2278 - val_accuracy: 0.8959\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2524 - accuracy: 0.8858 - val_loss: 0.2403 - val_accuracy: 0.8883\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2370 - accuracy: 0.8922 - val_loss: 0.2404 - val_accuracy: 0.8853\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2388 - accuracy: 0.8937 - val_loss: 0.2303 - val_accuracy: 0.8881\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2247 - accuracy: 0.8981 - val_loss: 0.2996 - val_accuracy: 0.8590\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2349 - accuracy: 0.8940 - val_loss: 0.2239 - val_accuracy: 0.8976\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2341 - accuracy: 0.8961 - val_loss: 0.2518 - val_accuracy: 0.8838\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2218 - accuracy: 0.9020 - val_loss: 0.2157 - val_accuracy: 0.8999\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2224 - accuracy: 0.8998 - val_loss: 0.2150 - val_accuracy: 0.8975\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2129 - accuracy: 0.9061 - val_loss: 0.2318 - val_accuracy: 0.8862\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2118 - accuracy: 0.9067 - val_loss: 0.2528 - val_accuracy: 0.8793\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2157 - accuracy: 0.9041 - val_loss: 0.2114 - val_accuracy: 0.9014\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1999 - accuracy: 0.9130 - val_loss: 0.2366 - val_accuracy: 0.8850\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2144 - accuracy: 0.9066 - val_loss: 0.2163 - val_accuracy: 0.9002\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1951 - accuracy: 0.9125 - val_loss: 0.2216 - val_accuracy: 0.8926\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2025 - accuracy: 0.9109 - val_loss: 0.2254 - val_accuracy: 0.8919\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1888 - accuracy: 0.9179 - val_loss: 0.2353 - val_accuracy: 0.8846\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1851 - accuracy: 0.9204 - val_loss: 0.2210 - val_accuracy: 0.8971\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1805 - accuracy: 0.9207 - val_loss: 0.2194 - val_accuracy: 0.9014\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1799 - accuracy: 0.9231 - val_loss: 0.2437 - val_accuracy: 0.8895\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1826 - accuracy: 0.9214 - val_loss: 0.2580 - val_accuracy: 0.8855\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1776 - accuracy: 0.9255 - val_loss: 0.2304 - val_accuracy: 0.8933\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1731 - accuracy: 0.9241 - val_loss: 0.2734 - val_accuracy: 0.8812\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1678 - accuracy: 0.9290 - val_loss: 0.2511 - val_accuracy: 0.8879\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1618 - accuracy: 0.9317 - val_loss: 0.2604 - val_accuracy: 0.8858\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1568 - accuracy: 0.9339 - val_loss: 0.2324 - val_accuracy: 0.8973\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1660 - accuracy: 0.9303 - val_loss: 0.2690 - val_accuracy: 0.8838\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1608 - accuracy: 0.9325 - val_loss: 0.2455 - val_accuracy: 0.8919\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1606 - accuracy: 0.9313 - val_loss: 0.2347 - val_accuracy: 0.8983\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1420 - accuracy: 0.9418 - val_loss: 0.2717 - val_accuracy: 0.8914\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1516 - accuracy: 0.9351 - val_loss: 0.2459 - val_accuracy: 0.8995\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1447 - accuracy: 0.9386 - val_loss: 0.2228 - val_accuracy: 0.9075\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1511 - accuracy: 0.9350 - val_loss: 0.2287 - val_accuracy: 0.9037\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1495 - accuracy: 0.9368 - val_loss: 0.2500 - val_accuracy: 0.8959\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1396 - accuracy: 0.9437 - val_loss: 0.2229 - val_accuracy: 0.9136\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1341 - accuracy: 0.9436 - val_loss: 0.2507 - val_accuracy: 0.9009\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1497 - accuracy: 0.9367 - val_loss: 0.2193 - val_accuracy: 0.9077\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1284 - accuracy: 0.9453 - val_loss: 0.2417 - val_accuracy: 0.8983\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1324 - accuracy: 0.9462 - val_loss: 0.2787 - val_accuracy: 0.8942\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1296 - accuracy: 0.9459 - val_loss: 0.2790 - val_accuracy: 0.8976\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1232 - accuracy: 0.9494 - val_loss: 0.2551 - val_accuracy: 0.9042\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1594 - accuracy: 0.9358 - val_loss: 0.2455 - val_accuracy: 0.8945\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1397 - accuracy: 0.9430 - val_loss: 0.2268 - val_accuracy: 0.9021\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1307 - accuracy: 0.9463 - val_loss: 0.2565 - val_accuracy: 0.8969\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1208 - accuracy: 0.9523 - val_loss: 0.2582 - val_accuracy: 0.9018\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1277 - accuracy: 0.9501 - val_loss: 0.2914 - val_accuracy: 0.8994\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1193 - accuracy: 0.9514 - val_loss: 0.2578 - val_accuracy: 0.9001\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1153 - accuracy: 0.9544 - val_loss: 0.2957 - val_accuracy: 0.8959\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1060 - accuracy: 0.9575 - val_loss: 0.2765 - val_accuracy: 0.8988\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1101 - accuracy: 0.9542 - val_loss: 0.2507 - val_accuracy: 0.8995\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1033 - accuracy: 0.9566 - val_loss: 0.4239 - val_accuracy: 0.8597\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1089 - accuracy: 0.9558 - val_loss: 0.2696 - val_accuracy: 0.9033\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1118 - accuracy: 0.9558 - val_loss: 0.2610 - val_accuracy: 0.8995\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1076 - accuracy: 0.9567 - val_loss: 0.2459 - val_accuracy: 0.9016\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.1559 - accuracy: 0.9379Restoring model weights from the end of the best epoch: 47.\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1559 - accuracy: 0.9379 - val_loss: 0.2790 - val_accuracy: 0.8883\n",
      "Epoch 67: early stopping\n",
      "Number of iterations 4\n",
      "F1-scores:  [0.8360944659851957, 0.8121301775147929, 0.8251978891820579, 0.8328308207705193]\n",
      "Average F1-Score 0.8265633383631414\n",
      "Std Dev F1-Score 0.009223669457096493\n",
      "Error bar F1-Score 0.0046118347285482465\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 11s 19ms/step - loss: 0.5686 - accuracy: 0.6987 - val_loss: 0.4270 - val_accuracy: 0.7627\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.5375 - accuracy: 0.7046 - val_loss: 0.4080 - val_accuracy: 0.7771\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4853 - accuracy: 0.7421 - val_loss: 0.3252 - val_accuracy: 0.8528\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3896 - accuracy: 0.8068 - val_loss: 0.3193 - val_accuracy: 0.8457\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3455 - accuracy: 0.8400 - val_loss: 0.3176 - val_accuracy: 0.8488\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.3349 - accuracy: 0.8497 - val_loss: 0.3122 - val_accuracy: 0.8554\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.3372 - accuracy: 0.8465 - val_loss: 0.3199 - val_accuracy: 0.8275\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.3106 - accuracy: 0.8637 - val_loss: 0.3180 - val_accuracy: 0.8559\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.3060 - accuracy: 0.8675 - val_loss: 0.3009 - val_accuracy: 0.8490\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2902 - accuracy: 0.8724 - val_loss: 0.2987 - val_accuracy: 0.8536\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2820 - accuracy: 0.8742 - val_loss: 0.2604 - val_accuracy: 0.8690\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2736 - accuracy: 0.8760 - val_loss: 0.3078 - val_accuracy: 0.8496\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2629 - accuracy: 0.8811 - val_loss: 0.3117 - val_accuracy: 0.8380\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2601 - accuracy: 0.8836 - val_loss: 0.3881 - val_accuracy: 0.8159\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2514 - accuracy: 0.8854 - val_loss: 0.3271 - val_accuracy: 0.8457\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2422 - accuracy: 0.8913 - val_loss: 0.2713 - val_accuracy: 0.8668\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2465 - accuracy: 0.8888 - val_loss: 0.2808 - val_accuracy: 0.8770\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2366 - accuracy: 0.8946 - val_loss: 0.2535 - val_accuracy: 0.8813\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2335 - accuracy: 0.8980 - val_loss: 0.2260 - val_accuracy: 0.8900\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2289 - accuracy: 0.8982 - val_loss: 0.2788 - val_accuracy: 0.8684\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2275 - accuracy: 0.8984 - val_loss: 0.2423 - val_accuracy: 0.8905\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2228 - accuracy: 0.9039 - val_loss: 0.2343 - val_accuracy: 0.8933\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2162 - accuracy: 0.9025 - val_loss: 0.2237 - val_accuracy: 0.8985\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2224 - accuracy: 0.9030 - val_loss: 0.2219 - val_accuracy: 0.8955\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2020 - accuracy: 0.9119 - val_loss: 0.2664 - val_accuracy: 0.8765\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2081 - accuracy: 0.9091 - val_loss: 0.2342 - val_accuracy: 0.8909\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.2015 - accuracy: 0.9130 - val_loss: 0.2104 - val_accuracy: 0.9033\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1987 - accuracy: 0.9150 - val_loss: 0.2202 - val_accuracy: 0.9007\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1914 - accuracy: 0.9184 - val_loss: 0.2068 - val_accuracy: 0.9059\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1953 - accuracy: 0.9160 - val_loss: 0.2166 - val_accuracy: 0.9006\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1821 - accuracy: 0.9227 - val_loss: 0.2554 - val_accuracy: 0.8881\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1820 - accuracy: 0.9227 - val_loss: 0.2033 - val_accuracy: 0.9091\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1767 - accuracy: 0.9266 - val_loss: 0.2527 - val_accuracy: 0.8807\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1764 - accuracy: 0.9272 - val_loss: 0.2154 - val_accuracy: 0.8968\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1739 - accuracy: 0.9276 - val_loss: 0.2302 - val_accuracy: 0.8968\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1734 - accuracy: 0.9280 - val_loss: 0.2001 - val_accuracy: 0.9117\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1717 - accuracy: 0.9276 - val_loss: 0.2389 - val_accuracy: 0.8964\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1597 - accuracy: 0.9342 - val_loss: 0.2590 - val_accuracy: 0.8857\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1666 - accuracy: 0.9301 - val_loss: 0.2212 - val_accuracy: 0.9077\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1552 - accuracy: 0.9367 - val_loss: 0.2316 - val_accuracy: 0.9032\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1503 - accuracy: 0.9374 - val_loss: 0.2040 - val_accuracy: 0.9084\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.1497 - accuracy: 0.9373 - val_loss: 0.2248 - val_accuracy: 0.9007\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1492 - accuracy: 0.9381 - val_loss: 0.2047 - val_accuracy: 0.9106\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1415 - accuracy: 0.9419 - val_loss: 0.2111 - val_accuracy: 0.9122\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1369 - accuracy: 0.9437 - val_loss: 0.2187 - val_accuracy: 0.9137\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1476 - accuracy: 0.9402 - val_loss: 0.2239 - val_accuracy: 0.9066\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1367 - accuracy: 0.9428 - val_loss: 0.1936 - val_accuracy: 0.9163\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1283 - accuracy: 0.9478 - val_loss: 0.1971 - val_accuracy: 0.9182\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1292 - accuracy: 0.9483 - val_loss: 0.2234 - val_accuracy: 0.9092\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1494 - accuracy: 0.9387 - val_loss: 0.2494 - val_accuracy: 0.9004\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1281 - accuracy: 0.9478 - val_loss: 0.2317 - val_accuracy: 0.9104\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1176 - accuracy: 0.9525 - val_loss: 0.2018 - val_accuracy: 0.9129\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1317 - accuracy: 0.9461 - val_loss: 0.1942 - val_accuracy: 0.9222\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1216 - accuracy: 0.9504 - val_loss: 0.1972 - val_accuracy: 0.9203\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1066 - accuracy: 0.9577 - val_loss: 0.1875 - val_accuracy: 0.9267\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1220 - accuracy: 0.9516 - val_loss: 0.2016 - val_accuracy: 0.9182\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1069 - accuracy: 0.9583 - val_loss: 0.1991 - val_accuracy: 0.9271\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1047 - accuracy: 0.9587 - val_loss: 0.2489 - val_accuracy: 0.9110\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1103 - accuracy: 0.9553 - val_loss: 0.2419 - val_accuracy: 0.9046\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1080 - accuracy: 0.9570 - val_loss: 0.2005 - val_accuracy: 0.9257\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1048 - accuracy: 0.9578 - val_loss: 0.2057 - val_accuracy: 0.9226\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0893 - accuracy: 0.9650 - val_loss: 0.2590 - val_accuracy: 0.9098\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0949 - accuracy: 0.9634 - val_loss: 0.2072 - val_accuracy: 0.9248\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0954 - accuracy: 0.9617 - val_loss: 0.2716 - val_accuracy: 0.9002\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0927 - accuracy: 0.9648 - val_loss: 0.1949 - val_accuracy: 0.9318\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0993 - accuracy: 0.9611 - val_loss: 0.2256 - val_accuracy: 0.9153\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0881 - accuracy: 0.9647 - val_loss: 0.2136 - val_accuracy: 0.9264\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0741 - accuracy: 0.9724 - val_loss: 0.2283 - val_accuracy: 0.9234\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0792 - accuracy: 0.9706 - val_loss: 0.2188 - val_accuracy: 0.9212\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0942 - accuracy: 0.9649 - val_loss: 0.2546 - val_accuracy: 0.9143\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0754 - accuracy: 0.9706 - val_loss: 0.2785 - val_accuracy: 0.9084\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0805 - accuracy: 0.9699 - val_loss: 0.2337 - val_accuracy: 0.9234\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0854 - accuracy: 0.9677 - val_loss: 0.2201 - val_accuracy: 0.9226\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0810 - accuracy: 0.9684 - val_loss: 0.2650 - val_accuracy: 0.9016\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0855 - accuracy: 0.9678 - val_loss: 0.2360 - val_accuracy: 0.9274\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0665 - accuracy: 0.9741 - val_loss: 0.2101 - val_accuracy: 0.9309\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0769 - accuracy: 0.9698 - val_loss: 0.2109 - val_accuracy: 0.9295\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0751 - accuracy: 0.9712 - val_loss: 0.2577 - val_accuracy: 0.9201\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0736 - accuracy: 0.9724 - val_loss: 0.2646 - val_accuracy: 0.8981\n",
      "Epoch 80/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0817 - accuracy: 0.9693 - val_loss: 0.2082 - val_accuracy: 0.9300\n",
      "Epoch 81/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0669 - accuracy: 0.9749 - val_loss: 0.2155 - val_accuracy: 0.9305\n",
      "Epoch 82/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0587 - accuracy: 0.9780 - val_loss: 0.2447 - val_accuracy: 0.9208\n",
      "Epoch 83/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0551 - accuracy: 0.9794 - val_loss: 0.2579 - val_accuracy: 0.9201\n",
      "Epoch 84/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0776 - accuracy: 0.9704 - val_loss: 0.2199 - val_accuracy: 0.9311\n",
      "Epoch 85/500\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.0523 - accuracy: 0.9804Restoring model weights from the end of the best epoch: 65.\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0522 - accuracy: 0.9804 - val_loss: 0.3006 - val_accuracy: 0.9144\n",
      "Epoch 85: early stopping\n",
      "Number of iterations 5\n",
      "F1-scores:  [0.8360944659851957, 0.8121301775147929, 0.8251978891820579, 0.8328308207705193, 0.8615600843288825]\n",
      "Average F1-Score 0.8335626875562896\n",
      "Std Dev F1-Score 0.016248828238169\n",
      "Error bar F1-Score 0.007266696899052804\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 12s 21ms/step - loss: 0.5619 - accuracy: 0.6988 - val_loss: 0.4229 - val_accuracy: 0.7797\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5372 - accuracy: 0.7063 - val_loss: 0.4329 - val_accuracy: 0.7712\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5236 - accuracy: 0.7176 - val_loss: 0.4158 - val_accuracy: 0.7861\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4351 - accuracy: 0.7774 - val_loss: 0.3603 - val_accuracy: 0.8166\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3731 - accuracy: 0.8216 - val_loss: 0.3049 - val_accuracy: 0.8600\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3487 - accuracy: 0.8368 - val_loss: 0.3127 - val_accuracy: 0.8547\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 4s 14ms/step - loss: 0.3205 - accuracy: 0.8572 - val_loss: 0.3130 - val_accuracy: 0.8581\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2947 - accuracy: 0.8690 - val_loss: 0.2651 - val_accuracy: 0.8666\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2932 - accuracy: 0.8671 - val_loss: 0.2985 - val_accuracy: 0.8554\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2870 - accuracy: 0.8711 - val_loss: 0.2995 - val_accuracy: 0.8467\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2640 - accuracy: 0.8792 - val_loss: 0.2699 - val_accuracy: 0.8735\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2650 - accuracy: 0.8810 - val_loss: 0.3349 - val_accuracy: 0.8439\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2543 - accuracy: 0.8874 - val_loss: 0.2277 - val_accuracy: 0.8949\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2619 - accuracy: 0.8817 - val_loss: 0.2940 - val_accuracy: 0.8533\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2476 - accuracy: 0.8883 - val_loss: 0.3415 - val_accuracy: 0.8446\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2418 - accuracy: 0.8931 - val_loss: 0.2150 - val_accuracy: 0.9006\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2366 - accuracy: 0.8939 - val_loss: 0.2605 - val_accuracy: 0.8775\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2403 - accuracy: 0.8933 - val_loss: 0.2220 - val_accuracy: 0.8947\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2283 - accuracy: 0.8982 - val_loss: 0.2400 - val_accuracy: 0.8883\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2430 - accuracy: 0.8924 - val_loss: 0.2667 - val_accuracy: 0.8694\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2263 - accuracy: 0.9005 - val_loss: 0.2366 - val_accuracy: 0.8900\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2148 - accuracy: 0.9035 - val_loss: 0.2785 - val_accuracy: 0.8663\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2131 - accuracy: 0.9056 - val_loss: 0.2115 - val_accuracy: 0.9004\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2016 - accuracy: 0.9125 - val_loss: 0.2202 - val_accuracy: 0.8999\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2145 - accuracy: 0.9066 - val_loss: 0.2472 - val_accuracy: 0.8737\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1942 - accuracy: 0.9163 - val_loss: 0.2276 - val_accuracy: 0.9013\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1961 - accuracy: 0.9155 - val_loss: 0.2366 - val_accuracy: 0.8874\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1916 - accuracy: 0.9179 - val_loss: 0.3060 - val_accuracy: 0.8716\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1908 - accuracy: 0.9202 - val_loss: 0.2571 - val_accuracy: 0.8841\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1786 - accuracy: 0.9229 - val_loss: 0.2477 - val_accuracy: 0.8912\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1802 - accuracy: 0.9247 - val_loss: 0.2944 - val_accuracy: 0.8737\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2107 - accuracy: 0.9098 - val_loss: 0.2333 - val_accuracy: 0.8962\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1665 - accuracy: 0.9310 - val_loss: 0.2345 - val_accuracy: 0.9009\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1745 - accuracy: 0.9274 - val_loss: 0.2406 - val_accuracy: 0.8976\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1684 - accuracy: 0.9299 - val_loss: 0.2492 - val_accuracy: 0.8928\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1656 - accuracy: 0.9317 - val_loss: 0.2182 - val_accuracy: 0.9049\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1586 - accuracy: 0.9342 - val_loss: 0.3017 - val_accuracy: 0.8829\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1641 - accuracy: 0.9307 - val_loss: 0.2789 - val_accuracy: 0.8867\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1629 - accuracy: 0.9332 - val_loss: 0.2185 - val_accuracy: 0.9106\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1532 - accuracy: 0.9380 - val_loss: 0.2519 - val_accuracy: 0.8994\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1698 - accuracy: 0.9285 - val_loss: 0.2417 - val_accuracy: 0.8978\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1530 - accuracy: 0.9366 - val_loss: 0.2406 - val_accuracy: 0.8995\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1473 - accuracy: 0.9398 - val_loss: 0.2248 - val_accuracy: 0.9049\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1542 - accuracy: 0.9375 - val_loss: 0.2148 - val_accuracy: 0.9110\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1488 - accuracy: 0.9377 - val_loss: 0.2838 - val_accuracy: 0.8855\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1492 - accuracy: 0.9384 - val_loss: 0.3470 - val_accuracy: 0.8663\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1480 - accuracy: 0.9394 - val_loss: 0.2660 - val_accuracy: 0.8878\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1483 - accuracy: 0.9403 - val_loss: 0.2064 - val_accuracy: 0.9144\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1390 - accuracy: 0.9436 - val_loss: 0.2083 - val_accuracy: 0.9111\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1354 - accuracy: 0.9441 - val_loss: 0.2193 - val_accuracy: 0.9139\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1340 - accuracy: 0.9433 - val_loss: 0.2412 - val_accuracy: 0.9039\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1310 - accuracy: 0.9460 - val_loss: 0.2358 - val_accuracy: 0.9072\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1239 - accuracy: 0.9492 - val_loss: 0.2447 - val_accuracy: 0.9027\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1333 - accuracy: 0.9442 - val_loss: 0.2342 - val_accuracy: 0.9072\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1287 - accuracy: 0.9482 - val_loss: 0.3014 - val_accuracy: 0.8864\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.1202 - accuracy: 0.9521 - val_loss: 0.2456 - val_accuracy: 0.9032\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1205 - accuracy: 0.9521 - val_loss: 0.3536 - val_accuracy: 0.8779\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1205 - accuracy: 0.9508 - val_loss: 0.2389 - val_accuracy: 0.9068\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1273 - accuracy: 0.9485 - val_loss: 0.2504 - val_accuracy: 0.9065\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1162 - accuracy: 0.9553 - val_loss: 0.2188 - val_accuracy: 0.9165\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1155 - accuracy: 0.9521 - val_loss: 0.2261 - val_accuracy: 0.9127\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1077 - accuracy: 0.9570 - val_loss: 0.2291 - val_accuracy: 0.9148\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1149 - accuracy: 0.9538 - val_loss: 0.2282 - val_accuracy: 0.9137\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1094 - accuracy: 0.9548 - val_loss: 0.2340 - val_accuracy: 0.9125\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0956 - accuracy: 0.9617 - val_loss: 0.2730 - val_accuracy: 0.9033\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1044 - accuracy: 0.9594 - val_loss: 0.2275 - val_accuracy: 0.9111\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0963 - accuracy: 0.9620 - val_loss: 0.2443 - val_accuracy: 0.9125\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1011 - accuracy: 0.9609 - val_loss: 0.2389 - val_accuracy: 0.9092\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0973 - accuracy: 0.9619 - val_loss: 0.2285 - val_accuracy: 0.9160\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0901 - accuracy: 0.9639 - val_loss: 0.2232 - val_accuracy: 0.9182\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0913 - accuracy: 0.9658 - val_loss: 0.2537 - val_accuracy: 0.9122\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0857 - accuracy: 0.9660 - val_loss: 0.2255 - val_accuracy: 0.9259\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0980 - accuracy: 0.9627 - val_loss: 0.2329 - val_accuracy: 0.9252\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0867 - accuracy: 0.9652 - val_loss: 0.3006 - val_accuracy: 0.9011\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0776 - accuracy: 0.9704 - val_loss: 0.2398 - val_accuracy: 0.9200\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0851 - accuracy: 0.9661 - val_loss: 0.2179 - val_accuracy: 0.9267\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0874 - accuracy: 0.9641 - val_loss: 0.2606 - val_accuracy: 0.9141\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0795 - accuracy: 0.9705 - val_loss: 0.2698 - val_accuracy: 0.9160\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0740 - accuracy: 0.9717 - val_loss: 0.2508 - val_accuracy: 0.9151\n",
      "Epoch 80/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0806 - accuracy: 0.9692 - val_loss: 0.2706 - val_accuracy: 0.9124\n",
      "Epoch 81/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0789 - accuracy: 0.9705 - val_loss: 0.2656 - val_accuracy: 0.9113\n",
      "Epoch 82/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0756 - accuracy: 0.9717 - val_loss: 0.2305 - val_accuracy: 0.9309\n",
      "Epoch 83/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0690 - accuracy: 0.9744 - val_loss: 0.2639 - val_accuracy: 0.9193\n",
      "Epoch 84/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0749 - accuracy: 0.9715 - val_loss: 0.2364 - val_accuracy: 0.9257\n",
      "Epoch 85/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0713 - accuracy: 0.9718 - val_loss: 0.2645 - val_accuracy: 0.9205\n",
      "Epoch 86/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0722 - accuracy: 0.9726 - val_loss: 0.2183 - val_accuracy: 0.9307\n",
      "Epoch 87/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0615 - accuracy: 0.9769 - val_loss: 0.2411 - val_accuracy: 0.9241\n",
      "Epoch 88/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0656 - accuracy: 0.9744 - val_loss: 0.2286 - val_accuracy: 0.9283\n",
      "Epoch 89/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0624 - accuracy: 0.9764 - val_loss: 0.2703 - val_accuracy: 0.9198\n",
      "Epoch 90/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0591 - accuracy: 0.9779 - val_loss: 0.2623 - val_accuracy: 0.9201\n",
      "Epoch 91/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0698 - accuracy: 0.9746 - val_loss: 0.2470 - val_accuracy: 0.9141\n",
      "Epoch 92/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0707 - accuracy: 0.9727 - val_loss: 0.2627 - val_accuracy: 0.9143\n",
      "Epoch 93/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0627 - accuracy: 0.9758 - val_loss: 0.2497 - val_accuracy: 0.9234\n",
      "Epoch 94/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0586 - accuracy: 0.9776 - val_loss: 0.2592 - val_accuracy: 0.9174\n",
      "Epoch 95/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0682 - accuracy: 0.9748 - val_loss: 0.2534 - val_accuracy: 0.9253\n",
      "Epoch 96/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0533 - accuracy: 0.9802 - val_loss: 0.2853 - val_accuracy: 0.9143\n",
      "Epoch 97/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0611 - accuracy: 0.9773 - val_loss: 0.2371 - val_accuracy: 0.9269\n",
      "Epoch 98/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0514 - accuracy: 0.9808 - val_loss: 0.2519 - val_accuracy: 0.9233\n",
      "Epoch 99/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0511 - accuracy: 0.9802 - val_loss: 0.3920 - val_accuracy: 0.8955\n",
      "Epoch 100/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0631 - accuracy: 0.9758 - val_loss: 0.3112 - val_accuracy: 0.9203\n",
      "Epoch 101/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0582 - accuracy: 0.9768 - val_loss: 0.2474 - val_accuracy: 0.9285\n",
      "Epoch 102/500\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9832Restoring model weights from the end of the best epoch: 82.\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0450 - accuracy: 0.9832 - val_loss: 0.2711 - val_accuracy: 0.9229\n",
      "Epoch 102: early stopping\n",
      "Number of iterations 6\n",
      "F1-scores:  [0.8360944659851957, 0.8121301775147929, 0.8251978891820579, 0.8328308207705193, 0.8615600843288825, 0.8603430171508576]\n",
      "Average F1-Score 0.838026075822051\n",
      "Std Dev F1-Score 0.017878185683003308\n",
      "Error bar F1-Score 0.007298738741681613\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 11s 21ms/step - loss: 0.5621 - accuracy: 0.7016 - val_loss: 0.4292 - val_accuracy: 0.7726\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5348 - accuracy: 0.7089 - val_loss: 0.4347 - val_accuracy: 0.7563\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4745 - accuracy: 0.7436 - val_loss: 0.3150 - val_accuracy: 0.8361\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3933 - accuracy: 0.8100 - val_loss: 0.3036 - val_accuracy: 0.8580\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3601 - accuracy: 0.8314 - val_loss: 0.3120 - val_accuracy: 0.8543\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3472 - accuracy: 0.8416 - val_loss: 0.3186 - val_accuracy: 0.8462\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3328 - accuracy: 0.8457 - val_loss: 0.3562 - val_accuracy: 0.8231\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3119 - accuracy: 0.8612 - val_loss: 0.3073 - val_accuracy: 0.8581\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3128 - accuracy: 0.8576 - val_loss: 0.2841 - val_accuracy: 0.8697\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3084 - accuracy: 0.8622 - val_loss: 0.2962 - val_accuracy: 0.8670\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2934 - accuracy: 0.8715 - val_loss: 0.3009 - val_accuracy: 0.8614\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3032 - accuracy: 0.8663 - val_loss: 0.3665 - val_accuracy: 0.8219\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2966 - accuracy: 0.8689 - val_loss: 0.3397 - val_accuracy: 0.8403\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2950 - accuracy: 0.8694 - val_loss: 0.2960 - val_accuracy: 0.8659\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2960 - accuracy: 0.8696 - val_loss: 0.2911 - val_accuracy: 0.8587\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2945 - accuracy: 0.8695 - val_loss: 0.2930 - val_accuracy: 0.8671\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3000 - accuracy: 0.8666 - val_loss: 0.4200 - val_accuracy: 0.7887\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2860 - accuracy: 0.8759 - val_loss: 0.3135 - val_accuracy: 0.8472\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3081 - accuracy: 0.8611 - val_loss: 0.2956 - val_accuracy: 0.8538\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2800 - accuracy: 0.8732 - val_loss: 0.2504 - val_accuracy: 0.8727\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2657 - accuracy: 0.8792 - val_loss: 0.2775 - val_accuracy: 0.8642\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.2602 - accuracy: 0.8809 - val_loss: 0.3134 - val_accuracy: 0.8602\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2594 - accuracy: 0.8841 - val_loss: 0.2539 - val_accuracy: 0.8786\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2645 - accuracy: 0.8796 - val_loss: 0.2977 - val_accuracy: 0.8418\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3169 - accuracy: 0.8567 - val_loss: 0.2532 - val_accuracy: 0.8807\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2986 - accuracy: 0.8622 - val_loss: 0.2469 - val_accuracy: 0.8801\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2719 - accuracy: 0.8791 - val_loss: 0.2720 - val_accuracy: 0.8659\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2491 - accuracy: 0.8880 - val_loss: 0.2959 - val_accuracy: 0.8632\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2491 - accuracy: 0.8885 - val_loss: 0.2433 - val_accuracy: 0.8895\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2452 - accuracy: 0.8886 - val_loss: 0.2468 - val_accuracy: 0.8872\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2443 - accuracy: 0.8914 - val_loss: 0.2275 - val_accuracy: 0.8940\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2346 - accuracy: 0.8951 - val_loss: 0.2403 - val_accuracy: 0.8810\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2378 - accuracy: 0.8951 - val_loss: 0.2379 - val_accuracy: 0.8921\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2317 - accuracy: 0.8963 - val_loss: 0.2209 - val_accuracy: 0.9011\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2286 - accuracy: 0.9007 - val_loss: 0.2455 - val_accuracy: 0.8867\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2303 - accuracy: 0.8988 - val_loss: 0.2416 - val_accuracy: 0.8928\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2168 - accuracy: 0.9062 - val_loss: 0.2714 - val_accuracy: 0.8732\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2194 - accuracy: 0.9046 - val_loss: 0.2143 - val_accuracy: 0.9042\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2186 - accuracy: 0.9059 - val_loss: 0.2806 - val_accuracy: 0.8649\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2312 - accuracy: 0.8996 - val_loss: 0.2705 - val_accuracy: 0.8749\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2152 - accuracy: 0.9045 - val_loss: 0.2794 - val_accuracy: 0.8739\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2056 - accuracy: 0.9114 - val_loss: 0.2602 - val_accuracy: 0.8864\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2161 - accuracy: 0.9043 - val_loss: 0.2306 - val_accuracy: 0.8942\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2013 - accuracy: 0.9129 - val_loss: 0.2452 - val_accuracy: 0.8862\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2000 - accuracy: 0.9131 - val_loss: 0.2173 - val_accuracy: 0.9009\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2059 - accuracy: 0.9115 - val_loss: 0.2287 - val_accuracy: 0.8992\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1979 - accuracy: 0.9151 - val_loss: 0.2238 - val_accuracy: 0.9014\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2032 - accuracy: 0.9115 - val_loss: 0.2491 - val_accuracy: 0.8839\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1898 - accuracy: 0.9188 - val_loss: 0.2169 - val_accuracy: 0.9049\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.1968 - accuracy: 0.9148 - val_loss: 0.2128 - val_accuracy: 0.9021\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1931 - accuracy: 0.9185 - val_loss: 0.2097 - val_accuracy: 0.9068\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1825 - accuracy: 0.9215 - val_loss: 0.2364 - val_accuracy: 0.8923\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1814 - accuracy: 0.9231 - val_loss: 0.2493 - val_accuracy: 0.8938\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1859 - accuracy: 0.9204 - val_loss: 0.2812 - val_accuracy: 0.8775\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1780 - accuracy: 0.9255 - val_loss: 0.2784 - val_accuracy: 0.8775\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1835 - accuracy: 0.9219 - val_loss: 0.2597 - val_accuracy: 0.8924\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1729 - accuracy: 0.9273 - val_loss: 0.2244 - val_accuracy: 0.9023\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1698 - accuracy: 0.9282 - val_loss: 0.2474 - val_accuracy: 0.8978\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1662 - accuracy: 0.9317 - val_loss: 0.2936 - val_accuracy: 0.8727\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1613 - accuracy: 0.9330 - val_loss: 0.2525 - val_accuracy: 0.8971\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2309 - accuracy: 0.8987 - val_loss: 0.2092 - val_accuracy: 0.9052\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1561 - accuracy: 0.9350 - val_loss: 0.2253 - val_accuracy: 0.9037\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1600 - accuracy: 0.9318 - val_loss: 0.3537 - val_accuracy: 0.8536\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1568 - accuracy: 0.9362 - val_loss: 0.2749 - val_accuracy: 0.8907\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1544 - accuracy: 0.9368 - val_loss: 0.2139 - val_accuracy: 0.9091\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1567 - accuracy: 0.9347 - val_loss: 0.2519 - val_accuracy: 0.8952\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1538 - accuracy: 0.9382 - val_loss: 0.2236 - val_accuracy: 0.9027\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1492 - accuracy: 0.9394 - val_loss: 0.2491 - val_accuracy: 0.8931\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1371 - accuracy: 0.9440 - val_loss: 0.2697 - val_accuracy: 0.8919\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1492 - accuracy: 0.9395 - val_loss: 0.2378 - val_accuracy: 0.9006\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1319 - accuracy: 0.9463 - val_loss: 0.2403 - val_accuracy: 0.8945\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1421 - accuracy: 0.9429 - val_loss: 0.2565 - val_accuracy: 0.9025\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1374 - accuracy: 0.9439 - val_loss: 0.2628 - val_accuracy: 0.8949\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1385 - accuracy: 0.9437 - val_loss: 0.2410 - val_accuracy: 0.9037\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1332 - accuracy: 0.9468 - val_loss: 0.2957 - val_accuracy: 0.8888\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 5s 18ms/step - loss: 0.1352 - accuracy: 0.9453 - val_loss: 0.2219 - val_accuracy: 0.9098\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1185 - accuracy: 0.9520 - val_loss: 0.2530 - val_accuracy: 0.9021\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1199 - accuracy: 0.9508 - val_loss: 0.2330 - val_accuracy: 0.9078\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1342 - accuracy: 0.9453 - val_loss: 0.2443 - val_accuracy: 0.9013\n",
      "Epoch 80/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1181 - accuracy: 0.9541 - val_loss: 0.2702 - val_accuracy: 0.8952\n",
      "Epoch 81/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1172 - accuracy: 0.9520 - val_loss: 0.2382 - val_accuracy: 0.9032\n",
      "Epoch 82/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.1237 - accuracy: 0.9490 - val_loss: 0.2443 - val_accuracy: 0.9056\n",
      "Epoch 83/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1059 - accuracy: 0.9577 - val_loss: 0.2862 - val_accuracy: 0.8957\n",
      "Epoch 84/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1220 - accuracy: 0.9514 - val_loss: 0.2607 - val_accuracy: 0.9061\n",
      "Epoch 85/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.1112 - accuracy: 0.9551 - val_loss: 0.2818 - val_accuracy: 0.9037\n",
      "Epoch 86/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1027 - accuracy: 0.9589 - val_loss: 0.2625 - val_accuracy: 0.9080\n",
      "Epoch 87/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1161 - accuracy: 0.9544 - val_loss: 0.2099 - val_accuracy: 0.9219\n",
      "Epoch 88/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1035 - accuracy: 0.9599 - val_loss: 0.2225 - val_accuracy: 0.9167\n",
      "Epoch 89/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1000 - accuracy: 0.9604 - val_loss: 0.2570 - val_accuracy: 0.9066\n",
      "Epoch 90/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1054 - accuracy: 0.9573 - val_loss: 0.2301 - val_accuracy: 0.9169\n",
      "Epoch 91/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0950 - accuracy: 0.9601 - val_loss: 0.2923 - val_accuracy: 0.8981\n",
      "Epoch 92/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0926 - accuracy: 0.9625 - val_loss: 0.2963 - val_accuracy: 0.8981\n",
      "Epoch 93/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1007 - accuracy: 0.9600 - val_loss: 0.2258 - val_accuracy: 0.9196\n",
      "Epoch 94/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0968 - accuracy: 0.9618 - val_loss: 0.2751 - val_accuracy: 0.9061\n",
      "Epoch 95/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0885 - accuracy: 0.9673 - val_loss: 0.2493 - val_accuracy: 0.9196\n",
      "Epoch 96/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0856 - accuracy: 0.9664 - val_loss: 0.3097 - val_accuracy: 0.9065\n",
      "Epoch 97/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0820 - accuracy: 0.9665 - val_loss: 0.2904 - val_accuracy: 0.9118\n",
      "Epoch 98/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0904 - accuracy: 0.9637 - val_loss: 0.2393 - val_accuracy: 0.9165\n",
      "Epoch 99/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0831 - accuracy: 0.9679 - val_loss: 0.3268 - val_accuracy: 0.9001\n",
      "Epoch 100/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0721 - accuracy: 0.9718 - val_loss: 0.2823 - val_accuracy: 0.9149\n",
      "Epoch 101/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0954 - accuracy: 0.9634 - val_loss: 0.2864 - val_accuracy: 0.9087\n",
      "Epoch 102/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0769 - accuracy: 0.9700 - val_loss: 0.3027 - val_accuracy: 0.9089\n",
      "Epoch 103/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0903 - accuracy: 0.9635 - val_loss: 0.2466 - val_accuracy: 0.9155\n",
      "Epoch 104/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0810 - accuracy: 0.9679 - val_loss: 0.3060 - val_accuracy: 0.9059\n",
      "Epoch 105/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0814 - accuracy: 0.9674 - val_loss: 0.2947 - val_accuracy: 0.9113\n",
      "Epoch 106/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0669 - accuracy: 0.9739 - val_loss: 0.2556 - val_accuracy: 0.9221\n",
      "Epoch 107/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.0683 - accuracy: 0.9724 - val_loss: 0.2512 - val_accuracy: 0.9208\n",
      "Epoch 108/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.0665 - accuracy: 0.9748 - val_loss: 0.3063 - val_accuracy: 0.9127\n",
      "Epoch 109/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0690 - accuracy: 0.9729 - val_loss: 0.3595 - val_accuracy: 0.9058\n",
      "Epoch 110/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0645 - accuracy: 0.9752 - val_loss: 0.3305 - val_accuracy: 0.9040\n",
      "Epoch 111/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0597 - accuracy: 0.9766 - val_loss: 0.3102 - val_accuracy: 0.9149\n",
      "Epoch 112/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0759 - accuracy: 0.9712 - val_loss: 0.2729 - val_accuracy: 0.9172\n",
      "Epoch 113/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0605 - accuracy: 0.9781 - val_loss: 0.2685 - val_accuracy: 0.9158\n",
      "Epoch 114/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0583 - accuracy: 0.9768 - val_loss: 0.3628 - val_accuracy: 0.8999\n",
      "Epoch 115/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0799 - accuracy: 0.9680 - val_loss: 0.2447 - val_accuracy: 0.9167\n",
      "Epoch 116/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0606 - accuracy: 0.9764 - val_loss: 0.3247 - val_accuracy: 0.9078\n",
      "Epoch 117/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0655 - accuracy: 0.9746 - val_loss: 0.2892 - val_accuracy: 0.9141\n",
      "Epoch 118/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0598 - accuracy: 0.9778 - val_loss: 0.2678 - val_accuracy: 0.9262\n",
      "Epoch 119/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0534 - accuracy: 0.9800 - val_loss: 0.3329 - val_accuracy: 0.9151\n",
      "Epoch 120/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0523 - accuracy: 0.9807 - val_loss: 0.3318 - val_accuracy: 0.9205\n",
      "Epoch 121/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0497 - accuracy: 0.9807 - val_loss: 0.3392 - val_accuracy: 0.9120\n",
      "Epoch 122/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.0545 - accuracy: 0.9797 - val_loss: 0.3530 - val_accuracy: 0.9134\n",
      "Epoch 123/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0439 - accuracy: 0.9837 - val_loss: 0.4050 - val_accuracy: 0.9098\n",
      "Epoch 124/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0571 - accuracy: 0.9780 - val_loss: 0.3741 - val_accuracy: 0.9110\n",
      "Epoch 125/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0474 - accuracy: 0.9828 - val_loss: 0.4156 - val_accuracy: 0.9033\n",
      "Epoch 126/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0490 - accuracy: 0.9803 - val_loss: 0.2988 - val_accuracy: 0.9217\n",
      "Epoch 127/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0522 - accuracy: 0.9818 - val_loss: 0.3460 - val_accuracy: 0.9153\n",
      "Epoch 128/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0354 - accuracy: 0.9871 - val_loss: 0.3302 - val_accuracy: 0.9200\n",
      "Epoch 129/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0577 - accuracy: 0.9790 - val_loss: 0.3597 - val_accuracy: 0.9111\n",
      "Epoch 130/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0556 - accuracy: 0.9795 - val_loss: 0.3657 - val_accuracy: 0.9068\n",
      "Epoch 131/500\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 0.0497 - accuracy: 0.9818 - val_loss: 0.3332 - val_accuracy: 0.9214\n",
      "Epoch 132/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0475 - accuracy: 0.9838 - val_loss: 0.3488 - val_accuracy: 0.9091\n",
      "Epoch 133/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0474 - accuracy: 0.9823 - val_loss: 0.3202 - val_accuracy: 0.9132\n",
      "Epoch 134/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0410 - accuracy: 0.9850 - val_loss: 0.2926 - val_accuracy: 0.9236\n",
      "Epoch 135/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0509 - accuracy: 0.9803 - val_loss: 0.3595 - val_accuracy: 0.9125\n",
      "Epoch 136/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.0410 - accuracy: 0.9853 - val_loss: 0.3831 - val_accuracy: 0.9072\n",
      "Epoch 137/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0486 - accuracy: 0.9821 - val_loss: 0.2752 - val_accuracy: 0.9217\n",
      "Epoch 138/500\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9880Restoring model weights from the end of the best epoch: 118.\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.0341 - accuracy: 0.9880 - val_loss: 0.3684 - val_accuracy: 0.9139\n",
      "Epoch 138: early stopping\n",
      "Number of iterations 7\n",
      "F1-scores:  [0.8360944659851957, 0.8121301775147929, 0.8251978891820579, 0.8328308207705193, 0.8615600843288825, 0.8603430171508576, 0.8591269841269841]\n",
      "Average F1-Score 0.8410404912941843\n",
      "Std Dev F1-Score 0.018124248030582064\n",
      "Error bar F1-Score 0.006850321855567474\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 10s 20ms/step - loss: 0.5782 - accuracy: 0.6994 - val_loss: 0.4226 - val_accuracy: 0.7701\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5387 - accuracy: 0.7065 - val_loss: 0.4500 - val_accuracy: 0.7733\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5376 - accuracy: 0.7048 - val_loss: 0.4392 - val_accuracy: 0.7618\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4972 - accuracy: 0.7380 - val_loss: 0.3331 - val_accuracy: 0.8342\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3992 - accuracy: 0.8083 - val_loss: 0.3545 - val_accuracy: 0.8318\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3768 - accuracy: 0.8217 - val_loss: 0.2965 - val_accuracy: 0.8611\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3492 - accuracy: 0.8405 - val_loss: 0.3216 - val_accuracy: 0.8413\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3412 - accuracy: 0.8441 - val_loss: 0.2971 - val_accuracy: 0.8555\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3343 - accuracy: 0.8477 - val_loss: 0.2962 - val_accuracy: 0.8642\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.3069 - accuracy: 0.8621 - val_loss: 0.3289 - val_accuracy: 0.8341\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3196 - accuracy: 0.8557 - val_loss: 0.2898 - val_accuracy: 0.8621\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2964 - accuracy: 0.8659 - val_loss: 0.3781 - val_accuracy: 0.8072\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2844 - accuracy: 0.8728 - val_loss: 0.3246 - val_accuracy: 0.8308\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2823 - accuracy: 0.8751 - val_loss: 0.3227 - val_accuracy: 0.8496\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2785 - accuracy: 0.8754 - val_loss: 0.2816 - val_accuracy: 0.8633\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2867 - accuracy: 0.8686 - val_loss: 0.3160 - val_accuracy: 0.8380\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2741 - accuracy: 0.8764 - val_loss: 0.2797 - val_accuracy: 0.8535\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2668 - accuracy: 0.8810 - val_loss: 0.2687 - val_accuracy: 0.8611\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2679 - accuracy: 0.8781 - val_loss: 0.2834 - val_accuracy: 0.8708\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2608 - accuracy: 0.8815 - val_loss: 0.2824 - val_accuracy: 0.8630\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2598 - accuracy: 0.8827 - val_loss: 0.2364 - val_accuracy: 0.8839\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2642 - accuracy: 0.8788 - val_loss: 0.2947 - val_accuracy: 0.8550\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2620 - accuracy: 0.8817 - val_loss: 0.2566 - val_accuracy: 0.8735\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2405 - accuracy: 0.8891 - val_loss: 0.2534 - val_accuracy: 0.8748\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.2457 - accuracy: 0.8899 - val_loss: 0.2206 - val_accuracy: 0.8962\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2486 - accuracy: 0.8908 - val_loss: 0.2699 - val_accuracy: 0.8706\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2367 - accuracy: 0.8938 - val_loss: 0.2297 - val_accuracy: 0.8910\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2321 - accuracy: 0.8965 - val_loss: 0.2381 - val_accuracy: 0.8898\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2231 - accuracy: 0.9017 - val_loss: 0.2245 - val_accuracy: 0.8964\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2258 - accuracy: 0.8994 - val_loss: 0.2226 - val_accuracy: 0.8992\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2190 - accuracy: 0.9031 - val_loss: 0.2218 - val_accuracy: 0.8971\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2130 - accuracy: 0.9050 - val_loss: 0.2556 - val_accuracy: 0.8836\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2163 - accuracy: 0.9053 - val_loss: 0.2204 - val_accuracy: 0.8981\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2092 - accuracy: 0.9110 - val_loss: 0.2278 - val_accuracy: 0.8969\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2022 - accuracy: 0.9152 - val_loss: 0.2122 - val_accuracy: 0.9014\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1986 - accuracy: 0.9155 - val_loss: 0.2162 - val_accuracy: 0.9007\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1942 - accuracy: 0.9161 - val_loss: 0.2457 - val_accuracy: 0.8904\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.1867 - accuracy: 0.9199 - val_loss: 0.2349 - val_accuracy: 0.8949\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1920 - accuracy: 0.9175 - val_loss: 0.2157 - val_accuracy: 0.8992\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.1940 - accuracy: 0.9189 - val_loss: 0.2249 - val_accuracy: 0.8990\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1856 - accuracy: 0.9215 - val_loss: 0.2372 - val_accuracy: 0.8942\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1723 - accuracy: 0.9271 - val_loss: 0.2225 - val_accuracy: 0.8973\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1862 - accuracy: 0.9221 - val_loss: 0.1963 - val_accuracy: 0.9099\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1719 - accuracy: 0.9283 - val_loss: 0.2485 - val_accuracy: 0.8931\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1730 - accuracy: 0.9267 - val_loss: 0.2785 - val_accuracy: 0.8755\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1784 - accuracy: 0.9255 - val_loss: 0.2472 - val_accuracy: 0.8924\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1592 - accuracy: 0.9326 - val_loss: 0.2332 - val_accuracy: 0.8983\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1583 - accuracy: 0.9341 - val_loss: 0.2238 - val_accuracy: 0.9023\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1624 - accuracy: 0.9337 - val_loss: 0.2076 - val_accuracy: 0.9089\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1537 - accuracy: 0.9362 - val_loss: 0.2413 - val_accuracy: 0.8936\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1452 - accuracy: 0.9392 - val_loss: 0.2137 - val_accuracy: 0.9063\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1460 - accuracy: 0.9419 - val_loss: 0.2354 - val_accuracy: 0.8975\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1466 - accuracy: 0.9402 - val_loss: 0.2082 - val_accuracy: 0.9080\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1407 - accuracy: 0.9424 - val_loss: 0.2128 - val_accuracy: 0.9117\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1482 - accuracy: 0.9415 - val_loss: 0.2022 - val_accuracy: 0.9132\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1351 - accuracy: 0.9456 - val_loss: 0.2160 - val_accuracy: 0.9077\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1447 - accuracy: 0.9415 - val_loss: 0.2450 - val_accuracy: 0.8990\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1269 - accuracy: 0.9484 - val_loss: 0.2063 - val_accuracy: 0.9156\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1291 - accuracy: 0.9479 - val_loss: 0.2574 - val_accuracy: 0.9007\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1344 - accuracy: 0.9459 - val_loss: 0.2354 - val_accuracy: 0.9004\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1329 - accuracy: 0.9444 - val_loss: 0.2495 - val_accuracy: 0.9016\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1245 - accuracy: 0.9506 - val_loss: 0.2308 - val_accuracy: 0.9078\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1130 - accuracy: 0.9543 - val_loss: 0.3476 - val_accuracy: 0.8746\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1247 - accuracy: 0.9498 - val_loss: 0.2018 - val_accuracy: 0.9184\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1205 - accuracy: 0.9519 - val_loss: 0.3001 - val_accuracy: 0.8938\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1223 - accuracy: 0.9516 - val_loss: 0.2182 - val_accuracy: 0.9082\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1105 - accuracy: 0.9566 - val_loss: 0.3397 - val_accuracy: 0.8746\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1062 - accuracy: 0.9583 - val_loss: 0.2162 - val_accuracy: 0.9193\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1101 - accuracy: 0.9557 - val_loss: 0.2373 - val_accuracy: 0.9085\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1184 - accuracy: 0.9514 - val_loss: 0.2591 - val_accuracy: 0.8999\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1099 - accuracy: 0.9579 - val_loss: 0.2344 - val_accuracy: 0.9082\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1112 - accuracy: 0.9561 - val_loss: 0.2300 - val_accuracy: 0.9115\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0977 - accuracy: 0.9623 - val_loss: 0.2459 - val_accuracy: 0.9089\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0933 - accuracy: 0.9628 - val_loss: 0.2052 - val_accuracy: 0.9227\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0930 - accuracy: 0.9639 - val_loss: 0.2349 - val_accuracy: 0.9096\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0948 - accuracy: 0.9626 - val_loss: 0.3380 - val_accuracy: 0.8862\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1009 - accuracy: 0.9606 - val_loss: 0.2823 - val_accuracy: 0.9028\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.0942 - accuracy: 0.9637 - val_loss: 0.2766 - val_accuracy: 0.9042\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0887 - accuracy: 0.9663 - val_loss: 0.2568 - val_accuracy: 0.9072\n",
      "Epoch 80/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0987 - accuracy: 0.9620 - val_loss: 0.2717 - val_accuracy: 0.9063\n",
      "Epoch 81/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0891 - accuracy: 0.9666 - val_loss: 0.2219 - val_accuracy: 0.9196\n",
      "Epoch 82/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0825 - accuracy: 0.9663 - val_loss: 0.2134 - val_accuracy: 0.9214\n",
      "Epoch 83/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.0847 - accuracy: 0.9678 - val_loss: 0.2727 - val_accuracy: 0.9056\n",
      "Epoch 84/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0879 - accuracy: 0.9667 - val_loss: 0.3106 - val_accuracy: 0.8905\n",
      "Epoch 85/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.0799 - accuracy: 0.9684 - val_loss: 0.2534 - val_accuracy: 0.9146\n",
      "Epoch 86/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0789 - accuracy: 0.9695 - val_loss: 0.3081 - val_accuracy: 0.9030\n",
      "Epoch 87/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0791 - accuracy: 0.9693 - val_loss: 0.2585 - val_accuracy: 0.9125\n",
      "Epoch 88/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0698 - accuracy: 0.9734 - val_loss: 0.2833 - val_accuracy: 0.9153\n",
      "Epoch 89/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.0843 - accuracy: 0.9675 - val_loss: 0.2810 - val_accuracy: 0.9092\n",
      "Epoch 90/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0697 - accuracy: 0.9733 - val_loss: 0.2337 - val_accuracy: 0.9160\n",
      "Epoch 91/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0647 - accuracy: 0.9758 - val_loss: 0.3224 - val_accuracy: 0.8980\n",
      "Epoch 92/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0640 - accuracy: 0.9757 - val_loss: 0.3325 - val_accuracy: 0.8966\n",
      "Epoch 93/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.0651 - accuracy: 0.9751 - val_loss: 0.2469 - val_accuracy: 0.9193\n",
      "Epoch 94/500\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.0798 - accuracy: 0.9698Restoring model weights from the end of the best epoch: 74.\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.0801 - accuracy: 0.9698 - val_loss: 0.2698 - val_accuracy: 0.9087\n",
      "Epoch 94: early stopping\n",
      "Number of iterations 8\n",
      "F1-scores:  [0.8360944659851957, 0.8121301775147929, 0.8251978891820579, 0.8328308207705193, 0.8615600843288825, 0.8603430171508576, 0.8591269841269841, 0.8474692202462382]\n",
      "Average F1-Score 0.841844082413191\n",
      "Std Dev F1-Score 0.01708647510885806\n",
      "Error bar F1-Score 0.006040981208024343\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 10s 20ms/step - loss: 0.5732 - accuracy: 0.6977 - val_loss: 0.4352 - val_accuracy: 0.7584\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5396 - accuracy: 0.7086 - val_loss: 0.4347 - val_accuracy: 0.7584\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5281 - accuracy: 0.7157 - val_loss: 0.4042 - val_accuracy: 0.7862\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5374 - accuracy: 0.7098 - val_loss: 0.4206 - val_accuracy: 0.7722\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5329 - accuracy: 0.7157 - val_loss: 0.4274 - val_accuracy: 0.7584\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5289 - accuracy: 0.7181 - val_loss: 0.4435 - val_accuracy: 0.7712\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.5280 - accuracy: 0.7141 - val_loss: 0.4281 - val_accuracy: 0.7842\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5286 - accuracy: 0.7187 - val_loss: 0.4256 - val_accuracy: 0.7708\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5232 - accuracy: 0.7223 - val_loss: 0.4214 - val_accuracy: 0.7875\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5280 - accuracy: 0.7187 - val_loss: 0.4217 - val_accuracy: 0.7800\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5251 - accuracy: 0.7187 - val_loss: 0.4383 - val_accuracy: 0.7849\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5231 - accuracy: 0.7218 - val_loss: 0.4293 - val_accuracy: 0.7734\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5234 - accuracy: 0.7229 - val_loss: 0.4249 - val_accuracy: 0.7783\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5249 - accuracy: 0.7209 - val_loss: 0.4113 - val_accuracy: 0.7895\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.5206 - accuracy: 0.7213 - val_loss: 0.4237 - val_accuracy: 0.7785\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.5180 - accuracy: 0.7250 - val_loss: 0.4183 - val_accuracy: 0.7909\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5209 - accuracy: 0.7230 - val_loss: 0.4340 - val_accuracy: 0.7791\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.5134 - accuracy: 0.7255 - val_loss: 0.4147 - val_accuracy: 0.7795\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.5113 - accuracy: 0.7278 - val_loss: 0.4151 - val_accuracy: 0.7826\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5125 - accuracy: 0.7183 - val_loss: 0.3944 - val_accuracy: 0.7949\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5087 - accuracy: 0.7266 - val_loss: 0.4055 - val_accuracy: 0.7897\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4994 - accuracy: 0.7332 - val_loss: 0.3882 - val_accuracy: 0.7980\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.4949 - accuracy: 0.7271 - val_loss: 0.4166 - val_accuracy: 0.7984\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4880 - accuracy: 0.7417 - val_loss: 0.4025 - val_accuracy: 0.7904\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.4867 - accuracy: 0.7359 - val_loss: 0.3884 - val_accuracy: 0.7939\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.4824 - accuracy: 0.7353 - val_loss: 0.4039 - val_accuracy: 0.7899\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4772 - accuracy: 0.7416 - val_loss: 0.3837 - val_accuracy: 0.8029\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4720 - accuracy: 0.7460 - val_loss: 0.3688 - val_accuracy: 0.8003\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.4692 - accuracy: 0.7484 - val_loss: 0.3884 - val_accuracy: 0.8005\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4538 - accuracy: 0.7544 - val_loss: 0.3667 - val_accuracy: 0.7908\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4259 - accuracy: 0.7740 - val_loss: 0.2970 - val_accuracy: 0.8490\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3676 - accuracy: 0.8226 - val_loss: 0.3503 - val_accuracy: 0.8070\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.3286 - accuracy: 0.8492 - val_loss: 0.3032 - val_accuracy: 0.8628\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2982 - accuracy: 0.8640 - val_loss: 0.2957 - val_accuracy: 0.8597\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.2818 - accuracy: 0.8742 - val_loss: 0.2710 - val_accuracy: 0.8729\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.2688 - accuracy: 0.8790 - val_loss: 0.2803 - val_accuracy: 0.8632\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2619 - accuracy: 0.8842 - val_loss: 0.2897 - val_accuracy: 0.8578\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2587 - accuracy: 0.8841 - val_loss: 0.2724 - val_accuracy: 0.8680\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.2550 - accuracy: 0.8864 - val_loss: 0.2719 - val_accuracy: 0.8730\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2490 - accuracy: 0.8890 - val_loss: 0.2645 - val_accuracy: 0.8722\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.2394 - accuracy: 0.8944 - val_loss: 0.2627 - val_accuracy: 0.8755\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2429 - accuracy: 0.8941 - val_loss: 0.3061 - val_accuracy: 0.8517\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2395 - accuracy: 0.8951 - val_loss: 0.3382 - val_accuracy: 0.8294\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.2319 - accuracy: 0.8981 - val_loss: 0.2786 - val_accuracy: 0.8687\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2328 - accuracy: 0.8980 - val_loss: 0.3490 - val_accuracy: 0.8432\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2621 - accuracy: 0.8792 - val_loss: 0.2821 - val_accuracy: 0.8606\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2270 - accuracy: 0.8987 - val_loss: 0.2684 - val_accuracy: 0.8749\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2202 - accuracy: 0.9020 - val_loss: 0.3031 - val_accuracy: 0.8606\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2205 - accuracy: 0.9053 - val_loss: 0.3025 - val_accuracy: 0.8680\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2216 - accuracy: 0.9031 - val_loss: 0.2885 - val_accuracy: 0.8659\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2198 - accuracy: 0.9035 - val_loss: 0.2613 - val_accuracy: 0.8800\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.2167 - accuracy: 0.9052 - val_loss: 0.3478 - val_accuracy: 0.8450\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.2116 - accuracy: 0.9085 - val_loss: 0.2954 - val_accuracy: 0.8619\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.2166 - accuracy: 0.9044 - val_loss: 0.2657 - val_accuracy: 0.8761\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2040 - accuracy: 0.9109 - val_loss: 0.2296 - val_accuracy: 0.8968\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2036 - accuracy: 0.9127 - val_loss: 0.2749 - val_accuracy: 0.8768\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2059 - accuracy: 0.9123 - val_loss: 0.2836 - val_accuracy: 0.8805\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2790 - accuracy: 0.8761 - val_loss: 0.4139 - val_accuracy: 0.7790\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.4084 - accuracy: 0.8105 - val_loss: 0.3614 - val_accuracy: 0.8212\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.3332 - accuracy: 0.8516 - val_loss: 0.2994 - val_accuracy: 0.8559\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.3247 - accuracy: 0.8554 - val_loss: 0.3143 - val_accuracy: 0.8484\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.3184 - accuracy: 0.8594 - val_loss: 0.3606 - val_accuracy: 0.8290\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3097 - accuracy: 0.8602 - val_loss: 0.2943 - val_accuracy: 0.8625\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3058 - accuracy: 0.8630 - val_loss: 0.3190 - val_accuracy: 0.8531\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3073 - accuracy: 0.8619 - val_loss: 0.4347 - val_accuracy: 0.7757\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.3032 - accuracy: 0.8646 - val_loss: 0.3162 - val_accuracy: 0.8438\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2980 - accuracy: 0.8663 - val_loss: 0.3112 - val_accuracy: 0.8429\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.2921 - accuracy: 0.8682 - val_loss: 0.3045 - val_accuracy: 0.8481\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2921 - accuracy: 0.8682 - val_loss: 0.3033 - val_accuracy: 0.8486\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.2916 - accuracy: 0.8695 - val_loss: 0.2984 - val_accuracy: 0.8450\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.3041 - accuracy: 0.8633 - val_loss: 0.3017 - val_accuracy: 0.8561\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.3563 - accuracy: 0.8288 - val_loss: 0.3421 - val_accuracy: 0.8363\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.2986 - accuracy: 0.8667 - val_loss: 0.3031 - val_accuracy: 0.8495\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.2884 - accuracy: 0.8723 - val_loss: 0.3348 - val_accuracy: 0.8271\n",
      "Epoch 75/500\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.2806 - accuracy: 0.8760Restoring model weights from the end of the best epoch: 55.\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2806 - accuracy: 0.8760 - val_loss: 0.3384 - val_accuracy: 0.8346\n",
      "Epoch 75: early stopping\n",
      "Number of iterations 9\n",
      "F1-scores:  [0.8360944659851957, 0.8121301775147929, 0.8251978891820579, 0.8328308207705193, 0.8615600843288825, 0.8603430171508576, 0.8591269841269841, 0.8474692202462382, 0.79714091218516]\n",
      "Average F1-Score 0.8368770634989653\n",
      "Std Dev F1-Score 0.021374733239538386\n",
      "Error bar F1-Score 0.007124911079846128\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 11s 20ms/step - loss: 0.5702 - accuracy: 0.6984 - val_loss: 0.4419 - val_accuracy: 0.7584\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5401 - accuracy: 0.7027 - val_loss: 0.4408 - val_accuracy: 0.7651\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.5274 - accuracy: 0.7153 - val_loss: 0.3893 - val_accuracy: 0.7887\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4837 - accuracy: 0.7377 - val_loss: 0.4084 - val_accuracy: 0.8032\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.3815 - accuracy: 0.8163 - val_loss: 0.3105 - val_accuracy: 0.8606\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.3474 - accuracy: 0.8409 - val_loss: 0.3290 - val_accuracy: 0.8438\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.3159 - accuracy: 0.8559 - val_loss: 0.3136 - val_accuracy: 0.8618\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.2920 - accuracy: 0.8684 - val_loss: 0.3203 - val_accuracy: 0.8486\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2898 - accuracy: 0.8723 - val_loss: 0.2783 - val_accuracy: 0.8571\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2752 - accuracy: 0.8730 - val_loss: 0.2842 - val_accuracy: 0.8630\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2822 - accuracy: 0.8726 - val_loss: 0.2645 - val_accuracy: 0.8711\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2605 - accuracy: 0.8784 - val_loss: 0.2584 - val_accuracy: 0.8671\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2615 - accuracy: 0.8806 - val_loss: 0.2474 - val_accuracy: 0.8782\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2458 - accuracy: 0.8886 - val_loss: 0.2339 - val_accuracy: 0.8872\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.2512 - accuracy: 0.8837 - val_loss: 0.2461 - val_accuracy: 0.8782\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.2382 - accuracy: 0.8904 - val_loss: 0.2695 - val_accuracy: 0.8751\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2513 - accuracy: 0.8867 - val_loss: 0.2217 - val_accuracy: 0.8916\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2340 - accuracy: 0.8929 - val_loss: 0.2137 - val_accuracy: 0.8945\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2320 - accuracy: 0.8955 - val_loss: 0.2531 - val_accuracy: 0.8813\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2403 - accuracy: 0.8910 - val_loss: 0.2220 - val_accuracy: 0.8961\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.2330 - accuracy: 0.8955 - val_loss: 0.2414 - val_accuracy: 0.8832\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2266 - accuracy: 0.8983 - val_loss: 0.2142 - val_accuracy: 0.8987\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2164 - accuracy: 0.9034 - val_loss: 0.2283 - val_accuracy: 0.8897\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2242 - accuracy: 0.9000 - val_loss: 0.2349 - val_accuracy: 0.8800\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2105 - accuracy: 0.9059 - val_loss: 0.2718 - val_accuracy: 0.8699\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.2135 - accuracy: 0.9060 - val_loss: 0.2195 - val_accuracy: 0.8994\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2153 - accuracy: 0.9054 - val_loss: 0.2635 - val_accuracy: 0.8768\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1971 - accuracy: 0.9142 - val_loss: 0.2161 - val_accuracy: 0.8985\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1915 - accuracy: 0.9172 - val_loss: 0.2374 - val_accuracy: 0.8945\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.2034 - accuracy: 0.9123 - val_loss: 0.2213 - val_accuracy: 0.8985\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1872 - accuracy: 0.9199 - val_loss: 0.1977 - val_accuracy: 0.9059\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1801 - accuracy: 0.9222 - val_loss: 0.2232 - val_accuracy: 0.9009\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1882 - accuracy: 0.9187 - val_loss: 0.2198 - val_accuracy: 0.9011\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1753 - accuracy: 0.9252 - val_loss: 0.2179 - val_accuracy: 0.9044\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.2228 - accuracy: 0.9006 - val_loss: 0.2636 - val_accuracy: 0.8867\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.1833 - accuracy: 0.9229 - val_loss: 0.2204 - val_accuracy: 0.8987\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.1876 - accuracy: 0.9214 - val_loss: 0.2334 - val_accuracy: 0.8968\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.1812 - accuracy: 0.9235 - val_loss: 0.3277 - val_accuracy: 0.8658\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1625 - accuracy: 0.9306 - val_loss: 0.2417 - val_accuracy: 0.8973\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1714 - accuracy: 0.9285 - val_loss: 0.2302 - val_accuracy: 0.9007\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1540 - accuracy: 0.9355 - val_loss: 0.2233 - val_accuracy: 0.9028\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1564 - accuracy: 0.9342 - val_loss: 0.2278 - val_accuracy: 0.9030\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1606 - accuracy: 0.9332 - val_loss: 0.2345 - val_accuracy: 0.9032\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.1497 - accuracy: 0.9377 - val_loss: 0.3490 - val_accuracy: 0.8614\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1545 - accuracy: 0.9355 - val_loss: 0.2114 - val_accuracy: 0.9096\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.1585 - accuracy: 0.9345 - val_loss: 0.2293 - val_accuracy: 0.9027\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1406 - accuracy: 0.9423 - val_loss: 0.2204 - val_accuracy: 0.9044\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1490 - accuracy: 0.9371 - val_loss: 0.2393 - val_accuracy: 0.8990\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1432 - accuracy: 0.9407 - val_loss: 0.2484 - val_accuracy: 0.9028\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1390 - accuracy: 0.9422 - val_loss: 0.2733 - val_accuracy: 0.8936\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1348 - accuracy: 0.9455 - val_loss: 0.3215 - val_accuracy: 0.8761\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1443 - accuracy: 0.9417 - val_loss: 0.2418 - val_accuracy: 0.9089\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1281 - accuracy: 0.9477 - val_loss: 0.2853 - val_accuracy: 0.8929\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.1393 - accuracy: 0.9442 - val_loss: 0.2493 - val_accuracy: 0.9009\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1271 - accuracy: 0.9474 - val_loss: 0.2652 - val_accuracy: 0.8971\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1243 - accuracy: 0.9497 - val_loss: 0.2603 - val_accuracy: 0.9020\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1190 - accuracy: 0.9522 - val_loss: 0.2984 - val_accuracy: 0.8945\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1185 - accuracy: 0.9538 - val_loss: 0.2429 - val_accuracy: 0.9108\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1191 - accuracy: 0.9522 - val_loss: 0.2838 - val_accuracy: 0.8917\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.1139 - accuracy: 0.9551 - val_loss: 0.2869 - val_accuracy: 0.8952\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.1277 - accuracy: 0.9490 - val_loss: 0.2823 - val_accuracy: 0.8988\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1121 - accuracy: 0.9554 - val_loss: 0.2899 - val_accuracy: 0.8976\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1126 - accuracy: 0.9557 - val_loss: 0.2894 - val_accuracy: 0.8985\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1090 - accuracy: 0.9567 - val_loss: 0.2966 - val_accuracy: 0.8942\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1084 - accuracy: 0.9566 - val_loss: 0.3147 - val_accuracy: 0.8883\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1103 - accuracy: 0.9563 - val_loss: 0.2438 - val_accuracy: 0.9137\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0982 - accuracy: 0.9619 - val_loss: 0.2673 - val_accuracy: 0.9061\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.0981 - accuracy: 0.9603 - val_loss: 0.3067 - val_accuracy: 0.9002\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1068 - accuracy: 0.9571 - val_loss: 0.4050 - val_accuracy: 0.8706\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1041 - accuracy: 0.9589 - val_loss: 0.2911 - val_accuracy: 0.9001\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.1000 - accuracy: 0.9609 - val_loss: 0.3248 - val_accuracy: 0.8962\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0992 - accuracy: 0.9601 - val_loss: 0.2630 - val_accuracy: 0.9144\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.0890 - accuracy: 0.9638 - val_loss: 0.2976 - val_accuracy: 0.9075\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0894 - accuracy: 0.9647 - val_loss: 0.3088 - val_accuracy: 0.9013\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0822 - accuracy: 0.9670 - val_loss: 0.3361 - val_accuracy: 0.8966\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.0906 - accuracy: 0.9650 - val_loss: 0.3053 - val_accuracy: 0.9033\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0903 - accuracy: 0.9637 - val_loss: 0.2830 - val_accuracy: 0.9101\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0757 - accuracy: 0.9709 - val_loss: 0.3135 - val_accuracy: 0.9058\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0802 - accuracy: 0.9691 - val_loss: 0.2919 - val_accuracy: 0.9120\n",
      "Epoch 80/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.0822 - accuracy: 0.9672 - val_loss: 0.2797 - val_accuracy: 0.9167\n",
      "Epoch 81/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0852 - accuracy: 0.9675 - val_loss: 0.3216 - val_accuracy: 0.9051\n",
      "Epoch 82/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0797 - accuracy: 0.9693 - val_loss: 0.3173 - val_accuracy: 0.9027\n",
      "Epoch 83/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0714 - accuracy: 0.9722 - val_loss: 0.3211 - val_accuracy: 0.9020\n",
      "Epoch 84/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.0711 - accuracy: 0.9719 - val_loss: 0.3089 - val_accuracy: 0.9092\n",
      "Epoch 85/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0881 - accuracy: 0.9661 - val_loss: 0.3382 - val_accuracy: 0.8929\n",
      "Epoch 86/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0687 - accuracy: 0.9733 - val_loss: 0.3539 - val_accuracy: 0.9061\n",
      "Epoch 87/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0685 - accuracy: 0.9721 - val_loss: 0.3552 - val_accuracy: 0.9072\n",
      "Epoch 88/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0775 - accuracy: 0.9714 - val_loss: 0.3221 - val_accuracy: 0.9104\n",
      "Epoch 89/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0654 - accuracy: 0.9744 - val_loss: 0.3918 - val_accuracy: 0.8976\n",
      "Epoch 90/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0809 - accuracy: 0.9684 - val_loss: 0.3627 - val_accuracy: 0.8888\n",
      "Epoch 91/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0599 - accuracy: 0.9770 - val_loss: 0.3212 - val_accuracy: 0.9096\n",
      "Epoch 92/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0705 - accuracy: 0.9735 - val_loss: 0.3557 - val_accuracy: 0.8961\n",
      "Epoch 93/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0641 - accuracy: 0.9747 - val_loss: 0.3667 - val_accuracy: 0.8964\n",
      "Epoch 94/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0594 - accuracy: 0.9774 - val_loss: 0.3348 - val_accuracy: 0.9035\n",
      "Epoch 95/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0628 - accuracy: 0.9756 - val_loss: 0.2972 - val_accuracy: 0.9101\n",
      "Epoch 96/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0630 - accuracy: 0.9750 - val_loss: 0.3222 - val_accuracy: 0.9070\n",
      "Epoch 97/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0613 - accuracy: 0.9769 - val_loss: 0.2841 - val_accuracy: 0.9191\n",
      "Epoch 98/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0635 - accuracy: 0.9768 - val_loss: 0.3183 - val_accuracy: 0.9120\n",
      "Epoch 99/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0678 - accuracy: 0.9737 - val_loss: 0.3432 - val_accuracy: 0.9075\n",
      "Epoch 100/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0448 - accuracy: 0.9834 - val_loss: 0.3217 - val_accuracy: 0.9132\n",
      "Epoch 101/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0626 - accuracy: 0.9772 - val_loss: 0.3244 - val_accuracy: 0.9089\n",
      "Epoch 102/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.0482 - accuracy: 0.9821 - val_loss: 0.4141 - val_accuracy: 0.8947\n",
      "Epoch 103/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0547 - accuracy: 0.9792 - val_loss: 0.3559 - val_accuracy: 0.9075\n",
      "Epoch 104/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0502 - accuracy: 0.9813 - val_loss: 0.3646 - val_accuracy: 0.9054\n",
      "Epoch 105/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0532 - accuracy: 0.9802 - val_loss: 0.3376 - val_accuracy: 0.9125\n",
      "Epoch 106/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0482 - accuracy: 0.9816 - val_loss: 0.2919 - val_accuracy: 0.9186\n",
      "Epoch 107/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0509 - accuracy: 0.9819 - val_loss: 0.3818 - val_accuracy: 0.9061\n",
      "Epoch 108/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0406 - accuracy: 0.9847 - val_loss: 0.4367 - val_accuracy: 0.9007\n",
      "Epoch 109/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0407 - accuracy: 0.9846 - val_loss: 0.3591 - val_accuracy: 0.9203\n",
      "Epoch 110/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0568 - accuracy: 0.9795 - val_loss: 0.4311 - val_accuracy: 0.8985\n",
      "Epoch 111/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0380 - accuracy: 0.9864 - val_loss: 0.3937 - val_accuracy: 0.9094\n",
      "Epoch 112/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0461 - accuracy: 0.9819 - val_loss: 0.3654 - val_accuracy: 0.9078\n",
      "Epoch 113/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0438 - accuracy: 0.9832 - val_loss: 0.3444 - val_accuracy: 0.9103\n",
      "Epoch 114/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0464 - accuracy: 0.9827 - val_loss: 0.3596 - val_accuracy: 0.9063\n",
      "Epoch 115/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0380 - accuracy: 0.9853 - val_loss: 0.3507 - val_accuracy: 0.9137\n",
      "Epoch 116/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0608 - accuracy: 0.9765 - val_loss: 0.3052 - val_accuracy: 0.9181\n",
      "Epoch 117/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0261 - accuracy: 0.9912 - val_loss: 0.3777 - val_accuracy: 0.9188\n",
      "Epoch 118/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0344 - accuracy: 0.9873 - val_loss: 0.4396 - val_accuracy: 0.9044\n",
      "Epoch 119/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0534 - accuracy: 0.9794 - val_loss: 0.3685 - val_accuracy: 0.9167\n",
      "Epoch 120/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0368 - accuracy: 0.9867 - val_loss: 0.3821 - val_accuracy: 0.9092\n",
      "Epoch 121/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0442 - accuracy: 0.9842 - val_loss: 0.3650 - val_accuracy: 0.9120\n",
      "Epoch 122/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0358 - accuracy: 0.9873 - val_loss: 0.3235 - val_accuracy: 0.9162\n",
      "Epoch 123/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0449 - accuracy: 0.9843 - val_loss: 0.3475 - val_accuracy: 0.9188\n",
      "Epoch 124/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 0.3824 - val_accuracy: 0.9110\n",
      "Epoch 125/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0409 - accuracy: 0.9846 - val_loss: 0.3898 - val_accuracy: 0.9087\n",
      "Epoch 126/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0319 - accuracy: 0.9888 - val_loss: 0.4259 - val_accuracy: 0.9007\n",
      "Epoch 127/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0534 - accuracy: 0.9810 - val_loss: 0.3483 - val_accuracy: 0.9165\n",
      "Epoch 128/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 0.3698 - val_accuracy: 0.9207\n",
      "Epoch 129/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0428 - accuracy: 0.9849 - val_loss: 0.3778 - val_accuracy: 0.9137\n",
      "Epoch 130/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0392 - accuracy: 0.9863 - val_loss: 0.3871 - val_accuracy: 0.9111\n",
      "Epoch 131/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0402 - accuracy: 0.9863 - val_loss: 0.3444 - val_accuracy: 0.9143\n",
      "Epoch 132/500\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.0283 - accuracy: 0.9902 - val_loss: 0.4777 - val_accuracy: 0.8990\n",
      "Epoch 133/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0473 - accuracy: 0.9828 - val_loss: 0.3592 - val_accuracy: 0.9027\n",
      "Epoch 134/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0287 - accuracy: 0.9900 - val_loss: 0.4906 - val_accuracy: 0.8949\n",
      "Epoch 135/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0374 - accuracy: 0.9869 - val_loss: 0.4289 - val_accuracy: 0.8917\n",
      "Epoch 136/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0272 - accuracy: 0.9909 - val_loss: 0.3857 - val_accuracy: 0.9129\n",
      "Epoch 137/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0299 - accuracy: 0.9897 - val_loss: 0.4025 - val_accuracy: 0.9172\n",
      "Epoch 138/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0430 - accuracy: 0.9842 - val_loss: 0.4056 - val_accuracy: 0.9101\n",
      "Epoch 139/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.4176 - val_accuracy: 0.9052\n",
      "Epoch 140/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0450 - accuracy: 0.9828 - val_loss: 0.3857 - val_accuracy: 0.9117\n",
      "Epoch 141/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0200 - accuracy: 0.9928 - val_loss: 0.4415 - val_accuracy: 0.9110\n",
      "Epoch 142/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0446 - accuracy: 0.9845 - val_loss: 0.3820 - val_accuracy: 0.9080\n",
      "Epoch 143/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0210 - accuracy: 0.9925 - val_loss: 0.3718 - val_accuracy: 0.9214\n",
      "Epoch 144/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0274 - accuracy: 0.9916 - val_loss: 0.5795 - val_accuracy: 0.8798\n",
      "Epoch 145/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0371 - accuracy: 0.9857 - val_loss: 0.4014 - val_accuracy: 0.9106\n",
      "Epoch 146/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0204 - accuracy: 0.9938 - val_loss: 0.4848 - val_accuracy: 0.9085\n",
      "Epoch 147/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0547 - accuracy: 0.9828 - val_loss: 0.3549 - val_accuracy: 0.9077\n",
      "Epoch 148/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0263 - accuracy: 0.9908 - val_loss: 0.4013 - val_accuracy: 0.9118\n",
      "Epoch 149/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.4587 - val_accuracy: 0.9108\n",
      "Epoch 150/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0308 - accuracy: 0.9900 - val_loss: 0.3722 - val_accuracy: 0.9089\n",
      "Epoch 151/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0269 - accuracy: 0.9913 - val_loss: 0.4144 - val_accuracy: 0.9181\n",
      "Epoch 152/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0411 - accuracy: 0.9853 - val_loss: 0.3399 - val_accuracy: 0.9191\n",
      "Epoch 153/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0477 - accuracy: 0.9842 - val_loss: 0.4097 - val_accuracy: 0.9094\n",
      "Epoch 154/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0282 - accuracy: 0.9909 - val_loss: 0.3749 - val_accuracy: 0.9155\n",
      "Epoch 155/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.4058 - val_accuracy: 0.9169\n",
      "Epoch 156/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.4282 - val_accuracy: 0.9149\n",
      "Epoch 157/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0434 - accuracy: 0.9847 - val_loss: 0.5124 - val_accuracy: 0.8862\n",
      "Epoch 158/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0302 - accuracy: 0.9891 - val_loss: 0.4172 - val_accuracy: 0.9084\n",
      "Epoch 159/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.3917 - val_accuracy: 0.9165\n",
      "Epoch 160/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0278 - accuracy: 0.9913 - val_loss: 0.4430 - val_accuracy: 0.9089\n",
      "Epoch 161/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0370 - accuracy: 0.9862 - val_loss: 0.4219 - val_accuracy: 0.9059\n",
      "Epoch 162/500\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.3548 - val_accuracy: 0.9207\n",
      "Epoch 163/500\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9922Restoring model weights from the end of the best epoch: 143.\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.0221 - accuracy: 0.9922 - val_loss: 0.4786 - val_accuracy: 0.9023\n",
      "Epoch 163: early stopping\n",
      "Number of iterations 10\n",
      "F1-scores:  [0.8360944659851957, 0.8121301775147929, 0.8251978891820579, 0.8328308207705193, 0.8615600843288825, 0.8603430171508576, 0.8591269841269841, 0.8474692202462382, 0.79714091218516, 0.8483633934535738]\n",
      "Average F1-Score 0.8380256964944263\n",
      "Std Dev F1-Score 0.02056855655556891\n",
      "Error bar F1-Score 0.006504348689758542\n"
     ]
    }
   ],
   "source": [
    "###Collect F-Score 10 times\n",
    "import sklearn\n",
    "from tqdm.notebook import tqdm\n",
    "def calc_f1_score(X_train_scaled,X_test_scaled,X_train_scaled_f,X_test_scaled_f,y_train,y_test,earlystop):\n",
    "  input_1 = Input((X_train_scaled.shape[1], X_train_scaled.shape[2]))\n",
    "  input_2 = Input((X_train_scaled_f.shape[1], X_train_scaled_f.shape[2]))\n",
    "  x1=LSTM(units = 100, return_sequences = True)(input_1)\n",
    "  x1=LSTM(units = 50)(x1)\n",
    "  x2=LSTM(units = 100, return_sequences = True)(input_2)\n",
    "  x2=LSTM(units = 50)(x2)\n",
    "  x = layers.concatenate([x1, x2])\n",
    "  output_layer = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "  classifier=keras.Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "  # Compiling the RNN\n",
    "  classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  classifier.fit([X_train_scaled,X_train_scaled_f], y_train[:,0], epochs = 500, batch_size = 64,validation_data=([X_test_scaled,X_test_scaled_f],y_test[:,0]),callbacks=[earlystop])\n",
    "  y_pred = classifier.predict([X_test_scaled,X_test_scaled_f])\n",
    "  y_pred= (y_pred>=0.5).astype(int)\n",
    "  return(sklearn.metrics.f1_score(y_test[:,0],y_pred))\n",
    "\n",
    "f1_score_list=[]\n",
    "for i in tqdm(range(10)):\n",
    "  f1_score_list=f1_score_list+[calc_f1_score(X_train_scaled,X_test_scaled,X_train_scaled_f,X_test_scaled_f,y_train,y_test,earlystop)]\n",
    "  print(\"Number of iterations\",len(f1_score_list))\n",
    "  print(\"F1-scores: \",f1_score_list)\n",
    "  print(\"Average F1-Score\",np.mean(f1_score_list))\n",
    "  print(\"Std Dev F1-Score\",np.std(f1_score_list))\n",
    "  print(\"Error bar F1-Score\",np.std(f1_score_list)/np.sqrt(len(f1_score_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average F1-Score 0.8380256964944263\n",
    "# Std Dev F1-Score 0.02056855655556891\n",
    "# Error bar F1-Score 0.006504348689758542"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_1d_freq_exp2_exp5_v2.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "024f22fc52ce45fe84edc5ded351e881": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "46f7e55be9584f1ea1f87850465255c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_595c6a0b563e4e16a11282e364c00bc4",
       "IPY_MODEL_fa98ea8875994aadbf9fd2d1f75ed846",
       "IPY_MODEL_e21941e7fdb74d0bb5ffaafe9a71cc6e"
      ],
      "layout": "IPY_MODEL_574c975037274b6ab2156ea2339ff8b9",
      "tabbable": null,
      "tooltip": null
     }
    },
    "5558f7c0156a4913bc10042f6e31f444": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "574c975037274b6ab2156ea2339ff8b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "595c6a0b563e4e16a11282e364c00bc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_601c20f1fd4d402180361057b4a0b644",
      "placeholder": "",
      "style": "IPY_MODEL_024f22fc52ce45fe84edc5ded351e881",
      "tabbable": null,
      "tooltip": null,
      "value": "100%"
     }
    },
    "601c20f1fd4d402180361057b4a0b644": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd9bd3cd58e7420dbafb57a2cdb1cfc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "e21941e7fdb74d0bb5ffaafe9a71cc6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_5558f7c0156a4913bc10042f6e31f444",
      "placeholder": "",
      "style": "IPY_MODEL_cd9bd3cd58e7420dbafb57a2cdb1cfc9",
      "tabbable": null,
      "tooltip": null,
      "value": " 10/10 [1:16:31&lt;00:00, 559.48s/it]"
     }
    },
    "f46b22ef7b7348309a7d8be7292a1cab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f6c81751c92d4de192451e008f1963a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa98ea8875994aadbf9fd2d1f75ed846": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_f6c81751c92d4de192451e008f1963a6",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f46b22ef7b7348309a7d8be7292a1cab",
      "tabbable": null,
      "tooltip": null,
      "value": 10
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
