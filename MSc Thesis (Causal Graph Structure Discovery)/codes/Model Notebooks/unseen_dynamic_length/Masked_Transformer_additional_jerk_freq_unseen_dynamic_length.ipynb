{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JYsWwiwnPzi",
    "outputId": "dddf7993-5e4f-4807-8388-1da00786932a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug  4 14:59:44 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdNIB899nhlq",
    "outputId": "6b2cd80d-33ca-4b79-cece-63719b03eed2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#mounting google drive on colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfSazzTdnmaM"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXN_d9Evntel"
   },
   "outputs": [],
   "source": [
    "X_train=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/GraphWise_X_trainv7_exp2_exp5.npy\")\n",
    "X_train_f=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/GraphWise_X_f_trainv7_exp2_exp5.npy\")\n",
    "y_train=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/GraphWise_y_trainv7_exp2_exp5.npy\").astype(int)\n",
    "\n",
    "X_test=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/GraphWise_X_testv7_exp2_exp5.npy\")\n",
    "X_test_f=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/GraphWise_X_f_testv7_exp2_exp5.npy\")\n",
    "y_test=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/GraphWise_y_testv7_exp2_exp5.npy\").astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ynZ-H4OtsGrl",
    "outputId": "4c6f56e5-d877-4337-dfd6-14c822ac1319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(875, 20, 50, 4)\n",
      "(875, 20, 26, 2)\n",
      "(875, 20, 20)\n",
      "(125, 20, 50, 4)\n",
      "(125, 20, 26, 2)\n",
      "(125, 20, 20)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_train_f.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_test_f.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SMPEt3tEPl6x",
    "outputId": "5a6e445a-b0be-4bdd-c6b4-b92730b4ac05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(875, 400, 1)\n",
      "(125, 400, 1)\n"
     ]
    }
   ],
   "source": [
    "y_train1=y_train.reshape(y_train.shape[0],-1)\n",
    "y_test1=y_test.reshape(y_test.shape[0],-1)\n",
    "\n",
    "y_train1=np.expand_dims(y_train1,-1)\n",
    "y_test1=np.expand_dims(y_test1,-1)\n",
    "\n",
    "print(y_train1.shape)\n",
    "print(y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WUhqnDj8Pl-N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvpdxcB6kS22"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "padding_dim=20\n",
    "padding_val=1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20tXUebI-PWL",
    "outputId": "e0404d1d-d8db-432e-cc14-2366b8d2d093"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
      "Collecting keras_nlp\n",
      "  Downloading keras_nlp-0.3.0-py3-none-any.whl (142 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |██▎                             | 10 kB 25.3 MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 20 kB 24.5 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 30 kB 11.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 40 kB 4.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 51 kB 4.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 61 kB 5.0 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 71 kB 5.5 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 81 kB 5.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 92 kB 6.0 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 102 kB 5.0 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 112 kB 5.0 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 122 kB 5.0 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 133 kB 5.0 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 142 kB 5.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras_nlp) (21.3)\n",
      "Collecting tensorflow-text\n",
      "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.6 MB 44.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras_nlp) (1.21.6)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from keras_nlp) (1.2.0)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras_nlp) (2.8.2+zzzcolab20220719082949)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras_nlp) (3.0.9)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (3.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (1.47.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (2.8.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (0.5.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (4.1.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (3.1.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (2.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (1.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (1.14.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (57.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (0.26.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (0.2.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_nlp) (14.0.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->keras_nlp) (0.37.1)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->keras_nlp) (1.5.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (2.23.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (1.35.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (4.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (2022.6.15)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->keras_nlp) (3.2.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->keras_nlp) (0.12.0)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 511.7 MB 6.0 kB/s \n",
      "\u001b[?25hCollecting gast>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 511.7 MB 4.7 kB/s \n",
      "\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-text to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow-text\n",
      "  Downloading tensorflow_text-2.8.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 58.7 MB/s \n",
      "\u001b[?25hInstalling collected packages: tensorflow-text, keras-nlp\n",
      "Successfully installed keras-nlp-0.3.0 tensorflow-text-2.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install keras keras_nlp\n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8CMIO_ToBr9"
   },
   "outputs": [],
   "source": [
    "padding_val=1e6\n",
    "\n",
    "class out_adj_mat(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(out_adj_mat, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        out1=tf.matmul(inputs,tf.transpose(inputs,[0,2,1]))#Loss\n",
    "        out2=tf.keras.layers.Activation('sigmoid')(out1)#Actual output\n",
    "        out1=tf.reshape(out1,(-1,20*20))\n",
    "        out1=tf.expand_dims(out1,-1)\n",
    "        return out1\n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        mask=tf.expand_dims(mask,axis=-1)\n",
    "        mask=tf.cast(mask,tf.dtypes.int64)\n",
    "        mask2=tf.matmul(mask,tf.transpose(mask,[0,2,1]))#Actual Output\n",
    "        mask1=tf.experimental.numpy.triu(mask2,1)#Loss\n",
    "        mask1=tf.cast(mask1,bool)\n",
    "        mask1=tf.reshape(mask1,(-1,20*20))\n",
    "        return mask1\n",
    "\n",
    "\n",
    "# Part 2 - Building the RNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "\n",
    "input_1 = Input((X_train.shape[1], X_train.shape[2], X_train.shape[3]),name=\"time\") #20,50,4\n",
    "input_2 = Input((X_train_f.shape[1], X_train_f.shape[2], X_train_f.shape[3]),name=\"freq\") #20,26,2\n",
    "\n",
    "x1=layers.Masking(mask_value=padding_val)(input_1)\n",
    "x1=layers.TimeDistributed(LSTM(units = 100, return_sequences = True))(x1)\n",
    "x1=layers.TimeDistributed(LSTM(units = 50))(x1)\n",
    "\n",
    "x2=layers.Masking(mask_value=padding_val)(input_2)\n",
    "x2=layers.TimeDistributed(LSTM(units = 100, return_sequences = True))(x2)\n",
    "x2=layers.TimeDistributed(LSTM(units = 50))(x2)\n",
    "\n",
    "merge_layer=layers.concatenate([x1,x2]) #B,20,100\n",
    "x=keras_nlp.layers.TransformerEncoder(intermediate_dim=64, num_heads=4,dropout=0.1)(merge_layer)\n",
    "x=keras_nlp.layers.TransformerEncoder(intermediate_dim=64, num_heads=4,dropout=0.1)(x)\n",
    "x=keras_nlp.layers.TransformerEncoder(intermediate_dim=64, num_heads=4,dropout=0.1)(x)\n",
    "\n",
    "out=out_adj_mat()(x)\n",
    "\n",
    "classifier=keras.Model(inputs=[input_1, input_2], outputs=[out])\n",
    "\n",
    "# # Compiling the RNN\n",
    "classifier.compile(optimizer = 'adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics = 'accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21ATfgO4x3PB",
    "outputId": "c6fe64d0-6407-4e13-9831-ef6e2a9d43ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.bool, name=None), name='Any:0')\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.bool, name=None), name='Any:0')\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.bool, name=None), name='All:0')\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 20), dtype=tf.bool, name=None), name='Placeholder_1:0')\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 400), dtype=tf.bool, name=None), name='Reshape:0')\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 400, 1), dtype=tf.float32, name=None), name='out_adj_mat/ExpandDims:0', description=\"created by layer 'out_adj_mat'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 20, 100), dtype=tf.float32, name=None), name='transformer_encoder_2/layer_normalization_1/batchnorm/add_1:0', description=\"created by layer 'transformer_encoder_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 100, 20), dtype=tf.float32, name=None), name='tf.compat.v1.transpose/transpose:0', description=\"created by layer 'tf.compat.v1.transpose'\")\n"
     ]
    }
   ],
   "source": [
    "print(x1._keras_mask)\n",
    "print(x2._keras_mask)\n",
    "print(merge_layer._keras_mask)\n",
    "print(x._keras_mask)\n",
    "print(out._keras_mask)\n",
    "# print(A_rec._keras_mask)\n",
    "\n",
    "print(out)\n",
    "# print(A_rec)\n",
    "\n",
    "print(x)\n",
    "print(tf.transpose(x,[0,2,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uf-jNI2KZJUu"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\",\n",
    "                             monitor=\"val_accuracy\",\n",
    "                             mode=\"max\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', # value being monitored for improvement\n",
    "                          min_delta = 0, #Abs value and is the min change required before we stop\n",
    "                          patience = 50, #Number of epochs we wait before stopping \n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True) #keeps the best weigths once stopped\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop,checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtZ5szc114Hu",
    "outputId": "fb865103-bf19-474e-e274-9129790259d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " time (InputLayer)              [(None, 20, 50, 4)]  0           []                               \n",
      "                                                                                                  \n",
      " freq (InputLayer)              [(None, 20, 26, 2)]  0           []                               \n",
      "                                                                                                  \n",
      " masking (Masking)              (None, 20, 50, 4)    0           ['time[0][0]']                   \n",
      "                                                                                                  \n",
      " masking_1 (Masking)            (None, 20, 26, 2)    0           ['freq[0][0]']                   \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 20, 50, 100)  42000      ['masking[0][0]']                \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      " time_distributed_2 (TimeDistri  (None, 20, 26, 100)  41200      ['masking_1[0][0]']              \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, 20, 50)      30200       ['time_distributed[0][0]']       \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDistri  (None, 20, 50)      30200       ['time_distributed_2[0][0]']     \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 20, 100)      0           ['time_distributed_1[0][0]',     \n",
      "                                                                  'time_distributed_3[0][0]']     \n",
      "                                                                                                  \n",
      " transformer_encoder (Transform  (None, 20, 100)     53764       ['concatenate[0][0]']            \n",
      " erEncoder)                                                                                       \n",
      "                                                                                                  \n",
      " transformer_encoder_1 (Transfo  (None, 20, 100)     53764       ['transformer_encoder[0][0]']    \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " transformer_encoder_2 (Transfo  (None, 20, 100)     53764       ['transformer_encoder_1[0][0]']  \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " out_adj_mat (out_adj_mat)      (None, 400, 1)       0           ['transformer_encoder_2[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 304,892\n",
      "Trainable params: 304,892\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 856
    },
    "id": "dvZf3AAQ6hdZ",
    "outputId": "84f66f36-c9c7-4ddb-9e37-1ee8c7f375e5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcUvZBOYoFNC",
    "outputId": "d4304f4b-8e9e-4809-d8c8-2f00712e62d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.3266 - accuracy: 0.3524\n",
      "Epoch 1: val_accuracy improved from -inf to 0.36134, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 45s 774ms/step - loss: 1.3266 - accuracy: 0.3524 - val_loss: 4.4189 - val_accuracy: 0.3613\n",
      "Epoch 2/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - ETA: 0s - loss: 0.3587 - accuracy: 0.4825\n",
      "Epoch 2: val_accuracy improved from 0.36134 to 0.51135, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 347ms/step - loss: 0.3587 - accuracy: 0.4825 - val_loss: 3.3480 - val_accuracy: 0.5113\n",
      "Epoch 3/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2937 - accuracy: 0.5333\n",
      "Epoch 3: val_accuracy improved from 0.51135 to 0.53560, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 346ms/step - loss: 0.2937 - accuracy: 0.5333 - val_loss: 3.1324 - val_accuracy: 0.5356\n",
      "Epoch 4/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2620 - accuracy: 0.5569\n",
      "Epoch 4: val_accuracy improved from 0.53560 to 0.55604, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 350ms/step - loss: 0.2620 - accuracy: 0.5569 - val_loss: 2.9544 - val_accuracy: 0.5560\n",
      "Epoch 5/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2433 - accuracy: 0.5726\n",
      "Epoch 5: val_accuracy improved from 0.55604 to 0.58289, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 348ms/step - loss: 0.2433 - accuracy: 0.5726 - val_loss: 2.7275 - val_accuracy: 0.5829\n",
      "Epoch 6/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2331 - accuracy: 0.5778\n",
      "Epoch 6: val_accuracy improved from 0.58289 to 0.59553, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 353ms/step - loss: 0.2331 - accuracy: 0.5778 - val_loss: 2.5643 - val_accuracy: 0.5955\n",
      "Epoch 7/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2189 - accuracy: 0.5853\n",
      "Epoch 7: val_accuracy did not improve from 0.59553\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.2189 - accuracy: 0.5853 - val_loss: 2.7232 - val_accuracy: 0.5404\n",
      "Epoch 8/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.2065 - accuracy: 0.5973\n",
      "Epoch 8: val_accuracy did not improve from 0.59553\n",
      "14/14 [==============================] - 5s 330ms/step - loss: 0.2065 - accuracy: 0.5973 - val_loss: 2.6569 - val_accuracy: 0.5301\n",
      "Epoch 9/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1974 - accuracy: 0.6044\n",
      "Epoch 9: val_accuracy did not improve from 0.59553\n",
      "14/14 [==============================] - 5s 330ms/step - loss: 0.1974 - accuracy: 0.6044 - val_loss: 2.4481 - val_accuracy: 0.5602\n",
      "Epoch 10/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1950 - accuracy: 0.6041\n",
      "Epoch 10: val_accuracy did not improve from 0.59553\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.1950 - accuracy: 0.6041 - val_loss: 2.4380 - val_accuracy: 0.5463\n",
      "Epoch 11/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1865 - accuracy: 0.6096\n",
      "Epoch 11: val_accuracy did not improve from 0.59553\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.1865 - accuracy: 0.6096 - val_loss: 2.4336 - val_accuracy: 0.5332\n",
      "Epoch 12/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1821 - accuracy: 0.6139\n",
      "Epoch 12: val_accuracy did not improve from 0.59553\n",
      "14/14 [==============================] - 5s 340ms/step - loss: 0.1821 - accuracy: 0.6139 - val_loss: 2.1772 - val_accuracy: 0.5675\n",
      "Epoch 13/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1740 - accuracy: 0.6174\n",
      "Epoch 13: val_accuracy did not improve from 0.59553\n",
      "14/14 [==============================] - 6s 417ms/step - loss: 0.1740 - accuracy: 0.6174 - val_loss: 2.1745 - val_accuracy: 0.5536\n",
      "Epoch 14/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1654 - accuracy: 0.6328\n",
      "Epoch 14: val_accuracy did not improve from 0.59553\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.1654 - accuracy: 0.6328 - val_loss: 2.1065 - val_accuracy: 0.5557\n",
      "Epoch 15/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.6268\n",
      "Epoch 15: val_accuracy improved from 0.59553 to 0.64507, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 390ms/step - loss: 0.1628 - accuracy: 0.6268 - val_loss: 1.6061 - val_accuracy: 0.6451\n",
      "Epoch 16/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1539 - accuracy: 0.6415\n",
      "Epoch 16: val_accuracy improved from 0.64507 to 0.67313, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 351ms/step - loss: 0.1539 - accuracy: 0.6415 - val_loss: 1.4492 - val_accuracy: 0.6731\n",
      "Epoch 17/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1503 - accuracy: 0.6531\n",
      "Epoch 17: val_accuracy improved from 0.67313 to 0.69981, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 348ms/step - loss: 0.1503 - accuracy: 0.6531 - val_loss: 1.3011 - val_accuracy: 0.6998\n",
      "Epoch 18/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 0.6693\n",
      "Epoch 18: val_accuracy improved from 0.69981 to 0.71453, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 391ms/step - loss: 0.1382 - accuracy: 0.6693 - val_loss: 1.1773 - val_accuracy: 0.7145\n",
      "Epoch 19/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1308 - accuracy: 0.6865\n",
      "Epoch 19: val_accuracy did not improve from 0.71453\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.1308 - accuracy: 0.6865 - val_loss: 1.2541 - val_accuracy: 0.7029\n",
      "Epoch 20/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1246 - accuracy: 0.6990\n",
      "Epoch 20: val_accuracy improved from 0.71453 to 0.72839, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 341ms/step - loss: 0.1246 - accuracy: 0.6990 - val_loss: 1.1662 - val_accuracy: 0.7284\n",
      "Epoch 21/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1136 - accuracy: 0.7133\n",
      "Epoch 21: val_accuracy did not improve from 0.72839\n",
      "14/14 [==============================] - 5s 323ms/step - loss: 0.1136 - accuracy: 0.7133 - val_loss: 1.3210 - val_accuracy: 0.6823\n",
      "Epoch 22/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.7255\n",
      "Epoch 22: val_accuracy did not improve from 0.72839\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.1096 - accuracy: 0.7255 - val_loss: 1.8998 - val_accuracy: 0.5891\n",
      "Epoch 23/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.7326\n",
      "Epoch 23: val_accuracy did not improve from 0.72839\n",
      "14/14 [==============================] - 5s 323ms/step - loss: 0.1037 - accuracy: 0.7326 - val_loss: 1.3906 - val_accuracy: 0.6678\n",
      "Epoch 24/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0994 - accuracy: 0.7366\n",
      "Epoch 24: val_accuracy did not improve from 0.72839\n",
      "14/14 [==============================] - 5s 328ms/step - loss: 0.0994 - accuracy: 0.7366 - val_loss: 1.5710 - val_accuracy: 0.6174\n",
      "Epoch 25/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.7343\n",
      "Epoch 25: val_accuracy improved from 0.72839 to 0.72995, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 370ms/step - loss: 0.0985 - accuracy: 0.7343 - val_loss: 1.0788 - val_accuracy: 0.7299\n",
      "Epoch 26/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0936 - accuracy: 0.7460\n",
      "Epoch 26: val_accuracy did not improve from 0.72995\n",
      "14/14 [==============================] - 5s 328ms/step - loss: 0.0936 - accuracy: 0.7460 - val_loss: 1.3474 - val_accuracy: 0.6636\n",
      "Epoch 27/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.7560\n",
      "Epoch 27: val_accuracy did not improve from 0.72995\n",
      "14/14 [==============================] - 5s 327ms/step - loss: 0.0886 - accuracy: 0.7560 - val_loss: 1.0848 - val_accuracy: 0.7178\n",
      "Epoch 28/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0884 - accuracy: 0.7540\n",
      "Epoch 28: val_accuracy did not improve from 0.72995\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0884 - accuracy: 0.7540 - val_loss: 1.0642 - val_accuracy: 0.7114\n",
      "Epoch 29/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.7564\n",
      "Epoch 29: val_accuracy did not improve from 0.72995\n",
      "14/14 [==============================] - 6s 450ms/step - loss: 0.0848 - accuracy: 0.7564 - val_loss: 1.0670 - val_accuracy: 0.7265\n",
      "Epoch 30/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.7605\n",
      "Epoch 30: val_accuracy did not improve from 0.72995\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0839 - accuracy: 0.7605 - val_loss: 1.0227 - val_accuracy: 0.7216\n",
      "Epoch 31/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 0.7656\n",
      "Epoch 31: val_accuracy improved from 0.72995 to 0.74710, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 378ms/step - loss: 0.0805 - accuracy: 0.7656 - val_loss: 0.8584 - val_accuracy: 0.7471\n",
      "Epoch 32/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.7673\n",
      "Epoch 32: val_accuracy did not improve from 0.74710\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0799 - accuracy: 0.7673 - val_loss: 0.9405 - val_accuracy: 0.7310\n",
      "Epoch 33/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.7601\n",
      "Epoch 33: val_accuracy improved from 0.74710 to 0.75351, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 347ms/step - loss: 0.0803 - accuracy: 0.7601 - val_loss: 0.8210 - val_accuracy: 0.7535\n",
      "Epoch 34/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.7613\n",
      "Epoch 34: val_accuracy did not improve from 0.75351\n",
      "14/14 [==============================] - 5s 328ms/step - loss: 0.0799 - accuracy: 0.7613 - val_loss: 1.2903 - val_accuracy: 0.6809\n",
      "Epoch 35/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.7603\n",
      "Epoch 35: val_accuracy did not improve from 0.75351\n",
      "14/14 [==============================] - 5s 326ms/step - loss: 0.0774 - accuracy: 0.7603 - val_loss: 0.8341 - val_accuracy: 0.7391\n",
      "Epoch 36/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.7704\n",
      "Epoch 36: val_accuracy did not improve from 0.75351\n",
      "14/14 [==============================] - 5s 330ms/step - loss: 0.0737 - accuracy: 0.7704 - val_loss: 0.7996 - val_accuracy: 0.7474\n",
      "Epoch 37/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.7737\n",
      "Epoch 37: val_accuracy improved from 0.75351 to 0.78936, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 374ms/step - loss: 0.0712 - accuracy: 0.7737 - val_loss: 0.6292 - val_accuracy: 0.7894\n",
      "Epoch 38/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.7778\n",
      "Epoch 38: val_accuracy did not improve from 0.78936\n",
      "14/14 [==============================] - 5s 328ms/step - loss: 0.0687 - accuracy: 0.7778 - val_loss: 0.6893 - val_accuracy: 0.7696\n",
      "Epoch 39/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.7781\n",
      "Epoch 39: val_accuracy did not improve from 0.78936\n",
      "14/14 [==============================] - 5s 329ms/step - loss: 0.0656 - accuracy: 0.7781 - val_loss: 0.6374 - val_accuracy: 0.7675\n",
      "Epoch 40/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0716 - accuracy: 0.7683\n",
      "Epoch 40: val_accuracy did not improve from 0.78936\n",
      "14/14 [==============================] - 5s 329ms/step - loss: 0.0716 - accuracy: 0.7683 - val_loss: 0.6253 - val_accuracy: 0.7601\n",
      "Epoch 41/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0655 - accuracy: 0.7752\n",
      "Epoch 41: val_accuracy did not improve from 0.78936\n",
      "14/14 [==============================] - 5s 373ms/step - loss: 0.0655 - accuracy: 0.7752 - val_loss: 0.5396 - val_accuracy: 0.7812\n",
      "Epoch 42/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 0.7745\n",
      "Epoch 42: val_accuracy did not improve from 0.78936\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0633 - accuracy: 0.7745 - val_loss: 0.5487 - val_accuracy: 0.7684\n",
      "Epoch 43/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.7841\n",
      "Epoch 43: val_accuracy did not improve from 0.78936\n",
      "14/14 [==============================] - 5s 339ms/step - loss: 0.0600 - accuracy: 0.7841 - val_loss: 0.4360 - val_accuracy: 0.7840\n",
      "Epoch 44/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 0.7873\n",
      "Epoch 44: val_accuracy improved from 0.78936 to 0.79820, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 387ms/step - loss: 0.0560 - accuracy: 0.7873 - val_loss: 0.3616 - val_accuracy: 0.7982\n",
      "Epoch 45/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.7861\n",
      "Epoch 45: val_accuracy did not improve from 0.79820\n",
      "14/14 [==============================] - 6s 455ms/step - loss: 0.0540 - accuracy: 0.7861 - val_loss: 0.3552 - val_accuracy: 0.7816\n",
      "Epoch 46/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.7863\n",
      "Epoch 46: val_accuracy improved from 0.79820 to 0.80062, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 351ms/step - loss: 0.0499 - accuracy: 0.7863 - val_loss: 0.2549 - val_accuracy: 0.8006\n",
      "Epoch 47/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.7881\n",
      "Epoch 47: val_accuracy improved from 0.80062 to 0.83302, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 352ms/step - loss: 0.0465 - accuracy: 0.7881 - val_loss: 0.1456 - val_accuracy: 0.8330\n",
      "Epoch 48/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 0.7919\n",
      "Epoch 48: val_accuracy did not improve from 0.83302\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0400 - accuracy: 0.7919 - val_loss: 0.1326 - val_accuracy: 0.8221\n",
      "Epoch 49/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.7979\n",
      "Epoch 49: val_accuracy did not improve from 0.83302\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0356 - accuracy: 0.7979 - val_loss: 0.0983 - val_accuracy: 0.8155\n",
      "Epoch 50/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.7972\n",
      "Epoch 50: val_accuracy did not improve from 0.83302\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0318 - accuracy: 0.7972 - val_loss: 0.0804 - val_accuracy: 0.8179\n",
      "Epoch 51/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.8075\n",
      "Epoch 51: val_accuracy did not improve from 0.83302\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0277 - accuracy: 0.8075 - val_loss: 0.0776 - val_accuracy: 0.8103\n",
      "Epoch 52/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.8044\n",
      "Epoch 52: val_accuracy did not improve from 0.83302\n",
      "14/14 [==============================] - 5s 330ms/step - loss: 0.0265 - accuracy: 0.8044 - val_loss: 0.0585 - val_accuracy: 0.8315\n",
      "Epoch 53/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.8033\n",
      "Epoch 53: val_accuracy did not improve from 0.83302\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0250 - accuracy: 0.8033 - val_loss: 0.0571 - val_accuracy: 0.8256\n",
      "Epoch 54/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.8055\n",
      "Epoch 54: val_accuracy improved from 0.83302 to 0.84428, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 385ms/step - loss: 0.0240 - accuracy: 0.8055 - val_loss: 0.0515 - val_accuracy: 0.8443\n",
      "Epoch 55/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.8087\n",
      "Epoch 55: val_accuracy improved from 0.84428 to 0.84739, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 348ms/step - loss: 0.0234 - accuracy: 0.8087 - val_loss: 0.0515 - val_accuracy: 0.8474\n",
      "Epoch 56/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.8129\n",
      "Epoch 56: val_accuracy did not improve from 0.84739\n",
      "14/14 [==============================] - 5s 329ms/step - loss: 0.0226 - accuracy: 0.8129 - val_loss: 0.0502 - val_accuracy: 0.8418\n",
      "Epoch 57/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.8113\n",
      "Epoch 57: val_accuracy improved from 0.84739 to 0.85432, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 346ms/step - loss: 0.0223 - accuracy: 0.8113 - val_loss: 0.0475 - val_accuracy: 0.8543\n",
      "Epoch 58/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.8167\n",
      "Epoch 58: val_accuracy did not improve from 0.85432\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0219 - accuracy: 0.8167 - val_loss: 0.0508 - val_accuracy: 0.8438\n",
      "Epoch 59/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.8196\n",
      "Epoch 59: val_accuracy did not improve from 0.85432\n",
      "14/14 [==============================] - 5s 368ms/step - loss: 0.0218 - accuracy: 0.8196 - val_loss: 0.0487 - val_accuracy: 0.8479\n",
      "Epoch 60/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.8180\n",
      "Epoch 60: val_accuracy did not improve from 0.85432\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0213 - accuracy: 0.8180 - val_loss: 0.0490 - val_accuracy: 0.8488\n",
      "Epoch 61/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.8199\n",
      "Epoch 61: val_accuracy improved from 0.85432 to 0.86368, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 7s 501ms/step - loss: 0.0212 - accuracy: 0.8199 - val_loss: 0.0464 - val_accuracy: 0.8637\n",
      "Epoch 62/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.8217\n",
      "Epoch 62: val_accuracy did not improve from 0.86368\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0210 - accuracy: 0.8217 - val_loss: 0.0481 - val_accuracy: 0.8524\n",
      "Epoch 63/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.8204\n",
      "Epoch 63: val_accuracy did not improve from 0.86368\n",
      "14/14 [==============================] - 5s 329ms/step - loss: 0.0210 - accuracy: 0.8204 - val_loss: 0.0459 - val_accuracy: 0.8592\n",
      "Epoch 64/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.8239\n",
      "Epoch 64: val_accuracy did not improve from 0.86368\n",
      "14/14 [==============================] - 5s 338ms/step - loss: 0.0206 - accuracy: 0.8239 - val_loss: 0.0457 - val_accuracy: 0.8602\n",
      "Epoch 65/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.8238\n",
      "Epoch 65: val_accuracy did not improve from 0.86368\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0203 - accuracy: 0.8238 - val_loss: 0.0451 - val_accuracy: 0.8597\n",
      "Epoch 66/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.8265\n",
      "Epoch 66: val_accuracy did not improve from 0.86368\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0202 - accuracy: 0.8265 - val_loss: 0.0457 - val_accuracy: 0.8569\n",
      "Epoch 67/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.8202\n",
      "Epoch 67: val_accuracy improved from 0.86368 to 0.87251, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 374ms/step - loss: 0.0208 - accuracy: 0.8202 - val_loss: 0.0467 - val_accuracy: 0.8725\n",
      "Epoch 68/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.8297\n",
      "Epoch 68: val_accuracy did not improve from 0.87251\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0203 - accuracy: 0.8297 - val_loss: 0.0441 - val_accuracy: 0.8593\n",
      "Epoch 69/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.8277\n",
      "Epoch 69: val_accuracy did not improve from 0.87251\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0198 - accuracy: 0.8277 - val_loss: 0.0434 - val_accuracy: 0.8684\n",
      "Epoch 70/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.8301\n",
      "Epoch 70: val_accuracy did not improve from 0.87251\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0200 - accuracy: 0.8301 - val_loss: 0.0421 - val_accuracy: 0.8659\n",
      "Epoch 71/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.8318\n",
      "Epoch 71: val_accuracy did not improve from 0.87251\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0195 - accuracy: 0.8318 - val_loss: 0.0428 - val_accuracy: 0.8680\n",
      "Epoch 72/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.8344\n",
      "Epoch 72: val_accuracy did not improve from 0.87251\n",
      "14/14 [==============================] - 5s 330ms/step - loss: 0.0195 - accuracy: 0.8344 - val_loss: 0.0420 - val_accuracy: 0.8645\n",
      "Epoch 73/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.8327\n",
      "Epoch 73: val_accuracy did not improve from 0.87251\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0195 - accuracy: 0.8327 - val_loss: 0.0422 - val_accuracy: 0.8640\n",
      "Epoch 74/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.8338\n",
      "Epoch 74: val_accuracy did not improve from 0.87251\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0193 - accuracy: 0.8338 - val_loss: 0.0439 - val_accuracy: 0.8613\n",
      "Epoch 75/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 0.8349\n",
      "Epoch 75: val_accuracy improved from 0.87251 to 0.87424, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 381ms/step - loss: 0.0192 - accuracy: 0.8349 - val_loss: 0.0430 - val_accuracy: 0.8742\n",
      "Epoch 76/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.8351\n",
      "Epoch 76: val_accuracy improved from 0.87424 to 0.87563, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 350ms/step - loss: 0.0194 - accuracy: 0.8351 - val_loss: 0.0426 - val_accuracy: 0.8756\n",
      "Epoch 77/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.8158\n",
      "Epoch 77: val_accuracy did not improve from 0.87563\n",
      "14/14 [==============================] - 6s 423ms/step - loss: 0.0217 - accuracy: 0.8158 - val_loss: 0.0671 - val_accuracy: 0.7793\n",
      "Epoch 78/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.7959\n",
      "Epoch 78: val_accuracy did not improve from 0.87563\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0234 - accuracy: 0.7959 - val_loss: 0.0494 - val_accuracy: 0.8734\n",
      "Epoch 79/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.8210\n",
      "Epoch 79: val_accuracy did not improve from 0.87563\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0215 - accuracy: 0.8210 - val_loss: 0.0411 - val_accuracy: 0.8723\n",
      "Epoch 80/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.8229\n",
      "Epoch 80: val_accuracy did not improve from 0.87563\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0201 - accuracy: 0.8229 - val_loss: 0.0417 - val_accuracy: 0.8623\n",
      "Epoch 81/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.8314\n",
      "Epoch 81: val_accuracy did not improve from 0.87563\n",
      "14/14 [==============================] - 5s 330ms/step - loss: 0.0195 - accuracy: 0.8314 - val_loss: 0.0404 - val_accuracy: 0.8668\n",
      "Epoch 82/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.8322\n",
      "Epoch 82: val_accuracy did not improve from 0.87563\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0191 - accuracy: 0.8322 - val_loss: 0.0396 - val_accuracy: 0.8699\n",
      "Epoch 83/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.8362\n",
      "Epoch 83: val_accuracy did not improve from 0.87563\n",
      "14/14 [==============================] - 5s 330ms/step - loss: 0.0190 - accuracy: 0.8362 - val_loss: 0.0396 - val_accuracy: 0.8755\n",
      "Epoch 84/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.8423\n",
      "Epoch 84: val_accuracy improved from 0.87563 to 0.87597, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 381ms/step - loss: 0.0187 - accuracy: 0.8423 - val_loss: 0.0399 - val_accuracy: 0.8760\n",
      "Epoch 85/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.8413\n",
      "Epoch 85: val_accuracy improved from 0.87597 to 0.88169, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 349ms/step - loss: 0.0185 - accuracy: 0.8413 - val_loss: 0.0381 - val_accuracy: 0.8817\n",
      "Epoch 86/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.8436\n",
      "Epoch 86: val_accuracy did not improve from 0.88169\n",
      "14/14 [==============================] - 5s 328ms/step - loss: 0.0184 - accuracy: 0.8436 - val_loss: 0.0388 - val_accuracy: 0.8706\n",
      "Epoch 87/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.8459\n",
      "Epoch 87: val_accuracy did not improve from 0.88169\n",
      "14/14 [==============================] - 5s 329ms/step - loss: 0.0183 - accuracy: 0.8459 - val_loss: 0.0412 - val_accuracy: 0.8632\n",
      "Epoch 88/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.8393\n",
      "Epoch 88: val_accuracy improved from 0.88169 to 0.88446, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 384ms/step - loss: 0.0186 - accuracy: 0.8393 - val_loss: 0.0379 - val_accuracy: 0.8845\n",
      "Epoch 89/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.8416\n",
      "Epoch 89: val_accuracy did not improve from 0.88446\n",
      "14/14 [==============================] - 5s 327ms/step - loss: 0.0185 - accuracy: 0.8416 - val_loss: 0.0387 - val_accuracy: 0.8761\n",
      "Epoch 90/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.8447\n",
      "Epoch 90: val_accuracy did not improve from 0.88446\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0182 - accuracy: 0.8447 - val_loss: 0.0381 - val_accuracy: 0.8767\n",
      "Epoch 91/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.8410\n",
      "Epoch 91: val_accuracy did not improve from 0.88446\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0178 - accuracy: 0.8410 - val_loss: 0.0378 - val_accuracy: 0.8786\n",
      "Epoch 92/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.8468\n",
      "Epoch 92: val_accuracy did not improve from 0.88446\n",
      "14/14 [==============================] - 5s 329ms/step - loss: 0.0179 - accuracy: 0.8468 - val_loss: 0.0399 - val_accuracy: 0.8658\n",
      "Epoch 93/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.8443\n",
      "Epoch 93: val_accuracy did not improve from 0.88446\n",
      "14/14 [==============================] - 5s 325ms/step - loss: 0.0178 - accuracy: 0.8443 - val_loss: 0.0401 - val_accuracy: 0.8651\n",
      "Epoch 94/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.8456\n",
      "Epoch 94: val_accuracy improved from 0.88446 to 0.88723, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 7s 494ms/step - loss: 0.0179 - accuracy: 0.8456 - val_loss: 0.0366 - val_accuracy: 0.8872\n",
      "Epoch 95/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.8495\n",
      "Epoch 95: val_accuracy did not improve from 0.88723\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0176 - accuracy: 0.8495 - val_loss: 0.0368 - val_accuracy: 0.8796\n",
      "Epoch 96/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.8505\n",
      "Epoch 96: val_accuracy did not improve from 0.88723\n",
      "14/14 [==============================] - 5s 330ms/step - loss: 0.0177 - accuracy: 0.8505 - val_loss: 0.0421 - val_accuracy: 0.8580\n",
      "Epoch 97/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.8485\n",
      "Epoch 97: val_accuracy did not improve from 0.88723\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0176 - accuracy: 0.8485 - val_loss: 0.0378 - val_accuracy: 0.8741\n",
      "Epoch 98/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.8555\n",
      "Epoch 98: val_accuracy did not improve from 0.88723\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0171 - accuracy: 0.8555 - val_loss: 0.0361 - val_accuracy: 0.8805\n",
      "Epoch 99/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.8530\n",
      "Epoch 99: val_accuracy did not improve from 0.88723\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0169 - accuracy: 0.8530 - val_loss: 0.0381 - val_accuracy: 0.8742\n",
      "Epoch 100/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.8521\n",
      "Epoch 100: val_accuracy did not improve from 0.88723\n",
      "14/14 [==============================] - 5s 329ms/step - loss: 0.0171 - accuracy: 0.8521 - val_loss: 0.0364 - val_accuracy: 0.8836\n",
      "Epoch 101/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.8503\n",
      "Epoch 101: val_accuracy did not improve from 0.88723\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0171 - accuracy: 0.8503 - val_loss: 0.0362 - val_accuracy: 0.8872\n",
      "Epoch 102/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.8555\n",
      "Epoch 102: val_accuracy did not improve from 0.88723\n",
      "14/14 [==============================] - 5s 329ms/step - loss: 0.0170 - accuracy: 0.8555 - val_loss: 0.0386 - val_accuracy: 0.8730\n",
      "Epoch 103/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.8457\n",
      "Epoch 103: val_accuracy did not improve from 0.88723\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0176 - accuracy: 0.8457 - val_loss: 0.0532 - val_accuracy: 0.8242\n",
      "Epoch 104/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.8372\n",
      "Epoch 104: val_accuracy improved from 0.88723 to 0.88758, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 375ms/step - loss: 0.0188 - accuracy: 0.8372 - val_loss: 0.0362 - val_accuracy: 0.8876\n",
      "Epoch 105/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.8449\n",
      "Epoch 105: val_accuracy did not improve from 0.88758\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0176 - accuracy: 0.8449 - val_loss: 0.0409 - val_accuracy: 0.8746\n",
      "Epoch 106/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.8520\n",
      "Epoch 106: val_accuracy did not improve from 0.88758\n",
      "14/14 [==============================] - 5s 326ms/step - loss: 0.0171 - accuracy: 0.8520 - val_loss: 0.0365 - val_accuracy: 0.8824\n",
      "Epoch 107/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.8564\n",
      "Epoch 107: val_accuracy did not improve from 0.88758\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0168 - accuracy: 0.8564 - val_loss: 0.0358 - val_accuracy: 0.8786\n",
      "Epoch 108/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.8565\n",
      "Epoch 108: val_accuracy did not improve from 0.88758\n",
      "14/14 [==============================] - 5s 330ms/step - loss: 0.0168 - accuracy: 0.8565 - val_loss: 0.0348 - val_accuracy: 0.8860\n",
      "Epoch 109/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.8542\n",
      "Epoch 109: val_accuracy improved from 0.88758 to 0.88879, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 389ms/step - loss: 0.0167 - accuracy: 0.8542 - val_loss: 0.0331 - val_accuracy: 0.8888\n",
      "Epoch 110/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.8592\n",
      "Epoch 110: val_accuracy improved from 0.88879 to 0.89018, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 6s 437ms/step - loss: 0.0166 - accuracy: 0.8592 - val_loss: 0.0341 - val_accuracy: 0.8902\n",
      "Epoch 111/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.8589\n",
      "Epoch 111: val_accuracy did not improve from 0.89018\n",
      "14/14 [==============================] - 5s 330ms/step - loss: 0.0161 - accuracy: 0.8589 - val_loss: 0.0339 - val_accuracy: 0.8902\n",
      "Epoch 112/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.8658\n",
      "Epoch 112: val_accuracy improved from 0.89018 to 0.89919, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 344ms/step - loss: 0.0159 - accuracy: 0.8658 - val_loss: 0.0333 - val_accuracy: 0.8992\n",
      "Epoch 113/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.8639\n",
      "Epoch 113: val_accuracy did not improve from 0.89919\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0160 - accuracy: 0.8639 - val_loss: 0.0395 - val_accuracy: 0.8599\n",
      "Epoch 114/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.8576\n",
      "Epoch 114: val_accuracy did not improve from 0.89919\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0165 - accuracy: 0.8576 - val_loss: 0.0458 - val_accuracy: 0.8533\n",
      "Epoch 115/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.8570\n",
      "Epoch 115: val_accuracy did not improve from 0.89919\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0167 - accuracy: 0.8570 - val_loss: 0.0341 - val_accuracy: 0.8929\n",
      "Epoch 116/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.8628\n",
      "Epoch 116: val_accuracy did not improve from 0.89919\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0158 - accuracy: 0.8628 - val_loss: 0.0346 - val_accuracy: 0.8945\n",
      "Epoch 117/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.8656\n",
      "Epoch 117: val_accuracy did not improve from 0.89919\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0158 - accuracy: 0.8656 - val_loss: 0.0331 - val_accuracy: 0.8878\n",
      "Epoch 118/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.8610\n",
      "Epoch 118: val_accuracy did not improve from 0.89919\n",
      "14/14 [==============================] - 5s 327ms/step - loss: 0.0164 - accuracy: 0.8610 - val_loss: 0.0346 - val_accuracy: 0.8971\n",
      "Epoch 119/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.8620\n",
      "Epoch 119: val_accuracy did not improve from 0.89919\n",
      "14/14 [==============================] - 5s 328ms/step - loss: 0.0160 - accuracy: 0.8620 - val_loss: 0.0346 - val_accuracy: 0.8938\n",
      "Epoch 120/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.8628\n",
      "Epoch 120: val_accuracy did not improve from 0.89919\n",
      "14/14 [==============================] - 5s 327ms/step - loss: 0.0160 - accuracy: 0.8628 - val_loss: 0.0377 - val_accuracy: 0.8798\n",
      "Epoch 121/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.8650\n",
      "Epoch 121: val_accuracy did not improve from 0.89919\n",
      "14/14 [==============================] - 5s 329ms/step - loss: 0.0154 - accuracy: 0.8650 - val_loss: 0.0328 - val_accuracy: 0.8987\n",
      "Epoch 122/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.8554\n",
      "Epoch 122: val_accuracy improved from 0.89919 to 0.90023, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 377ms/step - loss: 0.0165 - accuracy: 0.8554 - val_loss: 0.0311 - val_accuracy: 0.9002\n",
      "Epoch 123/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.8568\n",
      "Epoch 123: val_accuracy did not improve from 0.90023\n",
      "14/14 [==============================] - 5s 330ms/step - loss: 0.0167 - accuracy: 0.8568 - val_loss: 0.0341 - val_accuracy: 0.8914\n",
      "Epoch 124/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.8658\n",
      "Epoch 124: val_accuracy did not improve from 0.90023\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0156 - accuracy: 0.8658 - val_loss: 0.0359 - val_accuracy: 0.8770\n",
      "Epoch 125/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.8675\n",
      "Epoch 125: val_accuracy did not improve from 0.90023\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0154 - accuracy: 0.8675 - val_loss: 0.0343 - val_accuracy: 0.8878\n",
      "Epoch 126/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.8675\n",
      "Epoch 126: val_accuracy did not improve from 0.90023\n",
      "14/14 [==============================] - 5s 337ms/step - loss: 0.0154 - accuracy: 0.8675 - val_loss: 0.0325 - val_accuracy: 0.8969\n",
      "Epoch 127/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.8703\n",
      "Epoch 127: val_accuracy did not improve from 0.90023\n",
      "14/14 [==============================] - 6s 449ms/step - loss: 0.0150 - accuracy: 0.8703 - val_loss: 0.0329 - val_accuracy: 0.8936\n",
      "Epoch 128/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.8709\n",
      "Epoch 128: val_accuracy did not improve from 0.90023\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0148 - accuracy: 0.8709 - val_loss: 0.0325 - val_accuracy: 0.8916\n",
      "Epoch 129/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.8717\n",
      "Epoch 129: val_accuracy did not improve from 0.90023\n",
      "14/14 [==============================] - 5s 327ms/step - loss: 0.0149 - accuracy: 0.8717 - val_loss: 0.0349 - val_accuracy: 0.8884\n",
      "Epoch 130/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.8760\n",
      "Epoch 130: val_accuracy did not improve from 0.90023\n",
      "14/14 [==============================] - 5s 337ms/step - loss: 0.0147 - accuracy: 0.8760 - val_loss: 0.0353 - val_accuracy: 0.8829\n",
      "Epoch 131/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.8740\n",
      "Epoch 131: val_accuracy did not improve from 0.90023\n",
      "14/14 [==============================] - 5s 338ms/step - loss: 0.0149 - accuracy: 0.8740 - val_loss: 0.0318 - val_accuracy: 0.8952\n",
      "Epoch 132/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.8733\n",
      "Epoch 132: val_accuracy improved from 0.90023 to 0.90334, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 379ms/step - loss: 0.0146 - accuracy: 0.8733 - val_loss: 0.0309 - val_accuracy: 0.9033\n",
      "Epoch 133/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.8723\n",
      "Epoch 133: val_accuracy did not improve from 0.90334\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0148 - accuracy: 0.8723 - val_loss: 0.0325 - val_accuracy: 0.8987\n",
      "Epoch 134/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.8733\n",
      "Epoch 134: val_accuracy did not improve from 0.90334\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0148 - accuracy: 0.8733 - val_loss: 0.0333 - val_accuracy: 0.8976\n",
      "Epoch 135/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.8728\n",
      "Epoch 135: val_accuracy did not improve from 0.90334\n",
      "14/14 [==============================] - 5s 328ms/step - loss: 0.0147 - accuracy: 0.8728 - val_loss: 0.0375 - val_accuracy: 0.8803\n",
      "Epoch 136/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.8723\n",
      "Epoch 136: val_accuracy did not improve from 0.90334\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0151 - accuracy: 0.8723 - val_loss: 0.0330 - val_accuracy: 0.8905\n",
      "Epoch 137/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.8751\n",
      "Epoch 137: val_accuracy did not improve from 0.90334\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0146 - accuracy: 0.8751 - val_loss: 0.0355 - val_accuracy: 0.8782\n",
      "Epoch 138/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.8737\n",
      "Epoch 138: val_accuracy did not improve from 0.90334\n",
      "14/14 [==============================] - 5s 327ms/step - loss: 0.0144 - accuracy: 0.8737 - val_loss: 0.0336 - val_accuracy: 0.8995\n",
      "Epoch 139/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.8769\n",
      "Epoch 139: val_accuracy did not improve from 0.90334\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0145 - accuracy: 0.8769 - val_loss: 0.0311 - val_accuracy: 0.9009\n",
      "Epoch 140/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.8701\n",
      "Epoch 140: val_accuracy did not improve from 0.90334\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0150 - accuracy: 0.8701 - val_loss: 0.0308 - val_accuracy: 0.9027\n",
      "Epoch 141/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.8716\n",
      "Epoch 141: val_accuracy did not improve from 0.90334\n",
      "14/14 [==============================] - 5s 330ms/step - loss: 0.0149 - accuracy: 0.8716 - val_loss: 0.0337 - val_accuracy: 0.9006\n",
      "Epoch 142/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.8747\n",
      "Epoch 142: val_accuracy did not improve from 0.90334\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0149 - accuracy: 0.8747 - val_loss: 0.0362 - val_accuracy: 0.8864\n",
      "Epoch 143/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.8756\n",
      "Epoch 143: val_accuracy did not improve from 0.90334\n",
      "14/14 [==============================] - 5s 341ms/step - loss: 0.0144 - accuracy: 0.8756 - val_loss: 0.0312 - val_accuracy: 0.9027\n",
      "Epoch 144/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.8732\n",
      "Epoch 144: val_accuracy did not improve from 0.90334\n",
      "14/14 [==============================] - 6s 441ms/step - loss: 0.0146 - accuracy: 0.8732 - val_loss: 0.0319 - val_accuracy: 0.9011\n",
      "Epoch 145/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.8801\n",
      "Epoch 145: val_accuracy did not improve from 0.90334\n",
      "14/14 [==============================] - 5s 337ms/step - loss: 0.0141 - accuracy: 0.8801 - val_loss: 0.0313 - val_accuracy: 0.9011\n",
      "Epoch 146/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.8773\n",
      "Epoch 146: val_accuracy did not improve from 0.90334\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0141 - accuracy: 0.8773 - val_loss: 0.0305 - val_accuracy: 0.9021\n",
      "Epoch 147/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.8786\n",
      "Epoch 147: val_accuracy did not improve from 0.90334\n",
      "14/14 [==============================] - 5s 326ms/step - loss: 0.0142 - accuracy: 0.8786 - val_loss: 0.0313 - val_accuracy: 0.8990\n",
      "Epoch 148/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.8828\n",
      "Epoch 148: val_accuracy did not improve from 0.90334\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0138 - accuracy: 0.8828 - val_loss: 0.0311 - val_accuracy: 0.8969\n",
      "Epoch 149/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.8819\n",
      "Epoch 149: val_accuracy improved from 0.90334 to 0.90577, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 383ms/step - loss: 0.0138 - accuracy: 0.8819 - val_loss: 0.0301 - val_accuracy: 0.9058\n",
      "Epoch 150/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.8850\n",
      "Epoch 150: val_accuracy did not improve from 0.90577\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0134 - accuracy: 0.8850 - val_loss: 0.0329 - val_accuracy: 0.8926\n",
      "Epoch 151/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.8815\n",
      "Epoch 151: val_accuracy did not improve from 0.90577\n",
      "14/14 [==============================] - 5s 329ms/step - loss: 0.0136 - accuracy: 0.8815 - val_loss: 0.0311 - val_accuracy: 0.8997\n",
      "Epoch 152/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.8825\n",
      "Epoch 152: val_accuracy did not improve from 0.90577\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0139 - accuracy: 0.8825 - val_loss: 0.0319 - val_accuracy: 0.9004\n",
      "Epoch 153/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.8855\n",
      "Epoch 153: val_accuracy did not improve from 0.90577\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0138 - accuracy: 0.8855 - val_loss: 0.0303 - val_accuracy: 0.9037\n",
      "Epoch 154/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.8857\n",
      "Epoch 154: val_accuracy did not improve from 0.90577\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0137 - accuracy: 0.8857 - val_loss: 0.0324 - val_accuracy: 0.8938\n",
      "Epoch 155/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.8797\n",
      "Epoch 155: val_accuracy did not improve from 0.90577\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0139 - accuracy: 0.8797 - val_loss: 0.0305 - val_accuracy: 0.9007\n",
      "Epoch 156/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.8840\n",
      "Epoch 156: val_accuracy did not improve from 0.90577\n",
      "14/14 [==============================] - 5s 329ms/step - loss: 0.0135 - accuracy: 0.8840 - val_loss: 0.0347 - val_accuracy: 0.8807\n",
      "Epoch 157/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.8796\n",
      "Epoch 157: val_accuracy did not improve from 0.90577\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0142 - accuracy: 0.8796 - val_loss: 0.0373 - val_accuracy: 0.8826\n",
      "Epoch 158/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.8812\n",
      "Epoch 158: val_accuracy did not improve from 0.90577\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0139 - accuracy: 0.8812 - val_loss: 0.0313 - val_accuracy: 0.8952\n",
      "Epoch 159/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.8831\n",
      "Epoch 159: val_accuracy improved from 0.90577 to 0.90785, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 373ms/step - loss: 0.0134 - accuracy: 0.8831 - val_loss: 0.0291 - val_accuracy: 0.9078\n",
      "Epoch 160/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.8838\n",
      "Epoch 160: val_accuracy did not improve from 0.90785\n",
      "14/14 [==============================] - 6s 397ms/step - loss: 0.0134 - accuracy: 0.8838 - val_loss: 0.0300 - val_accuracy: 0.9072\n",
      "Epoch 161/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.8844\n",
      "Epoch 161: val_accuracy did not improve from 0.90785\n",
      "14/14 [==============================] - 5s 363ms/step - loss: 0.0135 - accuracy: 0.8844 - val_loss: 0.0299 - val_accuracy: 0.9014\n",
      "Epoch 162/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.8902\n",
      "Epoch 162: val_accuracy did not improve from 0.90785\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0129 - accuracy: 0.8902 - val_loss: 0.0310 - val_accuracy: 0.9013\n",
      "Epoch 163/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.8893\n",
      "Epoch 163: val_accuracy did not improve from 0.90785\n",
      "14/14 [==============================] - 5s 327ms/step - loss: 0.0130 - accuracy: 0.8893 - val_loss: 0.0319 - val_accuracy: 0.8964\n",
      "Epoch 164/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.8887\n",
      "Epoch 164: val_accuracy did not improve from 0.90785\n",
      "14/14 [==============================] - 5s 330ms/step - loss: 0.0132 - accuracy: 0.8887 - val_loss: 0.0310 - val_accuracy: 0.8945\n",
      "Epoch 165/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.8907\n",
      "Epoch 165: val_accuracy improved from 0.90785 to 0.90837, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 392ms/step - loss: 0.0130 - accuracy: 0.8907 - val_loss: 0.0304 - val_accuracy: 0.9084\n",
      "Epoch 166/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.8870\n",
      "Epoch 166: val_accuracy did not improve from 0.90837\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0134 - accuracy: 0.8870 - val_loss: 0.0290 - val_accuracy: 0.9040\n",
      "Epoch 167/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.8902\n",
      "Epoch 167: val_accuracy did not improve from 0.90837\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0128 - accuracy: 0.8902 - val_loss: 0.0312 - val_accuracy: 0.8961\n",
      "Epoch 168/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.8900\n",
      "Epoch 168: val_accuracy did not improve from 0.90837\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0129 - accuracy: 0.8900 - val_loss: 0.0356 - val_accuracy: 0.8862\n",
      "Epoch 169/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.8913\n",
      "Epoch 169: val_accuracy did not improve from 0.90837\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0127 - accuracy: 0.8913 - val_loss: 0.0293 - val_accuracy: 0.9013\n",
      "Epoch 170/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.8894\n",
      "Epoch 170: val_accuracy did not improve from 0.90837\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0129 - accuracy: 0.8894 - val_loss: 0.0294 - val_accuracy: 0.9028\n",
      "Epoch 171/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.8897\n",
      "Epoch 171: val_accuracy did not improve from 0.90837\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0133 - accuracy: 0.8897 - val_loss: 0.0311 - val_accuracy: 0.9020\n",
      "Epoch 172/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.8872\n",
      "Epoch 172: val_accuracy did not improve from 0.90837\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0135 - accuracy: 0.8872 - val_loss: 0.0316 - val_accuracy: 0.8981\n",
      "Epoch 173/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.8885\n",
      "Epoch 173: val_accuracy did not improve from 0.90837\n",
      "14/14 [==============================] - 5s 330ms/step - loss: 0.0127 - accuracy: 0.8885 - val_loss: 0.0301 - val_accuracy: 0.8994\n",
      "Epoch 174/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.8916\n",
      "Epoch 174: val_accuracy improved from 0.90837 to 0.90889, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 382ms/step - loss: 0.0126 - accuracy: 0.8916 - val_loss: 0.0286 - val_accuracy: 0.9089\n",
      "Epoch 175/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.8947\n",
      "Epoch 175: val_accuracy did not improve from 0.90889\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0124 - accuracy: 0.8947 - val_loss: 0.0308 - val_accuracy: 0.9063\n",
      "Epoch 176/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.8923\n",
      "Epoch 176: val_accuracy did not improve from 0.90889\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0129 - accuracy: 0.8923 - val_loss: 0.0346 - val_accuracy: 0.8855\n",
      "Epoch 177/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.8861\n",
      "Epoch 177: val_accuracy did not improve from 0.90889\n",
      "14/14 [==============================] - 6s 447ms/step - loss: 0.0135 - accuracy: 0.8861 - val_loss: 0.0330 - val_accuracy: 0.8902\n",
      "Epoch 178/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.8881\n",
      "Epoch 178: val_accuracy did not improve from 0.90889\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0130 - accuracy: 0.8881 - val_loss: 0.0337 - val_accuracy: 0.8994\n",
      "Epoch 179/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.8927\n",
      "Epoch 179: val_accuracy did not improve from 0.90889\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0126 - accuracy: 0.8927 - val_loss: 0.0319 - val_accuracy: 0.9002\n",
      "Epoch 180/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.8945\n",
      "Epoch 180: val_accuracy did not improve from 0.90889\n",
      "14/14 [==============================] - 5s 340ms/step - loss: 0.0125 - accuracy: 0.8945 - val_loss: 0.0292 - val_accuracy: 0.9082\n",
      "Epoch 181/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.8998\n",
      "Epoch 181: val_accuracy improved from 0.90889 to 0.91426, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 381ms/step - loss: 0.0119 - accuracy: 0.8998 - val_loss: 0.0279 - val_accuracy: 0.9143\n",
      "Epoch 182/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.8979\n",
      "Epoch 182: val_accuracy did not improve from 0.91426\n",
      "14/14 [==============================] - 5s 338ms/step - loss: 0.0119 - accuracy: 0.8979 - val_loss: 0.0283 - val_accuracy: 0.9134\n",
      "Epoch 183/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9005\n",
      "Epoch 183: val_accuracy did not improve from 0.91426\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0117 - accuracy: 0.9005 - val_loss: 0.0317 - val_accuracy: 0.9077\n",
      "Epoch 184/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9011\n",
      "Epoch 184: val_accuracy did not improve from 0.91426\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0122 - accuracy: 0.9011 - val_loss: 0.0282 - val_accuracy: 0.9127\n",
      "Epoch 185/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.8884\n",
      "Epoch 185: val_accuracy did not improve from 0.91426\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0133 - accuracy: 0.8884 - val_loss: 0.0328 - val_accuracy: 0.8938\n",
      "Epoch 186/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.8937\n",
      "Epoch 186: val_accuracy did not improve from 0.91426\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0126 - accuracy: 0.8937 - val_loss: 0.0313 - val_accuracy: 0.9059\n",
      "Epoch 187/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.8958\n",
      "Epoch 187: val_accuracy did not improve from 0.91426\n",
      "14/14 [==============================] - 5s 338ms/step - loss: 0.0125 - accuracy: 0.8958 - val_loss: 0.0279 - val_accuracy: 0.9099\n",
      "Epoch 188/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.8952\n",
      "Epoch 188: val_accuracy did not improve from 0.91426\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0125 - accuracy: 0.8952 - val_loss: 0.0326 - val_accuracy: 0.8886\n",
      "Epoch 189/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.8962\n",
      "Epoch 189: val_accuracy did not improve from 0.91426\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0126 - accuracy: 0.8962 - val_loss: 0.0288 - val_accuracy: 0.9056\n",
      "Epoch 190/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.8958\n",
      "Epoch 190: val_accuracy did not improve from 0.91426\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0123 - accuracy: 0.8958 - val_loss: 0.0277 - val_accuracy: 0.9063\n",
      "Epoch 191/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9015\n",
      "Epoch 191: val_accuracy did not improve from 0.91426\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0120 - accuracy: 0.9015 - val_loss: 0.0286 - val_accuracy: 0.9139\n",
      "Epoch 192/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.8913\n",
      "Epoch 192: val_accuracy did not improve from 0.91426\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0127 - accuracy: 0.8913 - val_loss: 0.0290 - val_accuracy: 0.9136\n",
      "Epoch 193/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.8987\n",
      "Epoch 193: val_accuracy improved from 0.91426 to 0.91963, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 6s 402ms/step - loss: 0.0121 - accuracy: 0.8987 - val_loss: 0.0318 - val_accuracy: 0.9196\n",
      "Epoch 194/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.8981\n",
      "Epoch 194: val_accuracy improved from 0.91963 to 0.92240, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 6s 401ms/step - loss: 0.0127 - accuracy: 0.8981 - val_loss: 0.0284 - val_accuracy: 0.9224\n",
      "Epoch 195/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.8944\n",
      "Epoch 195: val_accuracy did not improve from 0.92240\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0124 - accuracy: 0.8944 - val_loss: 0.0283 - val_accuracy: 0.9139\n",
      "Epoch 196/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.8970\n",
      "Epoch 196: val_accuracy did not improve from 0.92240\n",
      "14/14 [==============================] - 5s 337ms/step - loss: 0.0122 - accuracy: 0.8970 - val_loss: 0.0319 - val_accuracy: 0.8942\n",
      "Epoch 197/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.8995\n",
      "Epoch 197: val_accuracy did not improve from 0.92240\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0119 - accuracy: 0.8995 - val_loss: 0.0296 - val_accuracy: 0.9092\n",
      "Epoch 198/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9051\n",
      "Epoch 198: val_accuracy did not improve from 0.92240\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0116 - accuracy: 0.9051 - val_loss: 0.0284 - val_accuracy: 0.9028\n",
      "Epoch 199/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9035\n",
      "Epoch 199: val_accuracy did not improve from 0.92240\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0116 - accuracy: 0.9035 - val_loss: 0.0290 - val_accuracy: 0.9078\n",
      "Epoch 200/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9107\n",
      "Epoch 200: val_accuracy did not improve from 0.92240\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0110 - accuracy: 0.9107 - val_loss: 0.0295 - val_accuracy: 0.9018\n",
      "Epoch 201/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.8995\n",
      "Epoch 201: val_accuracy did not improve from 0.92240\n",
      "14/14 [==============================] - 5s 339ms/step - loss: 0.0120 - accuracy: 0.8995 - val_loss: 0.0337 - val_accuracy: 0.9193\n",
      "Epoch 202/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9066\n",
      "Epoch 202: val_accuracy improved from 0.92240 to 0.92638, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 390ms/step - loss: 0.0114 - accuracy: 0.9066 - val_loss: 0.0268 - val_accuracy: 0.9264\n",
      "Epoch 203/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9030\n",
      "Epoch 203: val_accuracy did not improve from 0.92638\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0120 - accuracy: 0.9030 - val_loss: 0.0337 - val_accuracy: 0.8928\n",
      "Epoch 204/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.8940\n",
      "Epoch 204: val_accuracy did not improve from 0.92638\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0131 - accuracy: 0.8940 - val_loss: 0.0277 - val_accuracy: 0.9106\n",
      "Epoch 205/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9008\n",
      "Epoch 205: val_accuracy did not improve from 0.92638\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0118 - accuracy: 0.9008 - val_loss: 0.0268 - val_accuracy: 0.9245\n",
      "Epoch 206/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9031\n",
      "Epoch 206: val_accuracy did not improve from 0.92638\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0117 - accuracy: 0.9031 - val_loss: 0.0316 - val_accuracy: 0.9198\n",
      "Epoch 207/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.8952\n",
      "Epoch 207: val_accuracy did not improve from 0.92638\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0127 - accuracy: 0.8952 - val_loss: 0.0344 - val_accuracy: 0.9091\n",
      "Epoch 208/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9062\n",
      "Epoch 208: val_accuracy did not improve from 0.92638\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0116 - accuracy: 0.9062 - val_loss: 0.0299 - val_accuracy: 0.9094\n",
      "Epoch 209/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9087\n",
      "Epoch 209: val_accuracy did not improve from 0.92638\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0111 - accuracy: 0.9087 - val_loss: 0.0316 - val_accuracy: 0.9169\n",
      "Epoch 210/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9140\n",
      "Epoch 210: val_accuracy did not improve from 0.92638\n",
      "14/14 [==============================] - 6s 440ms/step - loss: 0.0106 - accuracy: 0.9140 - val_loss: 0.0290 - val_accuracy: 0.9070\n",
      "Epoch 211/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9161\n",
      "Epoch 211: val_accuracy did not improve from 0.92638\n",
      "14/14 [==============================] - 5s 328ms/step - loss: 0.0106 - accuracy: 0.9161 - val_loss: 0.0266 - val_accuracy: 0.9148\n",
      "Epoch 212/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9139\n",
      "Epoch 212: val_accuracy did not improve from 0.92638\n",
      "14/14 [==============================] - 5s 337ms/step - loss: 0.0104 - accuracy: 0.9139 - val_loss: 0.0291 - val_accuracy: 0.9245\n",
      "Epoch 213/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9054\n",
      "Epoch 213: val_accuracy improved from 0.92638 to 0.92846, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 384ms/step - loss: 0.0117 - accuracy: 0.9054 - val_loss: 0.0275 - val_accuracy: 0.9285\n",
      "Epoch 214/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9098\n",
      "Epoch 214: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0114 - accuracy: 0.9098 - val_loss: 0.0303 - val_accuracy: 0.9158\n",
      "Epoch 215/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9051\n",
      "Epoch 215: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 340ms/step - loss: 0.0115 - accuracy: 0.9051 - val_loss: 0.0286 - val_accuracy: 0.9124\n",
      "Epoch 216/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9122\n",
      "Epoch 216: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0110 - accuracy: 0.9122 - val_loss: 0.0274 - val_accuracy: 0.9264\n",
      "Epoch 217/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9081\n",
      "Epoch 217: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0113 - accuracy: 0.9081 - val_loss: 0.0267 - val_accuracy: 0.9175\n",
      "Epoch 218/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9164\n",
      "Epoch 218: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 338ms/step - loss: 0.0104 - accuracy: 0.9164 - val_loss: 0.0283 - val_accuracy: 0.9233\n",
      "Epoch 219/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9076\n",
      "Epoch 219: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0111 - accuracy: 0.9076 - val_loss: 0.0305 - val_accuracy: 0.9099\n",
      "Epoch 220/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9141\n",
      "Epoch 220: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0107 - accuracy: 0.9141 - val_loss: 0.0267 - val_accuracy: 0.9207\n",
      "Epoch 221/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9179\n",
      "Epoch 221: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0103 - accuracy: 0.9179 - val_loss: 0.0273 - val_accuracy: 0.9158\n",
      "Epoch 222/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9137\n",
      "Epoch 222: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0107 - accuracy: 0.9137 - val_loss: 0.0589 - val_accuracy: 0.8687\n",
      "Epoch 223/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.8747\n",
      "Epoch 223: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0151 - accuracy: 0.8747 - val_loss: 0.0292 - val_accuracy: 0.9089\n",
      "Epoch 224/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.8885\n",
      "Epoch 224: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0136 - accuracy: 0.8885 - val_loss: 0.0330 - val_accuracy: 0.9181\n",
      "Epoch 225/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.8979\n",
      "Epoch 225: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0128 - accuracy: 0.8979 - val_loss: 0.0431 - val_accuracy: 0.8613\n",
      "Epoch 226/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.8891\n",
      "Epoch 226: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 338ms/step - loss: 0.0131 - accuracy: 0.8891 - val_loss: 0.0307 - val_accuracy: 0.9167\n",
      "Epoch 227/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9049\n",
      "Epoch 227: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 6s 454ms/step - loss: 0.0117 - accuracy: 0.9049 - val_loss: 0.0274 - val_accuracy: 0.9224\n",
      "Epoch 228/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9083\n",
      "Epoch 228: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 338ms/step - loss: 0.0115 - accuracy: 0.9083 - val_loss: 0.0335 - val_accuracy: 0.8935\n",
      "Epoch 229/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9114\n",
      "Epoch 229: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0110 - accuracy: 0.9114 - val_loss: 0.0252 - val_accuracy: 0.9262\n",
      "Epoch 230/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9108\n",
      "Epoch 230: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0112 - accuracy: 0.9108 - val_loss: 0.0438 - val_accuracy: 0.8706\n",
      "Epoch 231/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.8853\n",
      "Epoch 231: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0140 - accuracy: 0.8853 - val_loss: 0.0269 - val_accuracy: 0.9075\n",
      "Epoch 232/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9053\n",
      "Epoch 232: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 339ms/step - loss: 0.0115 - accuracy: 0.9053 - val_loss: 0.0265 - val_accuracy: 0.9201\n",
      "Epoch 233/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9149\n",
      "Epoch 233: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 337ms/step - loss: 0.0105 - accuracy: 0.9149 - val_loss: 0.0264 - val_accuracy: 0.9266\n",
      "Epoch 234/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9173\n",
      "Epoch 234: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0103 - accuracy: 0.9173 - val_loss: 0.0238 - val_accuracy: 0.9271\n",
      "Epoch 235/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9178\n",
      "Epoch 235: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 337ms/step - loss: 0.0104 - accuracy: 0.9178 - val_loss: 0.0267 - val_accuracy: 0.9134\n",
      "Epoch 236/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9207\n",
      "Epoch 236: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0098 - accuracy: 0.9207 - val_loss: 0.0300 - val_accuracy: 0.9096\n",
      "Epoch 237/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9125\n",
      "Epoch 237: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 332ms/step - loss: 0.0106 - accuracy: 0.9125 - val_loss: 0.0300 - val_accuracy: 0.9255\n",
      "Epoch 238/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9147\n",
      "Epoch 238: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0106 - accuracy: 0.9147 - val_loss: 0.0267 - val_accuracy: 0.9205\n",
      "Epoch 239/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9218\n",
      "Epoch 239: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0102 - accuracy: 0.9218 - val_loss: 0.0263 - val_accuracy: 0.9141\n",
      "Epoch 240/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9172\n",
      "Epoch 240: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0103 - accuracy: 0.9172 - val_loss: 0.0275 - val_accuracy: 0.9170\n",
      "Epoch 241/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9247\n",
      "Epoch 241: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0097 - accuracy: 0.9247 - val_loss: 0.0330 - val_accuracy: 0.9120\n",
      "Epoch 242/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9277\n",
      "Epoch 242: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0096 - accuracy: 0.9277 - val_loss: 0.0360 - val_accuracy: 0.8954\n",
      "Epoch 243/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9205\n",
      "Epoch 243: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0103 - accuracy: 0.9205 - val_loss: 0.0265 - val_accuracy: 0.9203\n",
      "Epoch 244/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9221\n",
      "Epoch 244: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 6s 441ms/step - loss: 0.0100 - accuracy: 0.9221 - val_loss: 0.0253 - val_accuracy: 0.9253\n",
      "Epoch 245/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9253\n",
      "Epoch 245: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0096 - accuracy: 0.9253 - val_loss: 0.0259 - val_accuracy: 0.9207\n",
      "Epoch 246/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9284\n",
      "Epoch 246: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 337ms/step - loss: 0.0094 - accuracy: 0.9284 - val_loss: 0.0272 - val_accuracy: 0.9227\n",
      "Epoch 247/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9253\n",
      "Epoch 247: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0098 - accuracy: 0.9253 - val_loss: 0.0288 - val_accuracy: 0.9207\n",
      "Epoch 248/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9290\n",
      "Epoch 248: val_accuracy did not improve from 0.92846\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0094 - accuracy: 0.9290 - val_loss: 0.0280 - val_accuracy: 0.9214\n",
      "Epoch 249/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9287\n",
      "Epoch 249: val_accuracy improved from 0.92846 to 0.93037, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\n",
      "14/14 [==============================] - 5s 386ms/step - loss: 0.0094 - accuracy: 0.9287 - val_loss: 0.0263 - val_accuracy: 0.9304\n",
      "Epoch 250/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9261\n",
      "Epoch 250: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 337ms/step - loss: 0.0095 - accuracy: 0.9261 - val_loss: 0.0259 - val_accuracy: 0.9217\n",
      "Epoch 251/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9265\n",
      "Epoch 251: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 337ms/step - loss: 0.0096 - accuracy: 0.9265 - val_loss: 0.0308 - val_accuracy: 0.9136\n",
      "Epoch 252/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9296\n",
      "Epoch 252: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0093 - accuracy: 0.9296 - val_loss: 0.0253 - val_accuracy: 0.9205\n",
      "Epoch 253/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9274\n",
      "Epoch 253: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0095 - accuracy: 0.9274 - val_loss: 0.0310 - val_accuracy: 0.9122\n",
      "Epoch 254/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9284\n",
      "Epoch 254: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0092 - accuracy: 0.9284 - val_loss: 0.0296 - val_accuracy: 0.9167\n",
      "Epoch 255/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9314\n",
      "Epoch 255: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 337ms/step - loss: 0.0091 - accuracy: 0.9314 - val_loss: 0.0288 - val_accuracy: 0.9132\n",
      "Epoch 256/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 0.9257\n",
      "Epoch 256: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0095 - accuracy: 0.9257 - val_loss: 0.0327 - val_accuracy: 0.9125\n",
      "Epoch 257/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9308\n",
      "Epoch 257: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0088 - accuracy: 0.9308 - val_loss: 0.0319 - val_accuracy: 0.9054\n",
      "Epoch 258/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9357\n",
      "Epoch 258: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0087 - accuracy: 0.9357 - val_loss: 0.0291 - val_accuracy: 0.9177\n",
      "Epoch 259/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9331\n",
      "Epoch 259: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0088 - accuracy: 0.9331 - val_loss: 0.0269 - val_accuracy: 0.9120\n",
      "Epoch 260/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9338\n",
      "Epoch 260: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0086 - accuracy: 0.9338 - val_loss: 0.0285 - val_accuracy: 0.9259\n",
      "Epoch 261/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9325\n",
      "Epoch 261: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 6s 450ms/step - loss: 0.0091 - accuracy: 0.9325 - val_loss: 0.0303 - val_accuracy: 0.9186\n",
      "Epoch 262/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9306\n",
      "Epoch 262: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0094 - accuracy: 0.9306 - val_loss: 0.0262 - val_accuracy: 0.9195\n",
      "Epoch 263/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9346\n",
      "Epoch 263: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 337ms/step - loss: 0.0089 - accuracy: 0.9346 - val_loss: 0.0338 - val_accuracy: 0.9042\n",
      "Epoch 264/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9336\n",
      "Epoch 264: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0088 - accuracy: 0.9336 - val_loss: 0.0263 - val_accuracy: 0.9234\n",
      "Epoch 265/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9365\n",
      "Epoch 265: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0086 - accuracy: 0.9365 - val_loss: 0.0291 - val_accuracy: 0.9139\n",
      "Epoch 266/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9337\n",
      "Epoch 266: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 345ms/step - loss: 0.0089 - accuracy: 0.9337 - val_loss: 0.0346 - val_accuracy: 0.9027\n",
      "Epoch 267/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9332\n",
      "Epoch 267: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0091 - accuracy: 0.9332 - val_loss: 0.0273 - val_accuracy: 0.9163\n",
      "Epoch 268/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9341\n",
      "Epoch 268: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 333ms/step - loss: 0.0087 - accuracy: 0.9341 - val_loss: 0.0328 - val_accuracy: 0.9125\n",
      "Epoch 269/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9324\n",
      "Epoch 269: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 338ms/step - loss: 0.0090 - accuracy: 0.9324 - val_loss: 0.0293 - val_accuracy: 0.9203\n",
      "Epoch 270/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9394\n",
      "Epoch 270: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 339ms/step - loss: 0.0085 - accuracy: 0.9394 - val_loss: 0.0273 - val_accuracy: 0.9207\n",
      "Epoch 271/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9360\n",
      "Epoch 271: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 340ms/step - loss: 0.0086 - accuracy: 0.9360 - val_loss: 0.0317 - val_accuracy: 0.9153\n",
      "Epoch 272/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9375\n",
      "Epoch 272: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0082 - accuracy: 0.9375 - val_loss: 0.0296 - val_accuracy: 0.9058\n",
      "Epoch 273/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9398\n",
      "Epoch 273: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 331ms/step - loss: 0.0082 - accuracy: 0.9398 - val_loss: 0.0281 - val_accuracy: 0.9207\n",
      "Epoch 274/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9408\n",
      "Epoch 274: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0082 - accuracy: 0.9408 - val_loss: 0.0304 - val_accuracy: 0.9052\n",
      "Epoch 275/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9414\n",
      "Epoch 275: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 330ms/step - loss: 0.0080 - accuracy: 0.9414 - val_loss: 0.0296 - val_accuracy: 0.9046\n",
      "Epoch 276/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9394\n",
      "Epoch 276: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0084 - accuracy: 0.9394 - val_loss: 0.0308 - val_accuracy: 0.9132\n",
      "Epoch 277/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9390\n",
      "Epoch 277: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 337ms/step - loss: 0.0083 - accuracy: 0.9390 - val_loss: 0.0279 - val_accuracy: 0.9200\n",
      "Epoch 278/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9441\n",
      "Epoch 278: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 6s 450ms/step - loss: 0.0080 - accuracy: 0.9441 - val_loss: 0.0289 - val_accuracy: 0.9158\n",
      "Epoch 279/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9450\n",
      "Epoch 279: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 338ms/step - loss: 0.0076 - accuracy: 0.9450 - val_loss: 0.0310 - val_accuracy: 0.9163\n",
      "Epoch 280/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9373\n",
      "Epoch 280: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 337ms/step - loss: 0.0085 - accuracy: 0.9373 - val_loss: 0.0306 - val_accuracy: 0.9136\n",
      "Epoch 281/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9383\n",
      "Epoch 281: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0087 - accuracy: 0.9383 - val_loss: 0.0316 - val_accuracy: 0.9122\n",
      "Epoch 282/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9401\n",
      "Epoch 282: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 341ms/step - loss: 0.0082 - accuracy: 0.9401 - val_loss: 0.0287 - val_accuracy: 0.9163\n",
      "Epoch 283/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9425\n",
      "Epoch 283: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 340ms/step - loss: 0.0078 - accuracy: 0.9425 - val_loss: 0.0308 - val_accuracy: 0.9098\n",
      "Epoch 284/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9457\n",
      "Epoch 284: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 337ms/step - loss: 0.0075 - accuracy: 0.9457 - val_loss: 0.0271 - val_accuracy: 0.9127\n",
      "Epoch 285/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9394\n",
      "Epoch 285: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0084 - accuracy: 0.9394 - val_loss: 0.0280 - val_accuracy: 0.9124\n",
      "Epoch 286/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9382\n",
      "Epoch 286: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0086 - accuracy: 0.9382 - val_loss: 0.0437 - val_accuracy: 0.9160\n",
      "Epoch 287/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9199\n",
      "Epoch 287: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0112 - accuracy: 0.9199 - val_loss: 0.0282 - val_accuracy: 0.9124\n",
      "Epoch 288/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9127\n",
      "Epoch 288: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 338ms/step - loss: 0.0111 - accuracy: 0.9127 - val_loss: 0.0341 - val_accuracy: 0.9018\n",
      "Epoch 289/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9057\n",
      "Epoch 289: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 342ms/step - loss: 0.0124 - accuracy: 0.9057 - val_loss: 0.0322 - val_accuracy: 0.9163\n",
      "Epoch 290/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9254\n",
      "Epoch 290: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0098 - accuracy: 0.9254 - val_loss: 0.0293 - val_accuracy: 0.9143\n",
      "Epoch 291/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9363\n",
      "Epoch 291: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 336ms/step - loss: 0.0087 - accuracy: 0.9363 - val_loss: 0.0259 - val_accuracy: 0.9266\n",
      "Epoch 292/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9415\n",
      "Epoch 292: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 334ms/step - loss: 0.0081 - accuracy: 0.9415 - val_loss: 0.0307 - val_accuracy: 0.9021\n",
      "Epoch 293/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9400\n",
      "Epoch 293: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0084 - accuracy: 0.9400 - val_loss: 0.0437 - val_accuracy: 0.8864\n",
      "Epoch 294/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9326\n",
      "Epoch 294: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 337ms/step - loss: 0.0091 - accuracy: 0.9326 - val_loss: 0.0282 - val_accuracy: 0.9087\n",
      "Epoch 295/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9382\n",
      "Epoch 295: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 6s 450ms/step - loss: 0.0085 - accuracy: 0.9382 - val_loss: 0.0325 - val_accuracy: 0.9104\n",
      "Epoch 296/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9405\n",
      "Epoch 296: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 343ms/step - loss: 0.0080 - accuracy: 0.9405 - val_loss: 0.0352 - val_accuracy: 0.9065\n",
      "Epoch 297/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9449\n",
      "Epoch 297: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 335ms/step - loss: 0.0078 - accuracy: 0.9449 - val_loss: 0.0320 - val_accuracy: 0.9098\n",
      "Epoch 298/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9381\n",
      "Epoch 298: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 339ms/step - loss: 0.0084 - accuracy: 0.9381 - val_loss: 0.0279 - val_accuracy: 0.9129\n",
      "Epoch 299/500\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9335Restoring model weights from the end of the best epoch: 249.\n",
      "\n",
      "Epoch 299: val_accuracy did not improve from 0.93037\n",
      "14/14 [==============================] - 5s 340ms/step - loss: 0.0090 - accuracy: 0.9335 - val_loss: 0.0356 - val_accuracy: 0.9092\n",
      "Epoch 299: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "history=classifier.fit([X_train,X_train_f], y_train1, epochs = 500, batch_size = 64,validation_data=([X_test,X_test_f],y_test1),callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9oZOnVixSQPq",
    "outputId": "f653af95-6547-405b-871a-bab53d003944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0263 - accuracy: 0.9304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.026278190314769745, 0.9303655028343201]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate([X_test,X_test_f],y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "k7oqU_taStd_",
    "outputId": "9cf9f354-aa9c-4967-cff4-32ebe6938034"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def display_learning_curves(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    ax1.plot(history.history[\"loss\"])\n",
    "    ax1.plot(history.history[\"val_loss\"])\n",
    "    ax1.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "    ax2.plot(history.history[\"accuracy\"])\n",
    "    ax2.plot(history.history[\"val_accuracy\"])\n",
    "    ax2.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "display_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-gaSl__OS0Yg"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "temp=tf.keras.models.load_model(\"./drive/MyDrive/MSc Thesis/Experiments/models/Transformer_1d_freq_exp2_exp5_v8.h5\",\n",
    "                                custom_objects={'TransformerEncoder': keras_nlp.layers.TransformerEncoder(intermediate_dim=64, num_heads=4,dropout=0.1),\n",
    "                                                'out_adj_mat':out_adj_mat()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51TR2BIrUT-u",
    "outputId": "36309eb4-60f0-41c0-b09d-fa0f8f828f16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 22s 58ms/step - loss: 0.0263 - accuracy: 0.9304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.026278188452124596, 0.9303655028343201]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.evaluate([X_test,X_test_f], y_test1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "2a16328562f14bdd9e9561b5e47b56ee",
      "a6dbb58efa7441ddbce7527757918ce0",
      "7adfd2b51cb048c782a9defe26be3ba1",
      "ac977f6e091c4bc2bda6621c7cef54ba",
      "f8d65d474510491190b7c3ff4ce85399",
      "2253d14ee92b46ee951805ebf2d180ab",
      "7e133e50d5ed409daa67f166ce0543d4",
      "88e682d9f19144b9a7290d728db64136",
      "ad39ae9b17cb4e2ea65668c21201e5fe",
      "b90df567666a4fd6bb39a9fe2f80023d",
      "25608c56253a445dbb6b670482357fb3"
     ]
    },
    "id": "ZNBIwk1vZArd",
    "outputId": "679c752a-f1ed-4c96-c759-7d5d2835932b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a16328562f14bdd9e9561b5e47b56ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "true=[]\n",
    "pred=[]\n",
    "for i in tqdm(range(len(y_test1))):\n",
    "  result=temp([X_test[i:i+1],X_test_f[i:i+1]])\n",
    "  true=true+list(y_test1[i,:,0][result._keras_mask[0,:]])\n",
    "  temp_pred=np.array(result[result._keras_mask][:,0])\n",
    "  temp_pred[temp_pred>=0]=1\n",
    "  temp_pred[temp_pred<0]=0\n",
    "  pred=pred+list(temp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m3sALEoJbqYl"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tM1r9eFUbybo",
    "outputId": "649a2e0e-d715-4b9b-a742-f2715ce36e95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3933,  445],\n",
       "       [  35, 1360]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(true,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1Hh9Js3bz6T",
    "outputId": "fcc53ace-c8af-4611-8664-41cfe8f345dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9168543218430625"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(true,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQAefs8Nb1kF",
    "outputId": "6c39cbb6-41ee-47c3-db76-b42ee0471ac5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(true,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7uL1RGcKb3No",
    "outputId": "1e8f6556-9433-4544-8511-f021223cce99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      4378\n",
      "           1       0.75      0.97      0.85      1395\n",
      "\n",
      "    accuracy                           0.92      5773\n",
      "   macro avg       0.87      0.94      0.90      5773\n",
      "weighted avg       0.93      0.92      0.92      5773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMITRwASY1nB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3 Layer_Dropout10_numhead4_Transformer_1d_freq_exp2_exp5.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2253d14ee92b46ee951805ebf2d180ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25608c56253a445dbb6b670482357fb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a16328562f14bdd9e9561b5e47b56ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a6dbb58efa7441ddbce7527757918ce0",
       "IPY_MODEL_7adfd2b51cb048c782a9defe26be3ba1",
       "IPY_MODEL_ac977f6e091c4bc2bda6621c7cef54ba"
      ],
      "layout": "IPY_MODEL_f8d65d474510491190b7c3ff4ce85399"
     }
    },
    "7adfd2b51cb048c782a9defe26be3ba1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88e682d9f19144b9a7290d728db64136",
      "max": 125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ad39ae9b17cb4e2ea65668c21201e5fe",
      "value": 125
     }
    },
    "7e133e50d5ed409daa67f166ce0543d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88e682d9f19144b9a7290d728db64136": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6dbb58efa7441ddbce7527757918ce0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2253d14ee92b46ee951805ebf2d180ab",
      "placeholder": "​",
      "style": "IPY_MODEL_7e133e50d5ed409daa67f166ce0543d4",
      "value": "100%"
     }
    },
    "ac977f6e091c4bc2bda6621c7cef54ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b90df567666a4fd6bb39a9fe2f80023d",
      "placeholder": "​",
      "style": "IPY_MODEL_25608c56253a445dbb6b670482357fb3",
      "value": " 125/125 [00:41&lt;00:00,  3.03it/s]"
     }
    },
    "ad39ae9b17cb4e2ea65668c21201e5fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b90df567666a4fd6bb39a9fe2f80023d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8d65d474510491190b7c3ff4ce85399": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
