{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JYsWwiwnPzi",
    "outputId": "326fe9cf-d83c-4821-e934-0a9355475f91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 21 10:19:56 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdNIB899nhlq",
    "outputId": "ab3e8b28-c455-4f13-f516-3526489b05bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#mounting google drive on colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GfSazzTdnmaM"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bXN_d9Evntel"
   },
   "outputs": [],
   "source": [
    "X_train=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_X_trainv7_exp2_exp5.npy\")\n",
    "y_train=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_y_trainv7_exp2_exp5.npy\").astype(int)\n",
    "\n",
    "X_test=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_X_testv7_exp2_exp5.npy\")\n",
    "y_test=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_y_testv7_exp2_exp5.npy\").astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ieiDjU3Lp1B9"
   },
   "outputs": [],
   "source": [
    "X_train_1d=np.gradient(X_train,axis=1)\n",
    "X_test_1d=np.gradient(X_test,axis=1)\n",
    "\n",
    "X_train=np.dstack([X_train,X_train_1d])\n",
    "X_test=np.dstack([X_test,X_test_1d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14wUAUDwp5OU",
    "outputId": "3e1670b2-dfa9-4585-ac86-a4e1ecd02ff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18424, 50, 8)\n",
      "(5773, 50, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "S-5ZGwWXG5ek"
   },
   "outputs": [],
   "source": [
    "def custom_scaler(X, range=(0, 1),min=None,max=None):\n",
    "    mi, ma = range\n",
    "    if(min==None):\n",
    "      min=X.min()\n",
    "      max=X.max()\n",
    "      print(\"\\nTrain_Scaling:- min=\",min,\" max=\",max)\n",
    "    X_std = (X - min) / (max - min)\n",
    "    X_scaled = X_std * (ma - mi) + mi\n",
    "    return min,max,X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JceKGdin-e6",
    "outputId": "af79f580-c712-4980-b796-e8e36d7cb6d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train_Scaling:- min= -24.132592179310038  max= 28.36396103067893\n",
      "\n",
      "Train_Scaling:- min= -31.27613373276081  max= 33.197802245887985\n",
      "\n",
      "Train_Scaling:- min= -11.72770325673539  max= 13.779106439601684\n",
      "\n",
      "Train_Scaling:- min= -19.048373985970322  max= 18.311546903226954\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "#X_train contains 8 signals x1,x2,y1,y2,x1d,2d,y1d,y2d\n",
    "X_train_scaled=copy.copy(X_train)\n",
    "X_test_scaled=copy.copy(X_test)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,0:2]=custom_scaler(X_train_scaled[:,:,0:2],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,0:2]=custom_scaler(X_test_scaled[:,:,0:2],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,2:4]=custom_scaler(X_train_scaled[:,:,2:4],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,2:4]=custom_scaler(X_test_scaled[:,:,2:4],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,4:6]=custom_scaler(X_train_scaled[:,:,4:6],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,4:6]=custom_scaler(X_test_scaled[:,:,4:6],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,6:8]=custom_scaler(X_train_scaled[:,:,6:8],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,6:8]=custom_scaler(X_test_scaled[:,:,6:8],range=(0,1),min=min_temp,max=max_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "u8CMIO_ToBr9"
   },
   "outputs": [],
   "source": [
    "# Part 2 - Building the RNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Initialising the RNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "classifier.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train_scaled.shape[1], X_train_scaled.shape[2])))\n",
    "#regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "classifier.add(LSTM(units = 50))\n",
    "#regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1,activation='sigmoid'))\n",
    "\n",
    "# Compiling the RNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HQ_atROOpG9T"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_exp2_exp5.h5\",\n",
    "                             monitor=\"val_accuracy\",\n",
    "                             mode=\"max\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', # value being monitored for improvement\n",
    "                          min_delta = 0, #Abs value and is the min change required before we stop\n",
    "                          patience = 20, #Number of epochs we wait before stopping \n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True) #keeps the best weigths once stopped\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop,checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcUvZBOYoFNC",
    "outputId": "b4d55348-bcdc-4040-8c59-71570a5899a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.5985 - accuracy: 0.6927\n",
      "Epoch 1: val_accuracy improved from -inf to 0.72406, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_exp2_exp5.h5\n",
      "288/288 [==============================] - 11s 13ms/step - loss: 0.5981 - accuracy: 0.6928 - val_loss: 0.4242 - val_accuracy: 0.7241\n",
      "Epoch 2/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.4603 - accuracy: 0.7553\n",
      "Epoch 2: val_accuracy improved from 0.72406 to 0.84098, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_exp2_exp5.h5\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.4603 - accuracy: 0.7553 - val_loss: 0.3358 - val_accuracy: 0.8410\n",
      "Epoch 3/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.4037 - accuracy: 0.8055\n",
      "Epoch 3: val_accuracy did not improve from 0.84098\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.4037 - accuracy: 0.8055 - val_loss: 0.3438 - val_accuracy: 0.8224\n",
      "Epoch 4/200\n",
      "282/288 [============================>.] - ETA: 0s - loss: 0.3904 - accuracy: 0.8107\n",
      "Epoch 4: val_accuracy did not improve from 0.84098\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3901 - accuracy: 0.8114 - val_loss: 0.3785 - val_accuracy: 0.8200\n",
      "Epoch 5/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8161\n",
      "Epoch 5: val_accuracy did not improve from 0.84098\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3854 - accuracy: 0.8158 - val_loss: 0.3294 - val_accuracy: 0.8341\n",
      "Epoch 6/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.3707 - accuracy: 0.8238\n",
      "Epoch 6: val_accuracy did not improve from 0.84098\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3702 - accuracy: 0.8241 - val_loss: 0.3303 - val_accuracy: 0.8316\n",
      "Epoch 7/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.3693 - accuracy: 0.8241\n",
      "Epoch 7: val_accuracy improved from 0.84098 to 0.84479, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_exp2_exp5.h5\n",
      "288/288 [==============================] - 3s 12ms/step - loss: 0.3692 - accuracy: 0.8243 - val_loss: 0.3158 - val_accuracy: 0.8448\n",
      "Epoch 8/200\n",
      "283/288 [============================>.] - ETA: 0s - loss: 0.3639 - accuracy: 0.8292\n",
      "Epoch 8: val_accuracy improved from 0.84479 to 0.84826, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_exp2_exp5.h5\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3642 - accuracy: 0.8290 - val_loss: 0.3083 - val_accuracy: 0.8483\n",
      "Epoch 9/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.3615 - accuracy: 0.8287\n",
      "Epoch 9: val_accuracy did not improve from 0.84826\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3615 - accuracy: 0.8288 - val_loss: 0.3363 - val_accuracy: 0.8408\n",
      "Epoch 10/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.3632 - accuracy: 0.8262\n",
      "Epoch 10: val_accuracy did not improve from 0.84826\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3632 - accuracy: 0.8265 - val_loss: 0.3414 - val_accuracy: 0.8263\n",
      "Epoch 11/200\n",
      "283/288 [============================>.] - ETA: 0s - loss: 0.3507 - accuracy: 0.8367\n",
      "Epoch 11: val_accuracy did not improve from 0.84826\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3500 - accuracy: 0.8370 - val_loss: 0.3403 - val_accuracy: 0.8353\n",
      "Epoch 12/200\n",
      "282/288 [============================>.] - ETA: 0s - loss: 0.3589 - accuracy: 0.8308\n",
      "Epoch 12: val_accuracy did not improve from 0.84826\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3580 - accuracy: 0.8313 - val_loss: 0.3551 - val_accuracy: 0.8276\n",
      "Epoch 13/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.3471 - accuracy: 0.8388\n",
      "Epoch 13: val_accuracy did not improve from 0.84826\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3473 - accuracy: 0.8386 - val_loss: 0.3385 - val_accuracy: 0.8427\n",
      "Epoch 14/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.3450 - accuracy: 0.8402\n",
      "Epoch 14: val_accuracy improved from 0.84826 to 0.85657, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_exp2_exp5.h5\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3449 - accuracy: 0.8400 - val_loss: 0.3130 - val_accuracy: 0.8566\n",
      "Epoch 15/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.3346 - accuracy: 0.8477\n",
      "Epoch 15: val_accuracy improved from 0.85657 to 0.85969, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_exp2_exp5.h5\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3344 - accuracy: 0.8479 - val_loss: 0.3084 - val_accuracy: 0.8597\n",
      "Epoch 16/200\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.3381 - accuracy: 0.8445\n",
      "Epoch 16: val_accuracy did not improve from 0.85969\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3383 - accuracy: 0.8446 - val_loss: 0.3491 - val_accuracy: 0.8465\n",
      "Epoch 17/200\n",
      "283/288 [============================>.] - ETA: 0s - loss: 0.3262 - accuracy: 0.8525\n",
      "Epoch 17: val_accuracy did not improve from 0.85969\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3264 - accuracy: 0.8523 - val_loss: 0.3204 - val_accuracy: 0.8524\n",
      "Epoch 18/200\n",
      "283/288 [============================>.] - ETA: 0s - loss: 0.3360 - accuracy: 0.8481\n",
      "Epoch 18: val_accuracy did not improve from 0.85969\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3368 - accuracy: 0.8476 - val_loss: 0.3005 - val_accuracy: 0.8540\n",
      "Epoch 19/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.3265 - accuracy: 0.8560\n",
      "Epoch 19: val_accuracy improved from 0.85969 to 0.86021, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_exp2_exp5.h5\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3264 - accuracy: 0.8559 - val_loss: 0.3010 - val_accuracy: 0.8602\n",
      "Epoch 20/200\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.3199 - accuracy: 0.8572\n",
      "Epoch 20: val_accuracy did not improve from 0.86021\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3203 - accuracy: 0.8567 - val_loss: 0.3170 - val_accuracy: 0.8587\n",
      "Epoch 21/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.3082 - accuracy: 0.8634\n",
      "Epoch 21: val_accuracy did not improve from 0.86021\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3082 - accuracy: 0.8635 - val_loss: 0.3134 - val_accuracy: 0.8509\n",
      "Epoch 22/200\n",
      "282/288 [============================>.] - ETA: 0s - loss: 0.3094 - accuracy: 0.8629\n",
      "Epoch 22: val_accuracy did not improve from 0.86021\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3082 - accuracy: 0.8637 - val_loss: 0.3366 - val_accuracy: 0.8519\n",
      "Epoch 23/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.3138 - accuracy: 0.8612\n",
      "Epoch 23: val_accuracy improved from 0.86021 to 0.86662, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_exp2_exp5.h5\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3138 - accuracy: 0.8612 - val_loss: 0.2982 - val_accuracy: 0.8666\n",
      "Epoch 24/200\n",
      "282/288 [============================>.] - ETA: 0s - loss: 0.2946 - accuracy: 0.8702\n",
      "Epoch 24: val_accuracy did not improve from 0.86662\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2957 - accuracy: 0.8696 - val_loss: 0.4232 - val_accuracy: 0.7972\n",
      "Epoch 25/200\n",
      "283/288 [============================>.] - ETA: 0s - loss: 0.3138 - accuracy: 0.8600\n",
      "Epoch 25: val_accuracy improved from 0.86662 to 0.87112, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_exp2_exp5.h5\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3132 - accuracy: 0.8605 - val_loss: 0.2961 - val_accuracy: 0.8711\n",
      "Epoch 26/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.2951 - accuracy: 0.8699\n",
      "Epoch 26: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2956 - accuracy: 0.8697 - val_loss: 0.3101 - val_accuracy: 0.8465\n",
      "Epoch 27/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.2869 - accuracy: 0.8725\n",
      "Epoch 27: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2870 - accuracy: 0.8725 - val_loss: 0.3105 - val_accuracy: 0.8554\n",
      "Epoch 28/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.2884 - accuracy: 0.8733\n",
      "Epoch 28: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2883 - accuracy: 0.8734 - val_loss: 0.2941 - val_accuracy: 0.8701\n",
      "Epoch 29/200\n",
      "283/288 [============================>.] - ETA: 0s - loss: 0.3027 - accuracy: 0.8641\n",
      "Epoch 29: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3019 - accuracy: 0.8646 - val_loss: 0.2930 - val_accuracy: 0.8663\n",
      "Epoch 30/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.3271 - accuracy: 0.8444\n",
      "Epoch 30: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3269 - accuracy: 0.8447 - val_loss: 0.3404 - val_accuracy: 0.8218\n",
      "Epoch 31/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.3530 - accuracy: 0.8389\n",
      "Epoch 31: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3524 - accuracy: 0.8390 - val_loss: 0.3282 - val_accuracy: 0.8387\n",
      "Epoch 32/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.3076 - accuracy: 0.8643\n",
      "Epoch 32: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3074 - accuracy: 0.8645 - val_loss: 0.2926 - val_accuracy: 0.8633\n",
      "Epoch 33/200\n",
      "283/288 [============================>.] - ETA: 0s - loss: 0.3046 - accuracy: 0.8625\n",
      "Epoch 33: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3047 - accuracy: 0.8622 - val_loss: 0.2832 - val_accuracy: 0.8711\n",
      "Epoch 34/200\n",
      "283/288 [============================>.] - ETA: 0s - loss: 0.2899 - accuracy: 0.8731\n",
      "Epoch 34: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2891 - accuracy: 0.8736 - val_loss: 0.3118 - val_accuracy: 0.8559\n",
      "Epoch 35/200\n",
      "283/288 [============================>.] - ETA: 0s - loss: 0.3059 - accuracy: 0.8617\n",
      "Epoch 35: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3054 - accuracy: 0.8621 - val_loss: 0.3189 - val_accuracy: 0.8438\n",
      "Epoch 36/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.3191 - accuracy: 0.8575\n",
      "Epoch 36: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3191 - accuracy: 0.8575 - val_loss: 0.2856 - val_accuracy: 0.8651\n",
      "Epoch 37/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.2950 - accuracy: 0.8701\n",
      "Epoch 37: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2945 - accuracy: 0.8702 - val_loss: 0.2925 - val_accuracy: 0.8554\n",
      "Epoch 38/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.2938 - accuracy: 0.8714\n",
      "Epoch 38: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2932 - accuracy: 0.8715 - val_loss: 0.3304 - val_accuracy: 0.8420\n",
      "Epoch 39/200\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.2862 - accuracy: 0.8718\n",
      "Epoch 39: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2862 - accuracy: 0.8718 - val_loss: 0.2826 - val_accuracy: 0.8597\n",
      "Epoch 40/200\n",
      "283/288 [============================>.] - ETA: 0s - loss: 0.2850 - accuracy: 0.8739\n",
      "Epoch 40: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2881 - accuracy: 0.8727 - val_loss: 0.2765 - val_accuracy: 0.8696\n",
      "Epoch 41/200\n",
      "282/288 [============================>.] - ETA: 0s - loss: 0.2962 - accuracy: 0.8661\n",
      "Epoch 41: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2961 - accuracy: 0.8662 - val_loss: 0.2977 - val_accuracy: 0.8564\n",
      "Epoch 42/200\n",
      "283/288 [============================>.] - ETA: 0s - loss: 0.2898 - accuracy: 0.8713\n",
      "Epoch 42: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2897 - accuracy: 0.8713 - val_loss: 0.3043 - val_accuracy: 0.8509\n",
      "Epoch 43/200\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.2839 - accuracy: 0.8755\n",
      "Epoch 43: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2844 - accuracy: 0.8755 - val_loss: 0.3501 - val_accuracy: 0.8315\n",
      "Epoch 44/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.2818 - accuracy: 0.8759\n",
      "Epoch 44: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2818 - accuracy: 0.8758 - val_loss: 0.2875 - val_accuracy: 0.8666\n",
      "Epoch 45/200\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.2761 - accuracy: 0.8790Restoring model weights from the end of the best epoch: 25.\n",
      "\n",
      "Epoch 45: val_accuracy did not improve from 0.87112\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2763 - accuracy: 0.8791 - val_loss: 0.2761 - val_accuracy: 0.8694\n",
      "Epoch 45: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "history=classifier.fit(X_train_scaled, y_train[:,0], epochs = 200, batch_size = 64,validation_data=(X_test_scaled,y_test[:,0]),callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fr7pCHoBrcKa",
    "outputId": "f04a7df0-5bfa-4fed-f104-ee38d398861f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 1s 4ms/step - loss: 0.2961 - accuracy: 0.8711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29611313343048096, 0.8711242079734802]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(X_test_scaled,y_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "QZVd0A1ostvR",
    "outputId": "d4365a91-37c5-4570-bf39-bc5fdb0f88ea"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def display_learning_curves(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    ax1.plot(history.history[\"loss\"])\n",
    "    ax1.plot(history.history[\"val_loss\"])\n",
    "    ax1.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "    ax2.plot(history.history[\"accuracy\"])\n",
    "    ax2.plot(history.history[\"val_accuracy\"])\n",
    "    ax2.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "display_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ND2WPhO1pRNH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "L0VKJswYTc4O"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "temp=tf.keras.models.load_model(\"./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_exp2_exp5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9bgdUJETn0g",
    "outputId": "1ed42f4e-baec-47ed-f047-e35565a805f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5773/5773 [==============================] - 21s 3ms/step - loss: 0.2961 - accuracy: 0.8711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29611101746559143, 0.8711242079734802]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.evaluate(X_test_scaled, y_test[:,0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbTiJwqAZhcj",
    "outputId": "03b6c9ce-a35e-42ad-9d6f-267e8d858177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 1s 5ms/step - loss: 0.2961 - accuracy: 0.8711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29611313343048096, 0.8711242079734802]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.evaluate(X_test_scaled, y_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "RD4YF1AuT2tn"
   },
   "outputs": [],
   "source": [
    "y_pred = temp.predict(X_test_scaled)\n",
    "y_pred= (y_pred>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjx-DjHUWp52",
    "outputId": "b6e45c32-563e-4d49-8a04-8ece065bc28a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ipevqB9rXDeW"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rSeo2ltUXffg",
    "outputId": "220c5d6a-36f5-4c66-b41a-65f4de43f1b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4143,  235],\n",
       "       [ 509,  886]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eM1TBa2IXtj2",
    "outputId": "b225f66d-5cee-4071-bb12-c5b2fb8a124c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.871124198856747"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9V2DcARYNq6",
    "outputId": "2da6d90b-5f8c-4335-c5df-d926b92bcbd4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7042925278219397"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwAjeUnMYQ1O",
    "outputId": "ffb35bf8-6776-4ad8-e34d-c9b03ce8f227"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      4378\n",
      "           1       0.79      0.64      0.70      1395\n",
      "\n",
      "    accuracy                           0.87      5773\n",
      "   macro avg       0.84      0.79      0.81      5773\n",
      "weighted avg       0.87      0.87      0.87      5773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test[:,0],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8c3c8d64fcfd4af28110f2407e46814e",
      "35ae94fa3a87481089d6c92aa9e27846",
      "197a74f4926f48eab466660ba2d246b6",
      "e2447e8a24b046efa52d3adfd3aee81e",
      "79cb1d63b93847a5b756d62e82b37c90",
      "e47b4e05737d423b94897b6d77a1f1b1",
      "3fed207e2b7a404189d7bcfe01ad05a9",
      "be7ff47877574840be1fe75ff41dbf0f",
      "ab7637e2aff747f9aedf606a77831e4a",
      "8520147f92884f0ebcbb37158cd48e9c",
      "6c8ee637c9e64eff9e47a182c625c8bc"
     ]
    },
    "id": "AxyNyQGTjacp",
    "outputId": "861e91c5-753b-4371-a1c5-e531dc644c0c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017505168914794922,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3c8d64fcfd4af28110f2407e46814e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "288/288 [==============================] - 6s 11ms/step - loss: 0.5717 - accuracy: 0.6971 - val_loss: 0.4289 - val_accuracy: 0.7667\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.4880 - accuracy: 0.7283 - val_loss: 0.3631 - val_accuracy: 0.7951\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.4129 - accuracy: 0.7947 - val_loss: 0.4391 - val_accuracy: 0.7733\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3930 - accuracy: 0.8074 - val_loss: 0.3444 - val_accuracy: 0.8166\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3856 - accuracy: 0.8125 - val_loss: 0.3273 - val_accuracy: 0.8219\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3797 - accuracy: 0.8183 - val_loss: 0.3271 - val_accuracy: 0.8327\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3990 - accuracy: 0.8066 - val_loss: 0.3220 - val_accuracy: 0.8391\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3693 - accuracy: 0.8254 - val_loss: 0.3389 - val_accuracy: 0.8250\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3626 - accuracy: 0.8300 - val_loss: 0.3220 - val_accuracy: 0.8502\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.4145 - accuracy: 0.7807 - val_loss: 0.3454 - val_accuracy: 0.8209\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3799 - accuracy: 0.8161 - val_loss: 0.3202 - val_accuracy: 0.8382\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3648 - accuracy: 0.8286 - val_loss: 0.3851 - val_accuracy: 0.7916\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3626 - accuracy: 0.8305 - val_loss: 0.3029 - val_accuracy: 0.8557\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3557 - accuracy: 0.8371 - val_loss: 0.3276 - val_accuracy: 0.8405\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3509 - accuracy: 0.8416 - val_loss: 0.2942 - val_accuracy: 0.8585\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3278 - accuracy: 0.8509 - val_loss: 0.3092 - val_accuracy: 0.8613\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3897 - accuracy: 0.8018 - val_loss: 0.3418 - val_accuracy: 0.7847\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3833 - accuracy: 0.8148 - val_loss: 0.3313 - val_accuracy: 0.8197\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3602 - accuracy: 0.8330 - val_loss: 0.3089 - val_accuracy: 0.8460\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3510 - accuracy: 0.8381 - val_loss: 0.3574 - val_accuracy: 0.8173\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3292 - accuracy: 0.8524 - val_loss: 0.3013 - val_accuracy: 0.8668\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3669 - accuracy: 0.8269 - val_loss: 0.3500 - val_accuracy: 0.8283\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3236 - accuracy: 0.8553 - val_loss: 0.3109 - val_accuracy: 0.8557\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3362 - accuracy: 0.8450 - val_loss: 0.3149 - val_accuracy: 0.8566\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3253 - accuracy: 0.8533 - val_loss: 0.3036 - val_accuracy: 0.8528\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3122 - accuracy: 0.8598 - val_loss: 0.4297 - val_accuracy: 0.7836\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3031 - accuracy: 0.8627 - val_loss: 0.3100 - val_accuracy: 0.8536\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3027 - accuracy: 0.8645 - val_loss: 0.3056 - val_accuracy: 0.8531\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3068 - accuracy: 0.8619 - val_loss: 0.2900 - val_accuracy: 0.8569\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2974 - accuracy: 0.8675 - val_loss: 0.2970 - val_accuracy: 0.8522\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2876 - accuracy: 0.8715 - val_loss: 0.2885 - val_accuracy: 0.8638\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3356 - accuracy: 0.8380 - val_loss: 0.3173 - val_accuracy: 0.8368\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3346 - accuracy: 0.8495 - val_loss: 0.3074 - val_accuracy: 0.8457\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3034 - accuracy: 0.8652 - val_loss: 0.2894 - val_accuracy: 0.8616\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2888 - accuracy: 0.8712 - val_loss: 0.2801 - val_accuracy: 0.8706\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2861 - accuracy: 0.8729 - val_loss: 0.2875 - val_accuracy: 0.8689\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 3s 12ms/step - loss: 0.2889 - accuracy: 0.8720 - val_loss: 0.2878 - val_accuracy: 0.8767\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2811 - accuracy: 0.8766 - val_loss: 0.2998 - val_accuracy: 0.8574\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2877 - accuracy: 0.8736 - val_loss: 0.2892 - val_accuracy: 0.8716\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2786 - accuracy: 0.8761 - val_loss: 0.2780 - val_accuracy: 0.8680\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3038 - accuracy: 0.8659 - val_loss: 0.3239 - val_accuracy: 0.8413\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2785 - accuracy: 0.8767 - val_loss: 0.2707 - val_accuracy: 0.8760\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2835 - accuracy: 0.8755 - val_loss: 0.2813 - val_accuracy: 0.8555\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2712 - accuracy: 0.8835 - val_loss: 0.3103 - val_accuracy: 0.8574\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2743 - accuracy: 0.8792 - val_loss: 0.2587 - val_accuracy: 0.8839\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2658 - accuracy: 0.8843 - val_loss: 0.2962 - val_accuracy: 0.8625\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2765 - accuracy: 0.8797 - val_loss: 0.2621 - val_accuracy: 0.8729\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2668 - accuracy: 0.8836 - val_loss: 0.3254 - val_accuracy: 0.8413\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2803 - accuracy: 0.8766 - val_loss: 0.3406 - val_accuracy: 0.8616\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2757 - accuracy: 0.8803 - val_loss: 0.2661 - val_accuracy: 0.8761\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2852 - accuracy: 0.8762 - val_loss: 0.3288 - val_accuracy: 0.8483\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2636 - accuracy: 0.8860 - val_loss: 0.2651 - val_accuracy: 0.8775\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2651 - accuracy: 0.8837 - val_loss: 0.2791 - val_accuracy: 0.8675\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2587 - accuracy: 0.8866 - val_loss: 0.2823 - val_accuracy: 0.8734\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2586 - accuracy: 0.8870 - val_loss: 0.3190 - val_accuracy: 0.8548\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2662 - accuracy: 0.8882 - val_loss: 0.2792 - val_accuracy: 0.8649\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2508 - accuracy: 0.8933 - val_loss: 0.2697 - val_accuracy: 0.8704\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2500 - accuracy: 0.8932 - val_loss: 0.3321 - val_accuracy: 0.8479\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2435 - accuracy: 0.8976 - val_loss: 0.2772 - val_accuracy: 0.8725\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2398 - accuracy: 0.9007 - val_loss: 0.2749 - val_accuracy: 0.8718\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2456 - accuracy: 0.9001 - val_loss: 0.3096 - val_accuracy: 0.8637\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2256 - accuracy: 0.9087 - val_loss: 0.3225 - val_accuracy: 0.8462\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2369 - accuracy: 0.9022 - val_loss: 0.3049 - val_accuracy: 0.8625\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2324 - accuracy: 0.9041 - val_loss: 0.4954 - val_accuracy: 0.7842\n",
      "Epoch 65/500\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.2311 - accuracy: 0.9048Restoring model weights from the end of the best epoch: 45.\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2309 - accuracy: 0.9050 - val_loss: 0.3320 - val_accuracy: 0.8626\n",
      "Epoch 65: early stopping\n",
      "Number of iterations 1\n",
      "F1-scores:  [0.7370486656200943]\n",
      "Average F1-Score 0.7370486656200943\n",
      "Std Dev F1-Score 0.0\n",
      "Error bar F1-Score 0.0\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 6s 11ms/step - loss: 0.6002 - accuracy: 0.6937 - val_loss: 0.5683 - val_accuracy: 0.7584\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.5493 - accuracy: 0.7326 - val_loss: 0.3938 - val_accuracy: 0.8070\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.4193 - accuracy: 0.7968 - val_loss: 0.3145 - val_accuracy: 0.8458\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3826 - accuracy: 0.8258 - val_loss: 0.3253 - val_accuracy: 0.8457\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 3s 12ms/step - loss: 0.3771 - accuracy: 0.8244 - val_loss: 0.4080 - val_accuracy: 0.8022\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3655 - accuracy: 0.8328 - val_loss: 0.3694 - val_accuracy: 0.8145\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3565 - accuracy: 0.8374 - val_loss: 0.3222 - val_accuracy: 0.8519\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3544 - accuracy: 0.8406 - val_loss: 0.3382 - val_accuracy: 0.8351\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3508 - accuracy: 0.8399 - val_loss: 0.5675 - val_accuracy: 0.7336\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3560 - accuracy: 0.8386 - val_loss: 0.3612 - val_accuracy: 0.8280\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3394 - accuracy: 0.8460 - val_loss: 0.3231 - val_accuracy: 0.8503\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3585 - accuracy: 0.8398 - val_loss: 0.3369 - val_accuracy: 0.8486\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3839 - accuracy: 0.8098 - val_loss: 0.3244 - val_accuracy: 0.8677\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3955 - accuracy: 0.8083 - val_loss: 0.3559 - val_accuracy: 0.8399\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3543 - accuracy: 0.8400 - val_loss: 0.3861 - val_accuracy: 0.8264\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3358 - accuracy: 0.8487 - val_loss: 0.3550 - val_accuracy: 0.8242\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3753 - accuracy: 0.8176 - val_loss: 0.3676 - val_accuracy: 0.8224\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3562 - accuracy: 0.8384 - val_loss: 0.3303 - val_accuracy: 0.8387\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3359 - accuracy: 0.8494 - val_loss: 0.3048 - val_accuracy: 0.8559\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3335 - accuracy: 0.8487 - val_loss: 0.3415 - val_accuracy: 0.8358\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3310 - accuracy: 0.8469 - val_loss: 0.3122 - val_accuracy: 0.8597\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3343 - accuracy: 0.8483 - val_loss: 0.3369 - val_accuracy: 0.8432\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3373 - accuracy: 0.8485 - val_loss: 0.3351 - val_accuracy: 0.8432\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3198 - accuracy: 0.8553 - val_loss: 0.3120 - val_accuracy: 0.8479\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3258 - accuracy: 0.8536 - val_loss: 0.3861 - val_accuracy: 0.8041\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3187 - accuracy: 0.8575 - val_loss: 0.3403 - val_accuracy: 0.8413\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3208 - accuracy: 0.8563 - val_loss: 0.3271 - val_accuracy: 0.8559\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3192 - accuracy: 0.8573 - val_loss: 0.3062 - val_accuracy: 0.8614\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3136 - accuracy: 0.8578 - val_loss: 0.3052 - val_accuracy: 0.8548\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3135 - accuracy: 0.8588 - val_loss: 0.3733 - val_accuracy: 0.8231\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3157 - accuracy: 0.8564 - val_loss: 0.3761 - val_accuracy: 0.8179\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3123 - accuracy: 0.8605 - val_loss: 0.3021 - val_accuracy: 0.8587\n",
      "Epoch 33/500\n",
      "287/288 [============================>.] - ETA: 0s - loss: 0.3127 - accuracy: 0.8587Restoring model weights from the end of the best epoch: 13.\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3125 - accuracy: 0.8588 - val_loss: 0.3109 - val_accuracy: 0.8621\n",
      "Epoch 33: early stopping\n",
      "Number of iterations 2\n",
      "F1-scores:  [0.7370486656200943, 0.7239884393063584]\n",
      "Average F1-Score 0.7305185524632263\n",
      "Std Dev F1-Score 0.006530113156867967\n",
      "Error bar F1-Score 0.0046174872951368325\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 6s 11ms/step - loss: 0.5310 - accuracy: 0.7136 - val_loss: 0.3446 - val_accuracy: 0.8406\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.4090 - accuracy: 0.7979 - val_loss: 0.3211 - val_accuracy: 0.8460\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3936 - accuracy: 0.8127 - val_loss: 0.4229 - val_accuracy: 0.7939\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3944 - accuracy: 0.8125 - val_loss: 0.3856 - val_accuracy: 0.7951\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3750 - accuracy: 0.8232 - val_loss: 0.3378 - val_accuracy: 0.8273\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3745 - accuracy: 0.8243 - val_loss: 0.3729 - val_accuracy: 0.8179\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3641 - accuracy: 0.8317 - val_loss: 0.3113 - val_accuracy: 0.8559\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3644 - accuracy: 0.8322 - val_loss: 0.3782 - val_accuracy: 0.8043\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3604 - accuracy: 0.8318 - val_loss: 0.3406 - val_accuracy: 0.8334\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3653 - accuracy: 0.8303 - val_loss: 0.3100 - val_accuracy: 0.8590\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3488 - accuracy: 0.8391 - val_loss: 0.4072 - val_accuracy: 0.7830\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3602 - accuracy: 0.8326 - val_loss: 0.3743 - val_accuracy: 0.8088\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3453 - accuracy: 0.8383 - val_loss: 0.3168 - val_accuracy: 0.8578\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3464 - accuracy: 0.8416 - val_loss: 0.3728 - val_accuracy: 0.8041\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3242 - accuracy: 0.8532 - val_loss: 0.3263 - val_accuracy: 0.8500\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3598 - accuracy: 0.8349 - val_loss: 0.3627 - val_accuracy: 0.8173\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3352 - accuracy: 0.8482 - val_loss: 0.3323 - val_accuracy: 0.8325\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3199 - accuracy: 0.8559 - val_loss: 0.2879 - val_accuracy: 0.8661\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3255 - accuracy: 0.8534 - val_loss: 0.3502 - val_accuracy: 0.8353\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3150 - accuracy: 0.8582 - val_loss: 0.3194 - val_accuracy: 0.8541\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3226 - accuracy: 0.8537 - val_loss: 0.3410 - val_accuracy: 0.8472\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3041 - accuracy: 0.8656 - val_loss: 0.3009 - val_accuracy: 0.8677\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3076 - accuracy: 0.8634 - val_loss: 0.3824 - val_accuracy: 0.7908\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3147 - accuracy: 0.8580 - val_loss: 0.3147 - val_accuracy: 0.8645\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3131 - accuracy: 0.8593 - val_loss: 0.3062 - val_accuracy: 0.8545\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2971 - accuracy: 0.8649 - val_loss: 0.3221 - val_accuracy: 0.8571\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2999 - accuracy: 0.8680 - val_loss: 0.3128 - val_accuracy: 0.8545\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2904 - accuracy: 0.8718 - val_loss: 0.2889 - val_accuracy: 0.8678\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2885 - accuracy: 0.8709 - val_loss: 0.3156 - val_accuracy: 0.8547\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2875 - accuracy: 0.8727 - val_loss: 0.2888 - val_accuracy: 0.8729\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2841 - accuracy: 0.8742 - val_loss: 0.3030 - val_accuracy: 0.8561\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2906 - accuracy: 0.8722 - val_loss: 0.3107 - val_accuracy: 0.8588\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2967 - accuracy: 0.8670 - val_loss: 0.2932 - val_accuracy: 0.8607\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2802 - accuracy: 0.8787 - val_loss: 0.2884 - val_accuracy: 0.8687\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2827 - accuracy: 0.8760 - val_loss: 0.2974 - val_accuracy: 0.8625\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2817 - accuracy: 0.8782 - val_loss: 0.3066 - val_accuracy: 0.8593\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2760 - accuracy: 0.8825 - val_loss: 0.2866 - val_accuracy: 0.8756\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2682 - accuracy: 0.8860 - val_loss: 0.2712 - val_accuracy: 0.8798\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2660 - accuracy: 0.8874 - val_loss: 0.2761 - val_accuracy: 0.8782\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2695 - accuracy: 0.8853 - val_loss: 0.3389 - val_accuracy: 0.8448\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 3s 12ms/step - loss: 0.2659 - accuracy: 0.8878 - val_loss: 0.3176 - val_accuracy: 0.8571\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2586 - accuracy: 0.8908 - val_loss: 0.3209 - val_accuracy: 0.8541\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2627 - accuracy: 0.8910 - val_loss: 0.2838 - val_accuracy: 0.8682\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2658 - accuracy: 0.8866 - val_loss: 0.2827 - val_accuracy: 0.8670\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2540 - accuracy: 0.8943 - val_loss: 0.3102 - val_accuracy: 0.8569\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2388 - accuracy: 0.9024 - val_loss: 0.2646 - val_accuracy: 0.8813\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2402 - accuracy: 0.8990 - val_loss: 0.3829 - val_accuracy: 0.8199\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2390 - accuracy: 0.9007 - val_loss: 0.2491 - val_accuracy: 0.8836\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2270 - accuracy: 0.9053 - val_loss: 0.2316 - val_accuracy: 0.8784\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2152 - accuracy: 0.9095 - val_loss: 0.3137 - val_accuracy: 0.8502\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2177 - accuracy: 0.9060 - val_loss: 0.2303 - val_accuracy: 0.8881\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2147 - accuracy: 0.9092 - val_loss: 0.2203 - val_accuracy: 0.8936\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1839 - accuracy: 0.9240 - val_loss: 0.1985 - val_accuracy: 0.9169\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1844 - accuracy: 0.9218 - val_loss: 0.1973 - val_accuracy: 0.9129\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1787 - accuracy: 0.9261 - val_loss: 0.2090 - val_accuracy: 0.9087\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1634 - accuracy: 0.9343 - val_loss: 0.1941 - val_accuracy: 0.9160\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1713 - accuracy: 0.9312 - val_loss: 0.2025 - val_accuracy: 0.9198\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1627 - accuracy: 0.9334 - val_loss: 0.2074 - val_accuracy: 0.9120\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1597 - accuracy: 0.9344 - val_loss: 0.1778 - val_accuracy: 0.9196\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1424 - accuracy: 0.9408 - val_loss: 0.1822 - val_accuracy: 0.9236\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1355 - accuracy: 0.9456 - val_loss: 0.1922 - val_accuracy: 0.9193\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1457 - accuracy: 0.9415 - val_loss: 0.2301 - val_accuracy: 0.8988\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1461 - accuracy: 0.9412 - val_loss: 0.1753 - val_accuracy: 0.9260\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1341 - accuracy: 0.9464 - val_loss: 0.1866 - val_accuracy: 0.9304\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1498 - accuracy: 0.9401 - val_loss: 0.2293 - val_accuracy: 0.9049\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1164 - accuracy: 0.9550 - val_loss: 0.1892 - val_accuracy: 0.9278\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1253 - accuracy: 0.9503 - val_loss: 0.2028 - val_accuracy: 0.9163\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1251 - accuracy: 0.9499 - val_loss: 0.1744 - val_accuracy: 0.9286\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1216 - accuracy: 0.9521 - val_loss: 0.1729 - val_accuracy: 0.9271\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0999 - accuracy: 0.9608 - val_loss: 0.2072 - val_accuracy: 0.9203\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1214 - accuracy: 0.9532 - val_loss: 0.1849 - val_accuracy: 0.9279\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1277 - accuracy: 0.9490 - val_loss: 0.2059 - val_accuracy: 0.9144\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0972 - accuracy: 0.9619 - val_loss: 0.3129 - val_accuracy: 0.8916\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1322 - accuracy: 0.9496 - val_loss: 0.1832 - val_accuracy: 0.9292\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1018 - accuracy: 0.9608 - val_loss: 0.1879 - val_accuracy: 0.9295\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1614 - accuracy: 0.9363 - val_loss: 0.1868 - val_accuracy: 0.9231\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1052 - accuracy: 0.9597 - val_loss: 0.3832 - val_accuracy: 0.8718\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1093 - accuracy: 0.9587 - val_loss: 0.1833 - val_accuracy: 0.9326\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0896 - accuracy: 0.9660 - val_loss: 0.3356 - val_accuracy: 0.8860\n",
      "Epoch 80/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1156 - accuracy: 0.9555 - val_loss: 0.1744 - val_accuracy: 0.9331\n",
      "Epoch 81/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1060 - accuracy: 0.9584 - val_loss: 0.1842 - val_accuracy: 0.9286\n",
      "Epoch 82/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0818 - accuracy: 0.9696 - val_loss: 0.1647 - val_accuracy: 0.9390\n",
      "Epoch 83/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1512 - accuracy: 0.9384 - val_loss: 0.2245 - val_accuracy: 0.9124\n",
      "Epoch 84/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0839 - accuracy: 0.9678 - val_loss: 0.1765 - val_accuracy: 0.9342\n",
      "Epoch 85/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.1109 - accuracy: 0.9572 - val_loss: 0.1927 - val_accuracy: 0.9255\n",
      "Epoch 86/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0748 - accuracy: 0.9725 - val_loss: 0.3984 - val_accuracy: 0.8784\n",
      "Epoch 87/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0923 - accuracy: 0.9643 - val_loss: 0.1830 - val_accuracy: 0.9318\n",
      "Epoch 88/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0852 - accuracy: 0.9671 - val_loss: 0.1617 - val_accuracy: 0.9359\n",
      "Epoch 89/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0826 - accuracy: 0.9698 - val_loss: 0.1958 - val_accuracy: 0.9290\n",
      "Epoch 90/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0874 - accuracy: 0.9661 - val_loss: 0.2150 - val_accuracy: 0.9174\n",
      "Epoch 91/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0774 - accuracy: 0.9717 - val_loss: 0.2398 - val_accuracy: 0.9103\n",
      "Epoch 92/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0982 - accuracy: 0.9624 - val_loss: 0.1562 - val_accuracy: 0.9399\n",
      "Epoch 93/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0722 - accuracy: 0.9725 - val_loss: 0.1777 - val_accuracy: 0.9330\n",
      "Epoch 94/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0744 - accuracy: 0.9725 - val_loss: 0.1646 - val_accuracy: 0.9361\n",
      "Epoch 95/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0906 - accuracy: 0.9650 - val_loss: 0.1794 - val_accuracy: 0.9349\n",
      "Epoch 96/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0880 - accuracy: 0.9671 - val_loss: 0.1592 - val_accuracy: 0.9442\n",
      "Epoch 97/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0768 - accuracy: 0.9715 - val_loss: 0.2180 - val_accuracy: 0.9122\n",
      "Epoch 98/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0851 - accuracy: 0.9680 - val_loss: 0.1783 - val_accuracy: 0.9369\n",
      "Epoch 99/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0618 - accuracy: 0.9769 - val_loss: 0.1781 - val_accuracy: 0.9354\n",
      "Epoch 100/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0585 - accuracy: 0.9788 - val_loss: 0.1450 - val_accuracy: 0.9463\n",
      "Epoch 101/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0805 - accuracy: 0.9693 - val_loss: 0.1978 - val_accuracy: 0.9264\n",
      "Epoch 102/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0676 - accuracy: 0.9754 - val_loss: 0.2222 - val_accuracy: 0.9163\n",
      "Epoch 103/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0817 - accuracy: 0.9682 - val_loss: 0.1624 - val_accuracy: 0.9373\n",
      "Epoch 104/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0777 - accuracy: 0.9722 - val_loss: 0.2025 - val_accuracy: 0.9335\n",
      "Epoch 105/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0663 - accuracy: 0.9742 - val_loss: 0.1443 - val_accuracy: 0.9470\n",
      "Epoch 106/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0607 - accuracy: 0.9766 - val_loss: 0.1703 - val_accuracy: 0.9397\n",
      "Epoch 107/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0622 - accuracy: 0.9777 - val_loss: 0.1603 - val_accuracy: 0.9461\n",
      "Epoch 108/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0581 - accuracy: 0.9797 - val_loss: 0.2172 - val_accuracy: 0.9300\n",
      "Epoch 109/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0653 - accuracy: 0.9761 - val_loss: 0.1678 - val_accuracy: 0.9408\n",
      "Epoch 110/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0568 - accuracy: 0.9780 - val_loss: 0.1763 - val_accuracy: 0.9458\n",
      "Epoch 111/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0681 - accuracy: 0.9758 - val_loss: 0.2086 - val_accuracy: 0.9324\n",
      "Epoch 112/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0666 - accuracy: 0.9752 - val_loss: 0.1641 - val_accuracy: 0.9408\n",
      "Epoch 113/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0556 - accuracy: 0.9796 - val_loss: 0.1910 - val_accuracy: 0.9402\n",
      "Epoch 114/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0691 - accuracy: 0.9742 - val_loss: 0.1730 - val_accuracy: 0.9387\n",
      "Epoch 115/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0645 - accuracy: 0.9766 - val_loss: 0.2611 - val_accuracy: 0.9130\n",
      "Epoch 116/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0564 - accuracy: 0.9780 - val_loss: 0.2098 - val_accuracy: 0.9323\n",
      "Epoch 117/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0565 - accuracy: 0.9807 - val_loss: 0.1855 - val_accuracy: 0.9318\n",
      "Epoch 118/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0505 - accuracy: 0.9825 - val_loss: 0.2374 - val_accuracy: 0.9274\n",
      "Epoch 119/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0611 - accuracy: 0.9772 - val_loss: 0.1949 - val_accuracy: 0.9383\n",
      "Epoch 120/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0554 - accuracy: 0.9817 - val_loss: 0.2342 - val_accuracy: 0.9149\n",
      "Epoch 121/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0614 - accuracy: 0.9777 - val_loss: 0.2474 - val_accuracy: 0.9198\n",
      "Epoch 122/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0579 - accuracy: 0.9793 - val_loss: 0.1900 - val_accuracy: 0.9366\n",
      "Epoch 123/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0503 - accuracy: 0.9815 - val_loss: 0.1677 - val_accuracy: 0.9416\n",
      "Epoch 124/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.0518 - accuracy: 0.9809 - val_loss: 0.2081 - val_accuracy: 0.9319\n",
      "Epoch 125/500\n",
      "285/288 [============================>.] - ETA: 0s - loss: 0.0991 - accuracy: 0.9633Restoring model weights from the end of the best epoch: 105.\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.1000 - accuracy: 0.9629 - val_loss: 0.2993 - val_accuracy: 0.8770\n",
      "Epoch 125: early stopping\n",
      "Number of iterations 3\n",
      "F1-scores:  [0.7370486656200943, 0.7239884393063584, 0.8929321203638908]\n",
      "Average F1-Score 0.7846564084301145\n",
      "Std Dev F1-Score 0.0767479195110681\n",
      "Error bar F1-Score 0.0443104319894589\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 6s 12ms/step - loss: 0.5798 - accuracy: 0.6973 - val_loss: 0.3696 - val_accuracy: 0.8138\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.4376 - accuracy: 0.7753 - val_loss: 0.3522 - val_accuracy: 0.8244\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3952 - accuracy: 0.8076 - val_loss: 0.3462 - val_accuracy: 0.8077\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3842 - accuracy: 0.8146 - val_loss: 0.3451 - val_accuracy: 0.8432\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3713 - accuracy: 0.8259 - val_loss: 0.3832 - val_accuracy: 0.7946\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3700 - accuracy: 0.8239 - val_loss: 0.3415 - val_accuracy: 0.8330\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3624 - accuracy: 0.8314 - val_loss: 0.3382 - val_accuracy: 0.8394\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3473 - accuracy: 0.8397 - val_loss: 0.3515 - val_accuracy: 0.8221\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3453 - accuracy: 0.8397 - val_loss: 0.3210 - val_accuracy: 0.8528\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3394 - accuracy: 0.8438 - val_loss: 0.3378 - val_accuracy: 0.8373\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3185 - accuracy: 0.8559 - val_loss: 0.3025 - val_accuracy: 0.8737\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3376 - accuracy: 0.8451 - val_loss: 0.3076 - val_accuracy: 0.8488\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3213 - accuracy: 0.8532 - val_loss: 0.2813 - val_accuracy: 0.8730\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3327 - accuracy: 0.8483 - val_loss: 0.2996 - val_accuracy: 0.8547\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3114 - accuracy: 0.8604 - val_loss: 0.3324 - val_accuracy: 0.8401\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2959 - accuracy: 0.8688 - val_loss: 0.2974 - val_accuracy: 0.8595\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3095 - accuracy: 0.8620 - val_loss: 0.2816 - val_accuracy: 0.8734\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3133 - accuracy: 0.8597 - val_loss: 0.2873 - val_accuracy: 0.8661\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2992 - accuracy: 0.8674 - val_loss: 0.2839 - val_accuracy: 0.8703\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3610 - accuracy: 0.8282 - val_loss: 0.3592 - val_accuracy: 0.8190\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3556 - accuracy: 0.8354 - val_loss: 0.2977 - val_accuracy: 0.8616\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3387 - accuracy: 0.8461 - val_loss: 0.3605 - val_accuracy: 0.8159\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3060 - accuracy: 0.8663 - val_loss: 0.2885 - val_accuracy: 0.8670\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2921 - accuracy: 0.8719 - val_loss: 0.3643 - val_accuracy: 0.8280\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2979 - accuracy: 0.8681 - val_loss: 0.3257 - val_accuracy: 0.8469\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2975 - accuracy: 0.8691 - val_loss: 0.2838 - val_accuracy: 0.8697\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2873 - accuracy: 0.8728 - val_loss: 0.2907 - val_accuracy: 0.8561\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2829 - accuracy: 0.8748 - val_loss: 0.3114 - val_accuracy: 0.8479\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2852 - accuracy: 0.8729 - val_loss: 0.2632 - val_accuracy: 0.8727\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2862 - accuracy: 0.8732 - val_loss: 0.2944 - val_accuracy: 0.8561\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.3067 - accuracy: 0.8610Restoring model weights from the end of the best epoch: 11.\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3067 - accuracy: 0.8610 - val_loss: 0.2815 - val_accuracy: 0.8670\n",
      "Epoch 31: early stopping\n",
      "Number of iterations 4\n",
      "F1-scores:  [0.7370486656200943, 0.7239884393063584, 0.8929321203638908, 0.6920152091254752]\n",
      "Average F1-Score 0.7614961086039547\n",
      "Std Dev F1-Score 0.07763298800169229\n",
      "Error bar F1-Score 0.03881649400084614\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 6s 12ms/step - loss: 0.5679 - accuracy: 0.6933 - val_loss: 0.3501 - val_accuracy: 0.8205\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.4324 - accuracy: 0.7807 - val_loss: 0.3330 - val_accuracy: 0.8344\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.4030 - accuracy: 0.8031 - val_loss: 0.3453 - val_accuracy: 0.8193\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3916 - accuracy: 0.8094 - val_loss: 0.3657 - val_accuracy: 0.8153\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.4071 - accuracy: 0.8028 - val_loss: 0.3584 - val_accuracy: 0.8358\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3745 - accuracy: 0.8248 - val_loss: 0.3101 - val_accuracy: 0.8337\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3820 - accuracy: 0.8208 - val_loss: 0.3338 - val_accuracy: 0.8316\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3670 - accuracy: 0.8296 - val_loss: 0.2982 - val_accuracy: 0.8578\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3394 - accuracy: 0.8450 - val_loss: 0.3080 - val_accuracy: 0.8562\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3334 - accuracy: 0.8504 - val_loss: 0.3300 - val_accuracy: 0.8353\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3155 - accuracy: 0.8596 - val_loss: 0.2780 - val_accuracy: 0.8664\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3100 - accuracy: 0.8634 - val_loss: 0.3118 - val_accuracy: 0.8555\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3192 - accuracy: 0.8563 - val_loss: 0.3978 - val_accuracy: 0.8240\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3019 - accuracy: 0.8640 - val_loss: 0.3604 - val_accuracy: 0.8205\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3080 - accuracy: 0.8638 - val_loss: 0.2866 - val_accuracy: 0.8642\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2945 - accuracy: 0.8697 - val_loss: 0.3157 - val_accuracy: 0.8531\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.3057 - accuracy: 0.8661 - val_loss: 0.2925 - val_accuracy: 0.8554\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2972 - accuracy: 0.8720 - val_loss: 0.2677 - val_accuracy: 0.8710\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2963 - accuracy: 0.8694 - val_loss: 0.2753 - val_accuracy: 0.8793\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2884 - accuracy: 0.8722 - val_loss: 0.2613 - val_accuracy: 0.8761\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.2924 - accuracy: 0.8701 - val_loss: 0.2969 - val_accuracy: 0.8628\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3621 - accuracy: 0.8333 - val_loss: 0.2893 - val_accuracy: 0.8723\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2913 - accuracy: 0.8719 - val_loss: 0.2850 - val_accuracy: 0.8701\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2885 - accuracy: 0.8733 - val_loss: 0.2881 - val_accuracy: 0.8581\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2939 - accuracy: 0.8697 - val_loss: 0.2832 - val_accuracy: 0.8696\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3041 - accuracy: 0.8614 - val_loss: 0.3111 - val_accuracy: 0.8507\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.2789 - accuracy: 0.8783 - val_loss: 0.2762 - val_accuracy: 0.8640\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.2752 - accuracy: 0.8793 - val_loss: 0.3212 - val_accuracy: 0.8597\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3726 - accuracy: 0.8116 - val_loss: 0.3541 - val_accuracy: 0.8375\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 3s 9ms/step - loss: 0.2872 - accuracy: 0.8741 - val_loss: 0.3234 - val_accuracy: 0.8422\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2834 - accuracy: 0.8776 - val_loss: 0.2870 - val_accuracy: 0.8684\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2677 - accuracy: 0.8835 - val_loss: 0.3642 - val_accuracy: 0.8380\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2760 - accuracy: 0.8791 - val_loss: 0.2869 - val_accuracy: 0.8659\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2648 - accuracy: 0.8845 - val_loss: 0.2750 - val_accuracy: 0.8730\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2546 - accuracy: 0.8905 - val_loss: 0.2557 - val_accuracy: 0.8751\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2556 - accuracy: 0.8890 - val_loss: 0.2867 - val_accuracy: 0.8666\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2579 - accuracy: 0.8906 - val_loss: 0.2528 - val_accuracy: 0.8793\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2579 - accuracy: 0.8867 - val_loss: 0.3129 - val_accuracy: 0.8458\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.2583 - accuracy: 0.8895Restoring model weights from the end of the best epoch: 19.\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2583 - accuracy: 0.8895 - val_loss: 0.2729 - val_accuracy: 0.8545\n",
      "Epoch 39: early stopping\n",
      "Number of iterations 5\n",
      "F1-scores:  [0.7370486656200943, 0.7239884393063584, 0.8929321203638908, 0.6920152091254752, 0.7121024370095003]\n",
      "Average F1-Score 0.7516173742850638\n",
      "Std Dev F1-Score 0.0721932284070303\n",
      "Error bar F1-Score 0.032285793246657715\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 7s 15ms/step - loss: 0.5308 - accuracy: 0.7196 - val_loss: 0.3961 - val_accuracy: 0.7660\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.4281 - accuracy: 0.7803 - val_loss: 0.3337 - val_accuracy: 0.8412\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.4181 - accuracy: 0.7910 - val_loss: 0.3955 - val_accuracy: 0.7862\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3982 - accuracy: 0.8072 - val_loss: 0.3022 - val_accuracy: 0.8481\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3848 - accuracy: 0.8162 - val_loss: 0.3079 - val_accuracy: 0.8479\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3861 - accuracy: 0.8143 - val_loss: 0.3254 - val_accuracy: 0.8380\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3758 - accuracy: 0.8237 - val_loss: 0.3390 - val_accuracy: 0.8406\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3681 - accuracy: 0.8237 - val_loss: 0.3044 - val_accuracy: 0.8535\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3709 - accuracy: 0.8254 - val_loss: 0.3840 - val_accuracy: 0.7712\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.4091 - accuracy: 0.8089 - val_loss: 0.5617 - val_accuracy: 0.7584\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6121 - accuracy: 0.6999 - val_loss: 0.5577 - val_accuracy: 0.7584\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6113 - accuracy: 0.6999 - val_loss: 0.5642 - val_accuracy: 0.7584\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6094 - accuracy: 0.6999 - val_loss: 0.5677 - val_accuracy: 0.7584\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6105 - accuracy: 0.6981 - val_loss: 0.5421 - val_accuracy: 0.7584\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6063 - accuracy: 0.6999 - val_loss: 0.5362 - val_accuracy: 0.7584\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.5827 - accuracy: 0.6994 - val_loss: 0.3430 - val_accuracy: 0.8422\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.4253 - accuracy: 0.7860 - val_loss: 0.3440 - val_accuracy: 0.8214\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3900 - accuracy: 0.8137 - val_loss: 0.3166 - val_accuracy: 0.8477\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3957 - accuracy: 0.8128 - val_loss: 0.3130 - val_accuracy: 0.8541\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3700 - accuracy: 0.8276 - val_loss: 0.3591 - val_accuracy: 0.8289\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3569 - accuracy: 0.8341 - val_loss: 0.3106 - val_accuracy: 0.8500\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3476 - accuracy: 0.8389 - val_loss: 0.2967 - val_accuracy: 0.8405\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3644 - accuracy: 0.8305 - val_loss: 0.3152 - val_accuracy: 0.8486\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3777 - accuracy: 0.8199 - val_loss: 0.3590 - val_accuracy: 0.8114\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3700 - accuracy: 0.8271 - val_loss: 0.3345 - val_accuracy: 0.8450\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3497 - accuracy: 0.8397 - val_loss: 0.3392 - val_accuracy: 0.8266\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3412 - accuracy: 0.8445 - val_loss: 0.3281 - val_accuracy: 0.8529\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3274 - accuracy: 0.8520 - val_loss: 0.3115 - val_accuracy: 0.8496\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3227 - accuracy: 0.8558 - val_loss: 0.3206 - val_accuracy: 0.8481\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3238 - accuracy: 0.8542 - val_loss: 0.3378 - val_accuracy: 0.8304\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3074 - accuracy: 0.8630 - val_loss: 0.3262 - val_accuracy: 0.8358\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3461 - accuracy: 0.8361 - val_loss: 0.3903 - val_accuracy: 0.8048\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3264 - accuracy: 0.8518 - val_loss: 0.3238 - val_accuracy: 0.8342\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3370 - accuracy: 0.8499 - val_loss: 0.3108 - val_accuracy: 0.8510\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3833 - accuracy: 0.8021 - val_loss: 0.3530 - val_accuracy: 0.8129\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3744 - accuracy: 0.8240 - val_loss: 0.4297 - val_accuracy: 0.7824\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3209 - accuracy: 0.8546 - val_loss: 0.3598 - val_accuracy: 0.8270\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3222 - accuracy: 0.8560 - val_loss: 0.3078 - val_accuracy: 0.8531\n",
      "Epoch 39/500\n",
      "283/288 [============================>.] - ETA: 0s - loss: 0.3563 - accuracy: 0.8391Restoring model weights from the end of the best epoch: 19.\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3547 - accuracy: 0.8398 - val_loss: 0.3070 - val_accuracy: 0.8495\n",
      "Epoch 39: early stopping\n",
      "Number of iterations 6\n",
      "F1-scores:  [0.7370486656200943, 0.7239884393063584, 0.8929321203638908, 0.6920152091254752, 0.7121024370095003, 0.6690251572327044]\n",
      "Average F1-Score 0.7378520047763373\n",
      "Std Dev F1-Score 0.07273682362978376\n",
      "Error bar F1-Score 0.029694683900630736\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 6s 12ms/step - loss: 0.6085 - accuracy: 0.6963 - val_loss: 0.5197 - val_accuracy: 0.7584\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6035 - accuracy: 0.6997 - val_loss: 0.5261 - val_accuracy: 0.7584\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.5895 - accuracy: 0.6953 - val_loss: 0.4541 - val_accuracy: 0.7584\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.5351 - accuracy: 0.6998 - val_loss: 0.3641 - val_accuracy: 0.7584\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.4465 - accuracy: 0.7715 - val_loss: 0.3169 - val_accuracy: 0.8490\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3954 - accuracy: 0.8120 - val_loss: 0.4019 - val_accuracy: 0.7939\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3768 - accuracy: 0.8232 - val_loss: 0.3454 - val_accuracy: 0.8339\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3558 - accuracy: 0.8344 - val_loss: 0.3049 - val_accuracy: 0.8496\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3496 - accuracy: 0.8375 - val_loss: 0.3080 - val_accuracy: 0.8567\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3581 - accuracy: 0.8376 - val_loss: 0.3824 - val_accuracy: 0.8089\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3476 - accuracy: 0.8410 - val_loss: 0.3478 - val_accuracy: 0.8297\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3334 - accuracy: 0.8543 - val_loss: 0.3402 - val_accuracy: 0.8462\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3404 - accuracy: 0.8437 - val_loss: 0.3165 - val_accuracy: 0.8571\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3206 - accuracy: 0.8552 - val_loss: 0.3524 - val_accuracy: 0.8328\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3240 - accuracy: 0.8567 - val_loss: 0.4292 - val_accuracy: 0.7873\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3135 - accuracy: 0.8584 - val_loss: 0.4301 - val_accuracy: 0.8037\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3067 - accuracy: 0.8616 - val_loss: 0.3498 - val_accuracy: 0.8465\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3209 - accuracy: 0.8542 - val_loss: 0.3557 - val_accuracy: 0.8266\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3003 - accuracy: 0.8660 - val_loss: 0.3069 - val_accuracy: 0.8554\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3098 - accuracy: 0.8609 - val_loss: 0.3136 - val_accuracy: 0.8540\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2974 - accuracy: 0.8686 - val_loss: 0.3152 - val_accuracy: 0.8644\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3089 - accuracy: 0.8626 - val_loss: 0.3024 - val_accuracy: 0.8616\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.2976 - accuracy: 0.8659 - val_loss: 0.3206 - val_accuracy: 0.8464\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3082 - accuracy: 0.8611 - val_loss: 0.2955 - val_accuracy: 0.8613\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.2970 - accuracy: 0.8676 - val_loss: 0.3041 - val_accuracy: 0.8554\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3055 - accuracy: 0.8603 - val_loss: 0.2973 - val_accuracy: 0.8590\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3073 - accuracy: 0.8606 - val_loss: 0.2929 - val_accuracy: 0.8666\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2899 - accuracy: 0.8713 - val_loss: 0.2836 - val_accuracy: 0.8708\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2919 - accuracy: 0.8712 - val_loss: 0.2866 - val_accuracy: 0.8685\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2989 - accuracy: 0.8649 - val_loss: 0.2847 - val_accuracy: 0.8678\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.2838 - accuracy: 0.8736 - val_loss: 0.2889 - val_accuracy: 0.8723\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2939 - accuracy: 0.8675 - val_loss: 0.2845 - val_accuracy: 0.8690\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2885 - accuracy: 0.8720 - val_loss: 0.2874 - val_accuracy: 0.8741\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2899 - accuracy: 0.8707 - val_loss: 0.2910 - val_accuracy: 0.8637\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2901 - accuracy: 0.8708 - val_loss: 0.3095 - val_accuracy: 0.8694\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2824 - accuracy: 0.8734 - val_loss: 0.2640 - val_accuracy: 0.8767\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2811 - accuracy: 0.8733 - val_loss: 0.3692 - val_accuracy: 0.8526\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.2795 - accuracy: 0.8761 - val_loss: 0.2982 - val_accuracy: 0.8690\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2874 - accuracy: 0.8722 - val_loss: 0.2713 - val_accuracy: 0.8763\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2794 - accuracy: 0.8746 - val_loss: 0.2823 - val_accuracy: 0.8729\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2947 - accuracy: 0.8637 - val_loss: 0.2618 - val_accuracy: 0.8749\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.2763 - accuracy: 0.8766 - val_loss: 0.2833 - val_accuracy: 0.8621\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2752 - accuracy: 0.8748 - val_loss: 0.2873 - val_accuracy: 0.8716\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2683 - accuracy: 0.8808 - val_loss: 0.2614 - val_accuracy: 0.8748\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2685 - accuracy: 0.8809 - val_loss: 0.3751 - val_accuracy: 0.8183\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2768 - accuracy: 0.8760 - val_loss: 0.2873 - val_accuracy: 0.8597\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2720 - accuracy: 0.8777 - val_loss: 0.3015 - val_accuracy: 0.8592\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2647 - accuracy: 0.8830 - val_loss: 0.2745 - val_accuracy: 0.8678\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2597 - accuracy: 0.8854 - val_loss: 0.2917 - val_accuracy: 0.8713\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2624 - accuracy: 0.8849 - val_loss: 0.3003 - val_accuracy: 0.8677\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2581 - accuracy: 0.8855 - val_loss: 0.2691 - val_accuracy: 0.8723\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2532 - accuracy: 0.8883 - val_loss: 0.2802 - val_accuracy: 0.8682\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2479 - accuracy: 0.8904 - val_loss: 0.2649 - val_accuracy: 0.8697\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2518 - accuracy: 0.8899 - val_loss: 0.2687 - val_accuracy: 0.8744\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2389 - accuracy: 0.8964 - val_loss: 0.2885 - val_accuracy: 0.8692\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.2548 - accuracy: 0.8900 - val_loss: 0.2700 - val_accuracy: 0.8791\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2405 - accuracy: 0.8952 - val_loss: 0.3490 - val_accuracy: 0.8413\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2449 - accuracy: 0.8946 - val_loss: 0.2879 - val_accuracy: 0.8585\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2450 - accuracy: 0.8920 - val_loss: 0.2920 - val_accuracy: 0.8476\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2348 - accuracy: 0.8995 - val_loss: 0.2629 - val_accuracy: 0.8761\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2266 - accuracy: 0.9053 - val_loss: 0.3058 - val_accuracy: 0.8574\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2191 - accuracy: 0.9071 - val_loss: 0.2986 - val_accuracy: 0.8557\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2155 - accuracy: 0.9098 - val_loss: 0.2706 - val_accuracy: 0.8744\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2184 - accuracy: 0.9083 - val_loss: 0.2717 - val_accuracy: 0.8744\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2070 - accuracy: 0.9105 - val_loss: 0.3270 - val_accuracy: 0.8434\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.2082 - accuracy: 0.9129 - val_loss: 0.2789 - val_accuracy: 0.8670\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 4s 13ms/step - loss: 0.2000 - accuracy: 0.9161 - val_loss: 0.2448 - val_accuracy: 0.8855\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1912 - accuracy: 0.9203 - val_loss: 0.2732 - val_accuracy: 0.8775\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1859 - accuracy: 0.9221 - val_loss: 0.3529 - val_accuracy: 0.8417\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.1938 - accuracy: 0.9195 - val_loss: 0.3072 - val_accuracy: 0.8625\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1881 - accuracy: 0.9217 - val_loss: 0.2856 - val_accuracy: 0.8744\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.1721 - accuracy: 0.9278 - val_loss: 0.2869 - val_accuracy: 0.8853\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1923 - accuracy: 0.9221 - val_loss: 0.3023 - val_accuracy: 0.8651\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1688 - accuracy: 0.9312 - val_loss: 0.2430 - val_accuracy: 0.8947\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1700 - accuracy: 0.9297 - val_loss: 0.2827 - val_accuracy: 0.8758\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1685 - accuracy: 0.9301 - val_loss: 0.2817 - val_accuracy: 0.8748\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1697 - accuracy: 0.9318 - val_loss: 0.2494 - val_accuracy: 0.8940\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1546 - accuracy: 0.9371 - val_loss: 0.3150 - val_accuracy: 0.8805\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1524 - accuracy: 0.9383 - val_loss: 0.2331 - val_accuracy: 0.9009\n",
      "Epoch 80/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1515 - accuracy: 0.9400 - val_loss: 0.2517 - val_accuracy: 0.8945\n",
      "Epoch 81/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.1466 - accuracy: 0.9412 - val_loss: 0.2466 - val_accuracy: 0.8964\n",
      "Epoch 82/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1569 - accuracy: 0.9379 - val_loss: 0.2214 - val_accuracy: 0.8981\n",
      "Epoch 83/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1424 - accuracy: 0.9437 - val_loss: 0.2643 - val_accuracy: 0.8895\n",
      "Epoch 84/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1451 - accuracy: 0.9411 - val_loss: 0.2564 - val_accuracy: 0.8949\n",
      "Epoch 85/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.1342 - accuracy: 0.9456 - val_loss: 0.2626 - val_accuracy: 0.9021\n",
      "Epoch 86/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.1305 - accuracy: 0.9474 - val_loss: 0.2252 - val_accuracy: 0.9051\n",
      "Epoch 87/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1219 - accuracy: 0.9517 - val_loss: 0.2720 - val_accuracy: 0.9030\n",
      "Epoch 88/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1348 - accuracy: 0.9460 - val_loss: 0.2555 - val_accuracy: 0.8985\n",
      "Epoch 89/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1329 - accuracy: 0.9472 - val_loss: 0.2501 - val_accuracy: 0.8943\n",
      "Epoch 90/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1174 - accuracy: 0.9529 - val_loss: 0.2610 - val_accuracy: 0.9007\n",
      "Epoch 91/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1406 - accuracy: 0.9457 - val_loss: 0.2729 - val_accuracy: 0.8992\n",
      "Epoch 92/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1190 - accuracy: 0.9530 - val_loss: 0.2211 - val_accuracy: 0.9163\n",
      "Epoch 93/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1216 - accuracy: 0.9520 - val_loss: 0.2323 - val_accuracy: 0.9122\n",
      "Epoch 94/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1284 - accuracy: 0.9494 - val_loss: 0.2640 - val_accuracy: 0.9004\n",
      "Epoch 95/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.1232 - accuracy: 0.9513 - val_loss: 0.2235 - val_accuracy: 0.9167\n",
      "Epoch 96/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1111 - accuracy: 0.9567 - val_loss: 0.3044 - val_accuracy: 0.8945\n",
      "Epoch 97/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1113 - accuracy: 0.9554 - val_loss: 0.2382 - val_accuracy: 0.9132\n",
      "Epoch 98/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1232 - accuracy: 0.9501 - val_loss: 0.1955 - val_accuracy: 0.9210\n",
      "Epoch 99/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1133 - accuracy: 0.9551 - val_loss: 0.2278 - val_accuracy: 0.9129\n",
      "Epoch 100/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0940 - accuracy: 0.9614 - val_loss: 0.2131 - val_accuracy: 0.9290\n",
      "Epoch 101/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1272 - accuracy: 0.9485 - val_loss: 0.2034 - val_accuracy: 0.9214\n",
      "Epoch 102/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0998 - accuracy: 0.9599 - val_loss: 0.3161 - val_accuracy: 0.9016\n",
      "Epoch 103/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1117 - accuracy: 0.9560 - val_loss: 0.2981 - val_accuracy: 0.8904\n",
      "Epoch 104/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.1018 - accuracy: 0.9593 - val_loss: 0.2817 - val_accuracy: 0.8959\n",
      "Epoch 105/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1167 - accuracy: 0.9549 - val_loss: 0.1780 - val_accuracy: 0.9324\n",
      "Epoch 106/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1024 - accuracy: 0.9606 - val_loss: 0.2155 - val_accuracy: 0.9274\n",
      "Epoch 107/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0909 - accuracy: 0.9654 - val_loss: 0.1982 - val_accuracy: 0.9281\n",
      "Epoch 108/500\n",
      "288/288 [==============================] - 4s 12ms/step - loss: 0.0932 - accuracy: 0.9642 - val_loss: 0.2655 - val_accuracy: 0.9094\n",
      "Epoch 109/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0908 - accuracy: 0.9647 - val_loss: 0.2580 - val_accuracy: 0.9170\n",
      "Epoch 110/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0980 - accuracy: 0.9620 - val_loss: 0.1974 - val_accuracy: 0.9246\n",
      "Epoch 111/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0881 - accuracy: 0.9644 - val_loss: 0.1902 - val_accuracy: 0.9345\n",
      "Epoch 112/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0880 - accuracy: 0.9662 - val_loss: 0.2485 - val_accuracy: 0.9130\n",
      "Epoch 113/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1127 - accuracy: 0.9561 - val_loss: 0.2273 - val_accuracy: 0.9191\n",
      "Epoch 114/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.0901 - accuracy: 0.9650 - val_loss: 0.1916 - val_accuracy: 0.9371\n",
      "Epoch 115/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0904 - accuracy: 0.9657 - val_loss: 0.2869 - val_accuracy: 0.9106\n",
      "Epoch 116/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0995 - accuracy: 0.9612 - val_loss: 0.2259 - val_accuracy: 0.9292\n",
      "Epoch 117/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0931 - accuracy: 0.9635 - val_loss: 0.2555 - val_accuracy: 0.9181\n",
      "Epoch 118/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1013 - accuracy: 0.9604 - val_loss: 0.2571 - val_accuracy: 0.8888\n",
      "Epoch 119/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0866 - accuracy: 0.9657 - val_loss: 0.2026 - val_accuracy: 0.9311\n",
      "Epoch 120/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0770 - accuracy: 0.9709 - val_loss: 0.2013 - val_accuracy: 0.9318\n",
      "Epoch 121/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0766 - accuracy: 0.9698 - val_loss: 0.1866 - val_accuracy: 0.9418\n",
      "Epoch 122/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0773 - accuracy: 0.9697 - val_loss: 0.3258 - val_accuracy: 0.8884\n",
      "Epoch 123/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1092 - accuracy: 0.9592 - val_loss: 0.2077 - val_accuracy: 0.9278\n",
      "Epoch 124/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0854 - accuracy: 0.9681 - val_loss: 0.1663 - val_accuracy: 0.9465\n",
      "Epoch 125/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0730 - accuracy: 0.9722 - val_loss: 0.2068 - val_accuracy: 0.9338\n",
      "Epoch 126/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0797 - accuracy: 0.9689 - val_loss: 0.2547 - val_accuracy: 0.9160\n",
      "Epoch 127/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0873 - accuracy: 0.9663 - val_loss: 0.2186 - val_accuracy: 0.9314\n",
      "Epoch 128/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0766 - accuracy: 0.9717 - val_loss: 0.2021 - val_accuracy: 0.9343\n",
      "Epoch 129/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0860 - accuracy: 0.9668 - val_loss: 0.2570 - val_accuracy: 0.9219\n",
      "Epoch 130/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0785 - accuracy: 0.9700 - val_loss: 0.2012 - val_accuracy: 0.9340\n",
      "Epoch 131/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.0761 - accuracy: 0.9713 - val_loss: 0.2353 - val_accuracy: 0.9318\n",
      "Epoch 132/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.0753 - accuracy: 0.9703 - val_loss: 0.2097 - val_accuracy: 0.9335\n",
      "Epoch 133/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0722 - accuracy: 0.9725 - val_loss: 0.1901 - val_accuracy: 0.9369\n",
      "Epoch 134/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0658 - accuracy: 0.9757 - val_loss: 0.2225 - val_accuracy: 0.9302\n",
      "Epoch 135/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0694 - accuracy: 0.9730 - val_loss: 0.2322 - val_accuracy: 0.9328\n",
      "Epoch 136/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0900 - accuracy: 0.9642 - val_loss: 0.1843 - val_accuracy: 0.9378\n",
      "Epoch 137/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1082 - accuracy: 0.9588 - val_loss: 0.1904 - val_accuracy: 0.9193\n",
      "Epoch 138/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0759 - accuracy: 0.9717 - val_loss: 0.2126 - val_accuracy: 0.9318\n",
      "Epoch 139/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0822 - accuracy: 0.9681 - val_loss: 0.2102 - val_accuracy: 0.9331\n",
      "Epoch 140/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0566 - accuracy: 0.9794 - val_loss: 0.3053 - val_accuracy: 0.9052\n",
      "Epoch 141/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0739 - accuracy: 0.9724 - val_loss: 0.2543 - val_accuracy: 0.9264\n",
      "Epoch 142/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0940 - accuracy: 0.9646 - val_loss: 0.1943 - val_accuracy: 0.9409\n",
      "Epoch 143/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0680 - accuracy: 0.9745 - val_loss: 0.1721 - val_accuracy: 0.9451\n",
      "Epoch 144/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0609 - accuracy: 0.9768 - val_loss: 0.1911 - val_accuracy: 0.9487\n",
      "Epoch 145/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0610 - accuracy: 0.9768 - val_loss: 0.2229 - val_accuracy: 0.9354\n",
      "Epoch 146/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0526 - accuracy: 0.9795 - val_loss: 0.2478 - val_accuracy: 0.9241\n",
      "Epoch 147/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0771 - accuracy: 0.9717 - val_loss: 0.2691 - val_accuracy: 0.9307\n",
      "Epoch 148/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.0845 - accuracy: 0.9679 - val_loss: 0.2003 - val_accuracy: 0.9378\n",
      "Epoch 149/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.0749 - accuracy: 0.9729 - val_loss: 0.2002 - val_accuracy: 0.9402\n",
      "Epoch 150/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.0527 - accuracy: 0.9803 - val_loss: 0.2673 - val_accuracy: 0.9259\n",
      "Epoch 151/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0442 - accuracy: 0.9839 - val_loss: 0.2318 - val_accuracy: 0.9389\n",
      "Epoch 152/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0684 - accuracy: 0.9737 - val_loss: 0.2533 - val_accuracy: 0.9195\n",
      "Epoch 153/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0507 - accuracy: 0.9809 - val_loss: 0.2751 - val_accuracy: 0.9212\n",
      "Epoch 154/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1172 - accuracy: 0.9557 - val_loss: 0.2762 - val_accuracy: 0.8917\n",
      "Epoch 155/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.1490 - accuracy: 0.9393 - val_loss: 0.1895 - val_accuracy: 0.9378\n",
      "Epoch 156/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0777 - accuracy: 0.9698 - val_loss: 0.1724 - val_accuracy: 0.9404\n",
      "Epoch 157/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0614 - accuracy: 0.9779 - val_loss: 0.1753 - val_accuracy: 0.9437\n",
      "Epoch 158/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0612 - accuracy: 0.9776 - val_loss: 0.2099 - val_accuracy: 0.9413\n",
      "Epoch 159/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0709 - accuracy: 0.9734 - val_loss: 0.2038 - val_accuracy: 0.9390\n",
      "Epoch 160/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.0622 - accuracy: 0.9764 - val_loss: 0.1776 - val_accuracy: 0.9427\n",
      "Epoch 161/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0520 - accuracy: 0.9809 - val_loss: 0.2756 - val_accuracy: 0.9307\n",
      "Epoch 162/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0676 - accuracy: 0.9750 - val_loss: 0.2028 - val_accuracy: 0.9409\n",
      "Epoch 163/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0720 - accuracy: 0.9732 - val_loss: 0.2120 - val_accuracy: 0.9380\n",
      "Epoch 164/500\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 0.9818Restoring model weights from the end of the best epoch: 144.\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.0487 - accuracy: 0.9814 - val_loss: 0.2485 - val_accuracy: 0.9245\n",
      "Epoch 164: early stopping\n",
      "Number of iterations 7\n",
      "F1-scores:  [0.7370486656200943, 0.7239884393063584, 0.8929321203638908, 0.6920152091254752, 0.7121024370095003, 0.6690251572327044, 0.8911764705882353]\n",
      "Average F1-Score 0.7597554998923227\n",
      "Std Dev F1-Score 0.08610120556558803\n",
      "Error bar F1-Score 0.032543196787056625\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 6s 12ms/step - loss: 0.5628 - accuracy: 0.7028 - val_loss: 0.4321 - val_accuracy: 0.8115\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.4166 - accuracy: 0.7973 - val_loss: 0.3793 - val_accuracy: 0.7937\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3899 - accuracy: 0.8137 - val_loss: 0.3430 - val_accuracy: 0.8368\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3781 - accuracy: 0.8228 - val_loss: 0.3660 - val_accuracy: 0.8140\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3719 - accuracy: 0.8270 - val_loss: 0.3928 - val_accuracy: 0.7985\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3737 - accuracy: 0.8243 - val_loss: 0.3587 - val_accuracy: 0.8202\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3669 - accuracy: 0.8305 - val_loss: 0.3128 - val_accuracy: 0.8507\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3538 - accuracy: 0.8367 - val_loss: 0.3442 - val_accuracy: 0.8375\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3552 - accuracy: 0.8381 - val_loss: 0.3607 - val_accuracy: 0.8185\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3535 - accuracy: 0.8335 - val_loss: 0.3061 - val_accuracy: 0.8630\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3742 - accuracy: 0.8285 - val_loss: 0.5601 - val_accuracy: 0.7584\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6121 - accuracy: 0.6999 - val_loss: 0.5613 - val_accuracy: 0.7584\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6103 - accuracy: 0.6999 - val_loss: 0.5610 - val_accuracy: 0.7584\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6090 - accuracy: 0.6999 - val_loss: 0.5435 - val_accuracy: 0.7584\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.5803 - accuracy: 0.6978 - val_loss: 0.4577 - val_accuracy: 0.7584\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.5725 - accuracy: 0.7008 - val_loss: 0.5587 - val_accuracy: 0.7584\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6094 - accuracy: 0.6999 - val_loss: 0.5494 - val_accuracy: 0.7584\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6043 - accuracy: 0.6999 - val_loss: 0.5199 - val_accuracy: 0.7584\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.5659 - accuracy: 0.6965 - val_loss: 0.4211 - val_accuracy: 0.7584\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.4552 - accuracy: 0.7593 - val_loss: 0.3269 - val_accuracy: 0.8483\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3994 - accuracy: 0.8066 - val_loss: 0.3516 - val_accuracy: 0.8204\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3547 - accuracy: 0.8363 - val_loss: 0.3202 - val_accuracy: 0.8569\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3418 - accuracy: 0.8450 - val_loss: 0.3812 - val_accuracy: 0.8193\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3342 - accuracy: 0.8509 - val_loss: 0.3066 - val_accuracy: 0.8628\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3321 - accuracy: 0.8522 - val_loss: 0.3326 - val_accuracy: 0.8429\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3100 - accuracy: 0.8605 - val_loss: 0.3368 - val_accuracy: 0.8420\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3044 - accuracy: 0.8644 - val_loss: 0.3211 - val_accuracy: 0.8548\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3132 - accuracy: 0.8627 - val_loss: 0.4112 - val_accuracy: 0.7985\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3104 - accuracy: 0.8574 - val_loss: 0.2971 - val_accuracy: 0.8673\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3099 - accuracy: 0.8603 - val_loss: 0.3198 - val_accuracy: 0.8535\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2977 - accuracy: 0.8657 - val_loss: 0.2884 - val_accuracy: 0.8607\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2872 - accuracy: 0.8684 - val_loss: 0.2810 - val_accuracy: 0.8644\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2832 - accuracy: 0.8706 - val_loss: 0.2632 - val_accuracy: 0.8791\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2788 - accuracy: 0.8707 - val_loss: 0.2732 - val_accuracy: 0.8696\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2748 - accuracy: 0.8723 - val_loss: 0.2733 - val_accuracy: 0.8758\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2683 - accuracy: 0.8754 - val_loss: 0.2663 - val_accuracy: 0.8692\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2645 - accuracy: 0.8785 - val_loss: 0.2676 - val_accuracy: 0.8746\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2668 - accuracy: 0.8769 - val_loss: 0.2466 - val_accuracy: 0.8831\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2681 - accuracy: 0.8761 - val_loss: 0.2593 - val_accuracy: 0.8858\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2929 - accuracy: 0.8650 - val_loss: 0.2658 - val_accuracy: 0.8761\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2638 - accuracy: 0.8793 - val_loss: 0.2644 - val_accuracy: 0.8722\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2620 - accuracy: 0.8797 - val_loss: 0.2654 - val_accuracy: 0.8779\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2560 - accuracy: 0.8820 - val_loss: 0.3471 - val_accuracy: 0.8425\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2736 - accuracy: 0.8761 - val_loss: 0.2399 - val_accuracy: 0.8876\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2630 - accuracy: 0.8797 - val_loss: 0.2441 - val_accuracy: 0.8777\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.2629 - accuracy: 0.8787 - val_loss: 0.2379 - val_accuracy: 0.8912\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2603 - accuracy: 0.8783 - val_loss: 0.2653 - val_accuracy: 0.8756\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2593 - accuracy: 0.8812 - val_loss: 0.2719 - val_accuracy: 0.8746\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2553 - accuracy: 0.8845 - val_loss: 0.2417 - val_accuracy: 0.8832\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2468 - accuracy: 0.8856 - val_loss: 0.2277 - val_accuracy: 0.8921\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.4988 - accuracy: 0.7634 - val_loss: 0.5478 - val_accuracy: 0.7584\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.5983 - accuracy: 0.6999 - val_loss: 0.4814 - val_accuracy: 0.7584\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.5505 - accuracy: 0.6984 - val_loss: 0.4276 - val_accuracy: 0.8091\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.4627 - accuracy: 0.7535 - val_loss: 0.3505 - val_accuracy: 0.8280\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.4059 - accuracy: 0.7977 - val_loss: 0.3189 - val_accuracy: 0.8438\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3937 - accuracy: 0.8071 - val_loss: 0.3296 - val_accuracy: 0.8455\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3889 - accuracy: 0.8114 - val_loss: 0.3292 - val_accuracy: 0.8384\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3788 - accuracy: 0.8182 - val_loss: 0.3050 - val_accuracy: 0.8464\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3655 - accuracy: 0.8250 - val_loss: 0.3130 - val_accuracy: 0.8491\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3485 - accuracy: 0.8353 - val_loss: 0.3869 - val_accuracy: 0.8039\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3431 - accuracy: 0.8377 - val_loss: 0.3374 - val_accuracy: 0.8192\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3433 - accuracy: 0.8380 - val_loss: 0.3636 - val_accuracy: 0.8124\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3364 - accuracy: 0.8448 - val_loss: 0.3147 - val_accuracy: 0.8460\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3281 - accuracy: 0.8482 - val_loss: 0.3292 - val_accuracy: 0.8406\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3624 - accuracy: 0.8327 - val_loss: 0.3713 - val_accuracy: 0.8134\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3433 - accuracy: 0.8408 - val_loss: 0.3547 - val_accuracy: 0.8160\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3248 - accuracy: 0.8491 - val_loss: 0.2946 - val_accuracy: 0.8526\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3405 - accuracy: 0.8410 - val_loss: 0.3024 - val_accuracy: 0.8510\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3283 - accuracy: 0.8504 - val_loss: 0.2979 - val_accuracy: 0.8540\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.3174 - accuracy: 0.8548Restoring model weights from the end of the best epoch: 50.\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3174 - accuracy: 0.8548 - val_loss: 0.3132 - val_accuracy: 0.8425\n",
      "Epoch 70: early stopping\n",
      "Number of iterations 8\n",
      "F1-scores:  [0.7370486656200943, 0.7239884393063584, 0.8929321203638908, 0.6920152091254752, 0.7121024370095003, 0.6690251572327044, 0.8911764705882353, 0.7764621456763544]\n",
      "Average F1-Score 0.7618438306153266\n",
      "Std Dev F1-Score 0.08072959975329487\n",
      "Error bar F1-Score 0.028542223714015318\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 6s 12ms/step - loss: 0.5551 - accuracy: 0.7040 - val_loss: 0.3886 - val_accuracy: 0.7868\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.4287 - accuracy: 0.7826 - val_loss: 0.3264 - val_accuracy: 0.8363\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.4153 - accuracy: 0.7931 - val_loss: 0.3024 - val_accuracy: 0.8507\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3903 - accuracy: 0.8120 - val_loss: 0.3103 - val_accuracy: 0.8477\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3977 - accuracy: 0.8051 - val_loss: 0.3941 - val_accuracy: 0.7904\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3775 - accuracy: 0.8192 - val_loss: 0.3478 - val_accuracy: 0.8328\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3741 - accuracy: 0.8221 - val_loss: 0.3286 - val_accuracy: 0.8373\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3742 - accuracy: 0.8208 - val_loss: 0.3311 - val_accuracy: 0.8403\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3599 - accuracy: 0.8324 - val_loss: 0.3149 - val_accuracy: 0.8462\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3590 - accuracy: 0.8341 - val_loss: 0.2940 - val_accuracy: 0.8526\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3527 - accuracy: 0.8354 - val_loss: 0.3668 - val_accuracy: 0.8159\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3365 - accuracy: 0.8461 - val_loss: 0.3033 - val_accuracy: 0.8587\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3350 - accuracy: 0.8495 - val_loss: 0.3282 - val_accuracy: 0.8354\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3297 - accuracy: 0.8480 - val_loss: 0.2894 - val_accuracy: 0.8571\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3300 - accuracy: 0.8507 - val_loss: 0.3135 - val_accuracy: 0.8664\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3510 - accuracy: 0.8401 - val_loss: 0.2891 - val_accuracy: 0.8609\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3142 - accuracy: 0.8582 - val_loss: 0.3681 - val_accuracy: 0.8190\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3089 - accuracy: 0.8634 - val_loss: 0.3285 - val_accuracy: 0.8393\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3208 - accuracy: 0.8565 - val_loss: 0.2878 - val_accuracy: 0.8638\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3004 - accuracy: 0.8670 - val_loss: 0.3644 - val_accuracy: 0.8287\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3050 - accuracy: 0.8628 - val_loss: 0.2944 - val_accuracy: 0.8649\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2988 - accuracy: 0.8662 - val_loss: 0.3889 - val_accuracy: 0.8069\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2959 - accuracy: 0.8685 - val_loss: 0.2799 - val_accuracy: 0.8689\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2888 - accuracy: 0.8724 - val_loss: 0.2795 - val_accuracy: 0.8671\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2929 - accuracy: 0.8710 - val_loss: 0.2899 - val_accuracy: 0.8661\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2944 - accuracy: 0.8694 - val_loss: 0.2838 - val_accuracy: 0.8635\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2886 - accuracy: 0.8739 - val_loss: 0.2935 - val_accuracy: 0.8654\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2768 - accuracy: 0.8750 - val_loss: 0.3100 - val_accuracy: 0.8630\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2752 - accuracy: 0.8779 - val_loss: 0.2897 - val_accuracy: 0.8701\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2962 - accuracy: 0.8676 - val_loss: 0.3079 - val_accuracy: 0.8434\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3855 - accuracy: 0.8146 - val_loss: 0.4665 - val_accuracy: 0.6870\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3968 - accuracy: 0.8073 - val_loss: 0.3342 - val_accuracy: 0.8316\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.5319 - accuracy: 0.7447 - val_loss: 0.5654 - val_accuracy: 0.7584\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6117 - accuracy: 0.6999 - val_loss: 0.5600 - val_accuracy: 0.7584\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6114 - accuracy: 0.6999 - val_loss: 0.5583 - val_accuracy: 0.7584\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6112 - accuracy: 0.6999 - val_loss: 0.5607 - val_accuracy: 0.7584\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6086 - accuracy: 0.6999 - val_loss: 0.5733 - val_accuracy: 0.7584\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6094 - accuracy: 0.6999 - val_loss: 0.5594 - val_accuracy: 0.7584\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.5751 - accuracy: 0.7010 - val_loss: 0.3466 - val_accuracy: 0.8654\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.4914 - accuracy: 0.7601 - val_loss: 0.5794 - val_accuracy: 0.7584\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6114 - accuracy: 0.6999 - val_loss: 0.5613 - val_accuracy: 0.7584\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6114 - accuracy: 0.6999 - val_loss: 0.5601 - val_accuracy: 0.7584\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6113 - accuracy: 0.6999 - val_loss: 0.5591 - val_accuracy: 0.7584\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6112 - accuracy: 0.6999 - val_loss: 0.5581 - val_accuracy: 0.7584\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6113 - accuracy: 0.6999 - val_loss: 0.5566 - val_accuracy: 0.7584\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6113 - accuracy: 0.6999 - val_loss: 0.5629 - val_accuracy: 0.7584\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6116 - accuracy: 0.6999 - val_loss: 0.5613 - val_accuracy: 0.7584\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6113 - accuracy: 0.6999 - val_loss: 0.5623 - val_accuracy: 0.7584\n",
      "Epoch 49/500\n",
      "286/288 [============================>.] - ETA: 0s - loss: 0.6115 - accuracy: 0.6995Restoring model weights from the end of the best epoch: 29.\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.6112 - accuracy: 0.6999 - val_loss: 0.5593 - val_accuracy: 0.7584\n",
      "Epoch 49: early stopping\n",
      "Number of iterations 9\n",
      "F1-scores:  [0.7370486656200943, 0.7239884393063584, 0.8929321203638908, 0.6920152091254752, 0.7121024370095003, 0.6690251572327044, 0.8911764705882353, 0.7764621456763544, 0.7033227848101266]\n",
      "Average F1-Score 0.7553414921925266\n",
      "Std Dev F1-Score 0.07830306888272164\n",
      "Error bar F1-Score 0.026101022960907213\n",
      "Epoch 1/500\n",
      "288/288 [==============================] - 7s 13ms/step - loss: 0.5835 - accuracy: 0.6983 - val_loss: 0.3722 - val_accuracy: 0.7793\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.4172 - accuracy: 0.7921 - val_loss: 0.4137 - val_accuracy: 0.7864\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.4010 - accuracy: 0.8066 - val_loss: 0.3558 - val_accuracy: 0.8218\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.4206 - accuracy: 0.7929 - val_loss: 0.3315 - val_accuracy: 0.8363\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3963 - accuracy: 0.8085 - val_loss: 0.3239 - val_accuracy: 0.8342\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3759 - accuracy: 0.8253 - val_loss: 0.3187 - val_accuracy: 0.8491\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3720 - accuracy: 0.8266 - val_loss: 0.3095 - val_accuracy: 0.8467\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3749 - accuracy: 0.8215 - val_loss: 0.3334 - val_accuracy: 0.8280\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3672 - accuracy: 0.8283 - val_loss: 0.3360 - val_accuracy: 0.8424\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3532 - accuracy: 0.8372 - val_loss: 0.3219 - val_accuracy: 0.8543\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3617 - accuracy: 0.8309 - val_loss: 0.3178 - val_accuracy: 0.8470\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3431 - accuracy: 0.8429 - val_loss: 0.3635 - val_accuracy: 0.8174\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3297 - accuracy: 0.8491 - val_loss: 0.3281 - val_accuracy: 0.8552\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3329 - accuracy: 0.8485 - val_loss: 0.2915 - val_accuracy: 0.8604\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3280 - accuracy: 0.8537 - val_loss: 0.3587 - val_accuracy: 0.8270\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3318 - accuracy: 0.8499 - val_loss: 0.4064 - val_accuracy: 0.7890\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3173 - accuracy: 0.8594 - val_loss: 0.3025 - val_accuracy: 0.8649\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3170 - accuracy: 0.8589 - val_loss: 0.2991 - val_accuracy: 0.8614\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3142 - accuracy: 0.8584 - val_loss: 0.3000 - val_accuracy: 0.8694\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3027 - accuracy: 0.8646 - val_loss: 0.3687 - val_accuracy: 0.8294\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3087 - accuracy: 0.8611 - val_loss: 0.2889 - val_accuracy: 0.8595\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.2992 - accuracy: 0.8691 - val_loss: 0.3094 - val_accuracy: 0.8642\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3060 - accuracy: 0.8649 - val_loss: 0.3199 - val_accuracy: 0.8585\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3006 - accuracy: 0.8675 - val_loss: 0.3239 - val_accuracy: 0.8588\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.2888 - accuracy: 0.8734 - val_loss: 0.2719 - val_accuracy: 0.8732\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3067 - accuracy: 0.8653 - val_loss: 0.3377 - val_accuracy: 0.8438\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2949 - accuracy: 0.8694 - val_loss: 0.2944 - val_accuracy: 0.8616\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2909 - accuracy: 0.8702 - val_loss: 0.3052 - val_accuracy: 0.8690\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.3186 - accuracy: 0.8588 - val_loss: 0.2976 - val_accuracy: 0.8602\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2886 - accuracy: 0.8734 - val_loss: 0.2884 - val_accuracy: 0.8739\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3072 - accuracy: 0.8654 - val_loss: 0.3036 - val_accuracy: 0.8703\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2872 - accuracy: 0.8748 - val_loss: 0.2935 - val_accuracy: 0.8701\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2816 - accuracy: 0.8776 - val_loss: 0.2950 - val_accuracy: 0.8761\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2761 - accuracy: 0.8782 - val_loss: 0.2806 - val_accuracy: 0.8729\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.3026 - accuracy: 0.8643 - val_loss: 0.2937 - val_accuracy: 0.8651\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2733 - accuracy: 0.8817 - val_loss: 0.2799 - val_accuracy: 0.8767\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2809 - accuracy: 0.8787 - val_loss: 0.2940 - val_accuracy: 0.8758\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2797 - accuracy: 0.8802 - val_loss: 0.2690 - val_accuracy: 0.8858\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2699 - accuracy: 0.8838 - val_loss: 0.2954 - val_accuracy: 0.8670\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.2659 - accuracy: 0.8845 - val_loss: 0.2743 - val_accuracy: 0.8871\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2548 - accuracy: 0.8876 - val_loss: 0.2905 - val_accuracy: 0.8614\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2532 - accuracy: 0.8924 - val_loss: 0.2410 - val_accuracy: 0.8878\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.2702 - accuracy: 0.8825 - val_loss: 0.2430 - val_accuracy: 0.8878\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2320 - accuracy: 0.9021 - val_loss: 0.3059 - val_accuracy: 0.8619\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2592 - accuracy: 0.8927 - val_loss: 0.2880 - val_accuracy: 0.8644\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2348 - accuracy: 0.9039 - val_loss: 0.3043 - val_accuracy: 0.8642\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2236 - accuracy: 0.9078 - val_loss: 0.2797 - val_accuracy: 0.8869\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2254 - accuracy: 0.9082 - val_loss: 0.3512 - val_accuracy: 0.8590\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2241 - accuracy: 0.9126 - val_loss: 0.2821 - val_accuracy: 0.8879\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2117 - accuracy: 0.9151 - val_loss: 0.2271 - val_accuracy: 0.8954\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1955 - accuracy: 0.9209 - val_loss: 0.2716 - val_accuracy: 0.8890\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1850 - accuracy: 0.9249 - val_loss: 0.2532 - val_accuracy: 0.8950\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2001 - accuracy: 0.9160 - val_loss: 0.2231 - val_accuracy: 0.9058\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.1705 - accuracy: 0.9309 - val_loss: 0.2207 - val_accuracy: 0.9047\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1909 - accuracy: 0.9212 - val_loss: 0.1993 - val_accuracy: 0.9087\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1517 - accuracy: 0.9383 - val_loss: 0.1920 - val_accuracy: 0.9208\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1648 - accuracy: 0.9313 - val_loss: 0.2200 - val_accuracy: 0.8995\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1420 - accuracy: 0.9440 - val_loss: 0.1689 - val_accuracy: 0.9343\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.1474 - accuracy: 0.9404 - val_loss: 0.1924 - val_accuracy: 0.9191\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2516 - accuracy: 0.8893 - val_loss: 0.2007 - val_accuracy: 0.9099\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1895 - accuracy: 0.9191 - val_loss: 0.1936 - val_accuracy: 0.9136\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1657 - accuracy: 0.9306 - val_loss: 0.1802 - val_accuracy: 0.9266\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1575 - accuracy: 0.9368 - val_loss: 0.2681 - val_accuracy: 0.8742\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1616 - accuracy: 0.9338 - val_loss: 0.1544 - val_accuracy: 0.9333\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1477 - accuracy: 0.9407 - val_loss: 0.1609 - val_accuracy: 0.9361\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1374 - accuracy: 0.9465 - val_loss: 0.1506 - val_accuracy: 0.9375\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1403 - accuracy: 0.9445 - val_loss: 0.1426 - val_accuracy: 0.9456\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1408 - accuracy: 0.9445 - val_loss: 0.1680 - val_accuracy: 0.9328\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1518 - accuracy: 0.9368 - val_loss: 0.2922 - val_accuracy: 0.8928\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1375 - accuracy: 0.9460 - val_loss: 0.1626 - val_accuracy: 0.9318\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1397 - accuracy: 0.9450 - val_loss: 0.1730 - val_accuracy: 0.9248\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1168 - accuracy: 0.9553 - val_loss: 0.1696 - val_accuracy: 0.9269\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1207 - accuracy: 0.9532 - val_loss: 0.1485 - val_accuracy: 0.9378\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2487 - accuracy: 0.8929 - val_loss: 0.3041 - val_accuracy: 0.8580\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.2960 - accuracy: 0.8711 - val_loss: 0.2590 - val_accuracy: 0.8824\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2650 - accuracy: 0.8861 - val_loss: 0.2433 - val_accuracy: 0.8904\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2407 - accuracy: 0.8946 - val_loss: 0.2241 - val_accuracy: 0.9020\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 3s 12ms/step - loss: 0.2302 - accuracy: 0.9014 - val_loss: 0.2516 - val_accuracy: 0.8838\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2302 - accuracy: 0.8995 - val_loss: 0.2390 - val_accuracy: 0.8905\n",
      "Epoch 80/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2183 - accuracy: 0.9071 - val_loss: 0.2666 - val_accuracy: 0.8836\n",
      "Epoch 81/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2139 - accuracy: 0.9075 - val_loss: 0.3256 - val_accuracy: 0.8521\n",
      "Epoch 82/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2137 - accuracy: 0.9071 - val_loss: 0.2506 - val_accuracy: 0.8897\n",
      "Epoch 83/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2042 - accuracy: 0.9128 - val_loss: 0.2339 - val_accuracy: 0.8999\n",
      "Epoch 84/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.1985 - accuracy: 0.9163 - val_loss: 0.2245 - val_accuracy: 0.9006\n",
      "Epoch 85/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2049 - accuracy: 0.9125 - val_loss: 0.2312 - val_accuracy: 0.9014\n",
      "Epoch 86/500\n",
      "288/288 [==============================] - 3s 10ms/step - loss: 0.2012 - accuracy: 0.9128 - val_loss: 0.2478 - val_accuracy: 0.8921\n",
      "Epoch 87/500\n",
      "284/288 [============================>.] - ETA: 0s - loss: 0.1946 - accuracy: 0.9176Restoring model weights from the end of the best epoch: 67.\n",
      "288/288 [==============================] - 3s 11ms/step - loss: 0.1942 - accuracy: 0.9176 - val_loss: 0.2291 - val_accuracy: 0.8999\n",
      "Epoch 87: early stopping\n",
      "Number of iterations 10\n",
      "F1-scores:  [0.7370486656200943, 0.7239884393063584, 0.8929321203638908, 0.6920152091254752, 0.7121024370095003, 0.6690251572327044, 0.8911764705882353, 0.7764621456763544, 0.7033227848101266, 0.8837037037037037]\n",
      "Average F1-Score 0.7681777133436443\n",
      "Std Dev F1-Score 0.08367287910530291\n",
      "Error bar F1-Score 0.026459687635666897\n"
     ]
    }
   ],
   "source": [
    "###Collect F-Score 10 times\n",
    "import sklearn\n",
    "from tqdm.notebook import tqdm\n",
    "def calc_f1_score(X_train_scaled,X_test_scaled,y_train,y_test,earlystop):\n",
    "  classifier = Sequential()\n",
    "  classifier.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train_scaled.shape[1], X_train_scaled.shape[2])))\n",
    "  classifier.add(LSTM(units = 50))\n",
    "  classifier.add(Dense(units = 1,activation='sigmoid'))\n",
    "  classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  classifier.fit(X_train_scaled, y_train[:,0], epochs = 500, batch_size = 64,validation_data=(X_test_scaled,y_test[:,0]),callbacks=[earlystop])\n",
    "  y_pred = classifier.predict(X_test_scaled)\n",
    "  y_pred= (y_pred>=0.5).astype(int)\n",
    "  return(sklearn.metrics.f1_score(y_test[:,0],y_pred))\n",
    "\n",
    "f1_score_list=[]\n",
    "for i in tqdm(range(10)):\n",
    "  f1_score_list=f1_score_list+[calc_f1_score(X_train_scaled,X_test_scaled,y_train,y_test,earlystop)]\n",
    "  print(\"Number of iterations\",len(f1_score_list))\n",
    "  print(\"F1-scores: \",f1_score_list)\n",
    "  print(\"Average F1-Score\",np.mean(f1_score_list))\n",
    "  print(\"Std Dev F1-Score\",np.std(f1_score_list))\n",
    "  print(\"Error bar F1-Score\",np.std(f1_score_list)/np.sqrt(len(f1_score_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average F1-Score 0.7681777133436443\n",
    "# Std Dev F1-Score 0.08367287910530291\n",
    "# Error bar F1-Score 0.026459687635666897"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_1d_exp2_exp5.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "197a74f4926f48eab466660ba2d246b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_be7ff47877574840be1fe75ff41dbf0f",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ab7637e2aff747f9aedf606a77831e4a",
      "tabbable": null,
      "tooltip": null,
      "value": 10
     }
    },
    "35ae94fa3a87481089d6c92aa9e27846": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_e47b4e05737d423b94897b6d77a1f1b1",
      "placeholder": "",
      "style": "IPY_MODEL_3fed207e2b7a404189d7bcfe01ad05a9",
      "tabbable": null,
      "tooltip": null,
      "value": "100%"
     }
    },
    "3fed207e2b7a404189d7bcfe01ad05a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "6c8ee637c9e64eff9e47a182c625c8bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "79cb1d63b93847a5b756d62e82b37c90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8520147f92884f0ebcbb37158cd48e9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c3c8d64fcfd4af28110f2407e46814e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_35ae94fa3a87481089d6c92aa9e27846",
       "IPY_MODEL_197a74f4926f48eab466660ba2d246b6",
       "IPY_MODEL_e2447e8a24b046efa52d3adfd3aee81e"
      ],
      "layout": "IPY_MODEL_79cb1d63b93847a5b756d62e82b37c90",
      "tabbable": null,
      "tooltip": null
     }
    },
    "ab7637e2aff747f9aedf606a77831e4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "be7ff47877574840be1fe75ff41dbf0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2447e8a24b046efa52d3adfd3aee81e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_8520147f92884f0ebcbb37158cd48e9c",
      "placeholder": "",
      "style": "IPY_MODEL_6c8ee637c9e64eff9e47a182c625c8bc",
      "tabbable": null,
      "tooltip": null,
      "value": " 10/10 [37:28&lt;00:00, 235.06s/it]"
     }
    },
    "e47b4e05737d423b94897b6d77a1f1b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
