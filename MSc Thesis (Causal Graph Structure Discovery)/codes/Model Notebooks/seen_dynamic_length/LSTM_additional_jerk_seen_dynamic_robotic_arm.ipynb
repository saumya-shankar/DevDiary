{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JYsWwiwnPzi",
    "outputId": "89a9a867-948c-4bf1-92d8-b165670623be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 17 12:09:08 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdNIB899nhlq",
    "outputId": "6b14512c-cf9c-4d52-9a2a-8fcb2d01885d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#mounting google drive on colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfSazzTdnmaM"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXN_d9Evntel"
   },
   "outputs": [],
   "source": [
    "X_train=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_X_trainv7_exp1_exp5_strat.npy\")\n",
    "y_train=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_y_trainv7_exp1_exp5_strat.npy\").astype(int)\n",
    "\n",
    "X_test=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_X_testv7_exp1_exp5_strat.npy\")\n",
    "y_test=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_y_testv7_exp1_exp5_strat.npy\").astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iuFwFqd2z7QP"
   },
   "outputs": [],
   "source": [
    "# X_train=X_train+np.random.choice([-1,1],X_train.shape)\n",
    "# X_test=X_test+np.random.choice([-1,1],X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ieiDjU3Lp1B9"
   },
   "outputs": [],
   "source": [
    "X_train_1d=np.gradient(X_train,axis=1)\n",
    "X_test_1d=np.gradient(X_test,axis=1)\n",
    "\n",
    "X_train=np.dstack([X_train,X_train_1d])\n",
    "X_test=np.dstack([X_test,X_test_1d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14wUAUDwp5OU",
    "outputId": "ad16ea25-19f9-4d0e-e23d-966690c9fd4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21346, 50, 8)\n",
      "(2851, 50, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YROkPvblKocM"
   },
   "outputs": [],
   "source": [
    "def custom_scaler(X, range=(0, 1),min=None,max=None):\n",
    "    mi, ma = range\n",
    "    if(min==None):\n",
    "      min=X.min()\n",
    "      max=X.max()\n",
    "      print(\"\\nTrain_Scaling:- min=\",min,\" max=\",max)\n",
    "    X_std = (X - min) / (max - min)\n",
    "    X_scaled = X_std * (ma - mi) + mi\n",
    "    return min,max,X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JceKGdin-e6",
    "outputId": "1c67ec12-b5a9-427e-f007-e030503e9698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train_Scaling:- min= -28.708703327621013  max= 37.07106781186548\n",
      "\n",
      "Train_Scaling:- min= -33.71032582929608  max= 32.1558468622422\n",
      "\n",
      "Train_Scaling:- min= -12.320254626359059  max= 14.385756524143293\n",
      "\n",
      "Train_Scaling:- min= -25.40645604165462  max= 17.0059508424483\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "#X_train contains 8 signals x1,x2,y1,y2,x1d,2d,y1d,y2d\n",
    "X_train_scaled=copy.copy(X_train)\n",
    "X_test_scaled=copy.copy(X_test)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,0:2]=custom_scaler(X_train_scaled[:,:,0:2],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,0:2]=custom_scaler(X_test_scaled[:,:,0:2],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,2:4]=custom_scaler(X_train_scaled[:,:,2:4],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,2:4]=custom_scaler(X_test_scaled[:,:,2:4],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,4:6]=custom_scaler(X_train_scaled[:,:,4:6],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,4:6]=custom_scaler(X_test_scaled[:,:,4:6],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,6:8]=custom_scaler(X_train_scaled[:,:,6:8],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,6:8]=custom_scaler(X_test_scaled[:,:,6:8],range=(0,1),min=min_temp,max=max_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8CMIO_ToBr9"
   },
   "outputs": [],
   "source": [
    "# Part 2 - Building the RNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Initialising the RNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "classifier.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train_scaled.shape[1], X_train_scaled.shape[2])))\n",
    "#regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "classifier.add(LSTM(units = 50))\n",
    "#regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1,activation='sigmoid'))\n",
    "\n",
    "# Compiling the RNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQ_atROOpG9T"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./drive/MyDrive/LSTM_1d_exp1_exp5.h5\",\n",
    "                             monitor=\"val_accuracy\",\n",
    "                             mode=\"max\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', # value being monitored for improvement\n",
    "                          min_delta = 0, #Abs value and is the min change required before we stop\n",
    "                          patience = 20, #Number of epochs we wait before stopping \n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True) #keeps the best weigths once stopped\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop,checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcUvZBOYoFNC",
    "outputId": "0e260f6b-127c-4685-def7-4d0a9cf31745"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.5570 - accuracy: 0.7001\n",
      "Epoch 1: val_accuracy improved from -inf to 0.71905, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 12s 12ms/step - loss: 0.5560 - accuracy: 0.6998 - val_loss: 0.4663 - val_accuracy: 0.7190\n",
      "Epoch 2/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.4130 - accuracy: 0.7836\n",
      "Epoch 2: val_accuracy improved from 0.71905 to 0.81901, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4130 - accuracy: 0.7836 - val_loss: 0.3762 - val_accuracy: 0.8190\n",
      "Epoch 3/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.3746 - accuracy: 0.8142\n",
      "Epoch 3: val_accuracy improved from 0.81901 to 0.82182, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3746 - accuracy: 0.8143 - val_loss: 0.3623 - val_accuracy: 0.8218\n",
      "Epoch 4/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.3667 - accuracy: 0.8197\n",
      "Epoch 4: val_accuracy did not improve from 0.82182\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3673 - accuracy: 0.8195 - val_loss: 0.4141 - val_accuracy: 0.7931\n",
      "Epoch 5/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.3602 - accuracy: 0.8258\n",
      "Epoch 5: val_accuracy improved from 0.82182 to 0.83795, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3606 - accuracy: 0.8257 - val_loss: 0.3439 - val_accuracy: 0.8380\n",
      "Epoch 6/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.3520 - accuracy: 0.8293\n",
      "Epoch 6: val_accuracy did not improve from 0.83795\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3520 - accuracy: 0.8293 - val_loss: 0.3665 - val_accuracy: 0.8190\n",
      "Epoch 7/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.3455 - accuracy: 0.8347\n",
      "Epoch 7: val_accuracy did not improve from 0.83795\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3455 - accuracy: 0.8348 - val_loss: 0.3363 - val_accuracy: 0.8373\n",
      "Epoch 8/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.3449 - accuracy: 0.8337\n",
      "Epoch 8: val_accuracy did not improve from 0.83795\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3449 - accuracy: 0.8337 - val_loss: 0.3581 - val_accuracy: 0.8190\n",
      "Epoch 9/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.3301 - accuracy: 0.8443\n",
      "Epoch 9: val_accuracy improved from 0.83795 to 0.84742, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3299 - accuracy: 0.8443 - val_loss: 0.3318 - val_accuracy: 0.8474\n",
      "Epoch 10/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.3337 - accuracy: 0.8441\n",
      "Epoch 10: val_accuracy did not improve from 0.84742\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3345 - accuracy: 0.8433 - val_loss: 0.3415 - val_accuracy: 0.8306\n",
      "Epoch 11/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.3308 - accuracy: 0.8432\n",
      "Epoch 11: val_accuracy improved from 0.84742 to 0.84882, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3308 - accuracy: 0.8432 - val_loss: 0.3353 - val_accuracy: 0.8488\n",
      "Epoch 12/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.3214 - accuracy: 0.8480\n",
      "Epoch 12: val_accuracy improved from 0.84882 to 0.85654, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3208 - accuracy: 0.8484 - val_loss: 0.3054 - val_accuracy: 0.8565\n",
      "Epoch 13/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.3106 - accuracy: 0.8554\n",
      "Epoch 13: val_accuracy did not improve from 0.85654\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3108 - accuracy: 0.8553 - val_loss: 0.3028 - val_accuracy: 0.8551\n",
      "Epoch 14/200\n",
      "327/334 [============================>.] - ETA: 0s - loss: 0.3245 - accuracy: 0.8503\n",
      "Epoch 14: val_accuracy did not improve from 0.85654\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3244 - accuracy: 0.8502 - val_loss: 0.3274 - val_accuracy: 0.8467\n",
      "Epoch 15/200\n",
      "327/334 [============================>.] - ETA: 0s - loss: 0.3046 - accuracy: 0.8605\n",
      "Epoch 15: val_accuracy did not improve from 0.85654\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3033 - accuracy: 0.8612 - val_loss: 0.3735 - val_accuracy: 0.8323\n",
      "Epoch 16/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.3013 - accuracy: 0.8613\n",
      "Epoch 16: val_accuracy improved from 0.85654 to 0.86636, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.3012 - accuracy: 0.8614 - val_loss: 0.2951 - val_accuracy: 0.8664\n",
      "Epoch 17/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.2925 - accuracy: 0.8655\n",
      "Epoch 17: val_accuracy did not improve from 0.86636\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2921 - accuracy: 0.8657 - val_loss: 0.3247 - val_accuracy: 0.8436\n",
      "Epoch 18/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.2904 - accuracy: 0.8645\n",
      "Epoch 18: val_accuracy did not improve from 0.86636\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2906 - accuracy: 0.8641 - val_loss: 0.3371 - val_accuracy: 0.8495\n",
      "Epoch 19/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.2858 - accuracy: 0.8668\n",
      "Epoch 19: val_accuracy did not improve from 0.86636\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2856 - accuracy: 0.8668 - val_loss: 0.2956 - val_accuracy: 0.8558\n",
      "Epoch 20/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.2840 - accuracy: 0.8676\n",
      "Epoch 20: val_accuracy did not improve from 0.86636\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2842 - accuracy: 0.8675 - val_loss: 0.3119 - val_accuracy: 0.8562\n",
      "Epoch 21/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.2696 - accuracy: 0.8728\n",
      "Epoch 21: val_accuracy improved from 0.86636 to 0.87864, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.2698 - accuracy: 0.8727 - val_loss: 0.2735 - val_accuracy: 0.8786\n",
      "Epoch 22/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.2669 - accuracy: 0.8748\n",
      "Epoch 22: val_accuracy did not improve from 0.87864\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2673 - accuracy: 0.8745 - val_loss: 0.3457 - val_accuracy: 0.8478\n",
      "Epoch 23/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.2600 - accuracy: 0.8811\n",
      "Epoch 23: val_accuracy did not improve from 0.87864\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2603 - accuracy: 0.8812 - val_loss: 0.3723 - val_accuracy: 0.8253\n",
      "Epoch 24/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2555 - accuracy: 0.8823\n",
      "Epoch 24: val_accuracy improved from 0.87864 to 0.89618, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.2555 - accuracy: 0.8823 - val_loss: 0.2341 - val_accuracy: 0.8962\n",
      "Epoch 25/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2383 - accuracy: 0.8924\n",
      "Epoch 25: val_accuracy did not improve from 0.89618\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2383 - accuracy: 0.8924 - val_loss: 0.3213 - val_accuracy: 0.8544\n",
      "Epoch 26/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.2356 - accuracy: 0.8926\n",
      "Epoch 26: val_accuracy did not improve from 0.89618\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2356 - accuracy: 0.8926 - val_loss: 0.2390 - val_accuracy: 0.8927\n",
      "Epoch 27/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.2360 - accuracy: 0.8925\n",
      "Epoch 27: val_accuracy improved from 0.89618 to 0.89723, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.2363 - accuracy: 0.8924 - val_loss: 0.2251 - val_accuracy: 0.8972\n",
      "Epoch 28/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.2272 - accuracy: 0.8960\n",
      "Epoch 28: val_accuracy did not improve from 0.89723\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2271 - accuracy: 0.8960 - val_loss: 0.2397 - val_accuracy: 0.8902\n",
      "Epoch 29/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.2390 - accuracy: 0.8914\n",
      "Epoch 29: val_accuracy improved from 0.89723 to 0.90565, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2389 - accuracy: 0.8916 - val_loss: 0.2182 - val_accuracy: 0.9056\n",
      "Epoch 30/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.2196 - accuracy: 0.9006\n",
      "Epoch 30: val_accuracy did not improve from 0.90565\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2195 - accuracy: 0.9007 - val_loss: 0.2344 - val_accuracy: 0.8934\n",
      "Epoch 31/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.2269 - accuracy: 0.8995\n",
      "Epoch 31: val_accuracy did not improve from 0.90565\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2270 - accuracy: 0.8994 - val_loss: 0.2791 - val_accuracy: 0.8723\n",
      "Epoch 32/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.2144 - accuracy: 0.9052\n",
      "Epoch 32: val_accuracy did not improve from 0.90565\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2141 - accuracy: 0.9053 - val_loss: 0.2245 - val_accuracy: 0.8976\n",
      "Epoch 33/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.2161 - accuracy: 0.9024\n",
      "Epoch 33: val_accuracy did not improve from 0.90565\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2162 - accuracy: 0.9024 - val_loss: 0.2142 - val_accuracy: 0.8983\n",
      "Epoch 34/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.2105 - accuracy: 0.9072\n",
      "Epoch 34: val_accuracy did not improve from 0.90565\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2104 - accuracy: 0.9071 - val_loss: 0.2181 - val_accuracy: 0.9021\n",
      "Epoch 35/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.2156 - accuracy: 0.9024\n",
      "Epoch 35: val_accuracy did not improve from 0.90565\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2153 - accuracy: 0.9026 - val_loss: 0.2346 - val_accuracy: 0.8937\n",
      "Epoch 36/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2040 - accuracy: 0.9077\n",
      "Epoch 36: val_accuracy did not improve from 0.90565\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2040 - accuracy: 0.9077 - val_loss: 0.2596 - val_accuracy: 0.8874\n",
      "Epoch 37/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1968 - accuracy: 0.9139\n",
      "Epoch 37: val_accuracy improved from 0.90565 to 0.91407, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1967 - accuracy: 0.9139 - val_loss: 0.2016 - val_accuracy: 0.9141\n",
      "Epoch 38/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1963 - accuracy: 0.9126\n",
      "Epoch 38: val_accuracy did not improve from 0.91407\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1961 - accuracy: 0.9125 - val_loss: 0.2547 - val_accuracy: 0.8853\n",
      "Epoch 39/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1962 - accuracy: 0.9131\n",
      "Epoch 39: val_accuracy improved from 0.91407 to 0.91722, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1962 - accuracy: 0.9131 - val_loss: 0.1930 - val_accuracy: 0.9172\n",
      "Epoch 40/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1901 - accuracy: 0.9164\n",
      "Epoch 40: val_accuracy did not improve from 0.91722\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1909 - accuracy: 0.9159 - val_loss: 0.2406 - val_accuracy: 0.8909\n",
      "Epoch 41/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.1894 - accuracy: 0.9163\n",
      "Epoch 41: val_accuracy did not improve from 0.91722\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1892 - accuracy: 0.9164 - val_loss: 0.2019 - val_accuracy: 0.9109\n",
      "Epoch 42/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1935 - accuracy: 0.9142\n",
      "Epoch 42: val_accuracy did not improve from 0.91722\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1936 - accuracy: 0.9141 - val_loss: 0.2026 - val_accuracy: 0.9071\n",
      "Epoch 43/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.1787 - accuracy: 0.9225\n",
      "Epoch 43: val_accuracy did not improve from 0.91722\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1786 - accuracy: 0.9226 - val_loss: 0.1995 - val_accuracy: 0.9155\n",
      "Epoch 44/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1871 - accuracy: 0.9183\n",
      "Epoch 44: val_accuracy did not improve from 0.91722\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1872 - accuracy: 0.9183 - val_loss: 0.2009 - val_accuracy: 0.9120\n",
      "Epoch 45/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.1749 - accuracy: 0.9251\n",
      "Epoch 45: val_accuracy improved from 0.91722 to 0.92248, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1754 - accuracy: 0.9247 - val_loss: 0.1864 - val_accuracy: 0.9225\n",
      "Epoch 46/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1739 - accuracy: 0.9237\n",
      "Epoch 46: val_accuracy did not improve from 0.92248\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1734 - accuracy: 0.9240 - val_loss: 0.2071 - val_accuracy: 0.9113\n",
      "Epoch 47/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.1723 - accuracy: 0.9257\n",
      "Epoch 47: val_accuracy did not improve from 0.92248\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1727 - accuracy: 0.9255 - val_loss: 0.1925 - val_accuracy: 0.9162\n",
      "Epoch 48/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1803 - accuracy: 0.9227\n",
      "Epoch 48: val_accuracy did not improve from 0.92248\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1803 - accuracy: 0.9227 - val_loss: 0.2137 - val_accuracy: 0.9074\n",
      "Epoch 49/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1717 - accuracy: 0.9246\n",
      "Epoch 49: val_accuracy did not improve from 0.92248\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1717 - accuracy: 0.9246 - val_loss: 0.2239 - val_accuracy: 0.9035\n",
      "Epoch 50/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1664 - accuracy: 0.9289\n",
      "Epoch 50: val_accuracy improved from 0.92248 to 0.92634, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1664 - accuracy: 0.9289 - val_loss: 0.1790 - val_accuracy: 0.9263\n",
      "Epoch 51/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.1617 - accuracy: 0.9327\n",
      "Epoch 51: val_accuracy did not improve from 0.92634\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1622 - accuracy: 0.9324 - val_loss: 0.2438 - val_accuracy: 0.8885\n",
      "Epoch 52/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.1579 - accuracy: 0.9325\n",
      "Epoch 52: val_accuracy did not improve from 0.92634\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1577 - accuracy: 0.9328 - val_loss: 0.1955 - val_accuracy: 0.9211\n",
      "Epoch 53/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1596 - accuracy: 0.9322\n",
      "Epoch 53: val_accuracy did not improve from 0.92634\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1596 - accuracy: 0.9322 - val_loss: 0.2014 - val_accuracy: 0.9165\n",
      "Epoch 54/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.1626 - accuracy: 0.9304\n",
      "Epoch 54: val_accuracy did not improve from 0.92634\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1635 - accuracy: 0.9303 - val_loss: 0.1929 - val_accuracy: 0.9190\n",
      "Epoch 55/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.1480 - accuracy: 0.9362\n",
      "Epoch 55: val_accuracy did not improve from 0.92634\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1486 - accuracy: 0.9359 - val_loss: 0.1806 - val_accuracy: 0.9235\n",
      "Epoch 56/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1474 - accuracy: 0.9379\n",
      "Epoch 56: val_accuracy did not improve from 0.92634\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1475 - accuracy: 0.9379 - val_loss: 0.2006 - val_accuracy: 0.9186\n",
      "Epoch 57/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.1472 - accuracy: 0.9380\n",
      "Epoch 57: val_accuracy improved from 0.92634 to 0.93055, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1471 - accuracy: 0.9380 - val_loss: 0.1679 - val_accuracy: 0.9306\n",
      "Epoch 58/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1368 - accuracy: 0.9419\n",
      "Epoch 58: val_accuracy did not improve from 0.93055\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1368 - accuracy: 0.9419 - val_loss: 0.1851 - val_accuracy: 0.9267\n",
      "Epoch 59/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1412 - accuracy: 0.9399\n",
      "Epoch 59: val_accuracy improved from 0.93055 to 0.93336, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1410 - accuracy: 0.9399 - val_loss: 0.1689 - val_accuracy: 0.9334\n",
      "Epoch 60/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.9463\n",
      "Epoch 60: val_accuracy improved from 0.93336 to 0.93546, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1294 - accuracy: 0.9463 - val_loss: 0.1532 - val_accuracy: 0.9355\n",
      "Epoch 61/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1338 - accuracy: 0.9448\n",
      "Epoch 61: val_accuracy improved from 0.93546 to 0.93932, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1338 - accuracy: 0.9448 - val_loss: 0.1568 - val_accuracy: 0.9393\n",
      "Epoch 62/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1393 - accuracy: 0.9439\n",
      "Epoch 62: val_accuracy did not improve from 0.93932\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1395 - accuracy: 0.9439 - val_loss: 0.2048 - val_accuracy: 0.9155\n",
      "Epoch 63/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.1312 - accuracy: 0.9457\n",
      "Epoch 63: val_accuracy did not improve from 0.93932\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1326 - accuracy: 0.9453 - val_loss: 0.2046 - val_accuracy: 0.9193\n",
      "Epoch 64/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1317 - accuracy: 0.9461\n",
      "Epoch 64: val_accuracy did not improve from 0.93932\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1317 - accuracy: 0.9461 - val_loss: 0.2705 - val_accuracy: 0.8951\n",
      "Epoch 65/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.1201 - accuracy: 0.9502\n",
      "Epoch 65: val_accuracy did not improve from 0.93932\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1201 - accuracy: 0.9502 - val_loss: 0.1610 - val_accuracy: 0.9365\n",
      "Epoch 66/200\n",
      "327/334 [============================>.] - ETA: 0s - loss: 0.1170 - accuracy: 0.9528\n",
      "Epoch 66: val_accuracy improved from 0.93932 to 0.93967, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1172 - accuracy: 0.9528 - val_loss: 0.1500 - val_accuracy: 0.9397\n",
      "Epoch 67/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.1387 - accuracy: 0.9432\n",
      "Epoch 67: val_accuracy did not improve from 0.93967\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1388 - accuracy: 0.9431 - val_loss: 0.1692 - val_accuracy: 0.9376\n",
      "Epoch 68/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1170 - accuracy: 0.9527\n",
      "Epoch 68: val_accuracy did not improve from 0.93967\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1169 - accuracy: 0.9528 - val_loss: 0.1580 - val_accuracy: 0.9355\n",
      "Epoch 69/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1069 - accuracy: 0.9565\n",
      "Epoch 69: val_accuracy improved from 0.93967 to 0.95054, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1066 - accuracy: 0.9566 - val_loss: 0.1317 - val_accuracy: 0.9505\n",
      "Epoch 70/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.1206 - accuracy: 0.9519\n",
      "Epoch 70: val_accuracy did not improve from 0.95054\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1207 - accuracy: 0.9519 - val_loss: 0.1593 - val_accuracy: 0.9407\n",
      "Epoch 71/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1101 - accuracy: 0.9562\n",
      "Epoch 71: val_accuracy did not improve from 0.95054\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1108 - accuracy: 0.9560 - val_loss: 0.1962 - val_accuracy: 0.9291\n",
      "Epoch 72/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1388 - accuracy: 0.9403\n",
      "Epoch 72: val_accuracy did not improve from 0.95054\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1388 - accuracy: 0.9403 - val_loss: 0.1897 - val_accuracy: 0.9211\n",
      "Epoch 73/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.1322 - accuracy: 0.9449\n",
      "Epoch 73: val_accuracy did not improve from 0.95054\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1325 - accuracy: 0.9447 - val_loss: 0.1784 - val_accuracy: 0.9256\n",
      "Epoch 74/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1135 - accuracy: 0.9544\n",
      "Epoch 74: val_accuracy did not improve from 0.95054\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1134 - accuracy: 0.9545 - val_loss: 0.1420 - val_accuracy: 0.9467\n",
      "Epoch 75/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1031 - accuracy: 0.9569\n",
      "Epoch 75: val_accuracy did not improve from 0.95054\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1030 - accuracy: 0.9570 - val_loss: 0.2199 - val_accuracy: 0.9155\n",
      "Epoch 76/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.9583\n",
      "Epoch 76: val_accuracy did not improve from 0.95054\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1027 - accuracy: 0.9583 - val_loss: 0.2260 - val_accuracy: 0.9148\n",
      "Epoch 77/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 0.9578\n",
      "Epoch 77: val_accuracy did not improve from 0.95054\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1048 - accuracy: 0.9578 - val_loss: 0.1559 - val_accuracy: 0.9400\n",
      "Epoch 78/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.0996 - accuracy: 0.9608\n",
      "Epoch 78: val_accuracy improved from 0.95054 to 0.95265, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0997 - accuracy: 0.9608 - val_loss: 0.1223 - val_accuracy: 0.9526\n",
      "Epoch 79/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.0972 - accuracy: 0.9624\n",
      "Epoch 79: val_accuracy did not improve from 0.95265\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0971 - accuracy: 0.9623 - val_loss: 0.1442 - val_accuracy: 0.9491\n",
      "Epoch 80/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.0920 - accuracy: 0.9636\n",
      "Epoch 80: val_accuracy did not improve from 0.95265\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0920 - accuracy: 0.9638 - val_loss: 0.1507 - val_accuracy: 0.9425\n",
      "Epoch 81/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.0959 - accuracy: 0.9622\n",
      "Epoch 81: val_accuracy did not improve from 0.95265\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0959 - accuracy: 0.9621 - val_loss: 0.1359 - val_accuracy: 0.9481\n",
      "Epoch 82/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.0988 - accuracy: 0.9607\n",
      "Epoch 82: val_accuracy did not improve from 0.95265\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0984 - accuracy: 0.9609 - val_loss: 0.1485 - val_accuracy: 0.9411\n",
      "Epoch 83/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1104 - accuracy: 0.9549\n",
      "Epoch 83: val_accuracy improved from 0.95265 to 0.95686, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.1102 - accuracy: 0.9549 - val_loss: 0.1264 - val_accuracy: 0.9569\n",
      "Epoch 84/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.0899 - accuracy: 0.9649\n",
      "Epoch 84: val_accuracy did not improve from 0.95686\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0895 - accuracy: 0.9651 - val_loss: 0.1278 - val_accuracy: 0.9523\n",
      "Epoch 85/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.0789 - accuracy: 0.9686\n",
      "Epoch 85: val_accuracy did not improve from 0.95686\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0787 - accuracy: 0.9688 - val_loss: 0.1301 - val_accuracy: 0.9530\n",
      "Epoch 86/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.0796 - accuracy: 0.9674\n",
      "Epoch 86: val_accuracy did not improve from 0.95686\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0795 - accuracy: 0.9675 - val_loss: 0.1732 - val_accuracy: 0.9362\n",
      "Epoch 87/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.0897 - accuracy: 0.9649\n",
      "Epoch 87: val_accuracy did not improve from 0.95686\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0899 - accuracy: 0.9648 - val_loss: 0.1554 - val_accuracy: 0.9453\n",
      "Epoch 88/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.0801 - accuracy: 0.9684\n",
      "Epoch 88: val_accuracy improved from 0.95686 to 0.96422, saving model to ./drive/MyDrive/LSTM_1d_exp1_exp5.h5\n",
      "334/334 [==============================] - 3s 9ms/step - loss: 0.0798 - accuracy: 0.9685 - val_loss: 0.1059 - val_accuracy: 0.9642\n",
      "Epoch 89/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.0740 - accuracy: 0.9725\n",
      "Epoch 89: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0742 - accuracy: 0.9724 - val_loss: 0.1510 - val_accuracy: 0.9449\n",
      "Epoch 90/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.0770 - accuracy: 0.9687\n",
      "Epoch 90: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0778 - accuracy: 0.9683 - val_loss: 0.1152 - val_accuracy: 0.9611\n",
      "Epoch 91/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0765 - accuracy: 0.9693\n",
      "Epoch 91: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0770 - accuracy: 0.9690 - val_loss: 0.1509 - val_accuracy: 0.9432\n",
      "Epoch 92/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1119 - accuracy: 0.9569\n",
      "Epoch 92: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1119 - accuracy: 0.9570 - val_loss: 0.1458 - val_accuracy: 0.9477\n",
      "Epoch 93/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.9717\n",
      "Epoch 93: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0727 - accuracy: 0.9717 - val_loss: 0.1728 - val_accuracy: 0.9411\n",
      "Epoch 94/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.0679 - accuracy: 0.9737\n",
      "Epoch 94: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0679 - accuracy: 0.9736 - val_loss: 0.1142 - val_accuracy: 0.9628\n",
      "Epoch 95/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9747\n",
      "Epoch 95: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0637 - accuracy: 0.9747 - val_loss: 0.1302 - val_accuracy: 0.9530\n",
      "Epoch 96/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.9747\n",
      "Epoch 96: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0673 - accuracy: 0.9747 - val_loss: 0.1168 - val_accuracy: 0.9597\n",
      "Epoch 97/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0835 - accuracy: 0.9680\n",
      "Epoch 97: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0840 - accuracy: 0.9678 - val_loss: 0.1568 - val_accuracy: 0.9400\n",
      "Epoch 98/200\n",
      "327/334 [============================>.] - ETA: 0s - loss: 0.0578 - accuracy: 0.9774\n",
      "Epoch 98: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0579 - accuracy: 0.9773 - val_loss: 0.1113 - val_accuracy: 0.9614\n",
      "Epoch 99/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.0728 - accuracy: 0.9745\n",
      "Epoch 99: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0723 - accuracy: 0.9747 - val_loss: 0.1062 - val_accuracy: 0.9628\n",
      "Epoch 100/200\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.0761 - accuracy: 0.9708\n",
      "Epoch 100: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0761 - accuracy: 0.9710 - val_loss: 0.1117 - val_accuracy: 0.9604\n",
      "Epoch 101/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.0600 - accuracy: 0.9779\n",
      "Epoch 101: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0602 - accuracy: 0.9777 - val_loss: 0.1423 - val_accuracy: 0.9488\n",
      "Epoch 102/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.0679 - accuracy: 0.9753\n",
      "Epoch 102: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0676 - accuracy: 0.9754 - val_loss: 0.1292 - val_accuracy: 0.9533\n",
      "Epoch 103/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0851 - accuracy: 0.9681\n",
      "Epoch 103: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0850 - accuracy: 0.9681 - val_loss: 0.1228 - val_accuracy: 0.9551\n",
      "Epoch 104/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0570 - accuracy: 0.9783\n",
      "Epoch 104: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0570 - accuracy: 0.9783 - val_loss: 0.1633 - val_accuracy: 0.9432\n",
      "Epoch 105/200\n",
      "327/334 [============================>.] - ETA: 0s - loss: 0.0660 - accuracy: 0.9758\n",
      "Epoch 105: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0660 - accuracy: 0.9757 - val_loss: 0.1248 - val_accuracy: 0.9551\n",
      "Epoch 106/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9631\n",
      "Epoch 106: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0941 - accuracy: 0.9628 - val_loss: 0.2101 - val_accuracy: 0.9169\n",
      "Epoch 107/200\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.1001 - accuracy: 0.9587\n",
      "Epoch 107: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0996 - accuracy: 0.9590 - val_loss: 0.1315 - val_accuracy: 0.9583\n",
      "Epoch 108/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0626 - accuracy: 0.9749Restoring model weights from the end of the best epoch: 88.\n",
      "\n",
      "Epoch 108: val_accuracy did not improve from 0.96422\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0625 - accuracy: 0.9750 - val_loss: 0.1247 - val_accuracy: 0.9586\n",
      "Epoch 108: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "history=classifier.fit(X_train_scaled, y_train[:,0], epochs = 200, batch_size = 64,validation_data=(X_test_scaled,y_test[:,0]),callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fr7pCHoBrcKa",
    "outputId": "ada3070a-b844-43f7-f1cc-a0d00d32c548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 4ms/step - loss: 0.1059 - accuracy: 0.9642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10585641115903854, 0.9642230868339539]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(X_test_scaled,y_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "QZVd0A1ostvR",
    "outputId": "079bb648-6221-4561-da40-01fc70fd0c44"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def display_learning_curves(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    ax1.plot(history.history[\"loss\"])\n",
    "    ax1.plot(history.history[\"val_loss\"])\n",
    "    ax1.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "    ax2.plot(history.history[\"accuracy\"])\n",
    "    ax2.plot(history.history[\"val_accuracy\"])\n",
    "    ax2.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "display_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ND2WPhO1pRNH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0VKJswYTc4O"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "temp=tf.keras.models.load_model(\"./drive/MyDrive/LSTM_1d_exp1_exp5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9bgdUJETn0g",
    "outputId": "dba5ea47-4a16-4edc-eb01-7c854dfc225c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2851/2851 [==============================] - 10s 3ms/step - loss: 0.1059 - accuracy: 0.9642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10585609078407288, 0.9642230868339539]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.evaluate(X_test_scaled, y_test[:,0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbTiJwqAZhcj",
    "outputId": "1753ad9b-7719-4b53-a950-e35fa12af235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 1s 4ms/step - loss: 0.1059 - accuracy: 0.9642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10585641115903854, 0.9642230868339539]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.evaluate(X_test_scaled, y_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RD4YF1AuT2tn"
   },
   "outputs": [],
   "source": [
    "y_pred = temp.predict(X_test_scaled)\n",
    "y_pred= (y_pred>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjx-DjHUWp52",
    "outputId": "3ce255cb-b9c5-4770-e6a3-e61f82a33a86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ipevqB9rXDeW"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rSeo2ltUXffg",
    "outputId": "08ebc409-2739-463b-906f-7b12c2f85562"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1960,   71],\n",
       "       [  31,  789]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eM1TBa2IXtj2",
    "outputId": "3d1ed35b-1507-4242-b719-61204cacd295"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9642230796211856"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9V2DcARYNq6",
    "outputId": "0772285f-5766-4006-9eb0-7fba2fc43293"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9392857142857143"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwAjeUnMYQ1O",
    "outputId": "dd91f71d-2aec-4c94-fe13-de4bc3838481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      2031\n",
      "           1       0.92      0.96      0.94       820\n",
      "\n",
      "    accuracy                           0.96      2851\n",
      "   macro avg       0.95      0.96      0.96      2851\n",
      "weighted avg       0.97      0.96      0.96      2851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test[:,0],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a4fb98cb7ad44dcaab82a0e5e478ac60",
      "b9c461e673bb42139c8e08ff463de087",
      "63b18f94224e4e6ea7c378d806e82d57",
      "1a0d186baabf4a068249de2af6a3eeed",
      "a143768c684f4817935bbfbf3f56a689",
      "0e1634033f2f4857b41b95a8dbb8c09b",
      "97a22bb53a2140a2a4b92690e0dd227b",
      "9e9fd4647a9f4192b54444ccf1a55a0d",
      "88190705dfe64d36af4b378e765f35a7",
      "f06691ba85684ee19f3ae768666ec3db",
      "9a64d884ed674eb38eaeb49a6e0d2600"
     ]
    },
    "id": "fY_iXz4GvFVl",
    "outputId": "702e3181-51b8-440b-c4e5-4135e1a3d167"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fb98cb7ad44dcaab82a0e5e478ac60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 10ms/step - loss: 0.5492 - accuracy: 0.7111 - val_loss: 0.5871 - val_accuracy: 0.7124\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5195 - accuracy: 0.7082 - val_loss: 0.4018 - val_accuracy: 0.7927\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4056 - accuracy: 0.7951 - val_loss: 0.3768 - val_accuracy: 0.8092\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3770 - accuracy: 0.8148 - val_loss: 0.3553 - val_accuracy: 0.8260\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3760 - accuracy: 0.8179 - val_loss: 0.3516 - val_accuracy: 0.8309\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3624 - accuracy: 0.8250 - val_loss: 0.3692 - val_accuracy: 0.8169\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3595 - accuracy: 0.8245 - val_loss: 0.3779 - val_accuracy: 0.8074\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3538 - accuracy: 0.8285 - val_loss: 0.3512 - val_accuracy: 0.8299\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3446 - accuracy: 0.8349 - val_loss: 0.3434 - val_accuracy: 0.8373\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3386 - accuracy: 0.8375 - val_loss: 0.3835 - val_accuracy: 0.8141\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3316 - accuracy: 0.8432 - val_loss: 0.3442 - val_accuracy: 0.8295\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3236 - accuracy: 0.8462 - val_loss: 0.3484 - val_accuracy: 0.8446\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3349 - accuracy: 0.8403 - val_loss: 0.3298 - val_accuracy: 0.8502\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3140 - accuracy: 0.8540 - val_loss: 0.3184 - val_accuracy: 0.8513\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3191 - accuracy: 0.8492 - val_loss: 0.2907 - val_accuracy: 0.8643\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3172 - accuracy: 0.8522 - val_loss: 0.4055 - val_accuracy: 0.7913\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3045 - accuracy: 0.8598 - val_loss: 0.3188 - val_accuracy: 0.8604\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2987 - accuracy: 0.8640 - val_loss: 0.3180 - val_accuracy: 0.8551\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2960 - accuracy: 0.8629 - val_loss: 0.2790 - val_accuracy: 0.8758\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2933 - accuracy: 0.8650 - val_loss: 0.2974 - val_accuracy: 0.8611\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2898 - accuracy: 0.8667 - val_loss: 0.2859 - val_accuracy: 0.8674\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2823 - accuracy: 0.8677 - val_loss: 0.3353 - val_accuracy: 0.8306\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2723 - accuracy: 0.8746 - val_loss: 0.2705 - val_accuracy: 0.8772\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2847 - accuracy: 0.8698 - val_loss: 0.4142 - val_accuracy: 0.8053\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5930 - accuracy: 0.7154 - val_loss: 0.5936 - val_accuracy: 0.7124\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4272 - accuracy: 0.7830 - val_loss: 0.4002 - val_accuracy: 0.8099\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3751 - accuracy: 0.8210 - val_loss: 0.3565 - val_accuracy: 0.8439\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3608 - accuracy: 0.8287 - val_loss: 0.3299 - val_accuracy: 0.8474\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3408 - accuracy: 0.8391 - val_loss: 0.3168 - val_accuracy: 0.8576\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3368 - accuracy: 0.8450 - val_loss: 0.3778 - val_accuracy: 0.8208\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3424 - accuracy: 0.8389 - val_loss: 0.3254 - val_accuracy: 0.8527\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3531 - accuracy: 0.8325 - val_loss: 0.3389 - val_accuracy: 0.8425\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3427 - accuracy: 0.8406 - val_loss: 0.3750 - val_accuracy: 0.7938\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3100 - accuracy: 0.8582 - val_loss: 0.3046 - val_accuracy: 0.8583\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4039 - accuracy: 0.7994 - val_loss: 0.4023 - val_accuracy: 0.8113\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3596 - accuracy: 0.8328 - val_loss: 0.3169 - val_accuracy: 0.8643\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3207 - accuracy: 0.8524 - val_loss: 0.3110 - val_accuracy: 0.8646\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3231 - accuracy: 0.8496 - val_loss: 0.3387 - val_accuracy: 0.8313\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4858 - accuracy: 0.7600 - val_loss: 0.4657 - val_accuracy: 0.7124\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4654 - accuracy: 0.7075 - val_loss: 0.4695 - val_accuracy: 0.7194\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4504 - accuracy: 0.7161 - val_loss: 0.4686 - val_accuracy: 0.7240\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4444 - accuracy: 0.7174 - val_loss: 0.4501 - val_accuracy: 0.7212\n",
      "Epoch 43/500\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.4411 - accuracy: 0.7234Restoring model weights from the end of the best epoch: 23.\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4410 - accuracy: 0.7237 - val_loss: 0.4436 - val_accuracy: 0.7538\n",
      "Epoch 43: early stopping\n",
      "Number of iterations 1\n",
      "F1-scores:  [0.7836835599505563]\n",
      "Average F1-Score 0.7836835599505563\n",
      "Std Dev F1-Score 0.0\n",
      "Error bar F1-Score 0.0\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 10ms/step - loss: 0.5123 - accuracy: 0.7286 - val_loss: 0.4031 - val_accuracy: 0.7871\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3963 - accuracy: 0.7989 - val_loss: 0.4259 - val_accuracy: 0.7629\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3868 - accuracy: 0.8078 - val_loss: 0.4104 - val_accuracy: 0.7878\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3798 - accuracy: 0.8113 - val_loss: 0.3764 - val_accuracy: 0.8137\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3667 - accuracy: 0.8206 - val_loss: 0.3543 - val_accuracy: 0.8341\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3647 - accuracy: 0.8234 - val_loss: 0.3626 - val_accuracy: 0.8243\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3655 - accuracy: 0.8198 - val_loss: 0.4000 - val_accuracy: 0.7938\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3541 - accuracy: 0.8270 - val_loss: 0.3545 - val_accuracy: 0.8201\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3423 - accuracy: 0.8365 - val_loss: 0.3648 - val_accuracy: 0.8288\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3426 - accuracy: 0.8373 - val_loss: 0.3776 - val_accuracy: 0.8067\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3326 - accuracy: 0.8430 - val_loss: 0.3816 - val_accuracy: 0.8106\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3264 - accuracy: 0.8452 - val_loss: 0.4482 - val_accuracy: 0.7590\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3250 - accuracy: 0.8481 - val_loss: 0.2966 - val_accuracy: 0.8646\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3242 - accuracy: 0.8506 - val_loss: 0.4461 - val_accuracy: 0.7646\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3258 - accuracy: 0.8463 - val_loss: 0.3571 - val_accuracy: 0.8299\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3113 - accuracy: 0.8592 - val_loss: 0.2868 - val_accuracy: 0.8713\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3087 - accuracy: 0.8568 - val_loss: 0.3151 - val_accuracy: 0.8509\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3013 - accuracy: 0.8625 - val_loss: 0.3392 - val_accuracy: 0.8436\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3391 - accuracy: 0.8462 - val_loss: 0.6158 - val_accuracy: 0.7124\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4348 - accuracy: 0.7771 - val_loss: 0.3709 - val_accuracy: 0.8313\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3739 - accuracy: 0.8231 - val_loss: 0.3465 - val_accuracy: 0.8408\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3666 - accuracy: 0.8284 - val_loss: 0.3456 - val_accuracy: 0.8436\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3581 - accuracy: 0.8332 - val_loss: 0.5177 - val_accuracy: 0.7187\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3545 - accuracy: 0.8372 - val_loss: 0.3315 - val_accuracy: 0.8502\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3338 - accuracy: 0.8477 - val_loss: 0.3169 - val_accuracy: 0.8615\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3313 - accuracy: 0.8495 - val_loss: 0.4560 - val_accuracy: 0.7983\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3564 - accuracy: 0.8355 - val_loss: 0.3098 - val_accuracy: 0.8618\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3393 - accuracy: 0.8439 - val_loss: 0.3780 - val_accuracy: 0.8043\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3329 - accuracy: 0.8488 - val_loss: 0.3130 - val_accuracy: 0.8576\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3145 - accuracy: 0.8589 - val_loss: 0.2955 - val_accuracy: 0.8688\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3312 - accuracy: 0.8492 - val_loss: 0.3890 - val_accuracy: 0.8123\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3157 - accuracy: 0.8589 - val_loss: 0.2812 - val_accuracy: 0.8692\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3495 - accuracy: 0.8353 - val_loss: 0.4968 - val_accuracy: 0.7029\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3254 - accuracy: 0.8498 - val_loss: 0.3535 - val_accuracy: 0.8467\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3064 - accuracy: 0.8622 - val_loss: 0.3009 - val_accuracy: 0.8727\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2944 - accuracy: 0.8660 - val_loss: 0.3443 - val_accuracy: 0.8474\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3498 - accuracy: 0.8337 - val_loss: 0.3406 - val_accuracy: 0.8450\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3243 - accuracy: 0.8512 - val_loss: 0.3159 - val_accuracy: 0.8555\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3006 - accuracy: 0.8655 - val_loss: 0.3036 - val_accuracy: 0.8699\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3065 - accuracy: 0.8620 - val_loss: 0.2926 - val_accuracy: 0.8692\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2915 - accuracy: 0.8689 - val_loss: 0.2736 - val_accuracy: 0.8776\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2928 - accuracy: 0.8680 - val_loss: 0.2783 - val_accuracy: 0.8762\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2964 - accuracy: 0.8662 - val_loss: 0.3282 - val_accuracy: 0.8404\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3128 - accuracy: 0.8576 - val_loss: 0.2834 - val_accuracy: 0.8748\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2981 - accuracy: 0.8681 - val_loss: 0.3126 - val_accuracy: 0.8537\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2887 - accuracy: 0.8713 - val_loss: 0.3157 - val_accuracy: 0.8523\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2837 - accuracy: 0.8728 - val_loss: 0.3038 - val_accuracy: 0.8600\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3448 - accuracy: 0.8276 - val_loss: 0.3482 - val_accuracy: 0.8355\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3242 - accuracy: 0.8528 - val_loss: 0.3703 - val_accuracy: 0.8436\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3119 - accuracy: 0.8612 - val_loss: 0.2936 - val_accuracy: 0.8741\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3042 - accuracy: 0.8656 - val_loss: 0.3012 - val_accuracy: 0.8639\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2923 - accuracy: 0.8694 - val_loss: 0.2791 - val_accuracy: 0.8762\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2857 - accuracy: 0.8740 - val_loss: 0.2773 - val_accuracy: 0.8741\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2928 - accuracy: 0.8692 - val_loss: 0.3172 - val_accuracy: 0.8478\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3097 - accuracy: 0.8549 - val_loss: 0.3278 - val_accuracy: 0.8506\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3126 - accuracy: 0.8596 - val_loss: 0.2892 - val_accuracy: 0.8692\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2940 - accuracy: 0.8693 - val_loss: 0.2798 - val_accuracy: 0.8730\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2852 - accuracy: 0.8703 - val_loss: 0.2789 - val_accuracy: 0.8776\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2904 - accuracy: 0.8652 - val_loss: 0.3157 - val_accuracy: 0.8608\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3081 - accuracy: 0.8567 - val_loss: 0.3486 - val_accuracy: 0.8239\n",
      "Epoch 61/500\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.2901 - accuracy: 0.8675Restoring model weights from the end of the best epoch: 41.\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2902 - accuracy: 0.8674 - val_loss: 0.3386 - val_accuracy: 0.8509\n",
      "Epoch 61: early stopping\n",
      "Number of iterations 2\n",
      "F1-scores:  [0.7836835599505563, 0.7772814294830889]\n",
      "Average F1-Score 0.7804824947168225\n",
      "Std Dev F1-Score 0.003201065233733702\n",
      "Error bar F1-Score 0.0022634949337936015\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 10ms/step - loss: 0.5364 - accuracy: 0.7125 - val_loss: 0.4490 - val_accuracy: 0.7124\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4358 - accuracy: 0.7560 - val_loss: 0.4655 - val_accuracy: 0.7808\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3926 - accuracy: 0.8076 - val_loss: 0.3765 - val_accuracy: 0.8155\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3779 - accuracy: 0.8166 - val_loss: 0.3591 - val_accuracy: 0.8267\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3617 - accuracy: 0.8305 - val_loss: 0.3705 - val_accuracy: 0.8257\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3689 - accuracy: 0.8263 - val_loss: 0.3781 - val_accuracy: 0.8039\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3633 - accuracy: 0.8279 - val_loss: 0.3623 - val_accuracy: 0.8257\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3667 - accuracy: 0.8255 - val_loss: 0.3452 - val_accuracy: 0.8348\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3639 - accuracy: 0.8270 - val_loss: 0.3452 - val_accuracy: 0.8390\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3571 - accuracy: 0.8337 - val_loss: 0.3723 - val_accuracy: 0.8323\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3483 - accuracy: 0.8395 - val_loss: 0.3308 - val_accuracy: 0.8478\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3529 - accuracy: 0.8376 - val_loss: 0.3353 - val_accuracy: 0.8450\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3431 - accuracy: 0.8396 - val_loss: 0.3382 - val_accuracy: 0.8481\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3382 - accuracy: 0.8428 - val_loss: 0.3387 - val_accuracy: 0.8397\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3429 - accuracy: 0.8402 - val_loss: 0.3424 - val_accuracy: 0.8516\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3303 - accuracy: 0.8461 - val_loss: 0.4402 - val_accuracy: 0.7759\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3436 - accuracy: 0.8367 - val_loss: 0.3245 - val_accuracy: 0.8429\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3227 - accuracy: 0.8515 - val_loss: 0.3538 - val_accuracy: 0.8394\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3159 - accuracy: 0.8543 - val_loss: 0.3168 - val_accuracy: 0.8481\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3395 - accuracy: 0.8441 - val_loss: 0.3226 - val_accuracy: 0.8548\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3160 - accuracy: 0.8517 - val_loss: 0.3193 - val_accuracy: 0.8562\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3302 - accuracy: 0.8484 - val_loss: 0.3079 - val_accuracy: 0.8618\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3164 - accuracy: 0.8558 - val_loss: 0.2973 - val_accuracy: 0.8660\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3096 - accuracy: 0.8597 - val_loss: 0.2873 - val_accuracy: 0.8755\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3092 - accuracy: 0.8619 - val_loss: 0.3584 - val_accuracy: 0.8302\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2988 - accuracy: 0.8618 - val_loss: 0.2894 - val_accuracy: 0.8699\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3127 - accuracy: 0.8564 - val_loss: 0.3258 - val_accuracy: 0.8537\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3163 - accuracy: 0.8514 - val_loss: 0.4116 - val_accuracy: 0.8246\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3003 - accuracy: 0.8636 - val_loss: 0.2812 - val_accuracy: 0.8783\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2955 - accuracy: 0.8670 - val_loss: 0.2947 - val_accuracy: 0.8758\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2904 - accuracy: 0.8678 - val_loss: 0.2881 - val_accuracy: 0.8653\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2948 - accuracy: 0.8657 - val_loss: 0.3358 - val_accuracy: 0.8485\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3067 - accuracy: 0.8609 - val_loss: 0.2829 - val_accuracy: 0.8751\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2925 - accuracy: 0.8682 - val_loss: 0.2846 - val_accuracy: 0.8765\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2927 - accuracy: 0.8676 - val_loss: 0.4479 - val_accuracy: 0.7790\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3235 - accuracy: 0.8515 - val_loss: 0.3198 - val_accuracy: 0.8481\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2924 - accuracy: 0.8672 - val_loss: 0.3653 - val_accuracy: 0.8264\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2959 - accuracy: 0.8699 - val_loss: 0.3330 - val_accuracy: 0.8478\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3127 - accuracy: 0.8514 - val_loss: 0.4820 - val_accuracy: 0.7120\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5192 - accuracy: 0.7291 - val_loss: 0.4282 - val_accuracy: 0.7762\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4100 - accuracy: 0.7860 - val_loss: 0.3748 - val_accuracy: 0.8173\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3770 - accuracy: 0.8095 - val_loss: 0.3499 - val_accuracy: 0.8316\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3638 - accuracy: 0.8215 - val_loss: 0.3565 - val_accuracy: 0.8215\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3529 - accuracy: 0.8289 - val_loss: 0.3617 - val_accuracy: 0.8337\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3457 - accuracy: 0.8337 - val_loss: 0.3429 - val_accuracy: 0.8292\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3417 - accuracy: 0.8355 - val_loss: 0.4090 - val_accuracy: 0.7987\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3370 - accuracy: 0.8386 - val_loss: 0.3213 - val_accuracy: 0.8593\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3368 - accuracy: 0.8416 - val_loss: 0.3325 - val_accuracy: 0.8394\n",
      "Epoch 49/500\n",
      "329/334 [============================>.] - ETA: 0s - loss: 0.3291 - accuracy: 0.8474Restoring model weights from the end of the best epoch: 29.\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3287 - accuracy: 0.8477 - val_loss: 0.3556 - val_accuracy: 0.8306\n",
      "Epoch 49: early stopping\n",
      "Number of iterations 3\n",
      "F1-scores:  [0.7836835599505563, 0.7772814294830889, 0.7835308796007485]\n",
      "Average F1-Score 0.7814986230114646\n",
      "Std Dev F1-Score 0.002982657513486328\n",
      "Error bar F1-Score 0.0017220381183117915\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 10ms/step - loss: 0.5845 - accuracy: 0.7075 - val_loss: 0.5264 - val_accuracy: 0.6847\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4373 - accuracy: 0.7697 - val_loss: 0.3640 - val_accuracy: 0.8176\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3788 - accuracy: 0.8122 - val_loss: 0.3803 - val_accuracy: 0.7987\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3665 - accuracy: 0.8224 - val_loss: 0.3699 - val_accuracy: 0.8232\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3589 - accuracy: 0.8251 - val_loss: 0.3544 - val_accuracy: 0.8253\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3538 - accuracy: 0.8283 - val_loss: 0.3788 - val_accuracy: 0.8208\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3516 - accuracy: 0.8314 - val_loss: 0.3497 - val_accuracy: 0.8369\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3418 - accuracy: 0.8341 - val_loss: 0.3406 - val_accuracy: 0.8422\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3304 - accuracy: 0.8455 - val_loss: 0.4053 - val_accuracy: 0.8025\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3257 - accuracy: 0.8462 - val_loss: 0.3236 - val_accuracy: 0.8639\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3281 - accuracy: 0.8432 - val_loss: 0.3148 - val_accuracy: 0.8502\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3271 - accuracy: 0.8451 - val_loss: 0.3275 - val_accuracy: 0.8453\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3209 - accuracy: 0.8464 - val_loss: 0.3121 - val_accuracy: 0.8527\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3261 - accuracy: 0.8443 - val_loss: 0.3128 - val_accuracy: 0.8562\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3114 - accuracy: 0.8566 - val_loss: 0.3630 - val_accuracy: 0.8250\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3019 - accuracy: 0.8592 - val_loss: 0.3567 - val_accuracy: 0.8278\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3056 - accuracy: 0.8590 - val_loss: 0.2964 - val_accuracy: 0.8706\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2961 - accuracy: 0.8633 - val_loss: 0.2969 - val_accuracy: 0.8625\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2875 - accuracy: 0.8659 - val_loss: 0.2755 - val_accuracy: 0.8737\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2865 - accuracy: 0.8668 - val_loss: 0.2938 - val_accuracy: 0.8604\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2903 - accuracy: 0.8650 - val_loss: 0.3911 - val_accuracy: 0.8285\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2919 - accuracy: 0.8630 - val_loss: 0.2970 - val_accuracy: 0.8569\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2827 - accuracy: 0.8691 - val_loss: 0.3294 - val_accuracy: 0.8471\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2866 - accuracy: 0.8677 - val_loss: 0.2889 - val_accuracy: 0.8664\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2764 - accuracy: 0.8715 - val_loss: 0.2958 - val_accuracy: 0.8713\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2724 - accuracy: 0.8748 - val_loss: 0.2653 - val_accuracy: 0.8758\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2728 - accuracy: 0.8726 - val_loss: 0.2794 - val_accuracy: 0.8713\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2657 - accuracy: 0.8761 - val_loss: 0.3056 - val_accuracy: 0.8509\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2660 - accuracy: 0.8760 - val_loss: 0.3047 - val_accuracy: 0.8590\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2635 - accuracy: 0.8781 - val_loss: 0.2674 - val_accuracy: 0.8772\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2555 - accuracy: 0.8829 - val_loss: 0.2453 - val_accuracy: 0.8881\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2485 - accuracy: 0.8857 - val_loss: 0.2640 - val_accuracy: 0.8864\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2484 - accuracy: 0.8873 - val_loss: 0.2251 - val_accuracy: 0.8965\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2668 - accuracy: 0.8776 - val_loss: 0.2630 - val_accuracy: 0.8776\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2349 - accuracy: 0.8935 - val_loss: 0.2383 - val_accuracy: 0.8916\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2308 - accuracy: 0.8979 - val_loss: 0.2068 - val_accuracy: 0.9039\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2209 - accuracy: 0.9033 - val_loss: 0.2334 - val_accuracy: 0.8969\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2017 - accuracy: 0.9122 - val_loss: 0.2011 - val_accuracy: 0.9141\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2030 - accuracy: 0.9103 - val_loss: 0.1733 - val_accuracy: 0.9260\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1862 - accuracy: 0.9187 - val_loss: 0.1859 - val_accuracy: 0.9197\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1931 - accuracy: 0.9187 - val_loss: 0.2427 - val_accuracy: 0.8997\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1957 - accuracy: 0.9159 - val_loss: 0.1634 - val_accuracy: 0.9341\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1752 - accuracy: 0.9271 - val_loss: 0.1470 - val_accuracy: 0.9428\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1696 - accuracy: 0.9286 - val_loss: 0.1562 - val_accuracy: 0.9379\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1589 - accuracy: 0.9319 - val_loss: 0.1659 - val_accuracy: 0.9309\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1703 - accuracy: 0.9298 - val_loss: 0.1380 - val_accuracy: 0.9449\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1655 - accuracy: 0.9299 - val_loss: 0.1894 - val_accuracy: 0.9186\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1576 - accuracy: 0.9333 - val_loss: 0.1890 - val_accuracy: 0.9162\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1614 - accuracy: 0.9328 - val_loss: 0.1428 - val_accuracy: 0.9365\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1449 - accuracy: 0.9403 - val_loss: 0.1446 - val_accuracy: 0.9393\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1447 - accuracy: 0.9418 - val_loss: 0.1244 - val_accuracy: 0.9541\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1499 - accuracy: 0.9376 - val_loss: 0.1345 - val_accuracy: 0.9477\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1356 - accuracy: 0.9440 - val_loss: 0.1245 - val_accuracy: 0.9537\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1343 - accuracy: 0.9463 - val_loss: 0.1258 - val_accuracy: 0.9491\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1283 - accuracy: 0.9485 - val_loss: 0.2169 - val_accuracy: 0.9074\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1418 - accuracy: 0.9420 - val_loss: 0.1768 - val_accuracy: 0.9295\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1267 - accuracy: 0.9497 - val_loss: 0.1144 - val_accuracy: 0.9519\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1349 - accuracy: 0.9444 - val_loss: 0.0949 - val_accuracy: 0.9649\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1422 - accuracy: 0.9435 - val_loss: 0.1272 - val_accuracy: 0.9491\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1257 - accuracy: 0.9492 - val_loss: 0.3068 - val_accuracy: 0.8572\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1227 - accuracy: 0.9513 - val_loss: 0.1111 - val_accuracy: 0.9569\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1236 - accuracy: 0.9505 - val_loss: 0.1532 - val_accuracy: 0.9344\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1475 - accuracy: 0.9388 - val_loss: 0.1112 - val_accuracy: 0.9555\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1233 - accuracy: 0.9516 - val_loss: 0.1126 - val_accuracy: 0.9526\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1228 - accuracy: 0.9500 - val_loss: 0.1107 - val_accuracy: 0.9572\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1204 - accuracy: 0.9510 - val_loss: 0.1596 - val_accuracy: 0.9341\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1338 - accuracy: 0.9436 - val_loss: 0.1449 - val_accuracy: 0.9435\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1091 - accuracy: 0.9580 - val_loss: 0.1254 - val_accuracy: 0.9548\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1284 - accuracy: 0.9490 - val_loss: 0.1219 - val_accuracy: 0.9523\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1723 - accuracy: 0.9256 - val_loss: 0.1242 - val_accuracy: 0.9460\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1087 - accuracy: 0.9568 - val_loss: 0.1855 - val_accuracy: 0.9211\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1126 - accuracy: 0.9563 - val_loss: 0.0999 - val_accuracy: 0.9611\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1239 - accuracy: 0.9518 - val_loss: 0.1313 - val_accuracy: 0.9474\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1113 - accuracy: 0.9573 - val_loss: 0.1482 - val_accuracy: 0.9411\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1162 - accuracy: 0.9554 - val_loss: 0.1049 - val_accuracy: 0.9562\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0971 - accuracy: 0.9623 - val_loss: 0.1177 - val_accuracy: 0.9569\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1272 - accuracy: 0.9497 - val_loss: 0.0904 - val_accuracy: 0.9653\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1008 - accuracy: 0.9625 - val_loss: 0.0872 - val_accuracy: 0.9653\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1273 - accuracy: 0.9488 - val_loss: 0.2486 - val_accuracy: 0.8871\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1194 - accuracy: 0.9516 - val_loss: 0.3349 - val_accuracy: 0.8685\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1198 - accuracy: 0.9520 - val_loss: 0.1042 - val_accuracy: 0.9614\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0941 - accuracy: 0.9648 - val_loss: 0.1661 - val_accuracy: 0.9309\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1028 - accuracy: 0.9606 - val_loss: 0.1051 - val_accuracy: 0.9593\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1036 - accuracy: 0.9596 - val_loss: 0.1491 - val_accuracy: 0.9425\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1111 - accuracy: 0.9550 - val_loss: 0.1700 - val_accuracy: 0.9284\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0937 - accuracy: 0.9628 - val_loss: 0.1075 - val_accuracy: 0.9625\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0921 - accuracy: 0.9644 - val_loss: 0.1074 - val_accuracy: 0.9551\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0875 - accuracy: 0.9681 - val_loss: 0.1454 - val_accuracy: 0.9386\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1221 - accuracy: 0.9516 - val_loss: 0.1165 - val_accuracy: 0.9590\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1012 - accuracy: 0.9616 - val_loss: 0.1080 - val_accuracy: 0.9604\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0923 - accuracy: 0.9639 - val_loss: 0.1070 - val_accuracy: 0.9590\n",
      "Epoch 92/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1445 - accuracy: 0.9406 - val_loss: 0.1614 - val_accuracy: 0.9334\n",
      "Epoch 93/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0904 - accuracy: 0.9637 - val_loss: 0.0904 - val_accuracy: 0.9660\n",
      "Epoch 94/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0867 - accuracy: 0.9661 - val_loss: 0.1823 - val_accuracy: 0.9221\n",
      "Epoch 95/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0991 - accuracy: 0.9611 - val_loss: 0.0899 - val_accuracy: 0.9677\n",
      "Epoch 96/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1610 - accuracy: 0.9323 - val_loss: 0.1181 - val_accuracy: 0.9533\n",
      "Epoch 97/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0901 - accuracy: 0.9647 - val_loss: 0.0924 - val_accuracy: 0.9653\n",
      "Epoch 98/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0798 - accuracy: 0.9698 - val_loss: 0.0999 - val_accuracy: 0.9635\n",
      "Epoch 99/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0798 - accuracy: 0.9685 - val_loss: 0.1517 - val_accuracy: 0.9411\n",
      "Epoch 100/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0955 - accuracy: 0.9634 - val_loss: 0.0986 - val_accuracy: 0.9642\n",
      "Epoch 101/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0875 - accuracy: 0.9657 - val_loss: 0.0888 - val_accuracy: 0.9681\n",
      "Epoch 102/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1042 - accuracy: 0.9599 - val_loss: 0.1146 - val_accuracy: 0.9607\n",
      "Epoch 103/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0853 - accuracy: 0.9678 - val_loss: 0.1208 - val_accuracy: 0.9551\n",
      "Epoch 104/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0784 - accuracy: 0.9716 - val_loss: 0.0831 - val_accuracy: 0.9684\n",
      "Epoch 105/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0929 - accuracy: 0.9646 - val_loss: 0.1131 - val_accuracy: 0.9558\n",
      "Epoch 106/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0971 - accuracy: 0.9633 - val_loss: 0.0801 - val_accuracy: 0.9698\n",
      "Epoch 107/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0987 - accuracy: 0.9613 - val_loss: 0.0941 - val_accuracy: 0.9670\n",
      "Epoch 108/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0845 - accuracy: 0.9679 - val_loss: 0.0797 - val_accuracy: 0.9709\n",
      "Epoch 109/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0731 - accuracy: 0.9725 - val_loss: 0.0968 - val_accuracy: 0.9611\n",
      "Epoch 110/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0844 - accuracy: 0.9682 - val_loss: 0.0981 - val_accuracy: 0.9611\n",
      "Epoch 111/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1680 - accuracy: 0.9286 - val_loss: 0.1965 - val_accuracy: 0.9120\n",
      "Epoch 112/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1422 - accuracy: 0.9408 - val_loss: 0.1223 - val_accuracy: 0.9505\n",
      "Epoch 113/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0755 - accuracy: 0.9724 - val_loss: 0.0954 - val_accuracy: 0.9667\n",
      "Epoch 114/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0653 - accuracy: 0.9757 - val_loss: 0.0959 - val_accuracy: 0.9660\n",
      "Epoch 115/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0878 - accuracy: 0.9664 - val_loss: 0.1165 - val_accuracy: 0.9541\n",
      "Epoch 116/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0687 - accuracy: 0.9734 - val_loss: 0.0804 - val_accuracy: 0.9691\n",
      "Epoch 117/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1031 - accuracy: 0.9599 - val_loss: 0.0798 - val_accuracy: 0.9677\n",
      "Epoch 118/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1683 - accuracy: 0.9279 - val_loss: 0.0885 - val_accuracy: 0.9660\n",
      "Epoch 119/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0618 - accuracy: 0.9775 - val_loss: 0.1329 - val_accuracy: 0.9474\n",
      "Epoch 120/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1027 - accuracy: 0.9619 - val_loss: 0.3269 - val_accuracy: 0.8706\n",
      "Epoch 121/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1168 - accuracy: 0.9556 - val_loss: 0.1041 - val_accuracy: 0.9604\n",
      "Epoch 122/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0729 - accuracy: 0.9728 - val_loss: 0.1010 - val_accuracy: 0.9632\n",
      "Epoch 123/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0823 - accuracy: 0.9694 - val_loss: 0.1365 - val_accuracy: 0.9463\n",
      "Epoch 124/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0869 - accuracy: 0.9670 - val_loss: 0.1591 - val_accuracy: 0.9379\n",
      "Epoch 125/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0649 - accuracy: 0.9752 - val_loss: 0.1330 - val_accuracy: 0.9502\n",
      "Epoch 126/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0774 - accuracy: 0.9700 - val_loss: 0.0977 - val_accuracy: 0.9646\n",
      "Epoch 127/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0819 - accuracy: 0.9688 - val_loss: 0.0987 - val_accuracy: 0.9611\n",
      "Epoch 128/500\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0716 - accuracy: 0.9728Restoring model weights from the end of the best epoch: 108.\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0712 - accuracy: 0.9731 - val_loss: 0.0874 - val_accuracy: 0.9691\n",
      "Epoch 128: early stopping\n",
      "Number of iterations 4\n",
      "F1-scores:  [0.7836835599505563, 0.7772814294830889, 0.7835308796007485, 0.951032448377581]\n",
      "Average F1-Score 0.8238820793529936\n",
      "Std Dev F1-Score 0.07345573019679938\n",
      "Error bar F1-Score 0.03672786509839969\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 10ms/step - loss: 0.5306 - accuracy: 0.7262 - val_loss: 0.3848 - val_accuracy: 0.8116\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3958 - accuracy: 0.8002 - val_loss: 0.3790 - val_accuracy: 0.8166\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3980 - accuracy: 0.7979 - val_loss: 0.3774 - val_accuracy: 0.8106\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3821 - accuracy: 0.8112 - val_loss: 0.3768 - val_accuracy: 0.8222\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3738 - accuracy: 0.8171 - val_loss: 0.4242 - val_accuracy: 0.7675\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3717 - accuracy: 0.8178 - val_loss: 0.3603 - val_accuracy: 0.8274\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3659 - accuracy: 0.8236 - val_loss: 0.4398 - val_accuracy: 0.7629\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3622 - accuracy: 0.8240 - val_loss: 0.3608 - val_accuracy: 0.8341\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3601 - accuracy: 0.8268 - val_loss: 0.3468 - val_accuracy: 0.8415\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3551 - accuracy: 0.8302 - val_loss: 0.3447 - val_accuracy: 0.8341\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3546 - accuracy: 0.8285 - val_loss: 0.3311 - val_accuracy: 0.8425\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3397 - accuracy: 0.8368 - val_loss: 0.3497 - val_accuracy: 0.8306\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3426 - accuracy: 0.8370 - val_loss: 0.3209 - val_accuracy: 0.8555\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3477 - accuracy: 0.8347 - val_loss: 0.3159 - val_accuracy: 0.8516\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3368 - accuracy: 0.8413 - val_loss: 0.3541 - val_accuracy: 0.8341\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3242 - accuracy: 0.8513 - val_loss: 0.3778 - val_accuracy: 0.8309\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3145 - accuracy: 0.8533 - val_loss: 0.3158 - val_accuracy: 0.8548\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3274 - accuracy: 0.8450 - val_loss: 0.4147 - val_accuracy: 0.8022\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3119 - accuracy: 0.8548 - val_loss: 0.3220 - val_accuracy: 0.8506\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3035 - accuracy: 0.8615 - val_loss: 0.3325 - val_accuracy: 0.8415\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3102 - accuracy: 0.8575 - val_loss: 0.2993 - val_accuracy: 0.8678\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3040 - accuracy: 0.8601 - val_loss: 0.3234 - val_accuracy: 0.8590\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2965 - accuracy: 0.8652 - val_loss: 0.2974 - val_accuracy: 0.8674\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2928 - accuracy: 0.8659 - val_loss: 0.2878 - val_accuracy: 0.8741\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4209 - accuracy: 0.7906 - val_loss: 0.5994 - val_accuracy: 0.7124\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5723 - accuracy: 0.7119 - val_loss: 0.5112 - val_accuracy: 0.7124\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4633 - accuracy: 0.7334 - val_loss: 0.4142 - val_accuracy: 0.7752\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4105 - accuracy: 0.8001 - val_loss: 0.3720 - val_accuracy: 0.8211\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3926 - accuracy: 0.8067 - val_loss: 0.3801 - val_accuracy: 0.8281\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3798 - accuracy: 0.8172 - val_loss: 0.3434 - val_accuracy: 0.8390\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3672 - accuracy: 0.8306 - val_loss: 0.3407 - val_accuracy: 0.8439\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3520 - accuracy: 0.8347 - val_loss: 0.3858 - val_accuracy: 0.8123\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3444 - accuracy: 0.8399 - val_loss: 0.3261 - val_accuracy: 0.8555\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3346 - accuracy: 0.8466 - val_loss: 0.3170 - val_accuracy: 0.8492\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3656 - accuracy: 0.8200 - val_loss: 0.3365 - val_accuracy: 0.8401\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3367 - accuracy: 0.8429 - val_loss: 0.3229 - val_accuracy: 0.8551\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3556 - accuracy: 0.8359 - val_loss: 0.4633 - val_accuracy: 0.7801\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3648 - accuracy: 0.8277 - val_loss: 0.3833 - val_accuracy: 0.8127\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3530 - accuracy: 0.8357 - val_loss: 0.3471 - val_accuracy: 0.8358\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3573 - accuracy: 0.8336 - val_loss: 0.3328 - val_accuracy: 0.8457\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3487 - accuracy: 0.8364 - val_loss: 0.3368 - val_accuracy: 0.8551\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3981 - accuracy: 0.8093 - val_loss: 0.5869 - val_accuracy: 0.7124\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5276 - accuracy: 0.7083 - val_loss: 0.6011 - val_accuracy: 0.7106\n",
      "Epoch 44/500\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.5923 - accuracy: 0.7112Restoring model weights from the end of the best epoch: 24.\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.5925 - accuracy: 0.7110 - val_loss: 0.5924 - val_accuracy: 0.7106\n",
      "Epoch 44: early stopping\n",
      "Number of iterations 5\n",
      "F1-scores:  [0.7836835599505563, 0.7772814294830889, 0.7835308796007485, 0.951032448377581, 0.7806963958460599]\n",
      "Average F1-Score 0.815244942651607\n",
      "Std Dev F1-Score 0.06793376156661543\n",
      "Error bar F1-Score 0.03038090176604294\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 11ms/step - loss: 0.5525 - accuracy: 0.7114 - val_loss: 0.5225 - val_accuracy: 0.7660\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4207 - accuracy: 0.7793 - val_loss: 0.3988 - val_accuracy: 0.7885\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3836 - accuracy: 0.8079 - val_loss: 0.3582 - val_accuracy: 0.8246\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4363 - accuracy: 0.7681 - val_loss: 0.3808 - val_accuracy: 0.8060\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3820 - accuracy: 0.8110 - val_loss: 0.3598 - val_accuracy: 0.8313\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3735 - accuracy: 0.8179 - val_loss: 0.3929 - val_accuracy: 0.8113\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3602 - accuracy: 0.8258 - val_loss: 0.3652 - val_accuracy: 0.8169\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3577 - accuracy: 0.8267 - val_loss: 0.3502 - val_accuracy: 0.8253\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3411 - accuracy: 0.8360 - val_loss: 0.3476 - val_accuracy: 0.8373\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3420 - accuracy: 0.8367 - val_loss: 0.3289 - val_accuracy: 0.8481\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3389 - accuracy: 0.8391 - val_loss: 0.3537 - val_accuracy: 0.8271\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3361 - accuracy: 0.8406 - val_loss: 0.3234 - val_accuracy: 0.8499\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3255 - accuracy: 0.8474 - val_loss: 0.3103 - val_accuracy: 0.8576\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3216 - accuracy: 0.8502 - val_loss: 0.4182 - val_accuracy: 0.7997\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3238 - accuracy: 0.8496 - val_loss: 0.3152 - val_accuracy: 0.8572\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3320 - accuracy: 0.8441 - val_loss: 0.3185 - val_accuracy: 0.8544\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3236 - accuracy: 0.8487 - val_loss: 0.3219 - val_accuracy: 0.8506\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3069 - accuracy: 0.8593 - val_loss: 0.3009 - val_accuracy: 0.8615\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3055 - accuracy: 0.8590 - val_loss: 0.2892 - val_accuracy: 0.8660\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2980 - accuracy: 0.8636 - val_loss: 0.3270 - val_accuracy: 0.8467\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2985 - accuracy: 0.8634 - val_loss: 0.2874 - val_accuracy: 0.8755\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2931 - accuracy: 0.8660 - val_loss: 0.2874 - val_accuracy: 0.8695\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2922 - accuracy: 0.8668 - val_loss: 0.3026 - val_accuracy: 0.8622\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2885 - accuracy: 0.8678 - val_loss: 0.4450 - val_accuracy: 0.8057\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2957 - accuracy: 0.8624 - val_loss: 0.2736 - val_accuracy: 0.8769\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2811 - accuracy: 0.8733 - val_loss: 0.2820 - val_accuracy: 0.8748\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2853 - accuracy: 0.8694 - val_loss: 0.2814 - val_accuracy: 0.8706\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2765 - accuracy: 0.8716 - val_loss: 0.2800 - val_accuracy: 0.8741\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2825 - accuracy: 0.8730 - val_loss: 0.2809 - val_accuracy: 0.8734\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2760 - accuracy: 0.8756 - val_loss: 0.2855 - val_accuracy: 0.8730\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2799 - accuracy: 0.8734 - val_loss: 0.2748 - val_accuracy: 0.8748\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2722 - accuracy: 0.8744 - val_loss: 0.2623 - val_accuracy: 0.8818\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2798 - accuracy: 0.8705 - val_loss: 0.2637 - val_accuracy: 0.8818\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2820 - accuracy: 0.8696 - val_loss: 0.2859 - val_accuracy: 0.8657\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2705 - accuracy: 0.8762 - val_loss: 0.2814 - val_accuracy: 0.8702\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2605 - accuracy: 0.8807 - val_loss: 0.2595 - val_accuracy: 0.8818\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2582 - accuracy: 0.8821 - val_loss: 0.2469 - val_accuracy: 0.8920\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2489 - accuracy: 0.8856 - val_loss: 0.3018 - val_accuracy: 0.8565\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2523 - accuracy: 0.8847 - val_loss: 0.2589 - val_accuracy: 0.8832\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2516 - accuracy: 0.8868 - val_loss: 0.2836 - val_accuracy: 0.8758\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2582 - accuracy: 0.8809 - val_loss: 0.2388 - val_accuracy: 0.8944\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2382 - accuracy: 0.8916 - val_loss: 0.2875 - val_accuracy: 0.8622\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2334 - accuracy: 0.8940 - val_loss: 0.2407 - val_accuracy: 0.8909\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2422 - accuracy: 0.8903 - val_loss: 0.2719 - val_accuracy: 0.8716\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2343 - accuracy: 0.8960 - val_loss: 0.2380 - val_accuracy: 0.8892\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2227 - accuracy: 0.9001 - val_loss: 0.2326 - val_accuracy: 0.8951\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2335 - accuracy: 0.8968 - val_loss: 0.2449 - val_accuracy: 0.8843\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2043 - accuracy: 0.9100 - val_loss: 0.2417 - val_accuracy: 0.8871\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1948 - accuracy: 0.9153 - val_loss: 0.2042 - val_accuracy: 0.9102\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1886 - accuracy: 0.9207 - val_loss: 0.1912 - val_accuracy: 0.9151\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1806 - accuracy: 0.9230 - val_loss: 0.1765 - val_accuracy: 0.9200\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1792 - accuracy: 0.9242 - val_loss: 0.3693 - val_accuracy: 0.8562\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1826 - accuracy: 0.9224 - val_loss: 0.1799 - val_accuracy: 0.9232\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1671 - accuracy: 0.9302 - val_loss: 0.2064 - val_accuracy: 0.9071\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1711 - accuracy: 0.9262 - val_loss: 0.1909 - val_accuracy: 0.9176\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1674 - accuracy: 0.9303 - val_loss: 0.1650 - val_accuracy: 0.9256\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1513 - accuracy: 0.9353 - val_loss: 0.1535 - val_accuracy: 0.9376\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1551 - accuracy: 0.9349 - val_loss: 0.2677 - val_accuracy: 0.8835\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1535 - accuracy: 0.9363 - val_loss: 0.1725 - val_accuracy: 0.9232\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2104 - accuracy: 0.9097 - val_loss: 0.1866 - val_accuracy: 0.9151\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1541 - accuracy: 0.9350 - val_loss: 0.1496 - val_accuracy: 0.9397\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1385 - accuracy: 0.9434 - val_loss: 0.1772 - val_accuracy: 0.9249\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1240 - accuracy: 0.9496 - val_loss: 0.1741 - val_accuracy: 0.9249\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1423 - accuracy: 0.9413 - val_loss: 0.2289 - val_accuracy: 0.9063\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1303 - accuracy: 0.9450 - val_loss: 0.1878 - val_accuracy: 0.9260\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1264 - accuracy: 0.9501 - val_loss: 0.1437 - val_accuracy: 0.9400\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1222 - accuracy: 0.9504 - val_loss: 0.1341 - val_accuracy: 0.9446\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1377 - accuracy: 0.9428 - val_loss: 0.1519 - val_accuracy: 0.9407\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1185 - accuracy: 0.9513 - val_loss: 0.1304 - val_accuracy: 0.9498\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1164 - accuracy: 0.9522 - val_loss: 0.1337 - val_accuracy: 0.9449\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1082 - accuracy: 0.9563 - val_loss: 0.1383 - val_accuracy: 0.9474\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1113 - accuracy: 0.9552 - val_loss: 0.1798 - val_accuracy: 0.9263\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1120 - accuracy: 0.9540 - val_loss: 0.1427 - val_accuracy: 0.9439\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1023 - accuracy: 0.9584 - val_loss: 0.1284 - val_accuracy: 0.9495\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1041 - accuracy: 0.9588 - val_loss: 0.1341 - val_accuracy: 0.9498\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0919 - accuracy: 0.9639 - val_loss: 0.1242 - val_accuracy: 0.9477\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1163 - accuracy: 0.9532 - val_loss: 0.1365 - val_accuracy: 0.9421\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1124 - accuracy: 0.9546 - val_loss: 0.2259 - val_accuracy: 0.8990\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0920 - accuracy: 0.9630 - val_loss: 0.1371 - val_accuracy: 0.9470\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0887 - accuracy: 0.9643 - val_loss: 0.1689 - val_accuracy: 0.9362\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1070 - accuracy: 0.9566 - val_loss: 0.1284 - val_accuracy: 0.9498\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0818 - accuracy: 0.9679 - val_loss: 0.1259 - val_accuracy: 0.9502\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0893 - accuracy: 0.9636 - val_loss: 0.1160 - val_accuracy: 0.9576\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0879 - accuracy: 0.9660 - val_loss: 0.1303 - val_accuracy: 0.9512\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0986 - accuracy: 0.9613 - val_loss: 0.1482 - val_accuracy: 0.9421\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0800 - accuracy: 0.9687 - val_loss: 0.1198 - val_accuracy: 0.9562\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0787 - accuracy: 0.9695 - val_loss: 0.1252 - val_accuracy: 0.9537\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0836 - accuracy: 0.9679 - val_loss: 0.1051 - val_accuracy: 0.9572\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0816 - accuracy: 0.9680 - val_loss: 0.1413 - val_accuracy: 0.9435\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0851 - accuracy: 0.9662 - val_loss: 0.1509 - val_accuracy: 0.9386\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0689 - accuracy: 0.9732 - val_loss: 0.1782 - val_accuracy: 0.9341\n",
      "Epoch 92/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0801 - accuracy: 0.9685 - val_loss: 0.1309 - val_accuracy: 0.9477\n",
      "Epoch 93/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0876 - accuracy: 0.9653 - val_loss: 0.1326 - val_accuracy: 0.9516\n",
      "Epoch 94/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0890 - accuracy: 0.9657 - val_loss: 0.1239 - val_accuracy: 0.9579\n",
      "Epoch 95/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0641 - accuracy: 0.9751 - val_loss: 0.1372 - val_accuracy: 0.9449\n",
      "Epoch 96/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0702 - accuracy: 0.9728 - val_loss: 0.1266 - val_accuracy: 0.9548\n",
      "Epoch 97/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0601 - accuracy: 0.9765 - val_loss: 0.1918 - val_accuracy: 0.9313\n",
      "Epoch 98/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0807 - accuracy: 0.9696 - val_loss: 0.1080 - val_accuracy: 0.9614\n",
      "Epoch 99/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0666 - accuracy: 0.9738 - val_loss: 0.1294 - val_accuracy: 0.9526\n",
      "Epoch 100/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0635 - accuracy: 0.9748 - val_loss: 0.1953 - val_accuracy: 0.9298\n",
      "Epoch 101/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0653 - accuracy: 0.9742 - val_loss: 0.1144 - val_accuracy: 0.9593\n",
      "Epoch 102/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0529 - accuracy: 0.9798 - val_loss: 0.1140 - val_accuracy: 0.9593\n",
      "Epoch 103/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0689 - accuracy: 0.9732 - val_loss: 0.1123 - val_accuracy: 0.9597\n",
      "Epoch 104/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0681 - accuracy: 0.9738 - val_loss: 0.1132 - val_accuracy: 0.9607\n",
      "Epoch 105/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0497 - accuracy: 0.9821 - val_loss: 0.1468 - val_accuracy: 0.9446\n",
      "Epoch 106/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0647 - accuracy: 0.9760 - val_loss: 0.1553 - val_accuracy: 0.9463\n",
      "Epoch 107/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0701 - accuracy: 0.9739 - val_loss: 0.1231 - val_accuracy: 0.9530\n",
      "Epoch 108/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0531 - accuracy: 0.9798 - val_loss: 0.1120 - val_accuracy: 0.9600\n",
      "Epoch 109/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0529 - accuracy: 0.9799 - val_loss: 0.3878 - val_accuracy: 0.9155\n",
      "Epoch 110/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4495 - accuracy: 0.7581 - val_loss: 0.4094 - val_accuracy: 0.7990\n",
      "Epoch 111/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3710 - accuracy: 0.8226 - val_loss: 0.3685 - val_accuracy: 0.8355\n",
      "Epoch 112/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3255 - accuracy: 0.8430 - val_loss: 0.2951 - val_accuracy: 0.8685\n",
      "Epoch 113/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2959 - accuracy: 0.8624 - val_loss: 0.2665 - val_accuracy: 0.8832\n",
      "Epoch 114/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2712 - accuracy: 0.8732 - val_loss: 0.2687 - val_accuracy: 0.8881\n",
      "Epoch 115/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2507 - accuracy: 0.8872 - val_loss: 0.2468 - val_accuracy: 0.8937\n",
      "Epoch 116/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2571 - accuracy: 0.8821 - val_loss: 0.2462 - val_accuracy: 0.8899\n",
      "Epoch 117/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2440 - accuracy: 0.8894 - val_loss: 0.2458 - val_accuracy: 0.8962\n",
      "Epoch 118/500\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.2390 - accuracy: 0.8921Restoring model weights from the end of the best epoch: 98.\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2396 - accuracy: 0.8915 - val_loss: 0.2315 - val_accuracy: 0.9025\n",
      "Epoch 118: early stopping\n",
      "Number of iterations 6\n",
      "F1-scores:  [0.7836835599505563, 0.7772814294830889, 0.7835308796007485, 0.951032448377581, 0.7806963958460599, 0.9338942307692307]\n",
      "Average F1-Score 0.8350198240045442\n",
      "Std Dev F1-Score 0.07616468755119965\n",
      "Error bar F1-Score 0.03109410348649153\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 10ms/step - loss: 0.5471 - accuracy: 0.7083 - val_loss: 0.5481 - val_accuracy: 0.6229\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4246 - accuracy: 0.7799 - val_loss: 0.4511 - val_accuracy: 0.7538\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3952 - accuracy: 0.8018 - val_loss: 0.3769 - val_accuracy: 0.8162\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3920 - accuracy: 0.8046 - val_loss: 0.3664 - val_accuracy: 0.8155\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3774 - accuracy: 0.8118 - val_loss: 0.3975 - val_accuracy: 0.7938\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3793 - accuracy: 0.8104 - val_loss: 0.3765 - val_accuracy: 0.8099\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3768 - accuracy: 0.8126 - val_loss: 0.3784 - val_accuracy: 0.8222\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3658 - accuracy: 0.8215 - val_loss: 0.3760 - val_accuracy: 0.8008\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3640 - accuracy: 0.8221 - val_loss: 0.3582 - val_accuracy: 0.8309\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3586 - accuracy: 0.8270 - val_loss: 0.3431 - val_accuracy: 0.8373\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3524 - accuracy: 0.8306 - val_loss: 0.3428 - val_accuracy: 0.8390\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3495 - accuracy: 0.8325 - val_loss: 0.3515 - val_accuracy: 0.8194\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3435 - accuracy: 0.8358 - val_loss: 0.3398 - val_accuracy: 0.8362\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3453 - accuracy: 0.8353 - val_loss: 0.3387 - val_accuracy: 0.8362\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3346 - accuracy: 0.8431 - val_loss: 0.3445 - val_accuracy: 0.8320\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3349 - accuracy: 0.8422 - val_loss: 0.3849 - val_accuracy: 0.7941\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3480 - accuracy: 0.8369 - val_loss: 0.3311 - val_accuracy: 0.8422\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3284 - accuracy: 0.8452 - val_loss: 0.3666 - val_accuracy: 0.8036\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3240 - accuracy: 0.8477 - val_loss: 0.3185 - val_accuracy: 0.8551\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3149 - accuracy: 0.8523 - val_loss: 0.3086 - val_accuracy: 0.8586\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3265 - accuracy: 0.8457 - val_loss: 0.3250 - val_accuracy: 0.8488\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3104 - accuracy: 0.8568 - val_loss: 0.3001 - val_accuracy: 0.8604\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3060 - accuracy: 0.8584 - val_loss: 0.3424 - val_accuracy: 0.8380\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3039 - accuracy: 0.8590 - val_loss: 0.3216 - val_accuracy: 0.8422\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3049 - accuracy: 0.8586 - val_loss: 0.2945 - val_accuracy: 0.8734\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3035 - accuracy: 0.8570 - val_loss: 0.3468 - val_accuracy: 0.8418\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2969 - accuracy: 0.8663 - val_loss: 0.3342 - val_accuracy: 0.8330\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2789 - accuracy: 0.8704 - val_loss: 0.2914 - val_accuracy: 0.8709\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2851 - accuracy: 0.8696 - val_loss: 0.3151 - val_accuracy: 0.8506\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2781 - accuracy: 0.8746 - val_loss: 0.2732 - val_accuracy: 0.8755\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2781 - accuracy: 0.8714 - val_loss: 0.2909 - val_accuracy: 0.8646\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2719 - accuracy: 0.8760 - val_loss: 0.2861 - val_accuracy: 0.8657\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2820 - accuracy: 0.8691 - val_loss: 0.2788 - val_accuracy: 0.8716\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2645 - accuracy: 0.8802 - val_loss: 0.2755 - val_accuracy: 0.8688\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2686 - accuracy: 0.8778 - val_loss: 0.3018 - val_accuracy: 0.8604\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2609 - accuracy: 0.8819 - val_loss: 0.2771 - val_accuracy: 0.8653\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2521 - accuracy: 0.8871 - val_loss: 0.2519 - val_accuracy: 0.8878\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2550 - accuracy: 0.8836 - val_loss: 0.2597 - val_accuracy: 0.8814\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2417 - accuracy: 0.8919 - val_loss: 0.2879 - val_accuracy: 0.8569\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2482 - accuracy: 0.8890 - val_loss: 0.2673 - val_accuracy: 0.8913\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2597 - accuracy: 0.8840 - val_loss: 0.2508 - val_accuracy: 0.8888\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2365 - accuracy: 0.8943 - val_loss: 0.2712 - val_accuracy: 0.8741\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2370 - accuracy: 0.8932 - val_loss: 0.2855 - val_accuracy: 0.8678\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2364 - accuracy: 0.8953 - val_loss: 0.2369 - val_accuracy: 0.8969\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2313 - accuracy: 0.8967 - val_loss: 0.2227 - val_accuracy: 0.9000\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2370 - accuracy: 0.8936 - val_loss: 0.2742 - val_accuracy: 0.8832\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2240 - accuracy: 0.9021 - val_loss: 0.2284 - val_accuracy: 0.9035\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2209 - accuracy: 0.9010 - val_loss: 0.2120 - val_accuracy: 0.9071\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2364 - accuracy: 0.8928 - val_loss: 0.4314 - val_accuracy: 0.7678\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2472 - accuracy: 0.8861 - val_loss: 0.2136 - val_accuracy: 0.9081\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2071 - accuracy: 0.9090 - val_loss: 0.2238 - val_accuracy: 0.8962\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2106 - accuracy: 0.9064 - val_loss: 0.2042 - val_accuracy: 0.9099\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2138 - accuracy: 0.9059 - val_loss: 0.2229 - val_accuracy: 0.9025\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2019 - accuracy: 0.9139 - val_loss: 0.1789 - val_accuracy: 0.9214\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1998 - accuracy: 0.9148 - val_loss: 0.1960 - val_accuracy: 0.9137\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1858 - accuracy: 0.9184 - val_loss: 0.1994 - val_accuracy: 0.9155\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1955 - accuracy: 0.9170 - val_loss: 0.1894 - val_accuracy: 0.9214\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1857 - accuracy: 0.9188 - val_loss: 0.1937 - val_accuracy: 0.9095\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1749 - accuracy: 0.9272 - val_loss: 0.1665 - val_accuracy: 0.9334\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1715 - accuracy: 0.9280 - val_loss: 0.1797 - val_accuracy: 0.9169\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2077 - accuracy: 0.9090 - val_loss: 0.1917 - val_accuracy: 0.9183\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1633 - accuracy: 0.9310 - val_loss: 0.2554 - val_accuracy: 0.8807\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1563 - accuracy: 0.9338 - val_loss: 0.1419 - val_accuracy: 0.9404\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1547 - accuracy: 0.9355 - val_loss: 0.1669 - val_accuracy: 0.9291\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2683 - accuracy: 0.8779 - val_loss: 0.2565 - val_accuracy: 0.8814\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2053 - accuracy: 0.9091 - val_loss: 0.2187 - val_accuracy: 0.8983\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1767 - accuracy: 0.9249 - val_loss: 0.3944 - val_accuracy: 0.8309\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1404 - accuracy: 0.9422 - val_loss: 0.1259 - val_accuracy: 0.9460\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1567 - accuracy: 0.9359 - val_loss: 0.1265 - val_accuracy: 0.9474\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1199 - accuracy: 0.9521 - val_loss: 0.2073 - val_accuracy: 0.9162\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1350 - accuracy: 0.9438 - val_loss: 0.1133 - val_accuracy: 0.9541\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1802 - accuracy: 0.9232 - val_loss: 0.1498 - val_accuracy: 0.9376\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1149 - accuracy: 0.9542 - val_loss: 0.1146 - val_accuracy: 0.9519\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1204 - accuracy: 0.9499 - val_loss: 0.1324 - val_accuracy: 0.9435\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2352 - accuracy: 0.8945 - val_loss: 0.2418 - val_accuracy: 0.8895\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1858 - accuracy: 0.9211 - val_loss: 0.1406 - val_accuracy: 0.9425\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1315 - accuracy: 0.9459 - val_loss: 0.1226 - val_accuracy: 0.9530\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1157 - accuracy: 0.9539 - val_loss: 0.1173 - val_accuracy: 0.9565\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1136 - accuracy: 0.9549 - val_loss: 0.1028 - val_accuracy: 0.9618\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1186 - accuracy: 0.9521 - val_loss: 0.1159 - val_accuracy: 0.9509\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1090 - accuracy: 0.9565 - val_loss: 0.1084 - val_accuracy: 0.9572\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1145 - accuracy: 0.9551 - val_loss: 0.1307 - val_accuracy: 0.9460\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1017 - accuracy: 0.9593 - val_loss: 0.2405 - val_accuracy: 0.9053\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0872 - accuracy: 0.9672 - val_loss: 0.1381 - val_accuracy: 0.9477\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1012 - accuracy: 0.9611 - val_loss: 0.2113 - val_accuracy: 0.9155\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1153 - accuracy: 0.9539 - val_loss: 0.1089 - val_accuracy: 0.9614\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1527 - accuracy: 0.9347 - val_loss: 0.2630 - val_accuracy: 0.8814\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1515 - accuracy: 0.9365 - val_loss: 0.1006 - val_accuracy: 0.9618\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1017 - accuracy: 0.9611 - val_loss: 0.0891 - val_accuracy: 0.9677\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0942 - accuracy: 0.9636 - val_loss: 0.1056 - val_accuracy: 0.9618\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0903 - accuracy: 0.9656 - val_loss: 0.1052 - val_accuracy: 0.9590\n",
      "Epoch 92/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0852 - accuracy: 0.9668 - val_loss: 0.1365 - val_accuracy: 0.9477\n",
      "Epoch 93/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0895 - accuracy: 0.9652 - val_loss: 0.0743 - val_accuracy: 0.9719\n",
      "Epoch 94/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0808 - accuracy: 0.9688 - val_loss: 0.0885 - val_accuracy: 0.9667\n",
      "Epoch 95/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0749 - accuracy: 0.9706 - val_loss: 0.1313 - val_accuracy: 0.9477\n",
      "Epoch 96/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1150 - accuracy: 0.9529 - val_loss: 0.3254 - val_accuracy: 0.8495\n",
      "Epoch 97/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1845 - accuracy: 0.9235 - val_loss: 0.1020 - val_accuracy: 0.9597\n",
      "Epoch 98/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1113 - accuracy: 0.9555 - val_loss: 0.1318 - val_accuracy: 0.9449\n",
      "Epoch 99/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0829 - accuracy: 0.9694 - val_loss: 0.1258 - val_accuracy: 0.9495\n",
      "Epoch 100/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0800 - accuracy: 0.9696 - val_loss: 0.0757 - val_accuracy: 0.9716\n",
      "Epoch 101/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0944 - accuracy: 0.9643 - val_loss: 0.0825 - val_accuracy: 0.9677\n",
      "Epoch 102/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0746 - accuracy: 0.9719 - val_loss: 0.4260 - val_accuracy: 0.8432\n",
      "Epoch 103/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0882 - accuracy: 0.9660 - val_loss: 0.0830 - val_accuracy: 0.9705\n",
      "Epoch 104/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0740 - accuracy: 0.9718 - val_loss: 0.0765 - val_accuracy: 0.9730\n",
      "Epoch 105/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0704 - accuracy: 0.9736 - val_loss: 0.0936 - val_accuracy: 0.9653\n",
      "Epoch 106/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0718 - accuracy: 0.9729 - val_loss: 0.1047 - val_accuracy: 0.9600\n",
      "Epoch 107/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0840 - accuracy: 0.9675 - val_loss: 0.1598 - val_accuracy: 0.9313\n",
      "Epoch 108/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0803 - accuracy: 0.9684 - val_loss: 0.0842 - val_accuracy: 0.9695\n",
      "Epoch 109/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0818 - accuracy: 0.9678 - val_loss: 0.0830 - val_accuracy: 0.9688\n",
      "Epoch 110/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0583 - accuracy: 0.9777 - val_loss: 0.0910 - val_accuracy: 0.9653\n",
      "Epoch 111/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0686 - accuracy: 0.9744 - val_loss: 0.0780 - val_accuracy: 0.9719\n",
      "Epoch 112/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0665 - accuracy: 0.9755 - val_loss: 0.1258 - val_accuracy: 0.9488\n",
      "Epoch 113/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0863 - accuracy: 0.9677 - val_loss: 0.1393 - val_accuracy: 0.9414\n",
      "Epoch 114/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0721 - accuracy: 0.9727 - val_loss: 0.0709 - val_accuracy: 0.9744\n",
      "Epoch 115/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0712 - accuracy: 0.9725 - val_loss: 0.0945 - val_accuracy: 0.9642\n",
      "Epoch 116/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1249 - accuracy: 0.9507 - val_loss: 0.1044 - val_accuracy: 0.9611\n",
      "Epoch 117/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0745 - accuracy: 0.9726 - val_loss: 0.0880 - val_accuracy: 0.9639\n",
      "Epoch 118/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0636 - accuracy: 0.9761 - val_loss: 0.0879 - val_accuracy: 0.9691\n",
      "Epoch 119/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0854 - accuracy: 0.9683 - val_loss: 0.0882 - val_accuracy: 0.9646\n",
      "Epoch 120/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0607 - accuracy: 0.9785 - val_loss: 0.0790 - val_accuracy: 0.9719\n",
      "Epoch 121/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0645 - accuracy: 0.9765 - val_loss: 0.0800 - val_accuracy: 0.9684\n",
      "Epoch 122/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1209 - accuracy: 0.9529 - val_loss: 0.2658 - val_accuracy: 0.8902\n",
      "Epoch 123/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0798 - accuracy: 0.9703 - val_loss: 0.0735 - val_accuracy: 0.9726\n",
      "Epoch 124/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0547 - accuracy: 0.9807 - val_loss: 0.0826 - val_accuracy: 0.9719\n",
      "Epoch 125/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0531 - accuracy: 0.9800 - val_loss: 0.1007 - val_accuracy: 0.9628\n",
      "Epoch 126/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0670 - accuracy: 0.9746 - val_loss: 0.0941 - val_accuracy: 0.9653\n",
      "Epoch 127/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0698 - accuracy: 0.9747 - val_loss: 0.1008 - val_accuracy: 0.9607\n",
      "Epoch 128/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0513 - accuracy: 0.9813 - val_loss: 0.0950 - val_accuracy: 0.9660\n",
      "Epoch 129/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0826 - accuracy: 0.9695 - val_loss: 0.0813 - val_accuracy: 0.9716\n",
      "Epoch 130/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0574 - accuracy: 0.9791 - val_loss: 0.0994 - val_accuracy: 0.9632\n",
      "Epoch 131/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0578 - accuracy: 0.9789 - val_loss: 0.0640 - val_accuracy: 0.9776\n",
      "Epoch 132/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0685 - accuracy: 0.9757 - val_loss: 0.1263 - val_accuracy: 0.9488\n",
      "Epoch 133/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0802 - accuracy: 0.9719 - val_loss: 0.1417 - val_accuracy: 0.9523\n",
      "Epoch 134/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0643 - accuracy: 0.9754 - val_loss: 0.1654 - val_accuracy: 0.9313\n",
      "Epoch 135/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0545 - accuracy: 0.9800 - val_loss: 0.0871 - val_accuracy: 0.9670\n",
      "Epoch 136/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0563 - accuracy: 0.9790 - val_loss: 0.0773 - val_accuracy: 0.9733\n",
      "Epoch 137/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0598 - accuracy: 0.9781 - val_loss: 0.0832 - val_accuracy: 0.9684\n",
      "Epoch 138/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0440 - accuracy: 0.9841 - val_loss: 0.0797 - val_accuracy: 0.9716\n",
      "Epoch 139/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0623 - accuracy: 0.9766 - val_loss: 0.0826 - val_accuracy: 0.9719\n",
      "Epoch 140/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0588 - accuracy: 0.9787 - val_loss: 0.0764 - val_accuracy: 0.9726\n",
      "Epoch 141/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0541 - accuracy: 0.9802 - val_loss: 0.0783 - val_accuracy: 0.9719\n",
      "Epoch 142/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0472 - accuracy: 0.9821 - val_loss: 0.0892 - val_accuracy: 0.9677\n",
      "Epoch 143/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0767 - accuracy: 0.9699 - val_loss: 0.0903 - val_accuracy: 0.9635\n",
      "Epoch 144/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0436 - accuracy: 0.9842 - val_loss: 0.0887 - val_accuracy: 0.9681\n",
      "Epoch 145/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0408 - accuracy: 0.9856 - val_loss: 0.0838 - val_accuracy: 0.9681\n",
      "Epoch 146/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0462 - accuracy: 0.9825 - val_loss: 0.1069 - val_accuracy: 0.9607\n",
      "Epoch 147/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0557 - accuracy: 0.9788 - val_loss: 0.0850 - val_accuracy: 0.9681\n",
      "Epoch 148/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0568 - accuracy: 0.9789 - val_loss: 0.0915 - val_accuracy: 0.9684\n",
      "Epoch 149/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0432 - accuracy: 0.9840 - val_loss: 0.0950 - val_accuracy: 0.9684\n",
      "Epoch 150/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0542 - accuracy: 0.9813 - val_loss: 0.0902 - val_accuracy: 0.9660\n",
      "Epoch 151/500\n",
      "328/334 [============================>.] - ETA: 0s - loss: 0.0416 - accuracy: 0.9857Restoring model weights from the end of the best epoch: 131.\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0413 - accuracy: 0.9858 - val_loss: 0.0739 - val_accuracy: 0.9751\n",
      "Epoch 151: early stopping\n",
      "Number of iterations 7\n",
      "F1-scores:  [0.7836835599505563, 0.7772814294830889, 0.7835308796007485, 0.951032448377581, 0.7806963958460599, 0.9338942307692307, 0.9613059250302297]\n",
      "Average F1-Score 0.8530606955796421\n",
      "Std Dev F1-Score 0.08321763700474677\n",
      "Error bar F1-Score 0.031453310315572275\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 10ms/step - loss: 0.5559 - accuracy: 0.7128 - val_loss: 0.4340 - val_accuracy: 0.7766\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4025 - accuracy: 0.7983 - val_loss: 0.3872 - val_accuracy: 0.8025\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3915 - accuracy: 0.8076 - val_loss: 0.4384 - val_accuracy: 0.7727\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3816 - accuracy: 0.8133 - val_loss: 0.3660 - val_accuracy: 0.8208\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3686 - accuracy: 0.8244 - val_loss: 0.3595 - val_accuracy: 0.8211\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3697 - accuracy: 0.8232 - val_loss: 0.3677 - val_accuracy: 0.8246\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3703 - accuracy: 0.8211 - val_loss: 0.4128 - val_accuracy: 0.8001\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3617 - accuracy: 0.8284 - val_loss: 0.3601 - val_accuracy: 0.8373\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3501 - accuracy: 0.8344 - val_loss: 0.3538 - val_accuracy: 0.8355\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3497 - accuracy: 0.8354 - val_loss: 0.3463 - val_accuracy: 0.8404\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3448 - accuracy: 0.8390 - val_loss: 0.3397 - val_accuracy: 0.8492\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3423 - accuracy: 0.8387 - val_loss: 0.3309 - val_accuracy: 0.8446\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3396 - accuracy: 0.8394 - val_loss: 0.3208 - val_accuracy: 0.8502\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3349 - accuracy: 0.8429 - val_loss: 0.3282 - val_accuracy: 0.8516\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3315 - accuracy: 0.8453 - val_loss: 0.3176 - val_accuracy: 0.8544\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3250 - accuracy: 0.8494 - val_loss: 0.3107 - val_accuracy: 0.8615\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3225 - accuracy: 0.8521 - val_loss: 0.3133 - val_accuracy: 0.8576\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3298 - accuracy: 0.8463 - val_loss: 0.3034 - val_accuracy: 0.8678\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3089 - accuracy: 0.8574 - val_loss: 0.2970 - val_accuracy: 0.8660\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3090 - accuracy: 0.8565 - val_loss: 0.2941 - val_accuracy: 0.8699\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3070 - accuracy: 0.8607 - val_loss: 0.3022 - val_accuracy: 0.8667\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2937 - accuracy: 0.8648 - val_loss: 0.2850 - val_accuracy: 0.8790\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2881 - accuracy: 0.8690 - val_loss: 0.2936 - val_accuracy: 0.8674\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3036 - accuracy: 0.8601 - val_loss: 0.2823 - val_accuracy: 0.8779\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2857 - accuracy: 0.8685 - val_loss: 0.2894 - val_accuracy: 0.8664\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2846 - accuracy: 0.8686 - val_loss: 0.2950 - val_accuracy: 0.8643\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2991 - accuracy: 0.8614 - val_loss: 0.2867 - val_accuracy: 0.8727\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2795 - accuracy: 0.8723 - val_loss: 0.2665 - val_accuracy: 0.8790\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3067 - accuracy: 0.8522 - val_loss: 0.2913 - val_accuracy: 0.8646\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2660 - accuracy: 0.8777 - val_loss: 0.2784 - val_accuracy: 0.8671\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2685 - accuracy: 0.8767 - val_loss: 0.2653 - val_accuracy: 0.8800\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2612 - accuracy: 0.8806 - val_loss: 0.2652 - val_accuracy: 0.8811\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2579 - accuracy: 0.8831 - val_loss: 0.3266 - val_accuracy: 0.8411\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2425 - accuracy: 0.8897 - val_loss: 0.2685 - val_accuracy: 0.8765\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2327 - accuracy: 0.8948 - val_loss: 0.2262 - val_accuracy: 0.9011\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2249 - accuracy: 0.9001 - val_loss: 0.2248 - val_accuracy: 0.8976\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2447 - accuracy: 0.8895 - val_loss: 0.2296 - val_accuracy: 0.8944\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2169 - accuracy: 0.9015 - val_loss: 0.2266 - val_accuracy: 0.8976\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2165 - accuracy: 0.9042 - val_loss: 0.2507 - val_accuracy: 0.9021\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2125 - accuracy: 0.9053 - val_loss: 0.2062 - val_accuracy: 0.9074\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2138 - accuracy: 0.9060 - val_loss: 0.2542 - val_accuracy: 0.8804\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1902 - accuracy: 0.9184 - val_loss: 0.2410 - val_accuracy: 0.8923\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1901 - accuracy: 0.9183 - val_loss: 0.3046 - val_accuracy: 0.8650\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1931 - accuracy: 0.9164 - val_loss: 0.2395 - val_accuracy: 0.8913\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2015 - accuracy: 0.9127 - val_loss: 0.2160 - val_accuracy: 0.9000\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1732 - accuracy: 0.9254 - val_loss: 0.2146 - val_accuracy: 0.9025\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1597 - accuracy: 0.9342 - val_loss: 0.1491 - val_accuracy: 0.9379\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1792 - accuracy: 0.9247 - val_loss: 0.1653 - val_accuracy: 0.9309\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1621 - accuracy: 0.9314 - val_loss: 0.1948 - val_accuracy: 0.9235\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1482 - accuracy: 0.9380 - val_loss: 0.2141 - val_accuracy: 0.9011\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1521 - accuracy: 0.9369 - val_loss: 0.2885 - val_accuracy: 0.8797\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1559 - accuracy: 0.9350 - val_loss: 0.1505 - val_accuracy: 0.9386\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1531 - accuracy: 0.9375 - val_loss: 0.1549 - val_accuracy: 0.9379\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1471 - accuracy: 0.9403 - val_loss: 0.1668 - val_accuracy: 0.9263\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1403 - accuracy: 0.9421 - val_loss: 0.2058 - val_accuracy: 0.9085\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1392 - accuracy: 0.9431 - val_loss: 0.1423 - val_accuracy: 0.9439\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1252 - accuracy: 0.9497 - val_loss: 0.1612 - val_accuracy: 0.9320\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1470 - accuracy: 0.9393 - val_loss: 0.1546 - val_accuracy: 0.9390\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1255 - accuracy: 0.9500 - val_loss: 0.1544 - val_accuracy: 0.9355\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1263 - accuracy: 0.9503 - val_loss: 0.1506 - val_accuracy: 0.9393\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1177 - accuracy: 0.9528 - val_loss: 0.1754 - val_accuracy: 0.9211\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1145 - accuracy: 0.9532 - val_loss: 0.1199 - val_accuracy: 0.9502\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1708 - accuracy: 0.9278 - val_loss: 0.3421 - val_accuracy: 0.8355\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2612 - accuracy: 0.8825 - val_loss: 0.2974 - val_accuracy: 0.8671\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2264 - accuracy: 0.8994 - val_loss: 0.2230 - val_accuracy: 0.8969\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2134 - accuracy: 0.9060 - val_loss: 0.2060 - val_accuracy: 0.9081\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2063 - accuracy: 0.9082 - val_loss: 0.2396 - val_accuracy: 0.8923\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1970 - accuracy: 0.9124 - val_loss: 0.2108 - val_accuracy: 0.9078\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1959 - accuracy: 0.9149 - val_loss: 0.2099 - val_accuracy: 0.9056\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1972 - accuracy: 0.9135 - val_loss: 0.2180 - val_accuracy: 0.8976\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1849 - accuracy: 0.9193 - val_loss: 0.2439 - val_accuracy: 0.8853\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1890 - accuracy: 0.9190 - val_loss: 0.2062 - val_accuracy: 0.9067\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1808 - accuracy: 0.9220 - val_loss: 0.1903 - val_accuracy: 0.9186\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1689 - accuracy: 0.9264 - val_loss: 0.1857 - val_accuracy: 0.9144\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1638 - accuracy: 0.9307 - val_loss: 0.1861 - val_accuracy: 0.9200\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1507 - accuracy: 0.9373 - val_loss: 0.1798 - val_accuracy: 0.9267\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1473 - accuracy: 0.9398 - val_loss: 0.2178 - val_accuracy: 0.9158\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1324 - accuracy: 0.9454 - val_loss: 0.1432 - val_accuracy: 0.9376\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1211 - accuracy: 0.9516 - val_loss: 0.1642 - val_accuracy: 0.9320\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1147 - accuracy: 0.9547 - val_loss: 0.1271 - val_accuracy: 0.9498\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1146 - accuracy: 0.9555 - val_loss: 0.1417 - val_accuracy: 0.9376\n",
      "Epoch 82/500\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1055 - accuracy: 0.9577Restoring model weights from the end of the best epoch: 62.\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1053 - accuracy: 0.9578 - val_loss: 0.1636 - val_accuracy: 0.9235\n",
      "Epoch 82: early stopping\n",
      "Number of iterations 8\n",
      "F1-scores:  [0.7836835599505563, 0.7772814294830889, 0.7835308796007485, 0.951032448377581, 0.7806963958460599, 0.9338942307692307, 0.9613059250302297, 0.9163722025912839]\n",
      "Average F1-Score 0.8609746339560973\n",
      "Std Dev F1-Score 0.08060980811573981\n",
      "Error bar F1-Score 0.028499870974393004\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 10ms/step - loss: 0.5246 - accuracy: 0.7225 - val_loss: 0.3959 - val_accuracy: 0.7924\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.4057 - accuracy: 0.7930 - val_loss: 0.3779 - val_accuracy: 0.8123\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3964 - accuracy: 0.8003 - val_loss: 0.4287 - val_accuracy: 0.7818\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3921 - accuracy: 0.8025 - val_loss: 0.3685 - val_accuracy: 0.8166\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3769 - accuracy: 0.8137 - val_loss: 0.3622 - val_accuracy: 0.8239\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3779 - accuracy: 0.8149 - val_loss: 0.3887 - val_accuracy: 0.8036\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3723 - accuracy: 0.8143 - val_loss: 0.3763 - val_accuracy: 0.8057\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3701 - accuracy: 0.8167 - val_loss: 0.3507 - val_accuracy: 0.8306\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3686 - accuracy: 0.8192 - val_loss: 0.3579 - val_accuracy: 0.8281\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3574 - accuracy: 0.8250 - val_loss: 0.3464 - val_accuracy: 0.8309\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3469 - accuracy: 0.8323 - val_loss: 0.3996 - val_accuracy: 0.7801\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3663 - accuracy: 0.8198 - val_loss: 0.3486 - val_accuracy: 0.8267\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3438 - accuracy: 0.8350 - val_loss: 0.3500 - val_accuracy: 0.8292\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3431 - accuracy: 0.8363 - val_loss: 0.3453 - val_accuracy: 0.8365\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3452 - accuracy: 0.8327 - val_loss: 0.3366 - val_accuracy: 0.8397\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3328 - accuracy: 0.8411 - val_loss: 0.3233 - val_accuracy: 0.8492\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3360 - accuracy: 0.8404 - val_loss: 0.3150 - val_accuracy: 0.8481\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3225 - accuracy: 0.8498 - val_loss: 0.3205 - val_accuracy: 0.8495\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3253 - accuracy: 0.8456 - val_loss: 0.3854 - val_accuracy: 0.8123\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3262 - accuracy: 0.8458 - val_loss: 0.3160 - val_accuracy: 0.8537\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3177 - accuracy: 0.8509 - val_loss: 0.3104 - val_accuracy: 0.8541\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3034 - accuracy: 0.8592 - val_loss: 0.3761 - val_accuracy: 0.8232\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3126 - accuracy: 0.8553 - val_loss: 0.3036 - val_accuracy: 0.8604\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2976 - accuracy: 0.8633 - val_loss: 0.2874 - val_accuracy: 0.8723\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3060 - accuracy: 0.8586 - val_loss: 0.3630 - val_accuracy: 0.8327\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3089 - accuracy: 0.8578 - val_loss: 0.2865 - val_accuracy: 0.8734\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3041 - accuracy: 0.8566 - val_loss: 0.3578 - val_accuracy: 0.8302\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2763 - accuracy: 0.8739 - val_loss: 0.3307 - val_accuracy: 0.8478\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2745 - accuracy: 0.8740 - val_loss: 0.3331 - val_accuracy: 0.8474\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2705 - accuracy: 0.8769 - val_loss: 0.2807 - val_accuracy: 0.8664\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2588 - accuracy: 0.8796 - val_loss: 0.2444 - val_accuracy: 0.8843\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2594 - accuracy: 0.8801 - val_loss: 0.2480 - val_accuracy: 0.8850\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2516 - accuracy: 0.8840 - val_loss: 0.2936 - val_accuracy: 0.8681\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2485 - accuracy: 0.8860 - val_loss: 0.2402 - val_accuracy: 0.8895\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2435 - accuracy: 0.8902 - val_loss: 0.2630 - val_accuracy: 0.8744\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2267 - accuracy: 0.8969 - val_loss: 0.2315 - val_accuracy: 0.8927\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2348 - accuracy: 0.8960 - val_loss: 0.2750 - val_accuracy: 0.8713\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2354 - accuracy: 0.8959 - val_loss: 0.2379 - val_accuracy: 0.8909\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2342 - accuracy: 0.8952 - val_loss: 0.2469 - val_accuracy: 0.8906\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2299 - accuracy: 0.8965 - val_loss: 0.3045 - val_accuracy: 0.8629\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2132 - accuracy: 0.9055 - val_loss: 0.2385 - val_accuracy: 0.8979\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2110 - accuracy: 0.9068 - val_loss: 0.2090 - val_accuracy: 0.9053\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2056 - accuracy: 0.9081 - val_loss: 0.2115 - val_accuracy: 0.9042\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2021 - accuracy: 0.9115 - val_loss: 0.2002 - val_accuracy: 0.9074\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2023 - accuracy: 0.9107 - val_loss: 0.2529 - val_accuracy: 0.8835\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2008 - accuracy: 0.9132 - val_loss: 0.2113 - val_accuracy: 0.9039\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1972 - accuracy: 0.9142 - val_loss: 0.2011 - val_accuracy: 0.9141\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1951 - accuracy: 0.9148 - val_loss: 0.2267 - val_accuracy: 0.9049\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1972 - accuracy: 0.9147 - val_loss: 0.2578 - val_accuracy: 0.8878\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1887 - accuracy: 0.9195 - val_loss: 0.2040 - val_accuracy: 0.9063\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1888 - accuracy: 0.9169 - val_loss: 0.1952 - val_accuracy: 0.9162\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1841 - accuracy: 0.9208 - val_loss: 0.2000 - val_accuracy: 0.9074\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1825 - accuracy: 0.9189 - val_loss: 0.1999 - val_accuracy: 0.9155\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1826 - accuracy: 0.9190 - val_loss: 0.1964 - val_accuracy: 0.9211\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1705 - accuracy: 0.9264 - val_loss: 0.2133 - val_accuracy: 0.9063\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1780 - accuracy: 0.9230 - val_loss: 0.2140 - val_accuracy: 0.9106\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1825 - accuracy: 0.9210 - val_loss: 0.1903 - val_accuracy: 0.9172\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1649 - accuracy: 0.9286 - val_loss: 0.1810 - val_accuracy: 0.9225\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1716 - accuracy: 0.9268 - val_loss: 0.1866 - val_accuracy: 0.9211\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1585 - accuracy: 0.9332 - val_loss: 0.2047 - val_accuracy: 0.9165\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1620 - accuracy: 0.9317 - val_loss: 0.1826 - val_accuracy: 0.9200\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1582 - accuracy: 0.9321 - val_loss: 0.1901 - val_accuracy: 0.9172\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1576 - accuracy: 0.9331 - val_loss: 0.1968 - val_accuracy: 0.9165\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1585 - accuracy: 0.9346 - val_loss: 0.2172 - val_accuracy: 0.9063\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1683 - accuracy: 0.9304 - val_loss: 0.1849 - val_accuracy: 0.9228\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1455 - accuracy: 0.9391 - val_loss: 0.2595 - val_accuracy: 0.8951\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1494 - accuracy: 0.9384 - val_loss: 0.1878 - val_accuracy: 0.9246\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1433 - accuracy: 0.9397 - val_loss: 0.1719 - val_accuracy: 0.9330\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1432 - accuracy: 0.9398 - val_loss: 0.1747 - val_accuracy: 0.9295\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1435 - accuracy: 0.9399 - val_loss: 0.1661 - val_accuracy: 0.9320\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1310 - accuracy: 0.9457 - val_loss: 0.1924 - val_accuracy: 0.9183\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1290 - accuracy: 0.9472 - val_loss: 0.1681 - val_accuracy: 0.9316\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1437 - accuracy: 0.9406 - val_loss: 0.1757 - val_accuracy: 0.9298\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1273 - accuracy: 0.9469 - val_loss: 0.1792 - val_accuracy: 0.9288\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1313 - accuracy: 0.9472 - val_loss: 0.1795 - val_accuracy: 0.9298\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1339 - accuracy: 0.9437 - val_loss: 0.1761 - val_accuracy: 0.9334\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1194 - accuracy: 0.9518 - val_loss: 0.1769 - val_accuracy: 0.9298\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1217 - accuracy: 0.9499 - val_loss: 0.1749 - val_accuracy: 0.9320\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1144 - accuracy: 0.9546 - val_loss: 0.1651 - val_accuracy: 0.9344\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1229 - accuracy: 0.9502 - val_loss: 0.1751 - val_accuracy: 0.9337\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1138 - accuracy: 0.9520 - val_loss: 0.1668 - val_accuracy: 0.9337\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1109 - accuracy: 0.9566 - val_loss: 0.1693 - val_accuracy: 0.9344\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1121 - accuracy: 0.9542 - val_loss: 0.1621 - val_accuracy: 0.9355\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1111 - accuracy: 0.9547 - val_loss: 0.1589 - val_accuracy: 0.9362\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1317 - accuracy: 0.9483 - val_loss: 0.2001 - val_accuracy: 0.9260\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1017 - accuracy: 0.9592 - val_loss: 0.1971 - val_accuracy: 0.9218\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0999 - accuracy: 0.9613 - val_loss: 0.1569 - val_accuracy: 0.9393\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0963 - accuracy: 0.9615 - val_loss: 0.2213 - val_accuracy: 0.9225\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1139 - accuracy: 0.9546 - val_loss: 0.1695 - val_accuracy: 0.9344\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0894 - accuracy: 0.9654 - val_loss: 0.1641 - val_accuracy: 0.9407\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0928 - accuracy: 0.9631 - val_loss: 0.2021 - val_accuracy: 0.9221\n",
      "Epoch 92/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0922 - accuracy: 0.9633 - val_loss: 0.1669 - val_accuracy: 0.9404\n",
      "Epoch 93/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0904 - accuracy: 0.9642 - val_loss: 0.1601 - val_accuracy: 0.9386\n",
      "Epoch 94/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0899 - accuracy: 0.9638 - val_loss: 0.1821 - val_accuracy: 0.9348\n",
      "Epoch 95/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0994 - accuracy: 0.9585 - val_loss: 0.1859 - val_accuracy: 0.9267\n",
      "Epoch 96/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0874 - accuracy: 0.9647 - val_loss: 0.1697 - val_accuracy: 0.9435\n",
      "Epoch 97/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0890 - accuracy: 0.9643 - val_loss: 0.2326 - val_accuracy: 0.9123\n",
      "Epoch 98/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1192 - accuracy: 0.9537 - val_loss: 0.2801 - val_accuracy: 0.8744\n",
      "Epoch 99/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1332 - accuracy: 0.9436 - val_loss: 0.1529 - val_accuracy: 0.9456\n",
      "Epoch 100/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0806 - accuracy: 0.9687 - val_loss: 0.2004 - val_accuracy: 0.9239\n",
      "Epoch 101/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0821 - accuracy: 0.9673 - val_loss: 0.1731 - val_accuracy: 0.9390\n",
      "Epoch 102/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0820 - accuracy: 0.9694 - val_loss: 0.1736 - val_accuracy: 0.9344\n",
      "Epoch 103/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0868 - accuracy: 0.9666 - val_loss: 0.1794 - val_accuracy: 0.9309\n",
      "Epoch 104/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0814 - accuracy: 0.9684 - val_loss: 0.1791 - val_accuracy: 0.9414\n",
      "Epoch 105/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0766 - accuracy: 0.9704 - val_loss: 0.1673 - val_accuracy: 0.9383\n",
      "Epoch 106/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0667 - accuracy: 0.9737 - val_loss: 0.1753 - val_accuracy: 0.9393\n",
      "Epoch 107/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0939 - accuracy: 0.9632 - val_loss: 0.1692 - val_accuracy: 0.9397\n",
      "Epoch 108/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0686 - accuracy: 0.9743 - val_loss: 0.1736 - val_accuracy: 0.9372\n",
      "Epoch 109/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0786 - accuracy: 0.9699 - val_loss: 0.1578 - val_accuracy: 0.9418\n",
      "Epoch 110/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0808 - accuracy: 0.9692 - val_loss: 0.1811 - val_accuracy: 0.9362\n",
      "Epoch 111/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0653 - accuracy: 0.9755 - val_loss: 0.1603 - val_accuracy: 0.9421\n",
      "Epoch 112/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0657 - accuracy: 0.9740 - val_loss: 0.1920 - val_accuracy: 0.9327\n",
      "Epoch 113/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0761 - accuracy: 0.9708 - val_loss: 0.1588 - val_accuracy: 0.9449\n",
      "Epoch 114/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0728 - accuracy: 0.9717 - val_loss: 0.1590 - val_accuracy: 0.9428\n",
      "Epoch 115/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0611 - accuracy: 0.9770 - val_loss: 0.1769 - val_accuracy: 0.9463\n",
      "Epoch 116/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0645 - accuracy: 0.9758 - val_loss: 0.1679 - val_accuracy: 0.9432\n",
      "Epoch 117/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0630 - accuracy: 0.9758 - val_loss: 0.1814 - val_accuracy: 0.9446\n",
      "Epoch 118/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0663 - accuracy: 0.9752 - val_loss: 0.1612 - val_accuracy: 0.9474\n",
      "Epoch 119/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0553 - accuracy: 0.9792 - val_loss: 0.1521 - val_accuracy: 0.9495\n",
      "Epoch 120/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0619 - accuracy: 0.9771 - val_loss: 0.1823 - val_accuracy: 0.9435\n",
      "Epoch 121/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0534 - accuracy: 0.9799 - val_loss: 0.1512 - val_accuracy: 0.9555\n",
      "Epoch 122/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0607 - accuracy: 0.9770 - val_loss: 0.1525 - val_accuracy: 0.9463\n",
      "Epoch 123/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0536 - accuracy: 0.9811 - val_loss: 0.2229 - val_accuracy: 0.9330\n",
      "Epoch 124/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0528 - accuracy: 0.9801 - val_loss: 0.1593 - val_accuracy: 0.9523\n",
      "Epoch 125/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0641 - accuracy: 0.9757 - val_loss: 0.1966 - val_accuracy: 0.9298\n",
      "Epoch 126/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0708 - accuracy: 0.9734 - val_loss: 0.1447 - val_accuracy: 0.9533\n",
      "Epoch 127/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0504 - accuracy: 0.9804 - val_loss: 0.2172 - val_accuracy: 0.9365\n",
      "Epoch 128/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0458 - accuracy: 0.9829 - val_loss: 0.1575 - val_accuracy: 0.9519\n",
      "Epoch 129/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0554 - accuracy: 0.9794 - val_loss: 0.1963 - val_accuracy: 0.9344\n",
      "Epoch 130/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0590 - accuracy: 0.9787 - val_loss: 0.1576 - val_accuracy: 0.9526\n",
      "Epoch 131/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0488 - accuracy: 0.9820 - val_loss: 0.1852 - val_accuracy: 0.9463\n",
      "Epoch 132/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0412 - accuracy: 0.9845 - val_loss: 0.1697 - val_accuracy: 0.9509\n",
      "Epoch 133/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0665 - accuracy: 0.9753 - val_loss: 0.1725 - val_accuracy: 0.9421\n",
      "Epoch 134/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0420 - accuracy: 0.9842 - val_loss: 0.2456 - val_accuracy: 0.9218\n",
      "Epoch 135/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0560 - accuracy: 0.9791 - val_loss: 0.1894 - val_accuracy: 0.9463\n",
      "Epoch 136/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0445 - accuracy: 0.9837 - val_loss: 0.1520 - val_accuracy: 0.9516\n",
      "Epoch 137/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0448 - accuracy: 0.9825 - val_loss: 0.1815 - val_accuracy: 0.9456\n",
      "Epoch 138/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0388 - accuracy: 0.9859 - val_loss: 0.1743 - val_accuracy: 0.9502\n",
      "Epoch 139/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0403 - accuracy: 0.9865 - val_loss: 0.1832 - val_accuracy: 0.9537\n",
      "Epoch 140/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0421 - accuracy: 0.9837 - val_loss: 0.2227 - val_accuracy: 0.9351\n",
      "Epoch 141/500\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.0661 - accuracy: 0.9756Restoring model weights from the end of the best epoch: 121.\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0661 - accuracy: 0.9755 - val_loss: 0.1810 - val_accuracy: 0.9414\n",
      "Epoch 141: early stopping\n",
      "Number of iterations 9\n",
      "F1-scores:  [0.7836835599505563, 0.7772814294830889, 0.7835308796007485, 0.951032448377581, 0.7806963958460599, 0.9338942307692307, 0.9613059250302297, 0.9163722025912839, 0.9240884638374177]\n",
      "Average F1-Score 0.8679872817206884\n",
      "Std Dev F1-Score 0.07854530877844211\n",
      "Error bar F1-Score 0.026181769592814038\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 6s 10ms/step - loss: 0.5193 - accuracy: 0.7349 - val_loss: 0.4002 - val_accuracy: 0.8015\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3901 - accuracy: 0.8125 - val_loss: 0.3780 - val_accuracy: 0.8116\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3865 - accuracy: 0.8094 - val_loss: 0.4036 - val_accuracy: 0.8130\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3747 - accuracy: 0.8193 - val_loss: 0.3618 - val_accuracy: 0.8306\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3640 - accuracy: 0.8278 - val_loss: 0.3514 - val_accuracy: 0.8316\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3707 - accuracy: 0.8205 - val_loss: 0.3478 - val_accuracy: 0.8348\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3556 - accuracy: 0.8298 - val_loss: 0.3677 - val_accuracy: 0.8253\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3569 - accuracy: 0.8306 - val_loss: 0.3774 - val_accuracy: 0.8271\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3560 - accuracy: 0.8328 - val_loss: 0.3477 - val_accuracy: 0.8292\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3499 - accuracy: 0.8347 - val_loss: 0.3668 - val_accuracy: 0.8218\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3435 - accuracy: 0.8373 - val_loss: 0.3300 - val_accuracy: 0.8488\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3447 - accuracy: 0.8372 - val_loss: 0.3763 - val_accuracy: 0.8130\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3499 - accuracy: 0.8349 - val_loss: 0.3706 - val_accuracy: 0.8351\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3305 - accuracy: 0.8433 - val_loss: 0.3484 - val_accuracy: 0.8390\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3297 - accuracy: 0.8461 - val_loss: 0.3056 - val_accuracy: 0.8639\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3261 - accuracy: 0.8482 - val_loss: 0.3187 - val_accuracy: 0.8544\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3133 - accuracy: 0.8533 - val_loss: 0.3100 - val_accuracy: 0.8657\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3068 - accuracy: 0.8586 - val_loss: 0.3109 - val_accuracy: 0.8618\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3045 - accuracy: 0.8601 - val_loss: 0.4775 - val_accuracy: 0.7531\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.3078 - accuracy: 0.8579 - val_loss: 0.3579 - val_accuracy: 0.8355\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2964 - accuracy: 0.8629 - val_loss: 0.2785 - val_accuracy: 0.8776\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2892 - accuracy: 0.8664 - val_loss: 0.2755 - val_accuracy: 0.8755\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2903 - accuracy: 0.8669 - val_loss: 0.2778 - val_accuracy: 0.8779\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2804 - accuracy: 0.8719 - val_loss: 0.3521 - val_accuracy: 0.8313\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2707 - accuracy: 0.8765 - val_loss: 0.2542 - val_accuracy: 0.8835\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2755 - accuracy: 0.8747 - val_loss: 0.2613 - val_accuracy: 0.8765\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2865 - accuracy: 0.8667 - val_loss: 0.2597 - val_accuracy: 0.8814\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2751 - accuracy: 0.8742 - val_loss: 0.2825 - val_accuracy: 0.8667\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2605 - accuracy: 0.8831 - val_loss: 0.2411 - val_accuracy: 0.8916\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2551 - accuracy: 0.8855 - val_loss: 0.2488 - val_accuracy: 0.8892\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2488 - accuracy: 0.8870 - val_loss: 0.2633 - val_accuracy: 0.8814\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2382 - accuracy: 0.8945 - val_loss: 0.2414 - val_accuracy: 0.8941\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2323 - accuracy: 0.9002 - val_loss: 0.2535 - val_accuracy: 0.8853\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2389 - accuracy: 0.8945 - val_loss: 0.2684 - val_accuracy: 0.8797\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2203 - accuracy: 0.9029 - val_loss: 0.2194 - val_accuracy: 0.9042\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2056 - accuracy: 0.9121 - val_loss: 0.2319 - val_accuracy: 0.9011\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2093 - accuracy: 0.9095 - val_loss: 0.2086 - val_accuracy: 0.9025\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1975 - accuracy: 0.9153 - val_loss: 0.2136 - val_accuracy: 0.9028\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1929 - accuracy: 0.9179 - val_loss: 0.1856 - val_accuracy: 0.9172\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1752 - accuracy: 0.9260 - val_loss: 0.1644 - val_accuracy: 0.9309\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1669 - accuracy: 0.9292 - val_loss: 0.1488 - val_accuracy: 0.9362\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1720 - accuracy: 0.9279 - val_loss: 0.1476 - val_accuracy: 0.9383\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1861 - accuracy: 0.9203 - val_loss: 0.1429 - val_accuracy: 0.9435\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1601 - accuracy: 0.9336 - val_loss: 0.3372 - val_accuracy: 0.8555\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1654 - accuracy: 0.9306 - val_loss: 0.2180 - val_accuracy: 0.9021\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1473 - accuracy: 0.9401 - val_loss: 0.1241 - val_accuracy: 0.9488\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1731 - accuracy: 0.9253 - val_loss: 0.2741 - val_accuracy: 0.8706\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1935 - accuracy: 0.9181 - val_loss: 0.2603 - val_accuracy: 0.8744\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1584 - accuracy: 0.9343 - val_loss: 0.1730 - val_accuracy: 0.9228\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1409 - accuracy: 0.9424 - val_loss: 0.1655 - val_accuracy: 0.9327\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1812 - accuracy: 0.9250 - val_loss: 0.2538 - val_accuracy: 0.8850\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2087 - accuracy: 0.9097 - val_loss: 0.1549 - val_accuracy: 0.9309\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1360 - accuracy: 0.9452 - val_loss: 0.1139 - val_accuracy: 0.9530\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1431 - accuracy: 0.9403 - val_loss: 0.1184 - val_accuracy: 0.9558\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1427 - accuracy: 0.9407 - val_loss: 0.1411 - val_accuracy: 0.9435\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1214 - accuracy: 0.9517 - val_loss: 0.1394 - val_accuracy: 0.9418\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1557 - accuracy: 0.9363 - val_loss: 0.1251 - val_accuracy: 0.9505\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1293 - accuracy: 0.9483 - val_loss: 0.1283 - val_accuracy: 0.9477\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1442 - accuracy: 0.9420 - val_loss: 0.1699 - val_accuracy: 0.9225\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1237 - accuracy: 0.9496 - val_loss: 0.1084 - val_accuracy: 0.9597\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1539 - accuracy: 0.9351 - val_loss: 0.1664 - val_accuracy: 0.9302\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1266 - accuracy: 0.9495 - val_loss: 0.1220 - val_accuracy: 0.9576\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1230 - accuracy: 0.9502 - val_loss: 0.1091 - val_accuracy: 0.9541\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1484 - accuracy: 0.9379 - val_loss: 0.3552 - val_accuracy: 0.8187\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.2145 - accuracy: 0.9072 - val_loss: 0.2111 - val_accuracy: 0.9081\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1527 - accuracy: 0.9371 - val_loss: 0.2213 - val_accuracy: 0.8972\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1568 - accuracy: 0.9325 - val_loss: 0.5123 - val_accuracy: 0.7917\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1793 - accuracy: 0.9227 - val_loss: 0.1221 - val_accuracy: 0.9509\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1277 - accuracy: 0.9493 - val_loss: 0.1676 - val_accuracy: 0.9267\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1174 - accuracy: 0.9542 - val_loss: 0.1690 - val_accuracy: 0.9298\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1110 - accuracy: 0.9555 - val_loss: 0.0998 - val_accuracy: 0.9597\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1227 - accuracy: 0.9514 - val_loss: 0.1567 - val_accuracy: 0.9323\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1184 - accuracy: 0.9510 - val_loss: 0.1339 - val_accuracy: 0.9477\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1254 - accuracy: 0.9500 - val_loss: 0.1456 - val_accuracy: 0.9442\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1320 - accuracy: 0.9465 - val_loss: 0.1082 - val_accuracy: 0.9555\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1125 - accuracy: 0.9563 - val_loss: 0.1232 - val_accuracy: 0.9505\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1069 - accuracy: 0.9578 - val_loss: 0.1214 - val_accuracy: 0.9555\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1148 - accuracy: 0.9546 - val_loss: 0.1827 - val_accuracy: 0.9155\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0994 - accuracy: 0.9603 - val_loss: 0.0877 - val_accuracy: 0.9695\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1116 - accuracy: 0.9555 - val_loss: 0.0977 - val_accuracy: 0.9628\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1035 - accuracy: 0.9603 - val_loss: 0.1202 - val_accuracy: 0.9509\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1024 - accuracy: 0.9589 - val_loss: 0.1174 - val_accuracy: 0.9523\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0863 - accuracy: 0.9669 - val_loss: 0.0854 - val_accuracy: 0.9667\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0910 - accuracy: 0.9634 - val_loss: 0.1480 - val_accuracy: 0.9355\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1196 - accuracy: 0.9535 - val_loss: 0.1015 - val_accuracy: 0.9628\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0871 - accuracy: 0.9673 - val_loss: 0.0971 - val_accuracy: 0.9625\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0930 - accuracy: 0.9644 - val_loss: 0.1042 - val_accuracy: 0.9607\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0854 - accuracy: 0.9673 - val_loss: 0.1271 - val_accuracy: 0.9526\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0775 - accuracy: 0.9699 - val_loss: 0.1265 - val_accuracy: 0.9477\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0868 - accuracy: 0.9673 - val_loss: 0.0761 - val_accuracy: 0.9691\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0913 - accuracy: 0.9643 - val_loss: 0.2528 - val_accuracy: 0.9056\n",
      "Epoch 92/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0877 - accuracy: 0.9673 - val_loss: 0.1248 - val_accuracy: 0.9523\n",
      "Epoch 93/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0911 - accuracy: 0.9657 - val_loss: 0.0792 - val_accuracy: 0.9712\n",
      "Epoch 94/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0855 - accuracy: 0.9672 - val_loss: 0.1467 - val_accuracy: 0.9407\n",
      "Epoch 95/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0755 - accuracy: 0.9717 - val_loss: 0.1696 - val_accuracy: 0.9288\n",
      "Epoch 96/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0813 - accuracy: 0.9687 - val_loss: 0.1108 - val_accuracy: 0.9607\n",
      "Epoch 97/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0944 - accuracy: 0.9640 - val_loss: 0.0952 - val_accuracy: 0.9653\n",
      "Epoch 98/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0848 - accuracy: 0.9680 - val_loss: 0.0838 - val_accuracy: 0.9709\n",
      "Epoch 99/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0789 - accuracy: 0.9717 - val_loss: 0.0931 - val_accuracy: 0.9712\n",
      "Epoch 100/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0855 - accuracy: 0.9656 - val_loss: 0.0739 - val_accuracy: 0.9751\n",
      "Epoch 101/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0741 - accuracy: 0.9729 - val_loss: 0.1055 - val_accuracy: 0.9597\n",
      "Epoch 102/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0812 - accuracy: 0.9688 - val_loss: 0.0688 - val_accuracy: 0.9751\n",
      "Epoch 103/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0679 - accuracy: 0.9758 - val_loss: 0.1031 - val_accuracy: 0.9614\n",
      "Epoch 104/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0793 - accuracy: 0.9700 - val_loss: 0.0790 - val_accuracy: 0.9723\n",
      "Epoch 105/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0725 - accuracy: 0.9722 - val_loss: 0.0807 - val_accuracy: 0.9667\n",
      "Epoch 106/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1095 - accuracy: 0.9565 - val_loss: 0.0660 - val_accuracy: 0.9779\n",
      "Epoch 107/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0772 - accuracy: 0.9714 - val_loss: 0.0658 - val_accuracy: 0.9769\n",
      "Epoch 108/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0743 - accuracy: 0.9710 - val_loss: 0.0779 - val_accuracy: 0.9716\n",
      "Epoch 109/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0729 - accuracy: 0.9717 - val_loss: 0.0751 - val_accuracy: 0.9747\n",
      "Epoch 110/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0845 - accuracy: 0.9685 - val_loss: 0.0730 - val_accuracy: 0.9765\n",
      "Epoch 111/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0677 - accuracy: 0.9749 - val_loss: 0.1178 - val_accuracy: 0.9572\n",
      "Epoch 112/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0646 - accuracy: 0.9760 - val_loss: 0.0805 - val_accuracy: 0.9719\n",
      "Epoch 113/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0686 - accuracy: 0.9740 - val_loss: 0.1267 - val_accuracy: 0.9576\n",
      "Epoch 114/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0757 - accuracy: 0.9712 - val_loss: 0.0699 - val_accuracy: 0.9730\n",
      "Epoch 115/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.1147 - accuracy: 0.9554 - val_loss: 0.0806 - val_accuracy: 0.9740\n",
      "Epoch 116/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0677 - accuracy: 0.9749 - val_loss: 0.1593 - val_accuracy: 0.9323\n",
      "Epoch 117/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0884 - accuracy: 0.9664 - val_loss: 0.0826 - val_accuracy: 0.9698\n",
      "Epoch 118/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0590 - accuracy: 0.9785 - val_loss: 0.1061 - val_accuracy: 0.9628\n",
      "Epoch 119/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0602 - accuracy: 0.9779 - val_loss: 0.0800 - val_accuracy: 0.9723\n",
      "Epoch 120/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0556 - accuracy: 0.9796 - val_loss: 0.0689 - val_accuracy: 0.9751\n",
      "Epoch 121/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0683 - accuracy: 0.9740 - val_loss: 0.0757 - val_accuracy: 0.9733\n",
      "Epoch 122/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0696 - accuracy: 0.9748 - val_loss: 0.1129 - val_accuracy: 0.9593\n",
      "Epoch 123/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0615 - accuracy: 0.9762 - val_loss: 0.0688 - val_accuracy: 0.9740\n",
      "Epoch 124/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0600 - accuracy: 0.9789 - val_loss: 0.1963 - val_accuracy: 0.9249\n",
      "Epoch 125/500\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0780 - accuracy: 0.9702 - val_loss: 0.0683 - val_accuracy: 0.9758\n",
      "Epoch 126/500\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.9749Restoring model weights from the end of the best epoch: 106.\n",
      "334/334 [==============================] - 3s 8ms/step - loss: 0.0670 - accuracy: 0.9749 - val_loss: 0.1015 - val_accuracy: 0.9628\n",
      "Epoch 126: early stopping\n",
      "Number of iterations 10\n",
      "F1-scores:  [0.7836835599505563, 0.7772814294830889, 0.7835308796007485, 0.951032448377581, 0.7806963958460599, 0.9338942307692307, 0.9613059250302297, 0.9163722025912839, 0.9240884638374177, 0.962432915921288]\n",
      "Average F1-Score 0.8774318451407485\n",
      "Std Dev F1-Score 0.07971967750656386\n",
      "Error bar F1-Score 0.025209575525483453\n"
     ]
    }
   ],
   "source": [
    "###Collect F-Score 10 times\n",
    "import sklearn\n",
    "from tqdm.notebook import tqdm\n",
    "def calc_f1_score(X_train_scaled,X_test_scaled,y_train,y_test,earlystop):\n",
    "  classifier = Sequential()\n",
    "  classifier.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train_scaled.shape[1], X_train_scaled.shape[2])))\n",
    "  classifier.add(LSTM(units = 50))\n",
    "  classifier.add(Dense(units = 1,activation='sigmoid'))\n",
    "  classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  classifier.fit(X_train_scaled, y_train[:,0], epochs = 500, batch_size = 64,validation_data=(X_test_scaled,y_test[:,0]),callbacks=[earlystop])\n",
    "  y_pred = classifier.predict(X_test_scaled)\n",
    "  y_pred= (y_pred>=0.5).astype(int)\n",
    "  return(sklearn.metrics.f1_score(y_test[:,0],y_pred))\n",
    "\n",
    "f1_score_list=[]\n",
    "for i in tqdm(range(10)):\n",
    "  f1_score_list=f1_score_list+[calc_f1_score(X_train_scaled,X_test_scaled,y_train,y_test,earlystop)]\n",
    "  print(\"Number of iterations\",len(f1_score_list))\n",
    "  print(\"F1-scores: \",f1_score_list)\n",
    "  print(\"Average F1-Score\",np.mean(f1_score_list))\n",
    "  print(\"Std Dev F1-Score\",np.std(f1_score_list))\n",
    "  print(\"Error bar F1-Score\",np.std(f1_score_list)/np.sqrt(len(f1_score_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average F1-Score 0.8774318451407485\n",
    "# Std Dev F1-Score 0.07971967750656386\n",
    "# Error bar F1-Score 0.025209575525483453"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "LSTM_1d_exp1_exp5.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e1634033f2f4857b41b95a8dbb8c09b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a0d186baabf4a068249de2af6a3eeed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f06691ba85684ee19f3ae768666ec3db",
      "placeholder": "​",
      "style": "IPY_MODEL_9a64d884ed674eb38eaeb49a6e0d2600",
      "value": " 10/10 [42:20&lt;00:00, 315.06s/it]"
     }
    },
    "63b18f94224e4e6ea7c378d806e82d57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e9fd4647a9f4192b54444ccf1a55a0d",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_88190705dfe64d36af4b378e765f35a7",
      "value": 10
     }
    },
    "88190705dfe64d36af4b378e765f35a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "97a22bb53a2140a2a4b92690e0dd227b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a64d884ed674eb38eaeb49a6e0d2600": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e9fd4647a9f4192b54444ccf1a55a0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a143768c684f4817935bbfbf3f56a689": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4fb98cb7ad44dcaab82a0e5e478ac60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b9c461e673bb42139c8e08ff463de087",
       "IPY_MODEL_63b18f94224e4e6ea7c378d806e82d57",
       "IPY_MODEL_1a0d186baabf4a068249de2af6a3eeed"
      ],
      "layout": "IPY_MODEL_a143768c684f4817935bbfbf3f56a689"
     }
    },
    "b9c461e673bb42139c8e08ff463de087": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e1634033f2f4857b41b95a8dbb8c09b",
      "placeholder": "​",
      "style": "IPY_MODEL_97a22bb53a2140a2a4b92690e0dd227b",
      "value": "100%"
     }
    },
    "f06691ba85684ee19f3ae768666ec3db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
