{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JYsWwiwnPzi",
    "outputId": "47ca614a-6ec4-44f5-b9b1-f73ea1553913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 21 21:31:34 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdNIB899nhlq",
    "outputId": "6789089c-eb84-41cc-c28d-b3bf05e0980f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#mounting google drive on colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GfSazzTdnmaM"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bXN_d9Evntel"
   },
   "outputs": [],
   "source": [
    "X_train=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_X_trainv7_exp1_exp5_strat_v2.npy\")\n",
    "y_train=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_y_trainv7_exp1_exp5_strat_v2.npy\").astype(int)\n",
    "\n",
    "X_test=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_X_testv7_exp1_exp5_strat_v2.npy\")\n",
    "y_test=np.load(\"./drive/MyDrive/MSc Thesis/Experiments/all_pairs_ts_data_y_testv7_exp1_exp5_strat_v2.npy\").astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NVkzHpArmQFD",
    "outputId": "479745ca-6729-44a3-ebcf-0ce732333a0b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/scipy/signal/spectral.py:1966: UserWarning: nperseg = 256 is greater than input length  = 50, using nperseg = 50\n",
      "  .format(nperseg, input_length))\n"
     ]
    }
   ],
   "source": [
    "def calc_freq_signal(arr):\n",
    "    freqs, psd = signal.welch(arr, fs=10)\n",
    "    return psd\n",
    "\n",
    "X_train_f=np.apply_along_axis(calc_freq_signal, 1, X_train)\n",
    "X_test_f=np.apply_along_axis(calc_freq_signal, 1, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6MFvsoGCeuLr"
   },
   "outputs": [],
   "source": [
    "X_train_1d=np.gradient(X_train,axis=1)\n",
    "X_test_1d=np.gradient(X_test,axis=1)\n",
    "X_train=np.dstack([X_train,X_train_1d])\n",
    "X_test=np.dstack([X_test,X_test_1d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X86rj9C3fCRa",
    "outputId": "82a15f70-e852-4626-ba0c-64108cc3b946"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21347, 50, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GxsigJWlDahT"
   },
   "outputs": [],
   "source": [
    "def custom_scaler(X, range=(0, 1),min=None,max=None):\n",
    "    mi, ma = range\n",
    "    if(min==None):\n",
    "      min=X.min()\n",
    "      max=X.max()\n",
    "      print(\"\\nTrain_Scaling:- min=\",min,\" max=\",max)\n",
    "    X_std = (X - min) / (max - min)\n",
    "    X_scaled = X_std * (ma - mi) + mi\n",
    "    return min,max,X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JceKGdin-e6",
    "outputId": "78d17b6c-471a-41ad-f55d-d51c0a73e20b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train_Scaling:- min= -28.15271043323709  max= 37.07106781186548\n",
      "\n",
      "Train_Scaling:- min= -33.71032582929608  max= 33.60247434978709\n",
      "\n",
      "Train_Scaling:- min= -12.320254626359059  max= 14.385756524143293\n",
      "\n",
      "Train_Scaling:- min= -25.40645604165462  max= 18.311546903226954\n",
      "Frequency signals scaling:-------------\n",
      "\n",
      "Train_Scaling:- min= 0.0  max= 717.6949576342864\n",
      "\n",
      "Train_Scaling:- min= 0.0  max= 1338.5393381137053\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "#X_train contains 8 signals x1,x2,y1,y2,x1d,2d,y1d,y2d\n",
    "X_train_scaled=copy.copy(X_train)\n",
    "X_test_scaled=copy.copy(X_test)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,0:2]=custom_scaler(X_train_scaled[:,:,0:2],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,0:2]=custom_scaler(X_test_scaled[:,:,0:2],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,2:4]=custom_scaler(X_train_scaled[:,:,2:4],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,2:4]=custom_scaler(X_test_scaled[:,:,2:4],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,4:6]=custom_scaler(X_train_scaled[:,:,4:6],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,4:6]=custom_scaler(X_test_scaled[:,:,4:6],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled[:,:,6:8]=custom_scaler(X_train_scaled[:,:,6:8],range=(0,1))\n",
    "_,_,X_test_scaled[:,:,6:8]=custom_scaler(X_test_scaled[:,:,6:8],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "\n",
    "print(\"Frequency signals scaling:-------------\")\n",
    "#X_train contains 8 signals x1f,x2f,y1f,y2f\n",
    "X_train_scaled_f=copy.copy(X_train_f)\n",
    "X_test_scaled_f=copy.copy(X_test_f)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled_f[:,:,0:2]=custom_scaler(X_train_scaled_f[:,:,0:2],range=(0,1))\n",
    "_,_,X_test_scaled_f[:,:,0:2]=custom_scaler(X_test_scaled_f[:,:,0:2],range=(0,1),min=min_temp,max=max_temp)\n",
    "\n",
    "min_temp,max_temp,X_train_scaled_f[:,:,2:4]=custom_scaler(X_train_scaled_f[:,:,2:4],range=(0,1))\n",
    "_,_,X_test_scaled_f[:,:,2:4]=custom_scaler(X_test_scaled_f[:,:,2:4],range=(0,1),min=min_temp,max=max_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L7JWtkWdfSCb",
    "outputId": "0bc09318-7a37-49ee-c768-29be65968aa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21347, 50, 8)\n",
      "(21347, 26, 4)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(X_train_scaled_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "u8CMIO_ToBr9"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Part 2 - Building the RNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "\n",
    "input_1 = Input((X_train_scaled.shape[1], X_train_scaled.shape[2]))\n",
    "input_2 = Input((X_train_scaled_f.shape[1], X_train_scaled_f.shape[2]))\n",
    "\n",
    "x1=LSTM(units = 100, return_sequences = True)(input_1)\n",
    "x1=LSTM(units = 50)(x1)\n",
    "\n",
    "x2=LSTM(units = 100, return_sequences = True)(input_2)\n",
    "x2=LSTM(units = 50)(x2)\n",
    "\n",
    "x = layers.concatenate([x1, x2])\n",
    "\n",
    "output_layer = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "classifier=keras.Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "\n",
    "\n",
    "# Compiling the RNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uf-jNI2KZJUu"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\",\n",
    "                             monitor=\"val_accuracy\",\n",
    "                             mode=\"max\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy', # value being monitored for improvement\n",
    "                          min_delta = 0, #Abs value and is the min change required before we stop\n",
    "                          patience = 20, #Number of epochs we wait before stopping \n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True) #keeps the best weigths once stopped\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop,checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcUvZBOYoFNC",
    "outputId": "c9bb2863-0a5c-47d7-94f0-1905b61ea0a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.5393 - accuracy: 0.7142\n",
      "Epoch 1: val_accuracy improved from -inf to 0.72702, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 16s 18ms/step - loss: 0.5393 - accuracy: 0.7142 - val_loss: 0.5209 - val_accuracy: 0.7270\n",
      "Epoch 2/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.5177 - accuracy: 0.7150\n",
      "Epoch 2: val_accuracy did not improve from 0.72702\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.5176 - accuracy: 0.7152 - val_loss: 0.5143 - val_accuracy: 0.7133\n",
      "Epoch 3/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.5070 - accuracy: 0.7240\n",
      "Epoch 3: val_accuracy did not improve from 0.72702\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.5070 - accuracy: 0.7240 - val_loss: 0.4955 - val_accuracy: 0.7140\n",
      "Epoch 4/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.4589 - accuracy: 0.7491\n",
      "Epoch 4: val_accuracy improved from 0.72702 to 0.80000, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.4576 - accuracy: 0.7502 - val_loss: 0.4161 - val_accuracy: 0.8000\n",
      "Epoch 5/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.3732 - accuracy: 0.8171\n",
      "Epoch 5: val_accuracy improved from 0.80000 to 0.81895, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.3732 - accuracy: 0.8171 - val_loss: 0.3604 - val_accuracy: 0.8189\n",
      "Epoch 6/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.3545 - accuracy: 0.8274\n",
      "Epoch 6: val_accuracy improved from 0.81895 to 0.84526, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.3543 - accuracy: 0.8276 - val_loss: 0.3439 - val_accuracy: 0.8453\n",
      "Epoch 7/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.3371 - accuracy: 0.8400\n",
      "Epoch 7: val_accuracy improved from 0.84526 to 0.84947, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.3371 - accuracy: 0.8400 - val_loss: 0.3255 - val_accuracy: 0.8495\n",
      "Epoch 8/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.3762 - accuracy: 0.8110\n",
      "Epoch 8: val_accuracy did not improve from 0.84947\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.3764 - accuracy: 0.8107 - val_loss: 0.3511 - val_accuracy: 0.8312\n",
      "Epoch 9/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.3437 - accuracy: 0.8339\n",
      "Epoch 9: val_accuracy did not improve from 0.84947\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.3437 - accuracy: 0.8339 - val_loss: 0.3613 - val_accuracy: 0.8298\n",
      "Epoch 10/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.3292 - accuracy: 0.8441\n",
      "Epoch 10: val_accuracy did not improve from 0.84947\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.3292 - accuracy: 0.8441 - val_loss: 0.3841 - val_accuracy: 0.7937\n",
      "Epoch 11/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.3142 - accuracy: 0.8545\n",
      "Epoch 11: val_accuracy did not improve from 0.84947\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.3142 - accuracy: 0.8545 - val_loss: 0.3484 - val_accuracy: 0.8253\n",
      "Epoch 12/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.3179 - accuracy: 0.8518\n",
      "Epoch 12: val_accuracy did not improve from 0.84947\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.3173 - accuracy: 0.8522 - val_loss: 0.3683 - val_accuracy: 0.8200\n",
      "Epoch 13/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.3023 - accuracy: 0.8621\n",
      "Epoch 13: val_accuracy did not improve from 0.84947\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.3023 - accuracy: 0.8622 - val_loss: 0.4049 - val_accuracy: 0.8249\n",
      "Epoch 14/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.3143 - accuracy: 0.8548\n",
      "Epoch 14: val_accuracy improved from 0.84947 to 0.87123, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.3141 - accuracy: 0.8549 - val_loss: 0.2882 - val_accuracy: 0.8712\n",
      "Epoch 15/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.2877 - accuracy: 0.8689\n",
      "Epoch 15: val_accuracy improved from 0.87123 to 0.87474, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2870 - accuracy: 0.8693 - val_loss: 0.2658 - val_accuracy: 0.8747\n",
      "Epoch 16/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.2760 - accuracy: 0.8722\n",
      "Epoch 16: val_accuracy did not improve from 0.87474\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2761 - accuracy: 0.8722 - val_loss: 0.3058 - val_accuracy: 0.8723\n",
      "Epoch 17/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2694 - accuracy: 0.8760\n",
      "Epoch 17: val_accuracy improved from 0.87474 to 0.88632, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2694 - accuracy: 0.8760 - val_loss: 0.2481 - val_accuracy: 0.8863\n",
      "Epoch 18/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2658 - accuracy: 0.8775\n",
      "Epoch 18: val_accuracy did not improve from 0.88632\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2658 - accuracy: 0.8775 - val_loss: 0.2690 - val_accuracy: 0.8751\n",
      "Epoch 19/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.2523 - accuracy: 0.8865\n",
      "Epoch 19: val_accuracy did not improve from 0.88632\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2525 - accuracy: 0.8865 - val_loss: 0.2467 - val_accuracy: 0.8863\n",
      "Epoch 20/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.2458 - accuracy: 0.8893\n",
      "Epoch 20: val_accuracy improved from 0.88632 to 0.88737, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2456 - accuracy: 0.8895 - val_loss: 0.2319 - val_accuracy: 0.8874\n",
      "Epoch 21/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.2541 - accuracy: 0.8881\n",
      "Epoch 21: val_accuracy improved from 0.88737 to 0.88842, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2541 - accuracy: 0.8880 - val_loss: 0.2460 - val_accuracy: 0.8884\n",
      "Epoch 22/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2385 - accuracy: 0.8923\n",
      "Epoch 22: val_accuracy did not improve from 0.88842\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2385 - accuracy: 0.8923 - val_loss: 0.3220 - val_accuracy: 0.8551\n",
      "Epoch 23/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.2349 - accuracy: 0.8929\n",
      "Epoch 23: val_accuracy improved from 0.88842 to 0.89965, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2344 - accuracy: 0.8934 - val_loss: 0.2260 - val_accuracy: 0.8996\n",
      "Epoch 24/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.2465 - accuracy: 0.8905\n",
      "Epoch 24: val_accuracy did not improve from 0.89965\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2465 - accuracy: 0.8905 - val_loss: 0.2410 - val_accuracy: 0.8863\n",
      "Epoch 25/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2323 - accuracy: 0.8951\n",
      "Epoch 25: val_accuracy improved from 0.89965 to 0.90211, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2323 - accuracy: 0.8951 - val_loss: 0.2140 - val_accuracy: 0.9021\n",
      "Epoch 26/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.2255 - accuracy: 0.8996\n",
      "Epoch 26: val_accuracy did not improve from 0.90211\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2255 - accuracy: 0.8995 - val_loss: 0.2273 - val_accuracy: 0.8982\n",
      "Epoch 27/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.2289 - accuracy: 0.8986\n",
      "Epoch 27: val_accuracy improved from 0.90211 to 0.90316, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2289 - accuracy: 0.8984 - val_loss: 0.2225 - val_accuracy: 0.9032\n",
      "Epoch 28/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.2204 - accuracy: 0.9002\n",
      "Epoch 28: val_accuracy did not improve from 0.90316\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2203 - accuracy: 0.9003 - val_loss: 0.2259 - val_accuracy: 0.8930\n",
      "Epoch 29/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.2479 - accuracy: 0.8859\n",
      "Epoch 29: val_accuracy did not improve from 0.90316\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2480 - accuracy: 0.8857 - val_loss: 0.2526 - val_accuracy: 0.8923\n",
      "Epoch 30/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.2186 - accuracy: 0.9023\n",
      "Epoch 30: val_accuracy improved from 0.90316 to 0.90351, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2191 - accuracy: 0.9022 - val_loss: 0.2098 - val_accuracy: 0.9035\n",
      "Epoch 31/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.2053 - accuracy: 0.9083\n",
      "Epoch 31: val_accuracy did not improve from 0.90351\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2053 - accuracy: 0.9082 - val_loss: 0.2158 - val_accuracy: 0.8972\n",
      "Epoch 32/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2108 - accuracy: 0.9063\n",
      "Epoch 32: val_accuracy improved from 0.90351 to 0.90912, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2108 - accuracy: 0.9063 - val_loss: 0.2011 - val_accuracy: 0.9091\n",
      "Epoch 33/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.2039 - accuracy: 0.9087\n",
      "Epoch 33: val_accuracy improved from 0.90912 to 0.91053, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2040 - accuracy: 0.9083 - val_loss: 0.2012 - val_accuracy: 0.9105\n",
      "Epoch 34/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1995 - accuracy: 0.9119\n",
      "Epoch 34: val_accuracy did not improve from 0.91053\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1996 - accuracy: 0.9117 - val_loss: 0.2222 - val_accuracy: 0.8968\n",
      "Epoch 35/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2015 - accuracy: 0.9100\n",
      "Epoch 35: val_accuracy did not improve from 0.91053\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2015 - accuracy: 0.9100 - val_loss: 0.2028 - val_accuracy: 0.9018\n",
      "Epoch 36/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1921 - accuracy: 0.9135\n",
      "Epoch 36: val_accuracy did not improve from 0.91053\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1927 - accuracy: 0.9133 - val_loss: 0.2003 - val_accuracy: 0.9039\n",
      "Epoch 37/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.2040 - accuracy: 0.9116\n",
      "Epoch 37: val_accuracy did not improve from 0.91053\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2040 - accuracy: 0.9115 - val_loss: 0.2245 - val_accuracy: 0.8902\n",
      "Epoch 38/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1922 - accuracy: 0.9165\n",
      "Epoch 38: val_accuracy did not improve from 0.91053\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1920 - accuracy: 0.9166 - val_loss: 0.2128 - val_accuracy: 0.8972\n",
      "Epoch 39/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1924 - accuracy: 0.9160\n",
      "Epoch 39: val_accuracy improved from 0.91053 to 0.91439, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1929 - accuracy: 0.9158 - val_loss: 0.1900 - val_accuracy: 0.9144\n",
      "Epoch 40/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.9162\n",
      "Epoch 40: val_accuracy did not improve from 0.91439\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1908 - accuracy: 0.9162 - val_loss: 0.2098 - val_accuracy: 0.9070\n",
      "Epoch 41/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1891 - accuracy: 0.9167\n",
      "Epoch 41: val_accuracy improved from 0.91439 to 0.91965, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1891 - accuracy: 0.9167 - val_loss: 0.1824 - val_accuracy: 0.9196\n",
      "Epoch 42/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1879 - accuracy: 0.9172\n",
      "Epoch 42: val_accuracy did not improve from 0.91965\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1883 - accuracy: 0.9169 - val_loss: 0.2585 - val_accuracy: 0.8842\n",
      "Epoch 43/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.9178\n",
      "Epoch 43: val_accuracy did not improve from 0.91965\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1881 - accuracy: 0.9178 - val_loss: 0.1994 - val_accuracy: 0.9109\n",
      "Epoch 44/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1729 - accuracy: 0.9249\n",
      "Epoch 44: val_accuracy did not improve from 0.91965\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.1729 - accuracy: 0.9250 - val_loss: 0.2032 - val_accuracy: 0.9088\n",
      "Epoch 45/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1802 - accuracy: 0.9208\n",
      "Epoch 45: val_accuracy did not improve from 0.91965\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1802 - accuracy: 0.9208 - val_loss: 0.1913 - val_accuracy: 0.9144\n",
      "Epoch 46/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1877 - accuracy: 0.9185\n",
      "Epoch 46: val_accuracy did not improve from 0.91965\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1880 - accuracy: 0.9185 - val_loss: 0.2121 - val_accuracy: 0.9028\n",
      "Epoch 47/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1745 - accuracy: 0.9250\n",
      "Epoch 47: val_accuracy did not improve from 0.91965\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1745 - accuracy: 0.9250 - val_loss: 0.1982 - val_accuracy: 0.9102\n",
      "Epoch 48/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1654 - accuracy: 0.9301\n",
      "Epoch 48: val_accuracy did not improve from 0.91965\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1654 - accuracy: 0.9301 - val_loss: 0.2065 - val_accuracy: 0.9130\n",
      "Epoch 49/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1736 - accuracy: 0.9259\n",
      "Epoch 49: val_accuracy did not improve from 0.91965\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1735 - accuracy: 0.9259 - val_loss: 0.2528 - val_accuracy: 0.8905\n",
      "Epoch 50/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1704 - accuracy: 0.9268\n",
      "Epoch 50: val_accuracy did not improve from 0.91965\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1699 - accuracy: 0.9269 - val_loss: 0.2043 - val_accuracy: 0.9137\n",
      "Epoch 51/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1630 - accuracy: 0.9306\n",
      "Epoch 51: val_accuracy did not improve from 0.91965\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1625 - accuracy: 0.9310 - val_loss: 0.1971 - val_accuracy: 0.9144\n",
      "Epoch 52/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1754 - accuracy: 0.9250\n",
      "Epoch 52: val_accuracy did not improve from 0.91965\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1759 - accuracy: 0.9248 - val_loss: 0.1874 - val_accuracy: 0.9182\n",
      "Epoch 53/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1612 - accuracy: 0.9312\n",
      "Epoch 53: val_accuracy did not improve from 0.91965\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1615 - accuracy: 0.9310 - val_loss: 0.1961 - val_accuracy: 0.9109\n",
      "Epoch 54/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1561 - accuracy: 0.9326\n",
      "Epoch 54: val_accuracy did not improve from 0.91965\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1561 - accuracy: 0.9326 - val_loss: 0.1796 - val_accuracy: 0.9189\n",
      "Epoch 55/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1599 - accuracy: 0.9310\n",
      "Epoch 55: val_accuracy improved from 0.91965 to 0.92000, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1599 - accuracy: 0.9310 - val_loss: 0.1775 - val_accuracy: 0.9200\n",
      "Epoch 56/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1679 - accuracy: 0.9272\n",
      "Epoch 56: val_accuracy did not improve from 0.92000\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1679 - accuracy: 0.9272 - val_loss: 0.1792 - val_accuracy: 0.9196\n",
      "Epoch 57/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1618 - accuracy: 0.9320\n",
      "Epoch 57: val_accuracy improved from 0.92000 to 0.92316, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1614 - accuracy: 0.9322 - val_loss: 0.1792 - val_accuracy: 0.9232\n",
      "Epoch 58/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1517 - accuracy: 0.9357\n",
      "Epoch 58: val_accuracy improved from 0.92316 to 0.93088, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1520 - accuracy: 0.9355 - val_loss: 0.1638 - val_accuracy: 0.9309\n",
      "Epoch 59/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1508 - accuracy: 0.9355\n",
      "Epoch 59: val_accuracy did not improve from 0.93088\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1506 - accuracy: 0.9355 - val_loss: 0.1795 - val_accuracy: 0.9274\n",
      "Epoch 60/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1506 - accuracy: 0.9358\n",
      "Epoch 60: val_accuracy did not improve from 0.93088\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1507 - accuracy: 0.9358 - val_loss: 0.1784 - val_accuracy: 0.9242\n",
      "Epoch 61/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1484 - accuracy: 0.9366\n",
      "Epoch 61: val_accuracy did not improve from 0.93088\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1487 - accuracy: 0.9366 - val_loss: 0.2234 - val_accuracy: 0.9077\n",
      "Epoch 62/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1508 - accuracy: 0.9356\n",
      "Epoch 62: val_accuracy did not improve from 0.93088\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1507 - accuracy: 0.9356 - val_loss: 0.1796 - val_accuracy: 0.9221\n",
      "Epoch 63/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1451 - accuracy: 0.9377\n",
      "Epoch 63: val_accuracy did not improve from 0.93088\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1451 - accuracy: 0.9377 - val_loss: 0.1648 - val_accuracy: 0.9302\n",
      "Epoch 64/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1471 - accuracy: 0.9390\n",
      "Epoch 64: val_accuracy improved from 0.93088 to 0.93228, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1471 - accuracy: 0.9390 - val_loss: 0.1727 - val_accuracy: 0.9323\n",
      "Epoch 65/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1502 - accuracy: 0.9350\n",
      "Epoch 65: val_accuracy did not improve from 0.93228\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1500 - accuracy: 0.9351 - val_loss: 0.1729 - val_accuracy: 0.9284\n",
      "Epoch 66/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 0.9414\n",
      "Epoch 66: val_accuracy did not improve from 0.93228\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1382 - accuracy: 0.9414 - val_loss: 0.1917 - val_accuracy: 0.9218\n",
      "Epoch 67/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1398 - accuracy: 0.9416\n",
      "Epoch 67: val_accuracy did not improve from 0.93228\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1397 - accuracy: 0.9416 - val_loss: 0.1683 - val_accuracy: 0.9281\n",
      "Epoch 68/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1317 - accuracy: 0.9444\n",
      "Epoch 68: val_accuracy did not improve from 0.93228\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1316 - accuracy: 0.9444 - val_loss: 0.1808 - val_accuracy: 0.9246\n",
      "Epoch 69/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1349 - accuracy: 0.9432\n",
      "Epoch 69: val_accuracy did not improve from 0.93228\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1348 - accuracy: 0.9432 - val_loss: 0.1918 - val_accuracy: 0.9179\n",
      "Epoch 70/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1330 - accuracy: 0.9434\n",
      "Epoch 70: val_accuracy did not improve from 0.93228\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1329 - accuracy: 0.9435 - val_loss: 0.1850 - val_accuracy: 0.9239\n",
      "Epoch 71/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1456 - accuracy: 0.9393\n",
      "Epoch 71: val_accuracy did not improve from 0.93228\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1460 - accuracy: 0.9393 - val_loss: 0.1724 - val_accuracy: 0.9298\n",
      "Epoch 72/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1306 - accuracy: 0.9456\n",
      "Epoch 72: val_accuracy improved from 0.93228 to 0.93404, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1306 - accuracy: 0.9457 - val_loss: 0.1625 - val_accuracy: 0.9340\n",
      "Epoch 73/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1297 - accuracy: 0.9451\n",
      "Epoch 73: val_accuracy did not improve from 0.93404\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1297 - accuracy: 0.9451 - val_loss: 0.1960 - val_accuracy: 0.9235\n",
      "Epoch 74/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1238 - accuracy: 0.9488\n",
      "Epoch 74: val_accuracy did not improve from 0.93404\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1236 - accuracy: 0.9489 - val_loss: 0.1812 - val_accuracy: 0.9267\n",
      "Epoch 75/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1266 - accuracy: 0.9467\n",
      "Epoch 75: val_accuracy did not improve from 0.93404\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1267 - accuracy: 0.9466 - val_loss: 0.1656 - val_accuracy: 0.9298\n",
      "Epoch 76/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1210 - accuracy: 0.9482\n",
      "Epoch 76: val_accuracy did not improve from 0.93404\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1211 - accuracy: 0.9482 - val_loss: 0.1975 - val_accuracy: 0.9225\n",
      "Epoch 77/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1289 - accuracy: 0.9448\n",
      "Epoch 77: val_accuracy did not improve from 0.93404\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1289 - accuracy: 0.9448 - val_loss: 0.2123 - val_accuracy: 0.9168\n",
      "Epoch 78/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 0.9518\n",
      "Epoch 78: val_accuracy did not improve from 0.93404\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1156 - accuracy: 0.9518 - val_loss: 0.2009 - val_accuracy: 0.9221\n",
      "Epoch 79/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9513\n",
      "Epoch 79: val_accuracy did not improve from 0.93404\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.1188 - accuracy: 0.9513 - val_loss: 0.1760 - val_accuracy: 0.9263\n",
      "Epoch 80/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1194 - accuracy: 0.9497\n",
      "Epoch 80: val_accuracy did not improve from 0.93404\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1195 - accuracy: 0.9498 - val_loss: 0.1662 - val_accuracy: 0.9340\n",
      "Epoch 81/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.1226 - accuracy: 0.9488\n",
      "Epoch 81: val_accuracy did not improve from 0.93404\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1222 - accuracy: 0.9490 - val_loss: 0.1744 - val_accuracy: 0.9323\n",
      "Epoch 82/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1173 - accuracy: 0.9505\n",
      "Epoch 82: val_accuracy did not improve from 0.93404\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1173 - accuracy: 0.9505 - val_loss: 0.1737 - val_accuracy: 0.9333\n",
      "Epoch 83/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1156 - accuracy: 0.9529\n",
      "Epoch 83: val_accuracy did not improve from 0.93404\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1156 - accuracy: 0.9529 - val_loss: 0.1922 - val_accuracy: 0.9232\n",
      "Epoch 84/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1294 - accuracy: 0.9473\n",
      "Epoch 84: val_accuracy improved from 0.93404 to 0.93789, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1290 - accuracy: 0.9473 - val_loss: 0.1638 - val_accuracy: 0.9379\n",
      "Epoch 85/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1034 - accuracy: 0.9568\n",
      "Epoch 85: val_accuracy did not improve from 0.93789\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1033 - accuracy: 0.9568 - val_loss: 0.2262 - val_accuracy: 0.9204\n",
      "Epoch 86/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1146 - accuracy: 0.9527\n",
      "Epoch 86: val_accuracy did not improve from 0.93789\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1146 - accuracy: 0.9528 - val_loss: 0.1814 - val_accuracy: 0.9295\n",
      "Epoch 87/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1113 - accuracy: 0.9538\n",
      "Epoch 87: val_accuracy did not improve from 0.93789\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1114 - accuracy: 0.9537 - val_loss: 0.1847 - val_accuracy: 0.9256\n",
      "Epoch 88/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1063 - accuracy: 0.9562\n",
      "Epoch 88: val_accuracy did not improve from 0.93789\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1062 - accuracy: 0.9563 - val_loss: 0.1737 - val_accuracy: 0.9340\n",
      "Epoch 89/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0992 - accuracy: 0.9596\n",
      "Epoch 89: val_accuracy did not improve from 0.93789\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0992 - accuracy: 0.9596 - val_loss: 0.1695 - val_accuracy: 0.9340\n",
      "Epoch 90/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.1118 - accuracy: 0.9538\n",
      "Epoch 90: val_accuracy improved from 0.93789 to 0.94105, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1117 - accuracy: 0.9538 - val_loss: 0.1648 - val_accuracy: 0.9411\n",
      "Epoch 91/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0995 - accuracy: 0.9582\n",
      "Epoch 91: val_accuracy did not improve from 0.94105\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0995 - accuracy: 0.9582 - val_loss: 0.2345 - val_accuracy: 0.9204\n",
      "Epoch 92/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.0930 - accuracy: 0.9612\n",
      "Epoch 92: val_accuracy did not improve from 0.94105\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0929 - accuracy: 0.9613 - val_loss: 0.1508 - val_accuracy: 0.9407\n",
      "Epoch 93/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9584\n",
      "Epoch 93: val_accuracy did not improve from 0.94105\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1009 - accuracy: 0.9584 - val_loss: 0.1751 - val_accuracy: 0.9333\n",
      "Epoch 94/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.1023 - accuracy: 0.9586\n",
      "Epoch 94: val_accuracy did not improve from 0.94105\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1026 - accuracy: 0.9586 - val_loss: 0.1790 - val_accuracy: 0.9316\n",
      "Epoch 95/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0967 - accuracy: 0.9618\n",
      "Epoch 95: val_accuracy did not improve from 0.94105\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0964 - accuracy: 0.9620 - val_loss: 0.2391 - val_accuracy: 0.9109\n",
      "Epoch 96/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.9632\n",
      "Epoch 96: val_accuracy did not improve from 0.94105\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0920 - accuracy: 0.9632 - val_loss: 0.1997 - val_accuracy: 0.9288\n",
      "Epoch 97/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.0966 - accuracy: 0.9618\n",
      "Epoch 97: val_accuracy did not improve from 0.94105\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0965 - accuracy: 0.9619 - val_loss: 0.1627 - val_accuracy: 0.9382\n",
      "Epoch 98/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0994 - accuracy: 0.9597\n",
      "Epoch 98: val_accuracy did not improve from 0.94105\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0995 - accuracy: 0.9597 - val_loss: 0.2296 - val_accuracy: 0.9172\n",
      "Epoch 99/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0839 - accuracy: 0.9652\n",
      "Epoch 99: val_accuracy did not improve from 0.94105\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0843 - accuracy: 0.9650 - val_loss: 0.1733 - val_accuracy: 0.9411\n",
      "Epoch 100/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.9649\n",
      "Epoch 100: val_accuracy did not improve from 0.94105\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0910 - accuracy: 0.9649 - val_loss: 0.1661 - val_accuracy: 0.9372\n",
      "Epoch 101/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.0830 - accuracy: 0.9662\n",
      "Epoch 101: val_accuracy did not improve from 0.94105\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0831 - accuracy: 0.9662 - val_loss: 0.1714 - val_accuracy: 0.9365\n",
      "Epoch 102/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.0988 - accuracy: 0.9616\n",
      "Epoch 102: val_accuracy did not improve from 0.94105\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0988 - accuracy: 0.9616 - val_loss: 0.1917 - val_accuracy: 0.9267\n",
      "Epoch 103/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0798 - accuracy: 0.9672\n",
      "Epoch 103: val_accuracy did not improve from 0.94105\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0798 - accuracy: 0.9671 - val_loss: 0.1865 - val_accuracy: 0.9326\n",
      "Epoch 104/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.0901 - accuracy: 0.9634\n",
      "Epoch 104: val_accuracy improved from 0.94105 to 0.94526, saving model to ./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0900 - accuracy: 0.9634 - val_loss: 0.1708 - val_accuracy: 0.9453\n",
      "Epoch 105/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.9682\n",
      "Epoch 105: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0777 - accuracy: 0.9682 - val_loss: 0.1664 - val_accuracy: 0.9439\n",
      "Epoch 106/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0875 - accuracy: 0.9640\n",
      "Epoch 106: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0874 - accuracy: 0.9642 - val_loss: 0.1779 - val_accuracy: 0.9418\n",
      "Epoch 107/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.0819 - accuracy: 0.9681\n",
      "Epoch 107: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0820 - accuracy: 0.9681 - val_loss: 0.1892 - val_accuracy: 0.9326\n",
      "Epoch 108/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0724 - accuracy: 0.9708\n",
      "Epoch 108: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0724 - accuracy: 0.9707 - val_loss: 0.1849 - val_accuracy: 0.9330\n",
      "Epoch 109/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.0830 - accuracy: 0.9683\n",
      "Epoch 109: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0829 - accuracy: 0.9683 - val_loss: 0.2018 - val_accuracy: 0.9386\n",
      "Epoch 110/200\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0798 - accuracy: 0.9678\n",
      "Epoch 110: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0797 - accuracy: 0.9678 - val_loss: 0.1886 - val_accuracy: 0.9379\n",
      "Epoch 111/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.0722 - accuracy: 0.9716\n",
      "Epoch 111: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0722 - accuracy: 0.9716 - val_loss: 0.2175 - val_accuracy: 0.9305\n",
      "Epoch 112/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0714 - accuracy: 0.9721\n",
      "Epoch 112: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0716 - accuracy: 0.9721 - val_loss: 0.1894 - val_accuracy: 0.9396\n",
      "Epoch 113/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.9703\n",
      "Epoch 113: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.0774 - accuracy: 0.9703 - val_loss: 0.2041 - val_accuracy: 0.9330\n",
      "Epoch 114/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0711 - accuracy: 0.9734\n",
      "Epoch 114: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0712 - accuracy: 0.9734 - val_loss: 0.1955 - val_accuracy: 0.9365\n",
      "Epoch 115/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0771 - accuracy: 0.9694\n",
      "Epoch 115: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0770 - accuracy: 0.9695 - val_loss: 0.1806 - val_accuracy: 0.9351\n",
      "Epoch 116/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.9722\n",
      "Epoch 116: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0714 - accuracy: 0.9722 - val_loss: 0.2178 - val_accuracy: 0.9288\n",
      "Epoch 117/200\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.0819 - accuracy: 0.9682\n",
      "Epoch 117: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0818 - accuracy: 0.9683 - val_loss: 0.1930 - val_accuracy: 0.9361\n",
      "Epoch 118/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9766\n",
      "Epoch 118: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0600 - accuracy: 0.9766 - val_loss: 0.1791 - val_accuracy: 0.9418\n",
      "Epoch 119/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0891 - accuracy: 0.9662\n",
      "Epoch 119: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0888 - accuracy: 0.9664 - val_loss: 0.1817 - val_accuracy: 0.9305\n",
      "Epoch 120/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0563 - accuracy: 0.9784\n",
      "Epoch 120: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0562 - accuracy: 0.9785 - val_loss: 0.1907 - val_accuracy: 0.9404\n",
      "Epoch 121/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.0578 - accuracy: 0.9769\n",
      "Epoch 121: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0578 - accuracy: 0.9769 - val_loss: 0.1900 - val_accuracy: 0.9400\n",
      "Epoch 122/200\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9743\n",
      "Epoch 122: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0667 - accuracy: 0.9743 - val_loss: 0.3026 - val_accuracy: 0.9088\n",
      "Epoch 123/200\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.0930 - accuracy: 0.9643\n",
      "Epoch 123: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0929 - accuracy: 0.9642 - val_loss: 0.1905 - val_accuracy: 0.9379\n",
      "Epoch 124/200\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0567 - accuracy: 0.9785Restoring model weights from the end of the best epoch: 104.\n",
      "\n",
      "Epoch 124: val_accuracy did not improve from 0.94526\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0565 - accuracy: 0.9786 - val_loss: 0.1748 - val_accuracy: 0.9411\n",
      "Epoch 124: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "history=classifier.fit([X_train_scaled,X_train_scaled_f], y_train[:,0], epochs = 200, batch_size = 64,validation_data=([X_test_scaled,X_test_scaled_f],y_test[:,0]),callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7puZMrQ6rZ8B",
    "outputId": "84393c68-128c-4801-c985-606bb3cae043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 1s 6ms/step - loss: 0.1708 - accuracy: 0.9453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17076759040355682, 0.945263147354126]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate([X_test_scaled,X_test_scaled_f],y_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "pXaIqqGvsq2-",
    "outputId": "409b3177-741e-4b8a-d57f-afd4ecfdac3b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def display_learning_curves(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    ax1.plot(history.history[\"loss\"])\n",
    "    ax1.plot(history.history[\"val_loss\"])\n",
    "    ax1.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "    ax2.plot(history.history[\"accuracy\"])\n",
    "    ax2.plot(history.history[\"val_accuracy\"])\n",
    "    ax2.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "display_learning_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jzJ3rz1JZlM7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "L0VKJswYTc4O"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "temp=tf.keras.models.load_model(\"./drive/MyDrive/MSc Thesis/Experiments/models/LSTM_1d_freq_exp1_exp5_strat_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u9bgdUJETn0g",
    "outputId": "4e83e3f8-ab6a-4c22-f7b0-8b39bf76bddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2850/2850 [==============================] - 15s 5ms/step - loss: 0.1708 - accuracy: 0.9453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1707671731710434, 0.945263147354126]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.evaluate([X_test_scaled,X_test_scaled_f], y_test[:,0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbTiJwqAZhcj",
    "outputId": "2f1e285c-6ff3-4462-fa14-a54e35ea5568"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 2s 6ms/step - loss: 0.1708 - accuracy: 0.9453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17076759040355682, 0.945263147354126]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.evaluate([X_test_scaled,X_test_scaled_f], y_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "RD4YF1AuT2tn"
   },
   "outputs": [],
   "source": [
    "y_pred = temp.predict([X_test_scaled,X_test_scaled_f])\n",
    "y_pred= (y_pred>=0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjx-DjHUWp52",
    "outputId": "31b6643e-3a44-42d9-c32b-278f3d80a95e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ipevqB9rXDeW"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rSeo2ltUXffg",
    "outputId": "cc8b36aa-21fd-4e70-a362-d4e04a6ede28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1941,   93],\n",
       "       [  63,  753]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eM1TBa2IXtj2",
    "outputId": "7192f62d-3d20-4881-b040-1fe25ab65d18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9452631578947368"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9V2DcARYNq6",
    "outputId": "9db74e19-af4f-4c03-eb14-9093f14cbf98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9061371841155235"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test[:,0],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwAjeUnMYQ1O",
    "outputId": "0596626d-7920-4c53-95c6-b1eebdbe237c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      2034\n",
      "           1       0.89      0.92      0.91       816\n",
      "\n",
      "    accuracy                           0.95      2850\n",
      "   macro avg       0.93      0.94      0.93      2850\n",
      "weighted avg       0.95      0.95      0.95      2850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test[:,0],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "6381052835b541a28bd40b3949815b15",
      "0affa90d67114fa1b9de8045fe1c79db",
      "52067950a0184c3ba827c94415260742",
      "496857438c3c4b1db63b3a17af848657",
      "06f5bb166b174c39b8f0d31a094b6701",
      "9766b7ad4dd8494fba7b17da4fb54181",
      "85fd543dad1d4ae5b4012f84964ab2bb",
      "ac8c91a0aa9b4914942cc8cd382dd1d8",
      "4175c2ea694745d1bb0d1683360bb27d",
      "a114e178da3b4a11a8e0f04b98082d26",
      "136fb09ba460411db8ba3bf7f16ca446"
     ]
    },
    "id": "QPN2XdzLqpp_",
    "outputId": "212fc15e-ec62-4538-853b-355401eaa5b4"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02194809913635254,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6381052835b541a28bd40b3949815b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "334/334 [==============================] - 10s 16ms/step - loss: 0.5726 - accuracy: 0.7087 - val_loss: 0.5722 - val_accuracy: 0.7137\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.5479 - accuracy: 0.7141 - val_loss: 0.4479 - val_accuracy: 0.7309\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.3897 - accuracy: 0.8083 - val_loss: 0.3601 - val_accuracy: 0.8312\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.3632 - accuracy: 0.8239 - val_loss: 0.3709 - val_accuracy: 0.8239\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.3484 - accuracy: 0.8333 - val_loss: 0.3460 - val_accuracy: 0.8323\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.3308 - accuracy: 0.8433 - val_loss: 0.3339 - val_accuracy: 0.8309\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.3292 - accuracy: 0.8460 - val_loss: 0.3166 - val_accuracy: 0.8505\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3159 - accuracy: 0.8515 - val_loss: 0.2891 - val_accuracy: 0.8663\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.3106 - accuracy: 0.8573 - val_loss: 0.3134 - val_accuracy: 0.8442\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2934 - accuracy: 0.8648 - val_loss: 0.2951 - val_accuracy: 0.8625\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.3130 - accuracy: 0.8523 - val_loss: 0.2898 - val_accuracy: 0.8702\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2828 - accuracy: 0.8712 - val_loss: 0.4217 - val_accuracy: 0.7870\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2943 - accuracy: 0.8621 - val_loss: 0.2531 - val_accuracy: 0.8828\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2654 - accuracy: 0.8782 - val_loss: 0.2869 - val_accuracy: 0.8684\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2543 - accuracy: 0.8847 - val_loss: 0.2389 - val_accuracy: 0.8856\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.3075 - accuracy: 0.8522 - val_loss: 0.2762 - val_accuracy: 0.8670\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2814 - accuracy: 0.8694 - val_loss: 0.2722 - val_accuracy: 0.8674\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2563 - accuracy: 0.8842 - val_loss: 0.3432 - val_accuracy: 0.8505\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2520 - accuracy: 0.8871 - val_loss: 0.2471 - val_accuracy: 0.8807\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2438 - accuracy: 0.8879 - val_loss: 0.2593 - val_accuracy: 0.8811\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2344 - accuracy: 0.8930 - val_loss: 0.2437 - val_accuracy: 0.8842\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2499 - accuracy: 0.8872 - val_loss: 0.2557 - val_accuracy: 0.8754\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2350 - accuracy: 0.8920 - val_loss: 0.2701 - val_accuracy: 0.8846\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2259 - accuracy: 0.8963 - val_loss: 0.2246 - val_accuracy: 0.8975\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2311 - accuracy: 0.8940 - val_loss: 0.2230 - val_accuracy: 0.8958\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2196 - accuracy: 0.9001 - val_loss: 0.2299 - val_accuracy: 0.8979\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2301 - accuracy: 0.8954 - val_loss: 0.2187 - val_accuracy: 0.8926\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2255 - accuracy: 0.8962 - val_loss: 0.2205 - val_accuracy: 0.8912\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2150 - accuracy: 0.9026 - val_loss: 0.2230 - val_accuracy: 0.8947\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2176 - accuracy: 0.9026 - val_loss: 0.2197 - val_accuracy: 0.9046\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2070 - accuracy: 0.9071 - val_loss: 0.2109 - val_accuracy: 0.9039\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2172 - accuracy: 0.9031 - val_loss: 0.2225 - val_accuracy: 0.9007\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2025 - accuracy: 0.9088 - val_loss: 0.1973 - val_accuracy: 0.9098\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.2087 - accuracy: 0.9066 - val_loss: 0.1937 - val_accuracy: 0.9126\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1948 - accuracy: 0.9133 - val_loss: 0.2458 - val_accuracy: 0.8933\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1992 - accuracy: 0.9112 - val_loss: 0.2499 - val_accuracy: 0.8846\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1932 - accuracy: 0.9145 - val_loss: 0.2071 - val_accuracy: 0.9091\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1905 - accuracy: 0.9164 - val_loss: 0.1959 - val_accuracy: 0.9123\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1947 - accuracy: 0.9146 - val_loss: 0.1877 - val_accuracy: 0.9151\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1871 - accuracy: 0.9189 - val_loss: 0.2189 - val_accuracy: 0.9018\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1873 - accuracy: 0.9180 - val_loss: 0.1961 - val_accuracy: 0.9091\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1813 - accuracy: 0.9203 - val_loss: 0.2270 - val_accuracy: 0.9025\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1816 - accuracy: 0.9217 - val_loss: 0.2026 - val_accuracy: 0.9088\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1851 - accuracy: 0.9195 - val_loss: 0.2058 - val_accuracy: 0.9028\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1840 - accuracy: 0.9195 - val_loss: 0.1757 - val_accuracy: 0.9204\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1713 - accuracy: 0.9268 - val_loss: 0.1755 - val_accuracy: 0.9239\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1692 - accuracy: 0.9282 - val_loss: 0.1771 - val_accuracy: 0.9256\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1778 - accuracy: 0.9235 - val_loss: 0.2021 - val_accuracy: 0.9130\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1683 - accuracy: 0.9271 - val_loss: 0.1813 - val_accuracy: 0.9211\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1671 - accuracy: 0.9284 - val_loss: 0.1874 - val_accuracy: 0.9151\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.1620 - accuracy: 0.9301 - val_loss: 0.1992 - val_accuracy: 0.9126\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1539 - accuracy: 0.9342 - val_loss: 0.2086 - val_accuracy: 0.9144\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1541 - accuracy: 0.9340 - val_loss: 0.1913 - val_accuracy: 0.9189\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1502 - accuracy: 0.9368 - val_loss: 0.2256 - val_accuracy: 0.9046\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1612 - accuracy: 0.9311 - val_loss: 0.1826 - val_accuracy: 0.9225\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1475 - accuracy: 0.9378 - val_loss: 0.1783 - val_accuracy: 0.9235\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1439 - accuracy: 0.9401 - val_loss: 0.1691 - val_accuracy: 0.9267\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1414 - accuracy: 0.9409 - val_loss: 0.1912 - val_accuracy: 0.9225\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1383 - accuracy: 0.9430 - val_loss: 0.1825 - val_accuracy: 0.9211\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1378 - accuracy: 0.9410 - val_loss: 0.1626 - val_accuracy: 0.9291\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1538 - accuracy: 0.9349 - val_loss: 0.1807 - val_accuracy: 0.9256\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1330 - accuracy: 0.9444 - val_loss: 0.1488 - val_accuracy: 0.9375\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1297 - accuracy: 0.9450 - val_loss: 0.1578 - val_accuracy: 0.9333\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1276 - accuracy: 0.9473 - val_loss: 0.1747 - val_accuracy: 0.9270\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1271 - accuracy: 0.9473 - val_loss: 0.2042 - val_accuracy: 0.9204\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1277 - accuracy: 0.9491 - val_loss: 0.1986 - val_accuracy: 0.9140\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1335 - accuracy: 0.9457 - val_loss: 0.1590 - val_accuracy: 0.9333\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1182 - accuracy: 0.9516 - val_loss: 0.1773 - val_accuracy: 0.9232\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1226 - accuracy: 0.9496 - val_loss: 0.1456 - val_accuracy: 0.9421\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1110 - accuracy: 0.9537 - val_loss: 0.1609 - val_accuracy: 0.9365\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1153 - accuracy: 0.9526 - val_loss: 0.1550 - val_accuracy: 0.9382\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1165 - accuracy: 0.9534 - val_loss: 0.1564 - val_accuracy: 0.9386\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1066 - accuracy: 0.9556 - val_loss: 0.1768 - val_accuracy: 0.9288\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1153 - accuracy: 0.9534 - val_loss: 0.1662 - val_accuracy: 0.9302\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1073 - accuracy: 0.9560 - val_loss: 0.1547 - val_accuracy: 0.9347\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1007 - accuracy: 0.9610 - val_loss: 0.1597 - val_accuracy: 0.9340\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1040 - accuracy: 0.9575 - val_loss: 0.1392 - val_accuracy: 0.9488\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1065 - accuracy: 0.9575 - val_loss: 0.1392 - val_accuracy: 0.9425\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.1035 - accuracy: 0.9593 - val_loss: 0.1463 - val_accuracy: 0.9439\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0927 - accuracy: 0.9619 - val_loss: 0.1583 - val_accuracy: 0.9319\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0895 - accuracy: 0.9638 - val_loss: 0.1310 - val_accuracy: 0.9453\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0847 - accuracy: 0.9673 - val_loss: 0.1281 - val_accuracy: 0.9484\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0897 - accuracy: 0.9638 - val_loss: 0.1557 - val_accuracy: 0.9404\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0944 - accuracy: 0.9616 - val_loss: 0.1369 - val_accuracy: 0.9467\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0972 - accuracy: 0.9621 - val_loss: 0.1409 - val_accuracy: 0.9389\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0844 - accuracy: 0.9661 - val_loss: 0.1300 - val_accuracy: 0.9512\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.0796 - accuracy: 0.9692 - val_loss: 0.1307 - val_accuracy: 0.9481\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0783 - accuracy: 0.9698 - val_loss: 0.1347 - val_accuracy: 0.9498\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0721 - accuracy: 0.9726 - val_loss: 0.1268 - val_accuracy: 0.9484\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0867 - accuracy: 0.9668 - val_loss: 0.1258 - val_accuracy: 0.9502\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0718 - accuracy: 0.9726 - val_loss: 0.1233 - val_accuracy: 0.9568\n",
      "Epoch 92/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0831 - accuracy: 0.9675 - val_loss: 0.1372 - val_accuracy: 0.9477\n",
      "Epoch 93/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0709 - accuracy: 0.9730 - val_loss: 0.1698 - val_accuracy: 0.9368\n",
      "Epoch 94/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0766 - accuracy: 0.9702 - val_loss: 0.1533 - val_accuracy: 0.9421\n",
      "Epoch 95/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0732 - accuracy: 0.9718 - val_loss: 0.1348 - val_accuracy: 0.9477\n",
      "Epoch 96/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0690 - accuracy: 0.9727 - val_loss: 0.2092 - val_accuracy: 0.9267\n",
      "Epoch 97/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0749 - accuracy: 0.9710 - val_loss: 0.1237 - val_accuracy: 0.9547\n",
      "Epoch 98/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0644 - accuracy: 0.9755 - val_loss: 0.1294 - val_accuracy: 0.9540\n",
      "Epoch 99/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0773 - accuracy: 0.9697 - val_loss: 0.1264 - val_accuracy: 0.9547\n",
      "Epoch 100/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0535 - accuracy: 0.9804 - val_loss: 0.1399 - val_accuracy: 0.9509\n",
      "Epoch 101/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0668 - accuracy: 0.9735 - val_loss: 0.1307 - val_accuracy: 0.9537\n",
      "Epoch 102/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0646 - accuracy: 0.9757 - val_loss: 0.1336 - val_accuracy: 0.9512\n",
      "Epoch 103/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0698 - accuracy: 0.9734 - val_loss: 0.1226 - val_accuracy: 0.9530\n",
      "Epoch 104/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0541 - accuracy: 0.9789 - val_loss: 0.1382 - val_accuracy: 0.9477\n",
      "Epoch 105/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0606 - accuracy: 0.9769 - val_loss: 0.1182 - val_accuracy: 0.9575\n",
      "Epoch 106/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0519 - accuracy: 0.9806 - val_loss: 0.1376 - val_accuracy: 0.9551\n",
      "Epoch 107/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0667 - accuracy: 0.9748 - val_loss: 0.1590 - val_accuracy: 0.9463\n",
      "Epoch 108/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0511 - accuracy: 0.9814 - val_loss: 0.1393 - val_accuracy: 0.9551\n",
      "Epoch 109/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0619 - accuracy: 0.9761 - val_loss: 0.1419 - val_accuracy: 0.9495\n",
      "Epoch 110/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0528 - accuracy: 0.9803 - val_loss: 0.1216 - val_accuracy: 0.9579\n",
      "Epoch 111/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0536 - accuracy: 0.9786 - val_loss: 0.2536 - val_accuracy: 0.9151\n",
      "Epoch 112/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0696 - accuracy: 0.9744 - val_loss: 0.1196 - val_accuracy: 0.9579\n",
      "Epoch 113/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0426 - accuracy: 0.9846 - val_loss: 0.1468 - val_accuracy: 0.9512\n",
      "Epoch 114/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0484 - accuracy: 0.9823 - val_loss: 0.1370 - val_accuracy: 0.9526\n",
      "Epoch 115/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0412 - accuracy: 0.9845 - val_loss: 0.1413 - val_accuracy: 0.9530\n",
      "Epoch 116/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0521 - accuracy: 0.9807 - val_loss: 0.1397 - val_accuracy: 0.9568\n",
      "Epoch 117/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0552 - accuracy: 0.9799 - val_loss: 0.1273 - val_accuracy: 0.9575\n",
      "Epoch 118/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0395 - accuracy: 0.9856 - val_loss: 0.1300 - val_accuracy: 0.9618\n",
      "Epoch 119/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0626 - accuracy: 0.9768 - val_loss: 0.1321 - val_accuracy: 0.9495\n",
      "Epoch 120/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.0529 - accuracy: 0.9807 - val_loss: 0.1122 - val_accuracy: 0.9632\n",
      "Epoch 121/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0342 - accuracy: 0.9875 - val_loss: 0.1481 - val_accuracy: 0.9537\n",
      "Epoch 122/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0448 - accuracy: 0.9837 - val_loss: 0.1183 - val_accuracy: 0.9632\n",
      "Epoch 123/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0399 - accuracy: 0.9853 - val_loss: 0.1239 - val_accuracy: 0.9611\n",
      "Epoch 124/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0490 - accuracy: 0.9812 - val_loss: 0.1400 - val_accuracy: 0.9582\n",
      "Epoch 125/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0457 - accuracy: 0.9825 - val_loss: 0.1100 - val_accuracy: 0.9628\n",
      "Epoch 126/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0425 - accuracy: 0.9850 - val_loss: 0.1076 - val_accuracy: 0.9653\n",
      "Epoch 127/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0926 - accuracy: 0.9658 - val_loss: 0.1409 - val_accuracy: 0.9449\n",
      "Epoch 128/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1014 - accuracy: 0.9613 - val_loss: 0.1106 - val_accuracy: 0.9604\n",
      "Epoch 129/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0335 - accuracy: 0.9884 - val_loss: 0.1257 - val_accuracy: 0.9604\n",
      "Epoch 130/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0350 - accuracy: 0.9877 - val_loss: 0.1297 - val_accuracy: 0.9600\n",
      "Epoch 131/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0360 - accuracy: 0.9870 - val_loss: 0.1193 - val_accuracy: 0.9625\n",
      "Epoch 132/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0538 - accuracy: 0.9797 - val_loss: 0.1569 - val_accuracy: 0.9460\n",
      "Epoch 133/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0525 - accuracy: 0.9809 - val_loss: 0.1208 - val_accuracy: 0.9575\n",
      "Epoch 134/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0337 - accuracy: 0.9881 - val_loss: 0.1321 - val_accuracy: 0.9568\n",
      "Epoch 135/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0381 - accuracy: 0.9862 - val_loss: 0.1156 - val_accuracy: 0.9646\n",
      "Epoch 136/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0304 - accuracy: 0.9895 - val_loss: 0.1427 - val_accuracy: 0.9561\n",
      "Epoch 137/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0441 - accuracy: 0.9837 - val_loss: 0.1226 - val_accuracy: 0.9586\n",
      "Epoch 138/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0380 - accuracy: 0.9860 - val_loss: 0.1641 - val_accuracy: 0.9481\n",
      "Epoch 139/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0287 - accuracy: 0.9904 - val_loss: 0.2259 - val_accuracy: 0.9361\n",
      "Epoch 140/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0807 - accuracy: 0.9703 - val_loss: 0.1251 - val_accuracy: 0.9589\n",
      "Epoch 141/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0344 - accuracy: 0.9875 - val_loss: 0.1226 - val_accuracy: 0.9642\n",
      "Epoch 142/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.0396 - accuracy: 0.9853 - val_loss: 0.1179 - val_accuracy: 0.9649\n",
      "Epoch 143/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0286 - accuracy: 0.9901 - val_loss: 0.1264 - val_accuracy: 0.9618\n",
      "Epoch 144/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0306 - accuracy: 0.9894 - val_loss: 0.1216 - val_accuracy: 0.9586\n",
      "Epoch 145/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0537 - accuracy: 0.9798 - val_loss: 0.1156 - val_accuracy: 0.9614\n",
      "Epoch 146/500\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9898Restoring model weights from the end of the best epoch: 126.\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0296 - accuracy: 0.9897 - val_loss: 0.1119 - val_accuracy: 0.9628\n",
      "Epoch 146: early stopping\n",
      "Number of iterations 1\n",
      "F1-scores:  [0.939744370054778]\n",
      "Average F1-Score 0.939744370054778\n",
      "Std Dev F1-Score 0.0\n",
      "Error bar F1-Score 0.0\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 12s 16ms/step - loss: 0.5497 - accuracy: 0.7107 - val_loss: 0.5071 - val_accuracy: 0.7382\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.5149 - accuracy: 0.7157 - val_loss: 0.5467 - val_accuracy: 0.6691\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.4834 - accuracy: 0.7360 - val_loss: 0.4023 - val_accuracy: 0.8105\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 5s 13ms/step - loss: 0.3723 - accuracy: 0.8195 - val_loss: 0.3467 - val_accuracy: 0.8382\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.3431 - accuracy: 0.8406 - val_loss: 0.3166 - val_accuracy: 0.8474\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.3324 - accuracy: 0.8451 - val_loss: 0.3135 - val_accuracy: 0.8523\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.3154 - accuracy: 0.8537 - val_loss: 0.2950 - val_accuracy: 0.8639\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.3054 - accuracy: 0.8589 - val_loss: 0.2700 - val_accuracy: 0.8761\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2869 - accuracy: 0.8672 - val_loss: 0.2668 - val_accuracy: 0.8744\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2727 - accuracy: 0.8734 - val_loss: 0.4501 - val_accuracy: 0.8060\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2724 - accuracy: 0.8738 - val_loss: 0.2602 - val_accuracy: 0.8775\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2521 - accuracy: 0.8849 - val_loss: 0.3062 - val_accuracy: 0.8477\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2458 - accuracy: 0.8885 - val_loss: 0.3194 - val_accuracy: 0.8642\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2512 - accuracy: 0.8878 - val_loss: 0.2277 - val_accuracy: 0.8933\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2448 - accuracy: 0.8888 - val_loss: 0.2291 - val_accuracy: 0.8923\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2317 - accuracy: 0.8951 - val_loss: 0.2197 - val_accuracy: 0.9014\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2319 - accuracy: 0.8937 - val_loss: 0.2122 - val_accuracy: 0.9025\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2261 - accuracy: 0.8987 - val_loss: 0.2162 - val_accuracy: 0.9007\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2260 - accuracy: 0.8991 - val_loss: 0.2650 - val_accuracy: 0.8779\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2220 - accuracy: 0.9005 - val_loss: 0.2079 - val_accuracy: 0.9077\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2172 - accuracy: 0.9030 - val_loss: 0.2766 - val_accuracy: 0.8705\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2169 - accuracy: 0.9029 - val_loss: 0.1974 - val_accuracy: 0.9081\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2031 - accuracy: 0.9086 - val_loss: 0.1927 - val_accuracy: 0.9151\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2078 - accuracy: 0.9068 - val_loss: 0.2164 - val_accuracy: 0.9053\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2028 - accuracy: 0.9096 - val_loss: 0.2048 - val_accuracy: 0.9088\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1980 - accuracy: 0.9131 - val_loss: 0.1850 - val_accuracy: 0.9196\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1962 - accuracy: 0.9134 - val_loss: 0.2078 - val_accuracy: 0.9091\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1925 - accuracy: 0.9167 - val_loss: 0.2030 - val_accuracy: 0.9077\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1974 - accuracy: 0.9130 - val_loss: 0.2131 - val_accuracy: 0.9032\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1907 - accuracy: 0.9171 - val_loss: 0.2017 - val_accuracy: 0.9112\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1865 - accuracy: 0.9185 - val_loss: 0.2105 - val_accuracy: 0.9137\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1870 - accuracy: 0.9195 - val_loss: 0.2004 - val_accuracy: 0.9063\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1900 - accuracy: 0.9168 - val_loss: 0.1846 - val_accuracy: 0.9179\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1895 - accuracy: 0.9188 - val_loss: 0.3108 - val_accuracy: 0.8730\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1787 - accuracy: 0.9233 - val_loss: 0.1725 - val_accuracy: 0.9277\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1797 - accuracy: 0.9220 - val_loss: 0.1862 - val_accuracy: 0.9189\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1746 - accuracy: 0.9247 - val_loss: 0.1975 - val_accuracy: 0.9154\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1626 - accuracy: 0.9295 - val_loss: 0.2066 - val_accuracy: 0.9056\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.1689 - accuracy: 0.9280 - val_loss: 0.1749 - val_accuracy: 0.9239\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1663 - accuracy: 0.9287 - val_loss: 0.1741 - val_accuracy: 0.9225\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1643 - accuracy: 0.9294 - val_loss: 0.2425 - val_accuracy: 0.8912\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1719 - accuracy: 0.9277 - val_loss: 0.1786 - val_accuracy: 0.9218\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1576 - accuracy: 0.9335 - val_loss: 0.1871 - val_accuracy: 0.9168\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1586 - accuracy: 0.9330 - val_loss: 0.1719 - val_accuracy: 0.9260\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1583 - accuracy: 0.9339 - val_loss: 0.1720 - val_accuracy: 0.9260\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1619 - accuracy: 0.9308 - val_loss: 0.1649 - val_accuracy: 0.9312\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1519 - accuracy: 0.9363 - val_loss: 0.1652 - val_accuracy: 0.9291\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1504 - accuracy: 0.9357 - val_loss: 0.1618 - val_accuracy: 0.9291\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1441 - accuracy: 0.9386 - val_loss: 0.1712 - val_accuracy: 0.9253\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1465 - accuracy: 0.9376 - val_loss: 0.1649 - val_accuracy: 0.9319\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1407 - accuracy: 0.9402 - val_loss: 0.1706 - val_accuracy: 0.9288\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1552 - accuracy: 0.9339 - val_loss: 0.1627 - val_accuracy: 0.9326\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1431 - accuracy: 0.9404 - val_loss: 0.1859 - val_accuracy: 0.9189\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1371 - accuracy: 0.9445 - val_loss: 0.1534 - val_accuracy: 0.9365\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1381 - accuracy: 0.9418 - val_loss: 0.1652 - val_accuracy: 0.9312\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1413 - accuracy: 0.9401 - val_loss: 0.1608 - val_accuracy: 0.9344\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1291 - accuracy: 0.9467 - val_loss: 0.1828 - val_accuracy: 0.9193\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1357 - accuracy: 0.9435 - val_loss: 0.1586 - val_accuracy: 0.9298\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1270 - accuracy: 0.9463 - val_loss: 0.1572 - val_accuracy: 0.9379\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1286 - accuracy: 0.9463 - val_loss: 0.1620 - val_accuracy: 0.9333\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1231 - accuracy: 0.9499 - val_loss: 0.1531 - val_accuracy: 0.9340\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1225 - accuracy: 0.9489 - val_loss: 0.1696 - val_accuracy: 0.9281\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1275 - accuracy: 0.9478 - val_loss: 0.1675 - val_accuracy: 0.9295\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1310 - accuracy: 0.9477 - val_loss: 0.1775 - val_accuracy: 0.9284\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1136 - accuracy: 0.9541 - val_loss: 0.2098 - val_accuracy: 0.9189\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1217 - accuracy: 0.9498 - val_loss: 0.1784 - val_accuracy: 0.9249\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1181 - accuracy: 0.9517 - val_loss: 0.1839 - val_accuracy: 0.9263\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1099 - accuracy: 0.9543 - val_loss: 0.1641 - val_accuracy: 0.9351\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1123 - accuracy: 0.9544 - val_loss: 0.1826 - val_accuracy: 0.9270\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1128 - accuracy: 0.9523 - val_loss: 0.1767 - val_accuracy: 0.9330\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1207 - accuracy: 0.9494 - val_loss: 0.1631 - val_accuracy: 0.9316\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1082 - accuracy: 0.9556 - val_loss: 0.1615 - val_accuracy: 0.9326\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.1058 - accuracy: 0.9567 - val_loss: 0.1552 - val_accuracy: 0.9386\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0971 - accuracy: 0.9612 - val_loss: 0.1580 - val_accuracy: 0.9368\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0948 - accuracy: 0.9609 - val_loss: 0.1918 - val_accuracy: 0.9246\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1011 - accuracy: 0.9588 - val_loss: 0.1490 - val_accuracy: 0.9425\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1075 - accuracy: 0.9562 - val_loss: 0.1643 - val_accuracy: 0.9368\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0940 - accuracy: 0.9613 - val_loss: 0.1611 - val_accuracy: 0.9372\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0995 - accuracy: 0.9603 - val_loss: 0.1552 - val_accuracy: 0.9375\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0871 - accuracy: 0.9641 - val_loss: 0.1594 - val_accuracy: 0.9389\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1041 - accuracy: 0.9591 - val_loss: 0.1477 - val_accuracy: 0.9425\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0794 - accuracy: 0.9691 - val_loss: 0.1386 - val_accuracy: 0.9481\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0907 - accuracy: 0.9639 - val_loss: 0.1516 - val_accuracy: 0.9396\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0783 - accuracy: 0.9686 - val_loss: 0.1806 - val_accuracy: 0.9260\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0990 - accuracy: 0.9607 - val_loss: 0.1569 - val_accuracy: 0.9407\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0822 - accuracy: 0.9676 - val_loss: 0.1769 - val_accuracy: 0.9425\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0831 - accuracy: 0.9670 - val_loss: 0.1468 - val_accuracy: 0.9432\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0789 - accuracy: 0.9692 - val_loss: 0.1457 - val_accuracy: 0.9439\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0744 - accuracy: 0.9703 - val_loss: 0.1395 - val_accuracy: 0.9533\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0708 - accuracy: 0.9717 - val_loss: 0.1429 - val_accuracy: 0.9509\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0818 - accuracy: 0.9679 - val_loss: 0.1442 - val_accuracy: 0.9442\n",
      "Epoch 92/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0730 - accuracy: 0.9732 - val_loss: 0.1498 - val_accuracy: 0.9421\n",
      "Epoch 93/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0829 - accuracy: 0.9658 - val_loss: 0.1631 - val_accuracy: 0.9368\n",
      "Epoch 94/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0764 - accuracy: 0.9693 - val_loss: 0.1781 - val_accuracy: 0.9347\n",
      "Epoch 95/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0649 - accuracy: 0.9755 - val_loss: 0.1684 - val_accuracy: 0.9400\n",
      "Epoch 96/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0709 - accuracy: 0.9725 - val_loss: 0.1756 - val_accuracy: 0.9404\n",
      "Epoch 97/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0684 - accuracy: 0.9743 - val_loss: 0.1495 - val_accuracy: 0.9470\n",
      "Epoch 98/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0797 - accuracy: 0.9686 - val_loss: 0.1359 - val_accuracy: 0.9488\n",
      "Epoch 99/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0634 - accuracy: 0.9751 - val_loss: 0.1570 - val_accuracy: 0.9425\n",
      "Epoch 100/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0574 - accuracy: 0.9780 - val_loss: 0.1462 - val_accuracy: 0.9481\n",
      "Epoch 101/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0661 - accuracy: 0.9738 - val_loss: 0.1863 - val_accuracy: 0.9354\n",
      "Epoch 102/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0643 - accuracy: 0.9758 - val_loss: 0.1429 - val_accuracy: 0.9442\n",
      "Epoch 103/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0533 - accuracy: 0.9806 - val_loss: 0.2142 - val_accuracy: 0.9228\n",
      "Epoch 104/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0720 - accuracy: 0.9722 - val_loss: 0.1500 - val_accuracy: 0.9463\n",
      "Epoch 105/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0587 - accuracy: 0.9772 - val_loss: 0.1555 - val_accuracy: 0.9446\n",
      "Epoch 106/500\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.0520 - accuracy: 0.9803 - val_loss: 0.1627 - val_accuracy: 0.9481\n",
      "Epoch 107/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0528 - accuracy: 0.9797 - val_loss: 0.2348 - val_accuracy: 0.9218\n",
      "Epoch 108/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0701 - accuracy: 0.9737 - val_loss: 0.1459 - val_accuracy: 0.9505\n",
      "Epoch 109/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0456 - accuracy: 0.9829 - val_loss: 0.1381 - val_accuracy: 0.9540\n",
      "Epoch 110/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0559 - accuracy: 0.9795 - val_loss: 0.1367 - val_accuracy: 0.9512\n",
      "Epoch 111/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0621 - accuracy: 0.9769 - val_loss: 0.1477 - val_accuracy: 0.9481\n",
      "Epoch 112/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0560 - accuracy: 0.9784 - val_loss: 0.1652 - val_accuracy: 0.9460\n",
      "Epoch 113/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0516 - accuracy: 0.9796 - val_loss: 0.1855 - val_accuracy: 0.9382\n",
      "Epoch 114/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0545 - accuracy: 0.9796 - val_loss: 0.1436 - val_accuracy: 0.9502\n",
      "Epoch 115/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0569 - accuracy: 0.9788 - val_loss: 0.1484 - val_accuracy: 0.9484\n",
      "Epoch 116/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0681 - accuracy: 0.9747 - val_loss: 0.1519 - val_accuracy: 0.9453\n",
      "Epoch 117/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0480 - accuracy: 0.9825 - val_loss: 0.1381 - val_accuracy: 0.9526\n",
      "Epoch 118/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0371 - accuracy: 0.9857 - val_loss: 0.1813 - val_accuracy: 0.9414\n",
      "Epoch 119/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0605 - accuracy: 0.9779 - val_loss: 0.1705 - val_accuracy: 0.9442\n",
      "Epoch 120/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0466 - accuracy: 0.9820 - val_loss: 0.1645 - val_accuracy: 0.9470\n",
      "Epoch 121/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0542 - accuracy: 0.9798 - val_loss: 0.1382 - val_accuracy: 0.9561\n",
      "Epoch 122/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0573 - accuracy: 0.9787 - val_loss: 0.1526 - val_accuracy: 0.9509\n",
      "Epoch 123/500\n",
      "334/334 [==============================] - 5s 13ms/step - loss: 0.0400 - accuracy: 0.9846 - val_loss: 0.1632 - val_accuracy: 0.9505\n",
      "Epoch 124/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0439 - accuracy: 0.9835 - val_loss: 0.1710 - val_accuracy: 0.9481\n",
      "Epoch 125/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0470 - accuracy: 0.9828 - val_loss: 0.1633 - val_accuracy: 0.9505\n",
      "Epoch 126/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0473 - accuracy: 0.9813 - val_loss: 0.1654 - val_accuracy: 0.9463\n",
      "Epoch 127/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0297 - accuracy: 0.9895 - val_loss: 0.1628 - val_accuracy: 0.9533\n",
      "Epoch 128/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0371 - accuracy: 0.9860 - val_loss: 0.1858 - val_accuracy: 0.9400\n",
      "Epoch 129/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0485 - accuracy: 0.9823 - val_loss: 0.2040 - val_accuracy: 0.9361\n",
      "Epoch 130/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0505 - accuracy: 0.9810 - val_loss: 0.2333 - val_accuracy: 0.9302\n",
      "Epoch 131/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0384 - accuracy: 0.9864 - val_loss: 0.1763 - val_accuracy: 0.9516\n",
      "Epoch 132/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0358 - accuracy: 0.9869 - val_loss: 0.1373 - val_accuracy: 0.9614\n",
      "Epoch 133/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0343 - accuracy: 0.9873 - val_loss: 0.1620 - val_accuracy: 0.9505\n",
      "Epoch 134/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0386 - accuracy: 0.9860 - val_loss: 0.1410 - val_accuracy: 0.9582\n",
      "Epoch 135/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0431 - accuracy: 0.9838 - val_loss: 0.1325 - val_accuracy: 0.9575\n",
      "Epoch 136/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0415 - accuracy: 0.9854 - val_loss: 0.1543 - val_accuracy: 0.9519\n",
      "Epoch 137/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.0370 - accuracy: 0.9866 - val_loss: 0.1711 - val_accuracy: 0.9435\n",
      "Epoch 138/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0336 - accuracy: 0.9874 - val_loss: 0.1464 - val_accuracy: 0.9596\n",
      "Epoch 139/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0392 - accuracy: 0.9861 - val_loss: 0.1435 - val_accuracy: 0.9558\n",
      "Epoch 140/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0419 - accuracy: 0.9851 - val_loss: 0.1920 - val_accuracy: 0.9446\n",
      "Epoch 141/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0305 - accuracy: 0.9896 - val_loss: 0.1478 - val_accuracy: 0.9509\n",
      "Epoch 142/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0395 - accuracy: 0.9867 - val_loss: 0.1449 - val_accuracy: 0.9579\n",
      "Epoch 143/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0347 - accuracy: 0.9874 - val_loss: 0.1744 - val_accuracy: 0.9484\n",
      "Epoch 144/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0382 - accuracy: 0.9864 - val_loss: 0.1537 - val_accuracy: 0.9547\n",
      "Epoch 145/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0372 - accuracy: 0.9864 - val_loss: 0.1448 - val_accuracy: 0.9495\n",
      "Epoch 146/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0215 - accuracy: 0.9924 - val_loss: 0.2101 - val_accuracy: 0.9411\n",
      "Epoch 147/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0359 - accuracy: 0.9864 - val_loss: 0.1383 - val_accuracy: 0.9600\n",
      "Epoch 148/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0216 - accuracy: 0.9921 - val_loss: 0.1801 - val_accuracy: 0.9502\n",
      "Epoch 149/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0313 - accuracy: 0.9892 - val_loss: 0.1552 - val_accuracy: 0.9544\n",
      "Epoch 150/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0542 - accuracy: 0.9802 - val_loss: 0.1366 - val_accuracy: 0.9575\n",
      "Epoch 151/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0184 - accuracy: 0.9946 - val_loss: 0.1646 - val_accuracy: 0.9547\n",
      "Epoch 152/500\n",
      "330/334 [============================>.] - ETA: 0s - loss: 0.0447 - accuracy: 0.9840Restoring model weights from the end of the best epoch: 132.\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.0444 - accuracy: 0.9841 - val_loss: 0.1774 - val_accuracy: 0.9463\n",
      "Epoch 152: early stopping\n",
      "Number of iterations 2\n",
      "F1-scores:  [0.939744370054778, 0.9323493234932348]\n",
      "Average F1-Score 0.9360468467740064\n",
      "Std Dev F1-Score 0.003697523280771553\n",
      "Error bar F1-Score 0.0026145437854286956\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 11s 17ms/step - loss: 0.5500 - accuracy: 0.7140 - val_loss: 0.5180 - val_accuracy: 0.7386\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.5176 - accuracy: 0.7121 - val_loss: 0.5135 - val_accuracy: 0.7172\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.5015 - accuracy: 0.7231 - val_loss: 0.4803 - val_accuracy: 0.7193\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.4626 - accuracy: 0.7459 - val_loss: 0.4754 - val_accuracy: 0.7277\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.4046 - accuracy: 0.7952 - val_loss: 0.3393 - val_accuracy: 0.8396\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.3601 - accuracy: 0.8265 - val_loss: 0.3437 - val_accuracy: 0.8344\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 5s 13ms/step - loss: 0.3033 - accuracy: 0.8625 - val_loss: 0.2759 - val_accuracy: 0.8684\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2832 - accuracy: 0.8691 - val_loss: 0.2632 - val_accuracy: 0.8796\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2754 - accuracy: 0.8732 - val_loss: 0.4108 - val_accuracy: 0.7944\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2778 - accuracy: 0.8732 - val_loss: 0.2464 - val_accuracy: 0.8870\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2550 - accuracy: 0.8835 - val_loss: 0.2452 - val_accuracy: 0.8863\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2433 - accuracy: 0.8912 - val_loss: 0.2456 - val_accuracy: 0.8825\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2380 - accuracy: 0.8930 - val_loss: 0.2274 - val_accuracy: 0.8944\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2353 - accuracy: 0.8924 - val_loss: 0.2294 - val_accuracy: 0.8940\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2360 - accuracy: 0.8953 - val_loss: 0.2783 - val_accuracy: 0.8846\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.2261 - accuracy: 0.8997 - val_loss: 0.2192 - val_accuracy: 0.8975\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2230 - accuracy: 0.9017 - val_loss: 0.2303 - val_accuracy: 0.8926\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 5s 13ms/step - loss: 0.2229 - accuracy: 0.9001 - val_loss: 0.2108 - val_accuracy: 0.9042\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2217 - accuracy: 0.9024 - val_loss: 0.2190 - val_accuracy: 0.8961\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2089 - accuracy: 0.9059 - val_loss: 0.1969 - val_accuracy: 0.9091\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.2110 - accuracy: 0.9052 - val_loss: 0.2147 - val_accuracy: 0.9067\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2114 - accuracy: 0.9070 - val_loss: 0.2051 - val_accuracy: 0.9056\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2034 - accuracy: 0.9107 - val_loss: 0.2042 - val_accuracy: 0.9088\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1954 - accuracy: 0.9143 - val_loss: 0.2140 - val_accuracy: 0.9060\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1943 - accuracy: 0.9164 - val_loss: 0.2114 - val_accuracy: 0.9056\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1982 - accuracy: 0.9120 - val_loss: 0.2121 - val_accuracy: 0.9049\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1867 - accuracy: 0.9183 - val_loss: 0.1895 - val_accuracy: 0.9175\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1843 - accuracy: 0.9199 - val_loss: 0.2041 - val_accuracy: 0.9119\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1828 - accuracy: 0.9216 - val_loss: 0.1900 - val_accuracy: 0.9147\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1792 - accuracy: 0.9213 - val_loss: 0.2080 - val_accuracy: 0.9144\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1802 - accuracy: 0.9227 - val_loss: 0.1814 - val_accuracy: 0.9182\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 5s 13ms/step - loss: 0.1726 - accuracy: 0.9260 - val_loss: 0.1938 - val_accuracy: 0.9182\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1695 - accuracy: 0.9282 - val_loss: 0.1885 - val_accuracy: 0.9154\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1742 - accuracy: 0.9245 - val_loss: 0.1914 - val_accuracy: 0.9126\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1643 - accuracy: 0.9317 - val_loss: 0.1832 - val_accuracy: 0.9196\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1587 - accuracy: 0.9322 - val_loss: 0.1779 - val_accuracy: 0.9239\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1608 - accuracy: 0.9320 - val_loss: 0.1868 - val_accuracy: 0.9242\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 5s 13ms/step - loss: 0.1571 - accuracy: 0.9353 - val_loss: 0.1724 - val_accuracy: 0.9221\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1592 - accuracy: 0.9322 - val_loss: 0.1999 - val_accuracy: 0.9151\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 5s 13ms/step - loss: 0.1604 - accuracy: 0.9329 - val_loss: 0.1930 - val_accuracy: 0.9144\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1550 - accuracy: 0.9365 - val_loss: 0.1753 - val_accuracy: 0.9235\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1457 - accuracy: 0.9390 - val_loss: 0.1733 - val_accuracy: 0.9239\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 5s 13ms/step - loss: 0.1535 - accuracy: 0.9378 - val_loss: 0.1792 - val_accuracy: 0.9225\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1454 - accuracy: 0.9387 - val_loss: 0.1626 - val_accuracy: 0.9281\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1408 - accuracy: 0.9401 - val_loss: 0.1787 - val_accuracy: 0.9267\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1471 - accuracy: 0.9374 - val_loss: 0.1786 - val_accuracy: 0.9260\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.1772 - accuracy: 0.9261 - val_loss: 0.1856 - val_accuracy: 0.9225\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1409 - accuracy: 0.9434 - val_loss: 0.1708 - val_accuracy: 0.9298\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.1644 - accuracy: 0.9312 - val_loss: 0.1662 - val_accuracy: 0.9316\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 5s 13ms/step - loss: 0.1325 - accuracy: 0.9463 - val_loss: 0.1739 - val_accuracy: 0.9267\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1274 - accuracy: 0.9478 - val_loss: 0.1812 - val_accuracy: 0.9288\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 5s 13ms/step - loss: 0.1388 - accuracy: 0.9425 - val_loss: 0.1847 - val_accuracy: 0.9175\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1277 - accuracy: 0.9473 - val_loss: 0.1644 - val_accuracy: 0.9358\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1328 - accuracy: 0.9458 - val_loss: 0.1800 - val_accuracy: 0.9242\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1220 - accuracy: 0.9509 - val_loss: 0.1732 - val_accuracy: 0.9340\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1307 - accuracy: 0.9464 - val_loss: 0.1879 - val_accuracy: 0.9232\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1363 - accuracy: 0.9453 - val_loss: 0.1676 - val_accuracy: 0.9361\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1232 - accuracy: 0.9503 - val_loss: 0.1928 - val_accuracy: 0.9246\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1252 - accuracy: 0.9502 - val_loss: 0.1991 - val_accuracy: 0.9186\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1221 - accuracy: 0.9509 - val_loss: 0.1741 - val_accuracy: 0.9295\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1176 - accuracy: 0.9533 - val_loss: 0.1810 - val_accuracy: 0.9309\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 5s 13ms/step - loss: 0.1131 - accuracy: 0.9545 - val_loss: 0.1769 - val_accuracy: 0.9302\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1088 - accuracy: 0.9557 - val_loss: 0.1799 - val_accuracy: 0.9232\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1104 - accuracy: 0.9552 - val_loss: 0.1713 - val_accuracy: 0.9372\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1083 - accuracy: 0.9576 - val_loss: 0.1647 - val_accuracy: 0.9358\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1272 - accuracy: 0.9494 - val_loss: 0.1852 - val_accuracy: 0.9249\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1042 - accuracy: 0.9584 - val_loss: 0.1538 - val_accuracy: 0.9372\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1074 - accuracy: 0.9561 - val_loss: 0.1678 - val_accuracy: 0.9337\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.1078 - accuracy: 0.9563 - val_loss: 0.2162 - val_accuracy: 0.9200\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1008 - accuracy: 0.9595 - val_loss: 0.1610 - val_accuracy: 0.9428\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1172 - accuracy: 0.9528 - val_loss: 0.2309 - val_accuracy: 0.9112\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 5s 13ms/step - loss: 0.0993 - accuracy: 0.9602 - val_loss: 0.1599 - val_accuracy: 0.9418\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1093 - accuracy: 0.9566 - val_loss: 0.1660 - val_accuracy: 0.9319\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1040 - accuracy: 0.9585 - val_loss: 0.1614 - val_accuracy: 0.9379\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1013 - accuracy: 0.9593 - val_loss: 0.1755 - val_accuracy: 0.9365\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0904 - accuracy: 0.9634 - val_loss: 0.1595 - val_accuracy: 0.9404\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0958 - accuracy: 0.9616 - val_loss: 0.1587 - val_accuracy: 0.9418\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.0961 - accuracy: 0.9620 - val_loss: 0.1554 - val_accuracy: 0.9407\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0888 - accuracy: 0.9666 - val_loss: 0.1736 - val_accuracy: 0.9330\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0941 - accuracy: 0.9624 - val_loss: 0.1815 - val_accuracy: 0.9288\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0871 - accuracy: 0.9660 - val_loss: 0.1579 - val_accuracy: 0.9418\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0884 - accuracy: 0.9643 - val_loss: 0.1501 - val_accuracy: 0.9453\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0913 - accuracy: 0.9651 - val_loss: 0.1478 - val_accuracy: 0.9418\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0830 - accuracy: 0.9677 - val_loss: 0.1570 - val_accuracy: 0.9411\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0804 - accuracy: 0.9683 - val_loss: 0.1823 - val_accuracy: 0.9365\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1036 - accuracy: 0.9602 - val_loss: 0.1613 - val_accuracy: 0.9449\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0738 - accuracy: 0.9709 - val_loss: 0.1551 - val_accuracy: 0.9470\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0786 - accuracy: 0.9696 - val_loss: 0.1517 - val_accuracy: 0.9439\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0916 - accuracy: 0.9651 - val_loss: 0.1557 - val_accuracy: 0.9432\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0708 - accuracy: 0.9726 - val_loss: 0.1575 - val_accuracy: 0.9491\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0826 - accuracy: 0.9679 - val_loss: 0.1584 - val_accuracy: 0.9463\n",
      "Epoch 92/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0773 - accuracy: 0.9697 - val_loss: 0.1489 - val_accuracy: 0.9439\n",
      "Epoch 93/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0755 - accuracy: 0.9702 - val_loss: 0.1702 - val_accuracy: 0.9382\n",
      "Epoch 94/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0796 - accuracy: 0.9694 - val_loss: 0.1796 - val_accuracy: 0.9382\n",
      "Epoch 95/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0724 - accuracy: 0.9726 - val_loss: 0.1594 - val_accuracy: 0.9442\n",
      "Epoch 96/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0683 - accuracy: 0.9735 - val_loss: 0.1675 - val_accuracy: 0.9432\n",
      "Epoch 97/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0812 - accuracy: 0.9681 - val_loss: 0.1623 - val_accuracy: 0.9421\n",
      "Epoch 98/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0676 - accuracy: 0.9746 - val_loss: 0.1686 - val_accuracy: 0.9414\n",
      "Epoch 99/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0724 - accuracy: 0.9725 - val_loss: 0.1631 - val_accuracy: 0.9400\n",
      "Epoch 100/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0686 - accuracy: 0.9733 - val_loss: 0.1584 - val_accuracy: 0.9456\n",
      "Epoch 101/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0638 - accuracy: 0.9754 - val_loss: 0.1776 - val_accuracy: 0.9393\n",
      "Epoch 102/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0985 - accuracy: 0.9632 - val_loss: 0.1663 - val_accuracy: 0.9411\n",
      "Epoch 103/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0574 - accuracy: 0.9783 - val_loss: 0.1503 - val_accuracy: 0.9516\n",
      "Epoch 104/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0598 - accuracy: 0.9776 - val_loss: 0.1518 - val_accuracy: 0.9477\n",
      "Epoch 105/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0734 - accuracy: 0.9720 - val_loss: 0.1567 - val_accuracy: 0.9418\n",
      "Epoch 106/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0711 - accuracy: 0.9727 - val_loss: 0.1822 - val_accuracy: 0.9400\n",
      "Epoch 107/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0650 - accuracy: 0.9754 - val_loss: 0.1702 - val_accuracy: 0.9453\n",
      "Epoch 108/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.0561 - accuracy: 0.9781 - val_loss: 0.1712 - val_accuracy: 0.9421\n",
      "Epoch 109/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.0646 - accuracy: 0.9738 - val_loss: 0.1542 - val_accuracy: 0.9474\n",
      "Epoch 110/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0775 - accuracy: 0.9712 - val_loss: 0.2575 - val_accuracy: 0.8940\n",
      "Epoch 111/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.0888 - accuracy: 0.9643 - val_loss: 0.1449 - val_accuracy: 0.9484\n",
      "Epoch 112/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0625 - accuracy: 0.9769 - val_loss: 0.1490 - val_accuracy: 0.9481\n",
      "Epoch 113/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0518 - accuracy: 0.9802 - val_loss: 0.1519 - val_accuracy: 0.9477\n",
      "Epoch 114/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0561 - accuracy: 0.9787 - val_loss: 0.1563 - val_accuracy: 0.9509\n",
      "Epoch 115/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0531 - accuracy: 0.9798 - val_loss: 0.1590 - val_accuracy: 0.9484\n",
      "Epoch 116/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0466 - accuracy: 0.9827 - val_loss: 0.1731 - val_accuracy: 0.9442\n",
      "Epoch 117/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0518 - accuracy: 0.9806 - val_loss: 0.1761 - val_accuracy: 0.9463\n",
      "Epoch 118/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0495 - accuracy: 0.9814 - val_loss: 0.1556 - val_accuracy: 0.9512\n",
      "Epoch 119/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0551 - accuracy: 0.9793 - val_loss: 0.1703 - val_accuracy: 0.9425\n",
      "Epoch 120/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0519 - accuracy: 0.9806 - val_loss: 0.1415 - val_accuracy: 0.9523\n",
      "Epoch 121/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0547 - accuracy: 0.9791 - val_loss: 0.1481 - val_accuracy: 0.9530\n",
      "Epoch 122/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0690 - accuracy: 0.9744 - val_loss: 0.1777 - val_accuracy: 0.9456\n",
      "Epoch 123/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0457 - accuracy: 0.9830 - val_loss: 0.1471 - val_accuracy: 0.9544\n",
      "Epoch 124/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0523 - accuracy: 0.9801 - val_loss: 0.1549 - val_accuracy: 0.9481\n",
      "Epoch 125/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0536 - accuracy: 0.9800 - val_loss: 0.1764 - val_accuracy: 0.9449\n",
      "Epoch 126/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0420 - accuracy: 0.9841 - val_loss: 0.1620 - val_accuracy: 0.9495\n",
      "Epoch 127/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0525 - accuracy: 0.9800 - val_loss: 0.1604 - val_accuracy: 0.9526\n",
      "Epoch 128/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0511 - accuracy: 0.9819 - val_loss: 0.1662 - val_accuracy: 0.9407\n",
      "Epoch 129/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0481 - accuracy: 0.9822 - val_loss: 0.1861 - val_accuracy: 0.9319\n",
      "Epoch 130/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0510 - accuracy: 0.9803 - val_loss: 0.1505 - val_accuracy: 0.9481\n",
      "Epoch 131/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0340 - accuracy: 0.9876 - val_loss: 0.1706 - val_accuracy: 0.9481\n",
      "Epoch 132/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0540 - accuracy: 0.9800 - val_loss: 0.1641 - val_accuracy: 0.9502\n",
      "Epoch 133/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0327 - accuracy: 0.9879 - val_loss: 0.1876 - val_accuracy: 0.9463\n",
      "Epoch 134/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0614 - accuracy: 0.9785 - val_loss: 0.1856 - val_accuracy: 0.9435\n",
      "Epoch 135/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0420 - accuracy: 0.9853 - val_loss: 0.1638 - val_accuracy: 0.9502\n",
      "Epoch 136/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0630 - accuracy: 0.9773 - val_loss: 0.1645 - val_accuracy: 0.9456\n",
      "Epoch 137/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0447 - accuracy: 0.9827 - val_loss: 0.1416 - val_accuracy: 0.9565\n",
      "Epoch 138/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0503 - accuracy: 0.9807 - val_loss: 0.1606 - val_accuracy: 0.9530\n",
      "Epoch 139/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.0417 - accuracy: 0.9848 - val_loss: 0.1568 - val_accuracy: 0.9572\n",
      "Epoch 140/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0362 - accuracy: 0.9866 - val_loss: 0.1453 - val_accuracy: 0.9526\n",
      "Epoch 141/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0332 - accuracy: 0.9881 - val_loss: 0.1722 - val_accuracy: 0.9509\n",
      "Epoch 142/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0339 - accuracy: 0.9877 - val_loss: 0.1666 - val_accuracy: 0.9509\n",
      "Epoch 143/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0537 - accuracy: 0.9805 - val_loss: 0.1498 - val_accuracy: 0.9512\n",
      "Epoch 144/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0349 - accuracy: 0.9885 - val_loss: 0.1422 - val_accuracy: 0.9589\n",
      "Epoch 145/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0453 - accuracy: 0.9838 - val_loss: 0.1500 - val_accuracy: 0.9526\n",
      "Epoch 146/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0312 - accuracy: 0.9883 - val_loss: 0.1553 - val_accuracy: 0.9537\n",
      "Epoch 147/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0327 - accuracy: 0.9892 - val_loss: 0.1541 - val_accuracy: 0.9505\n",
      "Epoch 148/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0257 - accuracy: 0.9904 - val_loss: 0.1509 - val_accuracy: 0.9533\n",
      "Epoch 149/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0455 - accuracy: 0.9842 - val_loss: 0.1542 - val_accuracy: 0.9537\n",
      "Epoch 150/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0282 - accuracy: 0.9897 - val_loss: 0.1876 - val_accuracy: 0.9460\n",
      "Epoch 151/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0458 - accuracy: 0.9838 - val_loss: 0.1662 - val_accuracy: 0.9519\n",
      "Epoch 152/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0324 - accuracy: 0.9887 - val_loss: 0.1631 - val_accuracy: 0.9505\n",
      "Epoch 153/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0372 - accuracy: 0.9873 - val_loss: 0.1760 - val_accuracy: 0.9488\n",
      "Epoch 154/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.1820 - val_accuracy: 0.9446\n",
      "Epoch 155/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0401 - accuracy: 0.9852 - val_loss: 0.1857 - val_accuracy: 0.9456\n",
      "Epoch 156/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0468 - accuracy: 0.9835 - val_loss: 0.1575 - val_accuracy: 0.9526\n",
      "Epoch 157/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0414 - accuracy: 0.9853 - val_loss: 0.1501 - val_accuracy: 0.9519\n",
      "Epoch 158/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0265 - accuracy: 0.9911 - val_loss: 0.1628 - val_accuracy: 0.9540\n",
      "Epoch 159/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0274 - accuracy: 0.9904 - val_loss: 0.1441 - val_accuracy: 0.9544\n",
      "Epoch 160/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0408 - accuracy: 0.9857 - val_loss: 0.1945 - val_accuracy: 0.9425\n",
      "Epoch 161/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0295 - accuracy: 0.9897 - val_loss: 0.1618 - val_accuracy: 0.9505\n",
      "Epoch 162/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0221 - accuracy: 0.9925 - val_loss: 0.1499 - val_accuracy: 0.9586\n",
      "Epoch 163/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0356 - accuracy: 0.9875 - val_loss: 0.2904 - val_accuracy: 0.9232\n",
      "Epoch 164/500\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9837Restoring model weights from the end of the best epoch: 144.\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0488 - accuracy: 0.9837 - val_loss: 0.1818 - val_accuracy: 0.9467\n",
      "Epoch 164: early stopping\n",
      "Number of iterations 3\n",
      "F1-scores:  [0.939744370054778, 0.9323493234932348, 0.9285277947464875]\n",
      "Average F1-Score 0.9335404960981668\n",
      "Std Dev F1-Score 0.00465596818021007\n",
      "Error bar F1-Score 0.002688124482182616\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 11s 18ms/step - loss: 0.5505 - accuracy: 0.7113 - val_loss: 0.5134 - val_accuracy: 0.7137\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.5208 - accuracy: 0.7149 - val_loss: 0.5111 - val_accuracy: 0.7137\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.5106 - accuracy: 0.7212 - val_loss: 0.4874 - val_accuracy: 0.7225\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.4736 - accuracy: 0.7351 - val_loss: 0.4375 - val_accuracy: 0.7877\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3762 - accuracy: 0.8192 - val_loss: 0.3416 - val_accuracy: 0.8323\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3441 - accuracy: 0.8373 - val_loss: 0.3278 - val_accuracy: 0.8456\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3146 - accuracy: 0.8532 - val_loss: 0.3014 - val_accuracy: 0.8586\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2926 - accuracy: 0.8671 - val_loss: 0.2746 - val_accuracy: 0.8677\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2739 - accuracy: 0.8762 - val_loss: 0.3145 - val_accuracy: 0.8505\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2675 - accuracy: 0.8797 - val_loss: 0.2743 - val_accuracy: 0.8621\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2811 - accuracy: 0.8730 - val_loss: 0.3063 - val_accuracy: 0.8558\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2580 - accuracy: 0.8824 - val_loss: 0.2571 - val_accuracy: 0.8702\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2499 - accuracy: 0.8854 - val_loss: 0.2515 - val_accuracy: 0.8835\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2677 - accuracy: 0.8772 - val_loss: 0.3066 - val_accuracy: 0.8575\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2653 - accuracy: 0.8803 - val_loss: 0.2582 - val_accuracy: 0.8863\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2466 - accuracy: 0.8874 - val_loss: 0.2375 - val_accuracy: 0.8874\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2456 - accuracy: 0.8879 - val_loss: 0.2756 - val_accuracy: 0.8709\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.2413 - accuracy: 0.8897 - val_loss: 0.2367 - val_accuracy: 0.8881\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2340 - accuracy: 0.8944 - val_loss: 0.2351 - val_accuracy: 0.8898\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2346 - accuracy: 0.8945 - val_loss: 0.2297 - val_accuracy: 0.8888\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2373 - accuracy: 0.8926 - val_loss: 0.2480 - val_accuracy: 0.8874\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2276 - accuracy: 0.8967 - val_loss: 0.2310 - val_accuracy: 0.8909\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2207 - accuracy: 0.9018 - val_loss: 0.2270 - val_accuracy: 0.8940\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.2301 - accuracy: 0.8974 - val_loss: 0.2376 - val_accuracy: 0.8909\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.2266 - accuracy: 0.8985 - val_loss: 0.2315 - val_accuracy: 0.8902\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2147 - accuracy: 0.9032 - val_loss: 0.2262 - val_accuracy: 0.8926\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2126 - accuracy: 0.9037 - val_loss: 0.2214 - val_accuracy: 0.9042\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2088 - accuracy: 0.9065 - val_loss: 0.2529 - val_accuracy: 0.8818\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2178 - accuracy: 0.9022 - val_loss: 0.2065 - val_accuracy: 0.9088\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2067 - accuracy: 0.9089 - val_loss: 0.2072 - val_accuracy: 0.9095\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1979 - accuracy: 0.9113 - val_loss: 0.2064 - val_accuracy: 0.9049\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2036 - accuracy: 0.9109 - val_loss: 0.2143 - val_accuracy: 0.9056\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1952 - accuracy: 0.9146 - val_loss: 0.1947 - val_accuracy: 0.9116\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1952 - accuracy: 0.9153 - val_loss: 0.1937 - val_accuracy: 0.9144\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1921 - accuracy: 0.9141 - val_loss: 0.1996 - val_accuracy: 0.9081\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1871 - accuracy: 0.9188 - val_loss: 0.1916 - val_accuracy: 0.9193\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1973 - accuracy: 0.9142 - val_loss: 0.2260 - val_accuracy: 0.8951\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1850 - accuracy: 0.9163 - val_loss: 0.2201 - val_accuracy: 0.9025\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1804 - accuracy: 0.9209 - val_loss: 0.1936 - val_accuracy: 0.9207\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1823 - accuracy: 0.9206 - val_loss: 0.1856 - val_accuracy: 0.9168\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1739 - accuracy: 0.9242 - val_loss: 0.1892 - val_accuracy: 0.9151\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1651 - accuracy: 0.9276 - val_loss: 0.1711 - val_accuracy: 0.9253\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1670 - accuracy: 0.9260 - val_loss: 0.1808 - val_accuracy: 0.9193\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1632 - accuracy: 0.9305 - val_loss: 0.2520 - val_accuracy: 0.8898\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1679 - accuracy: 0.9290 - val_loss: 0.1673 - val_accuracy: 0.9249\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1608 - accuracy: 0.9325 - val_loss: 0.1825 - val_accuracy: 0.9168\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1501 - accuracy: 0.9347 - val_loss: 0.1603 - val_accuracy: 0.9326\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1490 - accuracy: 0.9371 - val_loss: 0.1690 - val_accuracy: 0.9291\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1484 - accuracy: 0.9369 - val_loss: 0.1721 - val_accuracy: 0.9263\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1493 - accuracy: 0.9355 - val_loss: 0.1671 - val_accuracy: 0.9284\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1482 - accuracy: 0.9376 - val_loss: 0.1663 - val_accuracy: 0.9260\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1447 - accuracy: 0.9381 - val_loss: 0.1547 - val_accuracy: 0.9333\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1412 - accuracy: 0.9416 - val_loss: 0.1502 - val_accuracy: 0.9347\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.1309 - accuracy: 0.9472 - val_loss: 0.1691 - val_accuracy: 0.9284\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.1346 - accuracy: 0.9439 - val_loss: 0.1575 - val_accuracy: 0.9302\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1297 - accuracy: 0.9458 - val_loss: 0.1776 - val_accuracy: 0.9256\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1264 - accuracy: 0.9475 - val_loss: 0.1480 - val_accuracy: 0.9375\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1263 - accuracy: 0.9482 - val_loss: 0.1537 - val_accuracy: 0.9323\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1239 - accuracy: 0.9486 - val_loss: 0.1640 - val_accuracy: 0.9326\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1260 - accuracy: 0.9480 - val_loss: 0.1552 - val_accuracy: 0.9365\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1219 - accuracy: 0.9500 - val_loss: 0.1792 - val_accuracy: 0.9260\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1196 - accuracy: 0.9513 - val_loss: 0.1366 - val_accuracy: 0.9442\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1188 - accuracy: 0.9512 - val_loss: 0.1641 - val_accuracy: 0.9330\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1132 - accuracy: 0.9537 - val_loss: 0.1355 - val_accuracy: 0.9456\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1090 - accuracy: 0.9546 - val_loss: 0.1421 - val_accuracy: 0.9425\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1228 - accuracy: 0.9494 - val_loss: 0.1524 - val_accuracy: 0.9386\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1105 - accuracy: 0.9555 - val_loss: 0.1416 - val_accuracy: 0.9456\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1045 - accuracy: 0.9574 - val_loss: 0.1736 - val_accuracy: 0.9295\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1082 - accuracy: 0.9552 - val_loss: 0.1877 - val_accuracy: 0.9298\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1001 - accuracy: 0.9604 - val_loss: 0.1381 - val_accuracy: 0.9477\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0987 - accuracy: 0.9616 - val_loss: 0.1436 - val_accuracy: 0.9435\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0996 - accuracy: 0.9599 - val_loss: 0.1826 - val_accuracy: 0.9228\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0990 - accuracy: 0.9600 - val_loss: 0.1288 - val_accuracy: 0.9495\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0895 - accuracy: 0.9639 - val_loss: 0.1299 - val_accuracy: 0.9502\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0950 - accuracy: 0.9620 - val_loss: 0.1268 - val_accuracy: 0.9516\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0835 - accuracy: 0.9666 - val_loss: 0.1573 - val_accuracy: 0.9400\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0887 - accuracy: 0.9639 - val_loss: 0.1549 - val_accuracy: 0.9365\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0869 - accuracy: 0.9666 - val_loss: 0.1562 - val_accuracy: 0.9453\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0825 - accuracy: 0.9675 - val_loss: 0.1337 - val_accuracy: 0.9530\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0920 - accuracy: 0.9651 - val_loss: 0.1310 - val_accuracy: 0.9516\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0770 - accuracy: 0.9700 - val_loss: 0.1117 - val_accuracy: 0.9544\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0916 - accuracy: 0.9649 - val_loss: 0.1101 - val_accuracy: 0.9558\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0810 - accuracy: 0.9679 - val_loss: 0.1600 - val_accuracy: 0.9411\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0786 - accuracy: 0.9681 - val_loss: 0.1701 - val_accuracy: 0.9411\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.0727 - accuracy: 0.9727 - val_loss: 0.1198 - val_accuracy: 0.9554\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.0660 - accuracy: 0.9743 - val_loss: 0.1477 - val_accuracy: 0.9460\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0731 - accuracy: 0.9723 - val_loss: 0.1340 - val_accuracy: 0.9533\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0806 - accuracy: 0.9691 - val_loss: 0.1221 - val_accuracy: 0.9530\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0696 - accuracy: 0.9731 - val_loss: 0.1476 - val_accuracy: 0.9421\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0683 - accuracy: 0.9734 - val_loss: 0.1270 - val_accuracy: 0.9565\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0612 - accuracy: 0.9763 - val_loss: 0.1306 - val_accuracy: 0.9512\n",
      "Epoch 92/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1001 - accuracy: 0.9613 - val_loss: 0.1226 - val_accuracy: 0.9544\n",
      "Epoch 93/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0589 - accuracy: 0.9781 - val_loss: 0.1103 - val_accuracy: 0.9618\n",
      "Epoch 94/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0610 - accuracy: 0.9762 - val_loss: 0.1325 - val_accuracy: 0.9572\n",
      "Epoch 95/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0715 - accuracy: 0.9728 - val_loss: 0.1111 - val_accuracy: 0.9614\n",
      "Epoch 96/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0487 - accuracy: 0.9822 - val_loss: 0.1236 - val_accuracy: 0.9604\n",
      "Epoch 97/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0668 - accuracy: 0.9738 - val_loss: 0.1282 - val_accuracy: 0.9554\n",
      "Epoch 98/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0735 - accuracy: 0.9731 - val_loss: 0.1063 - val_accuracy: 0.9628\n",
      "Epoch 99/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0563 - accuracy: 0.9784 - val_loss: 0.1127 - val_accuracy: 0.9582\n",
      "Epoch 100/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0538 - accuracy: 0.9795 - val_loss: 0.1080 - val_accuracy: 0.9660\n",
      "Epoch 101/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0555 - accuracy: 0.9792 - val_loss: 0.1242 - val_accuracy: 0.9561\n",
      "Epoch 102/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.0505 - accuracy: 0.9806 - val_loss: 0.1069 - val_accuracy: 0.9649\n",
      "Epoch 103/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0577 - accuracy: 0.9786 - val_loss: 0.1718 - val_accuracy: 0.9421\n",
      "Epoch 104/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0704 - accuracy: 0.9730 - val_loss: 0.1013 - val_accuracy: 0.9639\n",
      "Epoch 105/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0468 - accuracy: 0.9822 - val_loss: 0.1176 - val_accuracy: 0.9621\n",
      "Epoch 106/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0469 - accuracy: 0.9806 - val_loss: 0.1207 - val_accuracy: 0.9628\n",
      "Epoch 107/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0454 - accuracy: 0.9832 - val_loss: 0.1236 - val_accuracy: 0.9509\n",
      "Epoch 108/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0556 - accuracy: 0.9797 - val_loss: 0.1172 - val_accuracy: 0.9589\n",
      "Epoch 109/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0625 - accuracy: 0.9751 - val_loss: 0.1002 - val_accuracy: 0.9674\n",
      "Epoch 110/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0481 - accuracy: 0.9821 - val_loss: 0.1193 - val_accuracy: 0.9611\n",
      "Epoch 111/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0535 - accuracy: 0.9793 - val_loss: 0.1066 - val_accuracy: 0.9639\n",
      "Epoch 112/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0440 - accuracy: 0.9841 - val_loss: 0.1683 - val_accuracy: 0.9453\n",
      "Epoch 113/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0621 - accuracy: 0.9757 - val_loss: 0.1138 - val_accuracy: 0.9656\n",
      "Epoch 114/500\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.0441 - accuracy: 0.9839 - val_loss: 0.1254 - val_accuracy: 0.9621\n",
      "Epoch 115/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0367 - accuracy: 0.9866 - val_loss: 0.1040 - val_accuracy: 0.9677\n",
      "Epoch 116/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0498 - accuracy: 0.9818 - val_loss: 0.1173 - val_accuracy: 0.9611\n",
      "Epoch 117/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0550 - accuracy: 0.9800 - val_loss: 0.1273 - val_accuracy: 0.9551\n",
      "Epoch 118/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0526 - accuracy: 0.9808 - val_loss: 0.1260 - val_accuracy: 0.9604\n",
      "Epoch 119/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0380 - accuracy: 0.9861 - val_loss: 0.1098 - val_accuracy: 0.9621\n",
      "Epoch 120/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0505 - accuracy: 0.9813 - val_loss: 0.1109 - val_accuracy: 0.9621\n",
      "Epoch 121/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0632 - accuracy: 0.9767 - val_loss: 0.1108 - val_accuracy: 0.9611\n",
      "Epoch 122/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0325 - accuracy: 0.9895 - val_loss: 0.2211 - val_accuracy: 0.9263\n",
      "Epoch 123/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0434 - accuracy: 0.9831 - val_loss: 0.1261 - val_accuracy: 0.9635\n",
      "Epoch 124/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0352 - accuracy: 0.9865 - val_loss: 0.1254 - val_accuracy: 0.9621\n",
      "Epoch 125/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0458 - accuracy: 0.9834 - val_loss: 0.1108 - val_accuracy: 0.9684\n",
      "Epoch 126/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0307 - accuracy: 0.9887 - val_loss: 0.1231 - val_accuracy: 0.9611\n",
      "Epoch 127/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0373 - accuracy: 0.9859 - val_loss: 0.1126 - val_accuracy: 0.9674\n",
      "Epoch 128/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0546 - accuracy: 0.9797 - val_loss: 0.1220 - val_accuracy: 0.9579\n",
      "Epoch 129/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0329 - accuracy: 0.9870 - val_loss: 0.1005 - val_accuracy: 0.9677\n",
      "Epoch 130/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0369 - accuracy: 0.9864 - val_loss: 0.1115 - val_accuracy: 0.9670\n",
      "Epoch 131/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0299 - accuracy: 0.9895 - val_loss: 0.1396 - val_accuracy: 0.9582\n",
      "Epoch 132/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0278 - accuracy: 0.9893 - val_loss: 0.1215 - val_accuracy: 0.9674\n",
      "Epoch 133/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0423 - accuracy: 0.9851 - val_loss: 0.1577 - val_accuracy: 0.9484\n",
      "Epoch 134/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0450 - accuracy: 0.9834 - val_loss: 0.1181 - val_accuracy: 0.9656\n",
      "Epoch 135/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 0.1215 - val_accuracy: 0.9621\n",
      "Epoch 136/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0343 - accuracy: 0.9873 - val_loss: 0.1464 - val_accuracy: 0.9579\n",
      "Epoch 137/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0547 - accuracy: 0.9801 - val_loss: 0.0956 - val_accuracy: 0.9667\n",
      "Epoch 138/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0209 - accuracy: 0.9926 - val_loss: 0.1458 - val_accuracy: 0.9586\n",
      "Epoch 139/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.0388 - accuracy: 0.9864 - val_loss: 0.1204 - val_accuracy: 0.9621\n",
      "Epoch 140/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0401 - accuracy: 0.9845 - val_loss: 0.1211 - val_accuracy: 0.9646\n",
      "Epoch 141/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0335 - accuracy: 0.9885 - val_loss: 0.1089 - val_accuracy: 0.9663\n",
      "Epoch 142/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0319 - accuracy: 0.9881 - val_loss: 0.1257 - val_accuracy: 0.9586\n",
      "Epoch 143/500\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.0616 - accuracy: 0.9775 - val_loss: 0.0981 - val_accuracy: 0.9726\n",
      "Epoch 144/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0241 - accuracy: 0.9912 - val_loss: 0.1204 - val_accuracy: 0.9632\n",
      "Epoch 145/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0177 - accuracy: 0.9940 - val_loss: 0.1331 - val_accuracy: 0.9625\n",
      "Epoch 146/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0336 - accuracy: 0.9887 - val_loss: 0.1492 - val_accuracy: 0.9604\n",
      "Epoch 147/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0316 - accuracy: 0.9889 - val_loss: 0.1367 - val_accuracy: 0.9554\n",
      "Epoch 148/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0307 - accuracy: 0.9889 - val_loss: 0.1279 - val_accuracy: 0.9635\n",
      "Epoch 149/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0352 - accuracy: 0.9874 - val_loss: 0.1090 - val_accuracy: 0.9733\n",
      "Epoch 150/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0387 - accuracy: 0.9856 - val_loss: 0.1187 - val_accuracy: 0.9611\n",
      "Epoch 151/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0218 - accuracy: 0.9923 - val_loss: 0.1164 - val_accuracy: 0.9670\n",
      "Epoch 152/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0241 - accuracy: 0.9912 - val_loss: 0.1250 - val_accuracy: 0.9625\n",
      "Epoch 153/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.1269 - val_accuracy: 0.9642\n",
      "Epoch 154/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0373 - accuracy: 0.9879 - val_loss: 0.1248 - val_accuracy: 0.9607\n",
      "Epoch 155/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.1670 - val_accuracy: 0.9582\n",
      "Epoch 156/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0317 - accuracy: 0.9881 - val_loss: 0.1325 - val_accuracy: 0.9632\n",
      "Epoch 157/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0476 - accuracy: 0.9835 - val_loss: 0.1148 - val_accuracy: 0.9607\n",
      "Epoch 158/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0217 - accuracy: 0.9929 - val_loss: 0.1085 - val_accuracy: 0.9684\n",
      "Epoch 159/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0359 - accuracy: 0.9881 - val_loss: 0.1322 - val_accuracy: 0.9547\n",
      "Epoch 160/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0278 - accuracy: 0.9902 - val_loss: 0.1145 - val_accuracy: 0.9674\n",
      "Epoch 161/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.1552 - val_accuracy: 0.9625\n",
      "Epoch 162/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0488 - accuracy: 0.9826 - val_loss: 0.1274 - val_accuracy: 0.9621\n",
      "Epoch 163/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0269 - accuracy: 0.9912 - val_loss: 0.1286 - val_accuracy: 0.9618\n",
      "Epoch 164/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0235 - accuracy: 0.9918 - val_loss: 0.0896 - val_accuracy: 0.9719\n",
      "Epoch 165/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0232 - accuracy: 0.9922 - val_loss: 0.1340 - val_accuracy: 0.9607\n",
      "Epoch 166/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0300 - accuracy: 0.9892 - val_loss: 0.1575 - val_accuracy: 0.9526\n",
      "Epoch 167/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 0.1151 - val_accuracy: 0.9649\n",
      "Epoch 168/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.1681 - val_accuracy: 0.9572\n",
      "Epoch 169/500\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0424 - accuracy: 0.9867Restoring model weights from the end of the best epoch: 149.\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0421 - accuracy: 0.9868 - val_loss: 0.1079 - val_accuracy: 0.9677\n",
      "Epoch 169: early stopping\n",
      "Number of iterations 4\n",
      "F1-scores:  [0.939744370054778, 0.9323493234932348, 0.9285277947464875, 0.9536019536019537]\n",
      "Average F1-Score 0.9385558604741135\n",
      "Std Dev F1-Score 0.009577064750845786\n",
      "Error bar F1-Score 0.004788532375422893\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 11s 18ms/step - loss: 0.5500 - accuracy: 0.7131 - val_loss: 0.5111 - val_accuracy: 0.7193\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.5126 - accuracy: 0.7156 - val_loss: 0.5097 - val_accuracy: 0.7309\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.4984 - accuracy: 0.7272 - val_loss: 0.4443 - val_accuracy: 0.7730\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3968 - accuracy: 0.8014 - val_loss: 0.4293 - val_accuracy: 0.8049\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3580 - accuracy: 0.8265 - val_loss: 0.3559 - val_accuracy: 0.8235\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3398 - accuracy: 0.8396 - val_loss: 0.3247 - val_accuracy: 0.8439\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3332 - accuracy: 0.8428 - val_loss: 0.3705 - val_accuracy: 0.8242\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3321 - accuracy: 0.8417 - val_loss: 0.3153 - val_accuracy: 0.8491\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3170 - accuracy: 0.8537 - val_loss: 0.3063 - val_accuracy: 0.8523\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3082 - accuracy: 0.8573 - val_loss: 0.2901 - val_accuracy: 0.8681\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3057 - accuracy: 0.8587 - val_loss: 0.2792 - val_accuracy: 0.8698\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2959 - accuracy: 0.8628 - val_loss: 0.2877 - val_accuracy: 0.8730\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2822 - accuracy: 0.8718 - val_loss: 0.3327 - val_accuracy: 0.8446\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2774 - accuracy: 0.8716 - val_loss: 0.2508 - val_accuracy: 0.8779\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2688 - accuracy: 0.8740 - val_loss: 0.2838 - val_accuracy: 0.8747\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2596 - accuracy: 0.8805 - val_loss: 0.2646 - val_accuracy: 0.8712\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2584 - accuracy: 0.8823 - val_loss: 0.2804 - val_accuracy: 0.8709\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2457 - accuracy: 0.8890 - val_loss: 0.2745 - val_accuracy: 0.8677\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2510 - accuracy: 0.8864 - val_loss: 0.2626 - val_accuracy: 0.8884\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2390 - accuracy: 0.8936 - val_loss: 0.2296 - val_accuracy: 0.8954\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.2295 - accuracy: 0.8962 - val_loss: 0.2234 - val_accuracy: 0.8965\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.2263 - accuracy: 0.8982 - val_loss: 0.2355 - val_accuracy: 0.8958\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2538 - accuracy: 0.8834 - val_loss: 0.3944 - val_accuracy: 0.8249\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3500 - accuracy: 0.8265 - val_loss: 0.2502 - val_accuracy: 0.8786\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2201 - accuracy: 0.9001 - val_loss: 0.2458 - val_accuracy: 0.8881\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2179 - accuracy: 0.9023 - val_loss: 0.2112 - val_accuracy: 0.9116\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2138 - accuracy: 0.9040 - val_loss: 0.2128 - val_accuracy: 0.9053\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2138 - accuracy: 0.9045 - val_loss: 0.2214 - val_accuracy: 0.8968\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2152 - accuracy: 0.9041 - val_loss: 0.2385 - val_accuracy: 0.8905\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2061 - accuracy: 0.9088 - val_loss: 0.2156 - val_accuracy: 0.9105\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2145 - accuracy: 0.9042 - val_loss: 0.2081 - val_accuracy: 0.9130\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2021 - accuracy: 0.9121 - val_loss: 0.1972 - val_accuracy: 0.9175\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2017 - accuracy: 0.9116 - val_loss: 0.2311 - val_accuracy: 0.9014\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1927 - accuracy: 0.9146 - val_loss: 0.2206 - val_accuracy: 0.8989\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2671 - accuracy: 0.8768 - val_loss: 0.2116 - val_accuracy: 0.9011\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2316 - accuracy: 0.8955 - val_loss: 0.2100 - val_accuracy: 0.9084\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2004 - accuracy: 0.9108 - val_loss: 0.2117 - val_accuracy: 0.8958\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1923 - accuracy: 0.9159 - val_loss: 0.2032 - val_accuracy: 0.9081\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1929 - accuracy: 0.9155 - val_loss: 0.2014 - val_accuracy: 0.9154\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.1894 - accuracy: 0.9176 - val_loss: 0.1974 - val_accuracy: 0.9161\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1884 - accuracy: 0.9191 - val_loss: 0.2162 - val_accuracy: 0.8958\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1772 - accuracy: 0.9227 - val_loss: 0.2401 - val_accuracy: 0.8972\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1890 - accuracy: 0.9195 - val_loss: 0.2138 - val_accuracy: 0.9077\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1752 - accuracy: 0.9250 - val_loss: 0.1821 - val_accuracy: 0.9228\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1817 - accuracy: 0.9227 - val_loss: 0.1993 - val_accuracy: 0.9007\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1777 - accuracy: 0.9231 - val_loss: 0.1818 - val_accuracy: 0.9239\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1746 - accuracy: 0.9245 - val_loss: 0.2079 - val_accuracy: 0.9211\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1728 - accuracy: 0.9267 - val_loss: 0.2335 - val_accuracy: 0.8940\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.1654 - accuracy: 0.9302 - val_loss: 0.1828 - val_accuracy: 0.9225\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.1634 - accuracy: 0.9310 - val_loss: 0.2064 - val_accuracy: 0.9088\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1744 - accuracy: 0.9242 - val_loss: 0.2606 - val_accuracy: 0.8874\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1601 - accuracy: 0.9302 - val_loss: 0.1798 - val_accuracy: 0.9186\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1630 - accuracy: 0.9301 - val_loss: 0.2016 - val_accuracy: 0.9060\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1635 - accuracy: 0.9299 - val_loss: 0.1807 - val_accuracy: 0.9200\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1533 - accuracy: 0.9350 - val_loss: 0.1788 - val_accuracy: 0.9249\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1528 - accuracy: 0.9340 - val_loss: 0.2222 - val_accuracy: 0.9046\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1619 - accuracy: 0.9332 - val_loss: 0.2256 - val_accuracy: 0.9007\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1488 - accuracy: 0.9365 - val_loss: 0.1720 - val_accuracy: 0.9291\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1455 - accuracy: 0.9387 - val_loss: 0.1860 - val_accuracy: 0.9232\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1482 - accuracy: 0.9378 - val_loss: 0.1808 - val_accuracy: 0.9228\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1484 - accuracy: 0.9369 - val_loss: 0.2009 - val_accuracy: 0.9179\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1545 - accuracy: 0.9368 - val_loss: 0.2050 - val_accuracy: 0.9140\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1417 - accuracy: 0.9400 - val_loss: 0.1896 - val_accuracy: 0.9228\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1394 - accuracy: 0.9420 - val_loss: 0.2945 - val_accuracy: 0.8719\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1372 - accuracy: 0.9430 - val_loss: 0.1835 - val_accuracy: 0.9232\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1454 - accuracy: 0.9378 - val_loss: 0.1673 - val_accuracy: 0.9291\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1344 - accuracy: 0.9439 - val_loss: 0.1802 - val_accuracy: 0.9263\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1338 - accuracy: 0.9443 - val_loss: 0.1661 - val_accuracy: 0.9284\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1300 - accuracy: 0.9454 - val_loss: 0.1937 - val_accuracy: 0.9218\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1308 - accuracy: 0.9460 - val_loss: 0.1676 - val_accuracy: 0.9305\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1302 - accuracy: 0.9452 - val_loss: 0.1631 - val_accuracy: 0.9365\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1239 - accuracy: 0.9476 - val_loss: 0.1633 - val_accuracy: 0.9354\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1193 - accuracy: 0.9503 - val_loss: 0.2108 - val_accuracy: 0.9154\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1240 - accuracy: 0.9477 - val_loss: 0.1844 - val_accuracy: 0.9239\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1217 - accuracy: 0.9503 - val_loss: 0.1782 - val_accuracy: 0.9284\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1198 - accuracy: 0.9506 - val_loss: 0.1756 - val_accuracy: 0.9298\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1109 - accuracy: 0.9553 - val_loss: 0.1593 - val_accuracy: 0.9358\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.1306 - accuracy: 0.9482 - val_loss: 0.1667 - val_accuracy: 0.9347\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.1153 - accuracy: 0.9532 - val_loss: 0.1809 - val_accuracy: 0.9281\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.1174 - accuracy: 0.9515 - val_loss: 0.1774 - val_accuracy: 0.9344\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1121 - accuracy: 0.9544 - val_loss: 0.1723 - val_accuracy: 0.9305\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1100 - accuracy: 0.9540 - val_loss: 0.1686 - val_accuracy: 0.9295\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1057 - accuracy: 0.9568 - val_loss: 0.1773 - val_accuracy: 0.9309\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1097 - accuracy: 0.9535 - val_loss: 0.1954 - val_accuracy: 0.9270\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1056 - accuracy: 0.9557 - val_loss: 0.1762 - val_accuracy: 0.9333\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0983 - accuracy: 0.9595 - val_loss: 0.1898 - val_accuracy: 0.9295\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0967 - accuracy: 0.9595 - val_loss: 0.1888 - val_accuracy: 0.9291\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1011 - accuracy: 0.9582 - val_loss: 0.1647 - val_accuracy: 0.9316\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1085 - accuracy: 0.9559 - val_loss: 0.2585 - val_accuracy: 0.9014\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1048 - accuracy: 0.9570 - val_loss: 0.2010 - val_accuracy: 0.9274\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 0.9592Restoring model weights from the end of the best epoch: 71.\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1006 - accuracy: 0.9592 - val_loss: 0.1796 - val_accuracy: 0.9274\n",
      "Epoch 91: early stopping\n",
      "Number of iterations 5\n",
      "F1-scores:  [0.939744370054778, 0.9323493234932348, 0.9285277947464875, 0.9536019536019537, 0.8907664453832227]\n",
      "Average F1-Score 0.9289979774559354\n",
      "Std Dev F1-Score 0.020947282557654778\n",
      "Error bar F1-Score 0.009367909548562347\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 11s 18ms/step - loss: 0.5563 - accuracy: 0.7082 - val_loss: 0.5130 - val_accuracy: 0.7137\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.5189 - accuracy: 0.7135 - val_loss: 0.5138 - val_accuracy: 0.7137\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.4715 - accuracy: 0.7387 - val_loss: 0.3993 - val_accuracy: 0.8025\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3827 - accuracy: 0.8072 - val_loss: 0.3562 - val_accuracy: 0.8302\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3648 - accuracy: 0.8205 - val_loss: 0.3694 - val_accuracy: 0.8102\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3498 - accuracy: 0.8300 - val_loss: 0.3284 - val_accuracy: 0.8428\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3508 - accuracy: 0.8294 - val_loss: 0.3784 - val_accuracy: 0.8084\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3387 - accuracy: 0.8397 - val_loss: 0.3268 - val_accuracy: 0.8428\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3333 - accuracy: 0.8415 - val_loss: 0.3193 - val_accuracy: 0.8575\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3264 - accuracy: 0.8467 - val_loss: 0.3623 - val_accuracy: 0.8365\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3239 - accuracy: 0.8485 - val_loss: 0.3035 - val_accuracy: 0.8628\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3150 - accuracy: 0.8527 - val_loss: 0.3297 - val_accuracy: 0.8382\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3635 - accuracy: 0.8234 - val_loss: 0.3457 - val_accuracy: 0.8330\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3258 - accuracy: 0.8494 - val_loss: 0.3193 - val_accuracy: 0.8470\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3124 - accuracy: 0.8560 - val_loss: 0.3757 - val_accuracy: 0.8112\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.3050 - accuracy: 0.8588 - val_loss: 0.2851 - val_accuracy: 0.8681\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3029 - accuracy: 0.8615 - val_loss: 0.3232 - val_accuracy: 0.8435\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3366 - accuracy: 0.8413 - val_loss: 0.3298 - val_accuracy: 0.8593\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2911 - accuracy: 0.8664 - val_loss: 0.2799 - val_accuracy: 0.8688\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3016 - accuracy: 0.8617 - val_loss: 0.2711 - val_accuracy: 0.8768\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2763 - accuracy: 0.8757 - val_loss: 0.2977 - val_accuracy: 0.8656\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2713 - accuracy: 0.8786 - val_loss: 0.3366 - val_accuracy: 0.8730\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2950 - accuracy: 0.8610 - val_loss: 0.3778 - val_accuracy: 0.8186\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3077 - accuracy: 0.8559 - val_loss: 0.2686 - val_accuracy: 0.8779\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2718 - accuracy: 0.8750 - val_loss: 0.2822 - val_accuracy: 0.8684\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2680 - accuracy: 0.8758 - val_loss: 0.2826 - val_accuracy: 0.8649\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2473 - accuracy: 0.8878 - val_loss: 0.2468 - val_accuracy: 0.8881\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2407 - accuracy: 0.8916 - val_loss: 0.2967 - val_accuracy: 0.8726\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2455 - accuracy: 0.8894 - val_loss: 0.2541 - val_accuracy: 0.8811\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2394 - accuracy: 0.8927 - val_loss: 0.2565 - val_accuracy: 0.8853\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.2357 - accuracy: 0.8936 - val_loss: 0.2285 - val_accuracy: 0.8965\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.2305 - accuracy: 0.8962 - val_loss: 0.2822 - val_accuracy: 0.8874\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2501 - accuracy: 0.8864 - val_loss: 0.2386 - val_accuracy: 0.8814\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2198 - accuracy: 0.9019 - val_loss: 0.2110 - val_accuracy: 0.9056\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2148 - accuracy: 0.9047 - val_loss: 0.2215 - val_accuracy: 0.8954\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2207 - accuracy: 0.9021 - val_loss: 0.2350 - val_accuracy: 0.8996\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2148 - accuracy: 0.9048 - val_loss: 0.2439 - val_accuracy: 0.8849\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2050 - accuracy: 0.9106 - val_loss: 0.2120 - val_accuracy: 0.9014\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2011 - accuracy: 0.9126 - val_loss: 0.2109 - val_accuracy: 0.9042\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2023 - accuracy: 0.9103 - val_loss: 0.2158 - val_accuracy: 0.9032\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2005 - accuracy: 0.9110 - val_loss: 0.2103 - val_accuracy: 0.9060\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2032 - accuracy: 0.9125 - val_loss: 0.2248 - val_accuracy: 0.8951\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1960 - accuracy: 0.9143 - val_loss: 0.2203 - val_accuracy: 0.9007\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1875 - accuracy: 0.9176 - val_loss: 0.2725 - val_accuracy: 0.8842\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1928 - accuracy: 0.9153 - val_loss: 0.1897 - val_accuracy: 0.9154\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1877 - accuracy: 0.9173 - val_loss: 0.1960 - val_accuracy: 0.9147\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2280 - accuracy: 0.8951 - val_loss: 0.2343 - val_accuracy: 0.8895\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1955 - accuracy: 0.9154 - val_loss: 0.1881 - val_accuracy: 0.9168\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1840 - accuracy: 0.9213 - val_loss: 0.1841 - val_accuracy: 0.9179\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1807 - accuracy: 0.9222 - val_loss: 0.2421 - val_accuracy: 0.9007\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1759 - accuracy: 0.9248 - val_loss: 0.1813 - val_accuracy: 0.9105\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2194 - accuracy: 0.9025 - val_loss: 0.1933 - val_accuracy: 0.9088\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.1727 - accuracy: 0.9278 - val_loss: 0.1686 - val_accuracy: 0.9330\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1673 - accuracy: 0.9291 - val_loss: 0.1898 - val_accuracy: 0.9175\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1692 - accuracy: 0.9292 - val_loss: 0.1725 - val_accuracy: 0.9284\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1677 - accuracy: 0.9304 - val_loss: 0.1803 - val_accuracy: 0.9214\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1609 - accuracy: 0.9326 - val_loss: 0.1636 - val_accuracy: 0.9298\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1615 - accuracy: 0.9318 - val_loss: 0.1745 - val_accuracy: 0.9284\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.1566 - accuracy: 0.9357 - val_loss: 0.2438 - val_accuracy: 0.8888\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.1563 - accuracy: 0.9342 - val_loss: 0.1669 - val_accuracy: 0.9295\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1719 - accuracy: 0.9273 - val_loss: 0.2748 - val_accuracy: 0.8663\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1682 - accuracy: 0.9295 - val_loss: 0.1679 - val_accuracy: 0.9295\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1790 - accuracy: 0.9231 - val_loss: 0.1728 - val_accuracy: 0.9298\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1461 - accuracy: 0.9399 - val_loss: 0.1787 - val_accuracy: 0.9295\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1541 - accuracy: 0.9361 - val_loss: 0.1466 - val_accuracy: 0.9400\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1358 - accuracy: 0.9453 - val_loss: 0.1495 - val_accuracy: 0.9439\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1384 - accuracy: 0.9427 - val_loss: 0.1526 - val_accuracy: 0.9414\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1374 - accuracy: 0.9437 - val_loss: 0.1672 - val_accuracy: 0.9274\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1366 - accuracy: 0.9443 - val_loss: 0.1985 - val_accuracy: 0.9182\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1356 - accuracy: 0.9444 - val_loss: 0.1302 - val_accuracy: 0.9481\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1271 - accuracy: 0.9495 - val_loss: 0.1511 - val_accuracy: 0.9393\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1303 - accuracy: 0.9471 - val_loss: 0.1873 - val_accuracy: 0.9256\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1323 - accuracy: 0.9457 - val_loss: 0.1350 - val_accuracy: 0.9481\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1221 - accuracy: 0.9492 - val_loss: 0.1656 - val_accuracy: 0.9386\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1229 - accuracy: 0.9511 - val_loss: 0.1442 - val_accuracy: 0.9396\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1132 - accuracy: 0.9538 - val_loss: 0.1519 - val_accuracy: 0.9432\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1238 - accuracy: 0.9503 - val_loss: 0.1766 - val_accuracy: 0.9270\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1104 - accuracy: 0.9551 - val_loss: 0.1445 - val_accuracy: 0.9456\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1137 - accuracy: 0.9547 - val_loss: 0.1484 - val_accuracy: 0.9435\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1148 - accuracy: 0.9539 - val_loss: 0.1811 - val_accuracy: 0.9267\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1044 - accuracy: 0.9593 - val_loss: 0.1294 - val_accuracy: 0.9526\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1065 - accuracy: 0.9572 - val_loss: 0.1501 - val_accuracy: 0.9389\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1062 - accuracy: 0.9584 - val_loss: 0.1349 - val_accuracy: 0.9519\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1110 - accuracy: 0.9561 - val_loss: 0.1659 - val_accuracy: 0.9323\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0970 - accuracy: 0.9619 - val_loss: 0.1557 - val_accuracy: 0.9411\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1022 - accuracy: 0.9610 - val_loss: 0.1384 - val_accuracy: 0.9491\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0940 - accuracy: 0.9630 - val_loss: 0.1201 - val_accuracy: 0.9575\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.1153 - accuracy: 0.9563 - val_loss: 0.1466 - val_accuracy: 0.9421\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.1006 - accuracy: 0.9607 - val_loss: 0.1418 - val_accuracy: 0.9477\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0869 - accuracy: 0.9656 - val_loss: 0.1460 - val_accuracy: 0.9389\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0946 - accuracy: 0.9628 - val_loss: 0.1378 - val_accuracy: 0.9484\n",
      "Epoch 92/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0929 - accuracy: 0.9641 - val_loss: 0.1722 - val_accuracy: 0.9309\n",
      "Epoch 93/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1226 - accuracy: 0.9535 - val_loss: 0.1398 - val_accuracy: 0.9439\n",
      "Epoch 94/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.0806 - accuracy: 0.9673 - val_loss: 0.1500 - val_accuracy: 0.9495\n",
      "Epoch 95/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0916 - accuracy: 0.9640 - val_loss: 0.1308 - val_accuracy: 0.9505\n",
      "Epoch 96/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0874 - accuracy: 0.9667 - val_loss: 0.1591 - val_accuracy: 0.9386\n",
      "Epoch 97/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0882 - accuracy: 0.9650 - val_loss: 0.1399 - val_accuracy: 0.9474\n",
      "Epoch 98/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0725 - accuracy: 0.9725 - val_loss: 0.1298 - val_accuracy: 0.9505\n",
      "Epoch 99/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0802 - accuracy: 0.9695 - val_loss: 0.1383 - val_accuracy: 0.9470\n",
      "Epoch 100/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1020 - accuracy: 0.9594 - val_loss: 0.1549 - val_accuracy: 0.9340\n",
      "Epoch 101/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0791 - accuracy: 0.9696 - val_loss: 0.1546 - val_accuracy: 0.9411\n",
      "Epoch 102/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0785 - accuracy: 0.9710 - val_loss: 0.1587 - val_accuracy: 0.9404\n",
      "Epoch 103/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0854 - accuracy: 0.9679 - val_loss: 0.1374 - val_accuracy: 0.9509\n",
      "Epoch 104/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0728 - accuracy: 0.9716 - val_loss: 0.1364 - val_accuracy: 0.9512\n",
      "Epoch 105/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0779 - accuracy: 0.9686 - val_loss: 0.1344 - val_accuracy: 0.9547\n",
      "Epoch 106/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0624 - accuracy: 0.9765 - val_loss: 0.1805 - val_accuracy: 0.9354\n",
      "Epoch 107/500\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.0681 - accuracy: 0.9730Restoring model weights from the end of the best epoch: 87.\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0678 - accuracy: 0.9732 - val_loss: 0.1705 - val_accuracy: 0.9393\n",
      "Epoch 107: early stopping\n",
      "Number of iterations 6\n",
      "F1-scores:  [0.939744370054778, 0.9323493234932348, 0.9285277947464875, 0.9536019536019537, 0.8907664453832227, 0.9274145170965806]\n",
      "Average F1-Score 0.9287340673960429\n",
      "Std Dev F1-Score 0.019131268856432015\n",
      "Error bar F1-Score 0.007810307805042915\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 13s 24ms/step - loss: 0.5480 - accuracy: 0.7147 - val_loss: 0.5255 - val_accuracy: 0.7137\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.5126 - accuracy: 0.7206 - val_loss: 0.4972 - val_accuracy: 0.7095\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.5008 - accuracy: 0.7209 - val_loss: 0.5006 - val_accuracy: 0.7519\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.4319 - accuracy: 0.7702 - val_loss: 0.3635 - val_accuracy: 0.8298\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3622 - accuracy: 0.8251 - val_loss: 0.3335 - val_accuracy: 0.8379\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3394 - accuracy: 0.8366 - val_loss: 0.3283 - val_accuracy: 0.8449\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3215 - accuracy: 0.8523 - val_loss: 0.2947 - val_accuracy: 0.8572\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2884 - accuracy: 0.8674 - val_loss: 0.2780 - val_accuracy: 0.8709\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2707 - accuracy: 0.8769 - val_loss: 0.3094 - val_accuracy: 0.8646\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2700 - accuracy: 0.8774 - val_loss: 0.2865 - val_accuracy: 0.8604\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2633 - accuracy: 0.8777 - val_loss: 0.3528 - val_accuracy: 0.8267\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2545 - accuracy: 0.8850 - val_loss: 0.3555 - val_accuracy: 0.8347\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2454 - accuracy: 0.8898 - val_loss: 0.2372 - val_accuracy: 0.8888\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2402 - accuracy: 0.8914 - val_loss: 0.2498 - val_accuracy: 0.8849\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2396 - accuracy: 0.8905 - val_loss: 0.3138 - val_accuracy: 0.8523\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2469 - accuracy: 0.8866 - val_loss: 0.2488 - val_accuracy: 0.8867\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2331 - accuracy: 0.8941 - val_loss: 0.2236 - val_accuracy: 0.8951\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.2287 - accuracy: 0.8962 - val_loss: 0.2411 - val_accuracy: 0.8842\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2256 - accuracy: 0.8976 - val_loss: 0.2280 - val_accuracy: 0.8926\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.2510 - accuracy: 0.8839 - val_loss: 0.2474 - val_accuracy: 0.8839\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2220 - accuracy: 0.9000 - val_loss: 0.2992 - val_accuracy: 0.8646\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2209 - accuracy: 0.9008 - val_loss: 0.2128 - val_accuracy: 0.8996\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2226 - accuracy: 0.8999 - val_loss: 0.2142 - val_accuracy: 0.8982\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2145 - accuracy: 0.9020 - val_loss: 0.2410 - val_accuracy: 0.8888\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2197 - accuracy: 0.8994 - val_loss: 0.2312 - val_accuracy: 0.8909\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2116 - accuracy: 0.9042 - val_loss: 0.2309 - val_accuracy: 0.8919\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2086 - accuracy: 0.9059 - val_loss: 0.2924 - val_accuracy: 0.8733\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2103 - accuracy: 0.9059 - val_loss: 0.2124 - val_accuracy: 0.8989\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.2017 - accuracy: 0.9090 - val_loss: 0.2511 - val_accuracy: 0.8888\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.2049 - accuracy: 0.9094 - val_loss: 0.2712 - val_accuracy: 0.8874\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2105 - accuracy: 0.9083 - val_loss: 0.2311 - val_accuracy: 0.9018\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1946 - accuracy: 0.9132 - val_loss: 0.2306 - val_accuracy: 0.9000\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2008 - accuracy: 0.9129 - val_loss: 0.2030 - val_accuracy: 0.9028\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1963 - accuracy: 0.9120 - val_loss: 0.1977 - val_accuracy: 0.9140\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1913 - accuracy: 0.9161 - val_loss: 0.2069 - val_accuracy: 0.9070\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1902 - accuracy: 0.9169 - val_loss: 0.1932 - val_accuracy: 0.9095\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1872 - accuracy: 0.9163 - val_loss: 0.1853 - val_accuracy: 0.9116\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1856 - accuracy: 0.9206 - val_loss: 0.1850 - val_accuracy: 0.9130\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1794 - accuracy: 0.9230 - val_loss: 0.1957 - val_accuracy: 0.9137\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1818 - accuracy: 0.9210 - val_loss: 0.1840 - val_accuracy: 0.9204\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1754 - accuracy: 0.9240 - val_loss: 0.1853 - val_accuracy: 0.9140\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1757 - accuracy: 0.9241 - val_loss: 0.1852 - val_accuracy: 0.9189\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1695 - accuracy: 0.9260 - val_loss: 0.1970 - val_accuracy: 0.9154\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1748 - accuracy: 0.9249 - val_loss: 0.2264 - val_accuracy: 0.9091\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1635 - accuracy: 0.9291 - val_loss: 0.2478 - val_accuracy: 0.8954\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1699 - accuracy: 0.9275 - val_loss: 0.1591 - val_accuracy: 0.9270\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1628 - accuracy: 0.9322 - val_loss: 0.1837 - val_accuracy: 0.9235\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1600 - accuracy: 0.9324 - val_loss: 0.1913 - val_accuracy: 0.9186\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.1604 - accuracy: 0.9312 - val_loss: 0.1687 - val_accuracy: 0.9249\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1603 - accuracy: 0.9315 - val_loss: 0.1827 - val_accuracy: 0.9126\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1588 - accuracy: 0.9332 - val_loss: 0.1787 - val_accuracy: 0.9232\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1497 - accuracy: 0.9371 - val_loss: 0.1755 - val_accuracy: 0.9263\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1581 - accuracy: 0.9339 - val_loss: 0.2205 - val_accuracy: 0.9105\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.1412 - accuracy: 0.9397 - val_loss: 0.1798 - val_accuracy: 0.9246\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1512 - accuracy: 0.9362 - val_loss: 0.1750 - val_accuracy: 0.9302\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1414 - accuracy: 0.9404 - val_loss: 0.1936 - val_accuracy: 0.9179\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.1400 - accuracy: 0.9414 - val_loss: 0.1806 - val_accuracy: 0.9214\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.1390 - accuracy: 0.9422 - val_loss: 0.1492 - val_accuracy: 0.9347\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1369 - accuracy: 0.9439 - val_loss: 0.1600 - val_accuracy: 0.9274\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1343 - accuracy: 0.9452 - val_loss: 0.1648 - val_accuracy: 0.9274\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1242 - accuracy: 0.9491 - val_loss: 0.1499 - val_accuracy: 0.9368\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1301 - accuracy: 0.9458 - val_loss: 0.1637 - val_accuracy: 0.9354\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1293 - accuracy: 0.9468 - val_loss: 0.1550 - val_accuracy: 0.9354\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1309 - accuracy: 0.9467 - val_loss: 0.1594 - val_accuracy: 0.9319\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1329 - accuracy: 0.9456 - val_loss: 0.2467 - val_accuracy: 0.8947\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1203 - accuracy: 0.9506 - val_loss: 0.1896 - val_accuracy: 0.9260\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1311 - accuracy: 0.9474 - val_loss: 0.1435 - val_accuracy: 0.9389\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1151 - accuracy: 0.9536 - val_loss: 0.1568 - val_accuracy: 0.9344\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1185 - accuracy: 0.9503 - val_loss: 0.1520 - val_accuracy: 0.9333\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1128 - accuracy: 0.9531 - val_loss: 0.1625 - val_accuracy: 0.9337\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1222 - accuracy: 0.9502 - val_loss: 0.1343 - val_accuracy: 0.9425\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1113 - accuracy: 0.9559 - val_loss: 0.1476 - val_accuracy: 0.9382\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1104 - accuracy: 0.9564 - val_loss: 0.1504 - val_accuracy: 0.9400\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1007 - accuracy: 0.9594 - val_loss: 0.1379 - val_accuracy: 0.9456\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1024 - accuracy: 0.9591 - val_loss: 0.1684 - val_accuracy: 0.9316\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1054 - accuracy: 0.9572 - val_loss: 0.1574 - val_accuracy: 0.9386\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1099 - accuracy: 0.9562 - val_loss: 0.1423 - val_accuracy: 0.9463\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1050 - accuracy: 0.9581 - val_loss: 0.1495 - val_accuracy: 0.9389\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0924 - accuracy: 0.9633 - val_loss: 0.1435 - val_accuracy: 0.9432\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1050 - accuracy: 0.9570 - val_loss: 0.1527 - val_accuracy: 0.9414\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1023 - accuracy: 0.9592 - val_loss: 0.1518 - val_accuracy: 0.9425\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0859 - accuracy: 0.9657 - val_loss: 0.1503 - val_accuracy: 0.9435\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0880 - accuracy: 0.9657 - val_loss: 0.1531 - val_accuracy: 0.9428\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0895 - accuracy: 0.9627 - val_loss: 0.1902 - val_accuracy: 0.9284\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.0949 - accuracy: 0.9631 - val_loss: 0.1421 - val_accuracy: 0.9414\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.0840 - accuracy: 0.9666 - val_loss: 0.1419 - val_accuracy: 0.9481\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0871 - accuracy: 0.9654 - val_loss: 0.1310 - val_accuracy: 0.9526\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0959 - accuracy: 0.9620 - val_loss: 0.1326 - val_accuracy: 0.9474\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0958 - accuracy: 0.9621 - val_loss: 0.1311 - val_accuracy: 0.9502\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0768 - accuracy: 0.9697 - val_loss: 0.1354 - val_accuracy: 0.9477\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0752 - accuracy: 0.9711 - val_loss: 0.1428 - val_accuracy: 0.9512\n",
      "Epoch 92/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0787 - accuracy: 0.9699 - val_loss: 0.1199 - val_accuracy: 0.9533\n",
      "Epoch 93/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0704 - accuracy: 0.9733 - val_loss: 0.1402 - val_accuracy: 0.9523\n",
      "Epoch 94/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0673 - accuracy: 0.9729 - val_loss: 0.1319 - val_accuracy: 0.9526\n",
      "Epoch 95/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0692 - accuracy: 0.9732 - val_loss: 0.1343 - val_accuracy: 0.9551\n",
      "Epoch 96/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0716 - accuracy: 0.9726 - val_loss: 0.1212 - val_accuracy: 0.9593\n",
      "Epoch 97/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.0752 - accuracy: 0.9714 - val_loss: 0.1123 - val_accuracy: 0.9586\n",
      "Epoch 98/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0654 - accuracy: 0.9754 - val_loss: 0.1493 - val_accuracy: 0.9460\n",
      "Epoch 99/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0679 - accuracy: 0.9741 - val_loss: 0.1266 - val_accuracy: 0.9551\n",
      "Epoch 100/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0682 - accuracy: 0.9747 - val_loss: 0.1398 - val_accuracy: 0.9530\n",
      "Epoch 101/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0645 - accuracy: 0.9747 - val_loss: 0.1310 - val_accuracy: 0.9575\n",
      "Epoch 102/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1217 - accuracy: 0.9510 - val_loss: 0.1304 - val_accuracy: 0.9509\n",
      "Epoch 103/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0637 - accuracy: 0.9751 - val_loss: 0.1673 - val_accuracy: 0.9368\n",
      "Epoch 104/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0622 - accuracy: 0.9769 - val_loss: 0.1337 - val_accuracy: 0.9516\n",
      "Epoch 105/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0612 - accuracy: 0.9763 - val_loss: 0.1081 - val_accuracy: 0.9575\n",
      "Epoch 106/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0699 - accuracy: 0.9743 - val_loss: 0.1240 - val_accuracy: 0.9554\n",
      "Epoch 107/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0493 - accuracy: 0.9812 - val_loss: 0.1340 - val_accuracy: 0.9516\n",
      "Epoch 108/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0566 - accuracy: 0.9789 - val_loss: 0.1186 - val_accuracy: 0.9575\n",
      "Epoch 109/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0626 - accuracy: 0.9774 - val_loss: 0.1440 - val_accuracy: 0.9533\n",
      "Epoch 110/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0533 - accuracy: 0.9794 - val_loss: 0.1077 - val_accuracy: 0.9667\n",
      "Epoch 111/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0458 - accuracy: 0.9832 - val_loss: 0.1485 - val_accuracy: 0.9484\n",
      "Epoch 112/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0464 - accuracy: 0.9824 - val_loss: 0.1134 - val_accuracy: 0.9628\n",
      "Epoch 113/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.0564 - accuracy: 0.9789 - val_loss: 0.1099 - val_accuracy: 0.9621\n",
      "Epoch 114/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.0484 - accuracy: 0.9823 - val_loss: 0.1151 - val_accuracy: 0.9575\n",
      "Epoch 115/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.0494 - accuracy: 0.9823 - val_loss: 0.1447 - val_accuracy: 0.9484\n",
      "Epoch 116/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0508 - accuracy: 0.9807 - val_loss: 0.1182 - val_accuracy: 0.9593\n",
      "Epoch 117/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0437 - accuracy: 0.9837 - val_loss: 0.1147 - val_accuracy: 0.9607\n",
      "Epoch 118/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0596 - accuracy: 0.9783 - val_loss: 0.1198 - val_accuracy: 0.9582\n",
      "Epoch 119/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0416 - accuracy: 0.9850 - val_loss: 0.1172 - val_accuracy: 0.9667\n",
      "Epoch 120/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0476 - accuracy: 0.9829 - val_loss: 0.1223 - val_accuracy: 0.9561\n",
      "Epoch 121/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0602 - accuracy: 0.9791 - val_loss: 0.1172 - val_accuracy: 0.9561\n",
      "Epoch 122/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0430 - accuracy: 0.9842 - val_loss: 0.0981 - val_accuracy: 0.9656\n",
      "Epoch 123/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0411 - accuracy: 0.9855 - val_loss: 0.0953 - val_accuracy: 0.9667\n",
      "Epoch 124/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0413 - accuracy: 0.9857 - val_loss: 0.1625 - val_accuracy: 0.9453\n",
      "Epoch 125/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0543 - accuracy: 0.9803 - val_loss: 0.1807 - val_accuracy: 0.9372\n",
      "Epoch 126/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.0448 - accuracy: 0.9840 - val_loss: 0.2601 - val_accuracy: 0.9267\n",
      "Epoch 127/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0408 - accuracy: 0.9849 - val_loss: 0.1458 - val_accuracy: 0.9498\n",
      "Epoch 128/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0483 - accuracy: 0.9822 - val_loss: 0.1161 - val_accuracy: 0.9575\n",
      "Epoch 129/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0439 - accuracy: 0.9842 - val_loss: 0.1256 - val_accuracy: 0.9544\n",
      "Epoch 130/500\n",
      "332/334 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 0.9831Restoring model weights from the end of the best epoch: 110.\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0481 - accuracy: 0.9829 - val_loss: 0.1412 - val_accuracy: 0.9554\n",
      "Epoch 130: early stopping\n",
      "Number of iterations 7\n",
      "F1-scores:  [0.939744370054778, 0.9323493234932348, 0.9285277947464875, 0.9536019536019537, 0.8907664453832227, 0.9274145170965806, 0.9425981873111783]\n",
      "Average F1-Score 0.930714655955348\n",
      "Std Dev F1-Score 0.0183645131088467\n",
      "Error bar F1-Score 0.0069411335192562885\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 11s 19ms/step - loss: 0.5458 - accuracy: 0.7113 - val_loss: 0.5220 - val_accuracy: 0.7137\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.5141 - accuracy: 0.7145 - val_loss: 0.5127 - val_accuracy: 0.7084\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.4836 - accuracy: 0.7333 - val_loss: 0.4443 - val_accuracy: 0.7779\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.3957 - accuracy: 0.8024 - val_loss: 0.3589 - val_accuracy: 0.8189\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3555 - accuracy: 0.8296 - val_loss: 0.3567 - val_accuracy: 0.8372\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 5s 14ms/step - loss: 0.3382 - accuracy: 0.8409 - val_loss: 0.3101 - val_accuracy: 0.8635\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3163 - accuracy: 0.8546 - val_loss: 0.2877 - val_accuracy: 0.8698\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3039 - accuracy: 0.8593 - val_loss: 0.2922 - val_accuracy: 0.8709\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2863 - accuracy: 0.8694 - val_loss: 0.3235 - val_accuracy: 0.8481\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2762 - accuracy: 0.8738 - val_loss: 0.2541 - val_accuracy: 0.8821\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2672 - accuracy: 0.8795 - val_loss: 0.2419 - val_accuracy: 0.8944\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2575 - accuracy: 0.8852 - val_loss: 0.2812 - val_accuracy: 0.8768\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2535 - accuracy: 0.8877 - val_loss: 0.2434 - val_accuracy: 0.8846\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2443 - accuracy: 0.8907 - val_loss: 0.2448 - val_accuracy: 0.8905\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2382 - accuracy: 0.8938 - val_loss: 0.2264 - val_accuracy: 0.8965\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2357 - accuracy: 0.8940 - val_loss: 0.2204 - val_accuracy: 0.9021\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2359 - accuracy: 0.8936 - val_loss: 0.2840 - val_accuracy: 0.8719\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2317 - accuracy: 0.8951 - val_loss: 0.2161 - val_accuracy: 0.9032\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2292 - accuracy: 0.8975 - val_loss: 0.2262 - val_accuracy: 0.8940\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2267 - accuracy: 0.8983 - val_loss: 0.2530 - val_accuracy: 0.8818\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2198 - accuracy: 0.9022 - val_loss: 0.2414 - val_accuracy: 0.8867\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2194 - accuracy: 0.9023 - val_loss: 0.2084 - val_accuracy: 0.9004\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2116 - accuracy: 0.9073 - val_loss: 0.2089 - val_accuracy: 0.9056\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2072 - accuracy: 0.9080 - val_loss: 0.2136 - val_accuracy: 0.9049\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2079 - accuracy: 0.9074 - val_loss: 0.1997 - val_accuracy: 0.9102\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2135 - accuracy: 0.9062 - val_loss: 0.2229 - val_accuracy: 0.8933\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2008 - accuracy: 0.9108 - val_loss: 0.2129 - val_accuracy: 0.9056\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1976 - accuracy: 0.9134 - val_loss: 0.2030 - val_accuracy: 0.9046\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1920 - accuracy: 0.9158 - val_loss: 0.2526 - val_accuracy: 0.8874\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1932 - accuracy: 0.9157 - val_loss: 0.1967 - val_accuracy: 0.9102\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.1932 - accuracy: 0.9170 - val_loss: 0.2020 - val_accuracy: 0.9053\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.1868 - accuracy: 0.9179 - val_loss: 0.1804 - val_accuracy: 0.9140\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1842 - accuracy: 0.9199 - val_loss: 0.2635 - val_accuracy: 0.8996\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1861 - accuracy: 0.9183 - val_loss: 0.1742 - val_accuracy: 0.9225\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.1849 - accuracy: 0.9184 - val_loss: 0.1885 - val_accuracy: 0.9218\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1729 - accuracy: 0.9249 - val_loss: 0.1900 - val_accuracy: 0.9123\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1778 - accuracy: 0.9233 - val_loss: 0.1727 - val_accuracy: 0.9242\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1694 - accuracy: 0.9270 - val_loss: 0.1767 - val_accuracy: 0.9186\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1644 - accuracy: 0.9298 - val_loss: 0.1762 - val_accuracy: 0.9218\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1705 - accuracy: 0.9274 - val_loss: 0.1794 - val_accuracy: 0.9168\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1681 - accuracy: 0.9281 - val_loss: 0.2401 - val_accuracy: 0.8954\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1628 - accuracy: 0.9295 - val_loss: 0.1953 - val_accuracy: 0.9158\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1619 - accuracy: 0.9311 - val_loss: 0.1833 - val_accuracy: 0.9186\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1502 - accuracy: 0.9370 - val_loss: 0.1922 - val_accuracy: 0.9218\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1516 - accuracy: 0.9358 - val_loss: 0.1688 - val_accuracy: 0.9312\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1517 - accuracy: 0.9354 - val_loss: 0.1596 - val_accuracy: 0.9337\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1483 - accuracy: 0.9380 - val_loss: 0.1577 - val_accuracy: 0.9323\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1384 - accuracy: 0.9423 - val_loss: 0.1394 - val_accuracy: 0.9453\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1411 - accuracy: 0.9392 - val_loss: 0.2000 - val_accuracy: 0.9151\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1290 - accuracy: 0.9467 - val_loss: 0.1553 - val_accuracy: 0.9361\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1347 - accuracy: 0.9446 - val_loss: 0.1366 - val_accuracy: 0.9442\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1226 - accuracy: 0.9483 - val_loss: 0.1449 - val_accuracy: 0.9375\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1261 - accuracy: 0.9495 - val_loss: 0.2252 - val_accuracy: 0.9200\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1273 - accuracy: 0.9470 - val_loss: 0.1243 - val_accuracy: 0.9488\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1111 - accuracy: 0.9548 - val_loss: 0.1377 - val_accuracy: 0.9474\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1196 - accuracy: 0.9511 - val_loss: 0.1429 - val_accuracy: 0.9386\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1261 - accuracy: 0.9484 - val_loss: 0.1242 - val_accuracy: 0.9502\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1134 - accuracy: 0.9542 - val_loss: 0.3312 - val_accuracy: 0.8765\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1262 - accuracy: 0.9476 - val_loss: 0.1391 - val_accuracy: 0.9400\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.1243 - accuracy: 0.9485 - val_loss: 0.1448 - val_accuracy: 0.9365\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.1100 - accuracy: 0.9554 - val_loss: 0.1350 - val_accuracy: 0.9449\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0940 - accuracy: 0.9636 - val_loss: 0.1182 - val_accuracy: 0.9495\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0966 - accuracy: 0.9624 - val_loss: 0.1247 - val_accuracy: 0.9484\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1078 - accuracy: 0.9565 - val_loss: 0.1402 - val_accuracy: 0.9414\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0907 - accuracy: 0.9644 - val_loss: 0.1101 - val_accuracy: 0.9568\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0871 - accuracy: 0.9664 - val_loss: 0.1066 - val_accuracy: 0.9614\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0953 - accuracy: 0.9632 - val_loss: 0.1159 - val_accuracy: 0.9526\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0913 - accuracy: 0.9641 - val_loss: 0.1072 - val_accuracy: 0.9565\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0800 - accuracy: 0.9689 - val_loss: 0.1012 - val_accuracy: 0.9618\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1030 - accuracy: 0.9593 - val_loss: 0.1384 - val_accuracy: 0.9446\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0871 - accuracy: 0.9649 - val_loss: 0.1376 - val_accuracy: 0.9474\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0930 - accuracy: 0.9629 - val_loss: 0.1259 - val_accuracy: 0.9498\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0894 - accuracy: 0.9654 - val_loss: 0.1099 - val_accuracy: 0.9568\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.0770 - accuracy: 0.9698 - val_loss: 0.1306 - val_accuracy: 0.9467\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0759 - accuracy: 0.9702 - val_loss: 0.1014 - val_accuracy: 0.9600\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0899 - accuracy: 0.9647 - val_loss: 0.1348 - val_accuracy: 0.9463\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0799 - accuracy: 0.9701 - val_loss: 0.1336 - val_accuracy: 0.9463\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0820 - accuracy: 0.9672 - val_loss: 0.0941 - val_accuracy: 0.9621\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0631 - accuracy: 0.9766 - val_loss: 0.0953 - val_accuracy: 0.9635\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0754 - accuracy: 0.9711 - val_loss: 0.1600 - val_accuracy: 0.9386\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0718 - accuracy: 0.9732 - val_loss: 0.0976 - val_accuracy: 0.9642\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0762 - accuracy: 0.9708 - val_loss: 0.2449 - val_accuracy: 0.9004\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0758 - accuracy: 0.9704 - val_loss: 0.0985 - val_accuracy: 0.9632\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0683 - accuracy: 0.9732 - val_loss: 0.1775 - val_accuracy: 0.9389\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0585 - accuracy: 0.9781 - val_loss: 0.1447 - val_accuracy: 0.9449\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0781 - accuracy: 0.9707 - val_loss: 0.1291 - val_accuracy: 0.9509\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.0614 - accuracy: 0.9764 - val_loss: 0.1157 - val_accuracy: 0.9565\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.0670 - accuracy: 0.9743 - val_loss: 0.1068 - val_accuracy: 0.9575\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0618 - accuracy: 0.9764 - val_loss: 0.1031 - val_accuracy: 0.9621\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0591 - accuracy: 0.9792 - val_loss: 0.1175 - val_accuracy: 0.9572\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0541 - accuracy: 0.9806 - val_loss: 0.1372 - val_accuracy: 0.9488\n",
      "Epoch 92/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0808 - accuracy: 0.9705 - val_loss: 0.1208 - val_accuracy: 0.9530\n",
      "Epoch 93/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0688 - accuracy: 0.9743 - val_loss: 0.1038 - val_accuracy: 0.9625\n",
      "Epoch 94/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0460 - accuracy: 0.9828 - val_loss: 0.1017 - val_accuracy: 0.9628\n",
      "Epoch 95/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0619 - accuracy: 0.9765 - val_loss: 0.1361 - val_accuracy: 0.9495\n",
      "Epoch 96/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0601 - accuracy: 0.9780 - val_loss: 0.0991 - val_accuracy: 0.9639\n",
      "Epoch 97/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0637 - accuracy: 0.9765 - val_loss: 0.1347 - val_accuracy: 0.9523\n",
      "Epoch 98/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0580 - accuracy: 0.9787 - val_loss: 0.1241 - val_accuracy: 0.9568\n",
      "Epoch 99/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0569 - accuracy: 0.9791 - val_loss: 0.2047 - val_accuracy: 0.9281\n",
      "Epoch 100/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.1171 - val_accuracy: 0.9589\n",
      "Epoch 101/500\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9820Restoring model weights from the end of the best epoch: 81.\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0487 - accuracy: 0.9820 - val_loss: 0.1243 - val_accuracy: 0.9512\n",
      "Epoch 101: early stopping\n",
      "Number of iterations 8\n",
      "F1-scores:  [0.939744370054778, 0.9323493234932348, 0.9285277947464875, 0.9536019536019537, 0.8907664453832227, 0.9274145170965806, 0.9425981873111783, 0.9392857142857143]\n",
      "Average F1-Score 0.9317860382466437\n",
      "Std Dev F1-Score 0.01741072784544324\n",
      "Error bar F1-Score 0.006155621862453181\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 13s 22ms/step - loss: 0.5506 - accuracy: 0.7141 - val_loss: 0.5087 - val_accuracy: 0.7137\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.5126 - accuracy: 0.7160 - val_loss: 0.4729 - val_accuracy: 0.7526\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.4049 - accuracy: 0.7914 - val_loss: 0.3582 - val_accuracy: 0.8189\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3660 - accuracy: 0.8217 - val_loss: 0.3409 - val_accuracy: 0.8407\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3489 - accuracy: 0.8319 - val_loss: 0.3366 - val_accuracy: 0.8407\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3324 - accuracy: 0.8443 - val_loss: 0.3163 - val_accuracy: 0.8554\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3309 - accuracy: 0.8436 - val_loss: 0.3189 - val_accuracy: 0.8509\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3182 - accuracy: 0.8527 - val_loss: 0.3059 - val_accuracy: 0.8618\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3145 - accuracy: 0.8559 - val_loss: 0.3037 - val_accuracy: 0.8604\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3018 - accuracy: 0.8613 - val_loss: 0.2897 - val_accuracy: 0.8628\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2975 - accuracy: 0.8630 - val_loss: 0.3315 - val_accuracy: 0.8425\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3084 - accuracy: 0.8568 - val_loss: 0.2981 - val_accuracy: 0.8625\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2846 - accuracy: 0.8699 - val_loss: 0.2755 - val_accuracy: 0.8723\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2837 - accuracy: 0.8704 - val_loss: 0.2648 - val_accuracy: 0.8744\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2669 - accuracy: 0.8758 - val_loss: 0.2808 - val_accuracy: 0.8737\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2670 - accuracy: 0.8774 - val_loss: 0.2862 - val_accuracy: 0.8642\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2590 - accuracy: 0.8822 - val_loss: 0.2609 - val_accuracy: 0.8796\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2657 - accuracy: 0.8783 - val_loss: 0.3692 - val_accuracy: 0.8154\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2502 - accuracy: 0.8876 - val_loss: 0.2376 - val_accuracy: 0.8888\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2407 - accuracy: 0.8916 - val_loss: 0.2260 - val_accuracy: 0.8954\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2374 - accuracy: 0.8937 - val_loss: 0.2405 - val_accuracy: 0.8867\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2398 - accuracy: 0.8918 - val_loss: 0.2254 - val_accuracy: 0.8944\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2301 - accuracy: 0.8970 - val_loss: 0.2351 - val_accuracy: 0.8898\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2347 - accuracy: 0.8938 - val_loss: 0.2216 - val_accuracy: 0.8940\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2323 - accuracy: 0.8961 - val_loss: 0.2127 - val_accuracy: 0.9035\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2132 - accuracy: 0.9054 - val_loss: 0.2775 - val_accuracy: 0.8730\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2191 - accuracy: 0.9019 - val_loss: 0.2064 - val_accuracy: 0.9109\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.2149 - accuracy: 0.9037 - val_loss: 0.2089 - val_accuracy: 0.9046\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.2117 - accuracy: 0.9075 - val_loss: 0.2026 - val_accuracy: 0.9102\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2052 - accuracy: 0.9104 - val_loss: 0.1986 - val_accuracy: 0.9109\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1976 - accuracy: 0.9131 - val_loss: 0.1894 - val_accuracy: 0.9182\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1994 - accuracy: 0.9144 - val_loss: 0.2021 - val_accuracy: 0.9091\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1944 - accuracy: 0.9158 - val_loss: 0.2416 - val_accuracy: 0.8916\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1887 - accuracy: 0.9168 - val_loss: 0.2692 - val_accuracy: 0.8867\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1930 - accuracy: 0.9148 - val_loss: 0.2062 - val_accuracy: 0.9081\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.1866 - accuracy: 0.9201 - val_loss: 0.1987 - val_accuracy: 0.9095\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.1829 - accuracy: 0.9212 - val_loss: 0.1798 - val_accuracy: 0.9193\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1875 - accuracy: 0.9181 - val_loss: 0.1924 - val_accuracy: 0.9161\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1851 - accuracy: 0.9199 - val_loss: 0.1881 - val_accuracy: 0.9161\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1788 - accuracy: 0.9234 - val_loss: 0.1931 - val_accuracy: 0.9126\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1736 - accuracy: 0.9254 - val_loss: 0.2012 - val_accuracy: 0.9081\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1719 - accuracy: 0.9248 - val_loss: 0.1868 - val_accuracy: 0.9207\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1702 - accuracy: 0.9265 - val_loss: 0.1894 - val_accuracy: 0.9179\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1662 - accuracy: 0.9302 - val_loss: 0.1748 - val_accuracy: 0.9263\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1573 - accuracy: 0.9328 - val_loss: 0.2355 - val_accuracy: 0.9046\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1626 - accuracy: 0.9301 - val_loss: 0.1769 - val_accuracy: 0.9246\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1685 - accuracy: 0.9290 - val_loss: 0.1940 - val_accuracy: 0.9144\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1620 - accuracy: 0.9313 - val_loss: 0.1920 - val_accuracy: 0.9172\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1531 - accuracy: 0.9349 - val_loss: 0.1697 - val_accuracy: 0.9263\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1515 - accuracy: 0.9363 - val_loss: 0.1811 - val_accuracy: 0.9200\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1563 - accuracy: 0.9345 - val_loss: 0.2142 - val_accuracy: 0.9165\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1477 - accuracy: 0.9377 - val_loss: 0.3917 - val_accuracy: 0.8509\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1504 - accuracy: 0.9368 - val_loss: 0.1868 - val_accuracy: 0.9256\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1390 - accuracy: 0.9431 - val_loss: 0.1801 - val_accuracy: 0.9182\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.1456 - accuracy: 0.9399 - val_loss: 0.1736 - val_accuracy: 0.9288\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.1379 - accuracy: 0.9435 - val_loss: 0.1995 - val_accuracy: 0.9214\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.1354 - accuracy: 0.9428 - val_loss: 0.2331 - val_accuracy: 0.9032\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1351 - accuracy: 0.9439 - val_loss: 0.1450 - val_accuracy: 0.9411\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1397 - accuracy: 0.9432 - val_loss: 0.2061 - val_accuracy: 0.9193\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1302 - accuracy: 0.9457 - val_loss: 0.1785 - val_accuracy: 0.9347\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1230 - accuracy: 0.9489 - val_loss: 0.1764 - val_accuracy: 0.9319\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1199 - accuracy: 0.9514 - val_loss: 0.1964 - val_accuracy: 0.9242\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1276 - accuracy: 0.9475 - val_loss: 0.1415 - val_accuracy: 0.9432\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1248 - accuracy: 0.9487 - val_loss: 0.1589 - val_accuracy: 0.9358\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1191 - accuracy: 0.9510 - val_loss: 0.1871 - val_accuracy: 0.9284\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1203 - accuracy: 0.9507 - val_loss: 0.1562 - val_accuracy: 0.9379\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1215 - accuracy: 0.9508 - val_loss: 0.1769 - val_accuracy: 0.9242\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1122 - accuracy: 0.9549 - val_loss: 0.1616 - val_accuracy: 0.9312\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1116 - accuracy: 0.9538 - val_loss: 0.1428 - val_accuracy: 0.9460\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1159 - accuracy: 0.9534 - val_loss: 0.1528 - val_accuracy: 0.9418\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1028 - accuracy: 0.9591 - val_loss: 0.1486 - val_accuracy: 0.9411\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1109 - accuracy: 0.9565 - val_loss: 0.1785 - val_accuracy: 0.9235\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.1100 - accuracy: 0.9557 - val_loss: 0.1550 - val_accuracy: 0.9386\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1091 - accuracy: 0.9564 - val_loss: 0.1313 - val_accuracy: 0.9498\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0979 - accuracy: 0.9600 - val_loss: 0.1466 - val_accuracy: 0.9418\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1008 - accuracy: 0.9602 - val_loss: 0.1767 - val_accuracy: 0.9295\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0926 - accuracy: 0.9636 - val_loss: 0.1670 - val_accuracy: 0.9379\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0989 - accuracy: 0.9606 - val_loss: 0.1560 - val_accuracy: 0.9375\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0926 - accuracy: 0.9628 - val_loss: 0.1463 - val_accuracy: 0.9477\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0972 - accuracy: 0.9617 - val_loss: 0.1510 - val_accuracy: 0.9428\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0881 - accuracy: 0.9650 - val_loss: 0.1521 - val_accuracy: 0.9484\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.0849 - accuracy: 0.9670 - val_loss: 0.1229 - val_accuracy: 0.9537\n",
      "Epoch 83/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.0797 - accuracy: 0.9695 - val_loss: 0.1256 - val_accuracy: 0.9505\n",
      "Epoch 84/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0836 - accuracy: 0.9680 - val_loss: 0.1280 - val_accuracy: 0.9516\n",
      "Epoch 85/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0795 - accuracy: 0.9685 - val_loss: 0.1620 - val_accuracy: 0.9435\n",
      "Epoch 86/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0759 - accuracy: 0.9715 - val_loss: 0.1341 - val_accuracy: 0.9502\n",
      "Epoch 87/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0816 - accuracy: 0.9688 - val_loss: 0.1947 - val_accuracy: 0.9330\n",
      "Epoch 88/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0747 - accuracy: 0.9708 - val_loss: 0.1340 - val_accuracy: 0.9488\n",
      "Epoch 89/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0729 - accuracy: 0.9725 - val_loss: 0.1322 - val_accuracy: 0.9502\n",
      "Epoch 90/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0692 - accuracy: 0.9721 - val_loss: 0.1422 - val_accuracy: 0.9495\n",
      "Epoch 91/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0757 - accuracy: 0.9710 - val_loss: 0.1377 - val_accuracy: 0.9544\n",
      "Epoch 92/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0732 - accuracy: 0.9708 - val_loss: 0.1653 - val_accuracy: 0.9432\n",
      "Epoch 93/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0653 - accuracy: 0.9753 - val_loss: 0.1332 - val_accuracy: 0.9512\n",
      "Epoch 94/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0697 - accuracy: 0.9727 - val_loss: 0.1286 - val_accuracy: 0.9519\n",
      "Epoch 95/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0650 - accuracy: 0.9763 - val_loss: 0.1242 - val_accuracy: 0.9572\n",
      "Epoch 96/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0703 - accuracy: 0.9723 - val_loss: 0.2258 - val_accuracy: 0.9186\n",
      "Epoch 97/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0656 - accuracy: 0.9752 - val_loss: 0.1179 - val_accuracy: 0.9565\n",
      "Epoch 98/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0629 - accuracy: 0.9762 - val_loss: 0.1291 - val_accuracy: 0.9565\n",
      "Epoch 99/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0686 - accuracy: 0.9736 - val_loss: 0.1304 - val_accuracy: 0.9596\n",
      "Epoch 100/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0724 - accuracy: 0.9724 - val_loss: 0.1796 - val_accuracy: 0.9396\n",
      "Epoch 101/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0772 - accuracy: 0.9706 - val_loss: 0.1357 - val_accuracy: 0.9533\n",
      "Epoch 102/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0524 - accuracy: 0.9806 - val_loss: 0.1306 - val_accuracy: 0.9537\n",
      "Epoch 103/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0718 - accuracy: 0.9730 - val_loss: 0.1149 - val_accuracy: 0.9600\n",
      "Epoch 104/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0631 - accuracy: 0.9766 - val_loss: 0.1741 - val_accuracy: 0.9368\n",
      "Epoch 105/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0824 - accuracy: 0.9685 - val_loss: 0.1411 - val_accuracy: 0.9579\n",
      "Epoch 106/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0454 - accuracy: 0.9838 - val_loss: 0.1411 - val_accuracy: 0.9495\n",
      "Epoch 107/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0597 - accuracy: 0.9786 - val_loss: 0.1331 - val_accuracy: 0.9561\n",
      "Epoch 108/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.0533 - accuracy: 0.9798 - val_loss: 0.1201 - val_accuracy: 0.9625\n",
      "Epoch 109/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.0701 - accuracy: 0.9748 - val_loss: 0.1304 - val_accuracy: 0.9537\n",
      "Epoch 110/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.0439 - accuracy: 0.9837 - val_loss: 0.1163 - val_accuracy: 0.9596\n",
      "Epoch 111/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0617 - accuracy: 0.9784 - val_loss: 0.1925 - val_accuracy: 0.9330\n",
      "Epoch 112/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0479 - accuracy: 0.9824 - val_loss: 0.1337 - val_accuracy: 0.9554\n",
      "Epoch 113/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0602 - accuracy: 0.9777 - val_loss: 0.1109 - val_accuracy: 0.9632\n",
      "Epoch 114/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0443 - accuracy: 0.9835 - val_loss: 0.1285 - val_accuracy: 0.9572\n",
      "Epoch 115/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0493 - accuracy: 0.9820 - val_loss: 0.1354 - val_accuracy: 0.9568\n",
      "Epoch 116/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0661 - accuracy: 0.9758 - val_loss: 0.1231 - val_accuracy: 0.9611\n",
      "Epoch 117/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0457 - accuracy: 0.9830 - val_loss: 0.1300 - val_accuracy: 0.9579\n",
      "Epoch 118/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2158 - accuracy: 0.9082 - val_loss: 0.1777 - val_accuracy: 0.9263\n",
      "Epoch 119/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1208 - accuracy: 0.9501 - val_loss: 0.1918 - val_accuracy: 0.9225\n",
      "Epoch 120/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0777 - accuracy: 0.9693 - val_loss: 0.1444 - val_accuracy: 0.9498\n",
      "Epoch 121/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0526 - accuracy: 0.9804 - val_loss: 0.1316 - val_accuracy: 0.9568\n",
      "Epoch 122/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0538 - accuracy: 0.9803 - val_loss: 0.2455 - val_accuracy: 0.9291\n",
      "Epoch 123/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0451 - accuracy: 0.9836 - val_loss: 0.1456 - val_accuracy: 0.9512\n",
      "Epoch 124/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0467 - accuracy: 0.9838 - val_loss: 0.1221 - val_accuracy: 0.9589\n",
      "Epoch 125/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0505 - accuracy: 0.9804 - val_loss: 0.1684 - val_accuracy: 0.9470\n",
      "Epoch 126/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0465 - accuracy: 0.9831 - val_loss: 0.1340 - val_accuracy: 0.9554\n",
      "Epoch 127/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0514 - accuracy: 0.9814 - val_loss: 0.1059 - val_accuracy: 0.9653\n",
      "Epoch 128/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0454 - accuracy: 0.9844 - val_loss: 0.1178 - val_accuracy: 0.9596\n",
      "Epoch 129/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0405 - accuracy: 0.9854 - val_loss: 0.1381 - val_accuracy: 0.9523\n",
      "Epoch 130/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0346 - accuracy: 0.9871 - val_loss: 0.1386 - val_accuracy: 0.9572\n",
      "Epoch 131/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1654 - accuracy: 0.9315 - val_loss: 0.1858 - val_accuracy: 0.9344\n",
      "Epoch 132/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0766 - accuracy: 0.9698 - val_loss: 0.1508 - val_accuracy: 0.9442\n",
      "Epoch 133/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0416 - accuracy: 0.9839 - val_loss: 0.1309 - val_accuracy: 0.9582\n",
      "Epoch 134/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0601 - accuracy: 0.9776 - val_loss: 0.2182 - val_accuracy: 0.9246\n",
      "Epoch 135/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0364 - accuracy: 0.9871 - val_loss: 0.1457 - val_accuracy: 0.9551\n",
      "Epoch 136/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0439 - accuracy: 0.9834 - val_loss: 0.1572 - val_accuracy: 0.9498\n",
      "Epoch 137/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.0315 - accuracy: 0.9891 - val_loss: 0.1330 - val_accuracy: 0.9540\n",
      "Epoch 138/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.0365 - accuracy: 0.9875 - val_loss: 0.1591 - val_accuracy: 0.9512\n",
      "Epoch 139/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0526 - accuracy: 0.9798 - val_loss: 0.1422 - val_accuracy: 0.9551\n",
      "Epoch 140/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0444 - accuracy: 0.9841 - val_loss: 0.1515 - val_accuracy: 0.9512\n",
      "Epoch 141/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0349 - accuracy: 0.9875 - val_loss: 0.1315 - val_accuracy: 0.9568\n",
      "Epoch 142/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0359 - accuracy: 0.9875 - val_loss: 0.1098 - val_accuracy: 0.9653\n",
      "Epoch 143/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0327 - accuracy: 0.9887 - val_loss: 0.0993 - val_accuracy: 0.9674\n",
      "Epoch 144/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0426 - accuracy: 0.9838 - val_loss: 0.1114 - val_accuracy: 0.9628\n",
      "Epoch 145/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0359 - accuracy: 0.9868 - val_loss: 0.1199 - val_accuracy: 0.9635\n",
      "Epoch 146/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0440 - accuracy: 0.9851 - val_loss: 0.1375 - val_accuracy: 0.9565\n",
      "Epoch 147/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0324 - accuracy: 0.9886 - val_loss: 0.1794 - val_accuracy: 0.9484\n",
      "Epoch 148/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0417 - accuracy: 0.9843 - val_loss: 0.1336 - val_accuracy: 0.9600\n",
      "Epoch 149/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.0426 - accuracy: 0.9848 - val_loss: 0.1554 - val_accuracy: 0.9460\n",
      "Epoch 150/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.1675 - val_accuracy: 0.9512\n",
      "Epoch 151/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0526 - accuracy: 0.9817 - val_loss: 0.1535 - val_accuracy: 0.9530\n",
      "Epoch 152/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0336 - accuracy: 0.9881 - val_loss: 0.2200 - val_accuracy: 0.9361\n",
      "Epoch 153/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0260 - accuracy: 0.9907 - val_loss: 0.1444 - val_accuracy: 0.9579\n",
      "Epoch 154/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0486 - accuracy: 0.9826 - val_loss: 0.1575 - val_accuracy: 0.9540\n",
      "Epoch 155/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0335 - accuracy: 0.9876 - val_loss: 0.1185 - val_accuracy: 0.9621\n",
      "Epoch 156/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0263 - accuracy: 0.9909 - val_loss: 0.1741 - val_accuracy: 0.9533\n",
      "Epoch 157/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0547 - accuracy: 0.9792 - val_loss: 0.1059 - val_accuracy: 0.9649\n",
      "Epoch 158/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0677 - accuracy: 0.9756 - val_loss: 0.1220 - val_accuracy: 0.9579\n",
      "Epoch 159/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.1414 - val_accuracy: 0.9593\n",
      "Epoch 160/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0219 - accuracy: 0.9930 - val_loss: 0.1354 - val_accuracy: 0.9582\n",
      "Epoch 161/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0396 - accuracy: 0.9849 - val_loss: 0.1159 - val_accuracy: 0.9649\n",
      "Epoch 162/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.0326 - accuracy: 0.9890 - val_loss: 0.1480 - val_accuracy: 0.9565\n",
      "Epoch 163/500\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9906Restoring model weights from the end of the best epoch: 143.\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.0257 - accuracy: 0.9906 - val_loss: 0.1538 - val_accuracy: 0.9551\n",
      "Epoch 163: early stopping\n",
      "Number of iterations 9\n",
      "F1-scores:  [0.939744370054778, 0.9323493234932348, 0.9285277947464875, 0.9536019536019537, 0.8907664453832227, 0.9274145170965806, 0.9425981873111783, 0.9392857142857143, 0.9435336976320582]\n",
      "Average F1-Score 0.9330913337339121\n",
      "Std Dev F1-Score 0.016825050394901286\n",
      "Error bar F1-Score 0.005608350131633762\n",
      "Epoch 1/500\n",
      "334/334 [==============================] - 11s 19ms/step - loss: 0.5543 - accuracy: 0.7112 - val_loss: 0.5276 - val_accuracy: 0.7137\n",
      "Epoch 2/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.5158 - accuracy: 0.7187 - val_loss: 0.5024 - val_accuracy: 0.7481\n",
      "Epoch 3/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.5107 - accuracy: 0.7235 - val_loss: 0.4960 - val_accuracy: 0.7442\n",
      "Epoch 4/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.4921 - accuracy: 0.7242 - val_loss: 0.4652 - val_accuracy: 0.7407\n",
      "Epoch 5/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.4895 - accuracy: 0.7260 - val_loss: 0.4941 - val_accuracy: 0.6947\n",
      "Epoch 6/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.4656 - accuracy: 0.7415 - val_loss: 0.4549 - val_accuracy: 0.7312\n",
      "Epoch 7/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.4399 - accuracy: 0.7546 - val_loss: 0.4210 - val_accuracy: 0.7533\n",
      "Epoch 8/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.4134 - accuracy: 0.7766 - val_loss: 0.4047 - val_accuracy: 0.7965\n",
      "Epoch 9/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3789 - accuracy: 0.8138 - val_loss: 0.4157 - val_accuracy: 0.7818\n",
      "Epoch 10/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3653 - accuracy: 0.8219 - val_loss: 0.3944 - val_accuracy: 0.8119\n",
      "Epoch 11/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3537 - accuracy: 0.8303 - val_loss: 0.3440 - val_accuracy: 0.8400\n",
      "Epoch 12/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3561 - accuracy: 0.8305 - val_loss: 0.3568 - val_accuracy: 0.8277\n",
      "Epoch 13/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.3495 - accuracy: 0.8338 - val_loss: 0.3485 - val_accuracy: 0.8267\n",
      "Epoch 14/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.3439 - accuracy: 0.8353 - val_loss: 0.3481 - val_accuracy: 0.8404\n",
      "Epoch 15/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3393 - accuracy: 0.8379 - val_loss: 0.3288 - val_accuracy: 0.8488\n",
      "Epoch 16/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3384 - accuracy: 0.8394 - val_loss: 0.3199 - val_accuracy: 0.8463\n",
      "Epoch 17/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3286 - accuracy: 0.8463 - val_loss: 0.3652 - val_accuracy: 0.8312\n",
      "Epoch 18/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3179 - accuracy: 0.8530 - val_loss: 0.3145 - val_accuracy: 0.8540\n",
      "Epoch 19/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.3253 - accuracy: 0.8463 - val_loss: 0.2992 - val_accuracy: 0.8653\n",
      "Epoch 20/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.3118 - accuracy: 0.8581 - val_loss: 0.3001 - val_accuracy: 0.8582\n",
      "Epoch 21/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.3078 - accuracy: 0.8583 - val_loss: 0.2945 - val_accuracy: 0.8754\n",
      "Epoch 22/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2953 - accuracy: 0.8636 - val_loss: 0.2892 - val_accuracy: 0.8684\n",
      "Epoch 23/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3027 - accuracy: 0.8601 - val_loss: 0.2839 - val_accuracy: 0.8698\n",
      "Epoch 24/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3039 - accuracy: 0.8613 - val_loss: 0.3223 - val_accuracy: 0.8432\n",
      "Epoch 25/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2889 - accuracy: 0.8680 - val_loss: 0.3111 - val_accuracy: 0.8639\n",
      "Epoch 26/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3022 - accuracy: 0.8636 - val_loss: 0.4521 - val_accuracy: 0.8242\n",
      "Epoch 27/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.2991 - accuracy: 0.8638 - val_loss: 0.2844 - val_accuracy: 0.8684\n",
      "Epoch 28/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2908 - accuracy: 0.8672 - val_loss: 0.2787 - val_accuracy: 0.8712\n",
      "Epoch 29/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2809 - accuracy: 0.8723 - val_loss: 0.3002 - val_accuracy: 0.8779\n",
      "Epoch 30/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2855 - accuracy: 0.8679 - val_loss: 0.3350 - val_accuracy: 0.8375\n",
      "Epoch 31/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2834 - accuracy: 0.8708 - val_loss: 0.3301 - val_accuracy: 0.8519\n",
      "Epoch 32/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3126 - accuracy: 0.8528 - val_loss: 0.3565 - val_accuracy: 0.8158\n",
      "Epoch 33/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2950 - accuracy: 0.8669 - val_loss: 0.2802 - val_accuracy: 0.8691\n",
      "Epoch 34/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2955 - accuracy: 0.8666 - val_loss: 0.2776 - val_accuracy: 0.8719\n",
      "Epoch 35/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2879 - accuracy: 0.8691 - val_loss: 0.4103 - val_accuracy: 0.8186\n",
      "Epoch 36/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2854 - accuracy: 0.8686 - val_loss: 0.2706 - val_accuracy: 0.8751\n",
      "Epoch 37/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2811 - accuracy: 0.8696 - val_loss: 0.2665 - val_accuracy: 0.8754\n",
      "Epoch 38/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2781 - accuracy: 0.8737 - val_loss: 0.2861 - val_accuracy: 0.8796\n",
      "Epoch 39/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2798 - accuracy: 0.8742 - val_loss: 0.3107 - val_accuracy: 0.8596\n",
      "Epoch 40/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2755 - accuracy: 0.8764 - val_loss: 0.2665 - val_accuracy: 0.8804\n",
      "Epoch 41/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2671 - accuracy: 0.8780 - val_loss: 0.3204 - val_accuracy: 0.8695\n",
      "Epoch 42/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2618 - accuracy: 0.8839 - val_loss: 0.2441 - val_accuracy: 0.8940\n",
      "Epoch 43/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2522 - accuracy: 0.8887 - val_loss: 0.2704 - val_accuracy: 0.8705\n",
      "Epoch 44/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2821 - accuracy: 0.8743 - val_loss: 0.2684 - val_accuracy: 0.8758\n",
      "Epoch 45/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2623 - accuracy: 0.8843 - val_loss: 0.2612 - val_accuracy: 0.8867\n",
      "Epoch 46/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.2482 - accuracy: 0.8899 - val_loss: 0.2612 - val_accuracy: 0.8898\n",
      "Epoch 47/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.2525 - accuracy: 0.8886 - val_loss: 0.2947 - val_accuracy: 0.8702\n",
      "Epoch 48/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2845 - accuracy: 0.8708 - val_loss: 0.2337 - val_accuracy: 0.9049\n",
      "Epoch 49/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2399 - accuracy: 0.8955 - val_loss: 0.3139 - val_accuracy: 0.8723\n",
      "Epoch 50/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2533 - accuracy: 0.8880 - val_loss: 0.2263 - val_accuracy: 0.9039\n",
      "Epoch 51/500\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.2361 - accuracy: 0.8973 - val_loss: 0.2469 - val_accuracy: 0.8902\n",
      "Epoch 52/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.2307 - accuracy: 0.8967 - val_loss: 0.2407 - val_accuracy: 0.8958\n",
      "Epoch 53/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2266 - accuracy: 0.9027 - val_loss: 0.2004 - val_accuracy: 0.9130\n",
      "Epoch 54/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2212 - accuracy: 0.9025 - val_loss: 0.2624 - val_accuracy: 0.8832\n",
      "Epoch 55/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2123 - accuracy: 0.9086 - val_loss: 0.2208 - val_accuracy: 0.9060\n",
      "Epoch 56/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1996 - accuracy: 0.9165 - val_loss: 0.2516 - val_accuracy: 0.8881\n",
      "Epoch 57/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2108 - accuracy: 0.9094 - val_loss: 0.1952 - val_accuracy: 0.9172\n",
      "Epoch 58/500\n",
      "334/334 [==============================] - 5s 16ms/step - loss: 0.1874 - accuracy: 0.9202 - val_loss: 0.1785 - val_accuracy: 0.9225\n",
      "Epoch 59/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1931 - accuracy: 0.9174 - val_loss: 0.1979 - val_accuracy: 0.9119\n",
      "Epoch 60/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2051 - accuracy: 0.9111 - val_loss: 0.2066 - val_accuracy: 0.9067\n",
      "Epoch 61/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1857 - accuracy: 0.9195 - val_loss: 0.1936 - val_accuracy: 0.9182\n",
      "Epoch 62/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1804 - accuracy: 0.9232 - val_loss: 0.1889 - val_accuracy: 0.9204\n",
      "Epoch 63/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1921 - accuracy: 0.9187 - val_loss: 0.1730 - val_accuracy: 0.9281\n",
      "Epoch 64/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1771 - accuracy: 0.9244 - val_loss: 0.1842 - val_accuracy: 0.9158\n",
      "Epoch 65/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1735 - accuracy: 0.9268 - val_loss: 0.1898 - val_accuracy: 0.9165\n",
      "Epoch 66/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.1695 - accuracy: 0.9290 - val_loss: 0.2633 - val_accuracy: 0.8846\n",
      "Epoch 67/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.4135 - accuracy: 0.7788 - val_loss: 0.3804 - val_accuracy: 0.8039\n",
      "Epoch 68/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3537 - accuracy: 0.8261 - val_loss: 0.3367 - val_accuracy: 0.8428\n",
      "Epoch 69/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3435 - accuracy: 0.8352 - val_loss: 0.3162 - val_accuracy: 0.8512\n",
      "Epoch 70/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3310 - accuracy: 0.8438 - val_loss: 0.3582 - val_accuracy: 0.8256\n",
      "Epoch 71/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3066 - accuracy: 0.8564 - val_loss: 0.2800 - val_accuracy: 0.8695\n",
      "Epoch 72/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3007 - accuracy: 0.8605 - val_loss: 0.2889 - val_accuracy: 0.8628\n",
      "Epoch 73/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.2974 - accuracy: 0.8639 - val_loss: 0.2945 - val_accuracy: 0.8698\n",
      "Epoch 74/500\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.2893 - accuracy: 0.8675 - val_loss: 0.3333 - val_accuracy: 0.8354\n",
      "Epoch 75/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2857 - accuracy: 0.8669 - val_loss: 0.3603 - val_accuracy: 0.8302\n",
      "Epoch 76/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2895 - accuracy: 0.8671 - val_loss: 0.3087 - val_accuracy: 0.8505\n",
      "Epoch 77/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2843 - accuracy: 0.8693 - val_loss: 0.3134 - val_accuracy: 0.8568\n",
      "Epoch 78/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2856 - accuracy: 0.8695 - val_loss: 0.2815 - val_accuracy: 0.8681\n",
      "Epoch 79/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.3161 - accuracy: 0.8501 - val_loss: 0.2974 - val_accuracy: 0.8526\n",
      "Epoch 80/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2850 - accuracy: 0.8693 - val_loss: 0.2604 - val_accuracy: 0.8754\n",
      "Epoch 81/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2739 - accuracy: 0.8752 - val_loss: 0.2616 - val_accuracy: 0.8765\n",
      "Epoch 82/500\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2631 - accuracy: 0.8800 - val_loss: 0.2504 - val_accuracy: 0.8814\n",
      "Epoch 83/500\n",
      "331/334 [============================>.] - ETA: 0s - loss: 0.2740 - accuracy: 0.8767Restoring model weights from the end of the best epoch: 63.\n",
      "334/334 [==============================] - 5s 15ms/step - loss: 0.2738 - accuracy: 0.8767 - val_loss: 0.2502 - val_accuracy: 0.8786\n",
      "Epoch 83: early stopping\n",
      "Number of iterations 10\n",
      "F1-scores:  [0.939744370054778, 0.9323493234932348, 0.9285277947464875, 0.9536019536019537, 0.8907664453832227, 0.9274145170965806, 0.9425981873111783, 0.9392857142857143, 0.9435336976320582, 0.8661005878510778]\n",
      "Average F1-Score 0.9263922591456286\n",
      "Std Dev F1-Score 0.02566461555851428\n",
      "Error bar F1-Score 0.008115864043749952\n"
     ]
    }
   ],
   "source": [
    "###Collect F-Score 10 times\n",
    "import sklearn\n",
    "from tqdm.notebook import tqdm\n",
    "def calc_f1_score(X_train_scaled,X_test_scaled,X_train_scaled_f,X_test_scaled_f,y_train,y_test,earlystop):\n",
    "  input_1 = Input((X_train_scaled.shape[1], X_train_scaled.shape[2]))\n",
    "  input_2 = Input((X_train_scaled_f.shape[1], X_train_scaled_f.shape[2]))\n",
    "  x1=LSTM(units = 100, return_sequences = True)(input_1)\n",
    "  x1=LSTM(units = 50)(x1)\n",
    "  x2=LSTM(units = 100, return_sequences = True)(input_2)\n",
    "  x2=LSTM(units = 50)(x2)\n",
    "  x = layers.concatenate([x1, x2])\n",
    "  output_layer = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "  classifier=keras.Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "  # Compiling the RNN\n",
    "  classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "  classifier.fit([X_train_scaled,X_train_scaled_f], y_train[:,0], epochs = 500, batch_size = 64,validation_data=([X_test_scaled,X_test_scaled_f],y_test[:,0]),callbacks=[earlystop])\n",
    "  y_pred = classifier.predict([X_test_scaled,X_test_scaled_f])\n",
    "  y_pred= (y_pred>=0.5).astype(int)\n",
    "  return(sklearn.metrics.f1_score(y_test[:,0],y_pred))\n",
    "\n",
    "f1_score_list=[]\n",
    "for i in tqdm(range(10)):\n",
    "  f1_score_list=f1_score_list+[calc_f1_score(X_train_scaled,X_test_scaled,X_train_scaled_f,X_test_scaled_f,y_train,y_test,earlystop)]\n",
    "  print(\"Number of iterations\",len(f1_score_list))\n",
    "  print(\"F1-scores: \",f1_score_list)\n",
    "  print(\"Average F1-Score\",np.mean(f1_score_list))\n",
    "  print(\"Std Dev F1-Score\",np.std(f1_score_list))\n",
    "  print(\"Error bar F1-Score\",np.std(f1_score_list)/np.sqrt(len(f1_score_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average F1-Score 0.9263922591456286\n",
    "# Std Dev F1-Score 0.02566461555851428\n",
    "# Error bar F1-Score 0.008115864043749952"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_1d_freq_exp1_exp5_v2.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06f5bb166b174c39b8f0d31a094b6701": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0affa90d67114fa1b9de8045fe1c79db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_9766b7ad4dd8494fba7b17da4fb54181",
      "placeholder": "",
      "style": "IPY_MODEL_85fd543dad1d4ae5b4012f84964ab2bb",
      "tabbable": null,
      "tooltip": null,
      "value": "100%"
     }
    },
    "136fb09ba460411db8ba3bf7f16ca446": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "4175c2ea694745d1bb0d1683360bb27d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "496857438c3c4b1db63b3a17af848657": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_a114e178da3b4a11a8e0f04b98082d26",
      "placeholder": "",
      "style": "IPY_MODEL_136fb09ba460411db8ba3bf7f16ca446",
      "tabbable": null,
      "tooltip": null,
      "value": " 10/10 [1:50:34&lt;00:00, 623.70s/it]"
     }
    },
    "52067950a0184c3ba827c94415260742": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_ac8c91a0aa9b4914942cc8cd382dd1d8",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4175c2ea694745d1bb0d1683360bb27d",
      "tabbable": null,
      "tooltip": null,
      "value": 10
     }
    },
    "6381052835b541a28bd40b3949815b15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0affa90d67114fa1b9de8045fe1c79db",
       "IPY_MODEL_52067950a0184c3ba827c94415260742",
       "IPY_MODEL_496857438c3c4b1db63b3a17af848657"
      ],
      "layout": "IPY_MODEL_06f5bb166b174c39b8f0d31a094b6701",
      "tabbable": null,
      "tooltip": null
     }
    },
    "85fd543dad1d4ae5b4012f84964ab2bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "9766b7ad4dd8494fba7b17da4fb54181": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a114e178da3b4a11a8e0f04b98082d26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac8c91a0aa9b4914942cc8cd382dd1d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
